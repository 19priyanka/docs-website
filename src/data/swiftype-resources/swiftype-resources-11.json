{
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67833,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataflow-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataproc-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-database-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-hosting-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-storage-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firestore-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-load-balancing-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.6783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-pubsub-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.6783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.3136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-router-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.6783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    },
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "6d984abfd016e252ec8c89791da61b3a347cb187",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d22619c05dae"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.6783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "6d984abfd016e252ec8c89791da61b3a347cb187",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d22619c05dae"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-sql-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.6783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-storage-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.6783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-datastore-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-direct-interconnect-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-kubernetes-engine-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached": [
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    },
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "6d984abfd016e252ec8c89791da61b3a347cb187",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d22619c05dae"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-30T05:52:39Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-30T07:29:53Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.67827,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-30T05:51:41Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.31357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/get-started/connect-google-cloud-platform-services-new-relic": [
    {
      "sections": [
        "Introduction to Google Cloud Platform integrations",
        "Connect GCP and New Relic",
        "View your GCP data"
      ],
      "title": "Introduction to Google Cloud Platform integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "20545af7b385b6343f3a02edb9c2941a1272742c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/introduction-google-cloud-platform-integrations/",
      "published_at": "2021-12-30T05:52:53Z",
      "updated_at": "2021-10-24T02:08:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations monitor the performance of popular products and services. New Relic's Google Cloud Platform (GCP) integrations let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures to connect your GCP service to New Relic. View your GCP data Once you follow the configuration process, data from your Google Cloud Platform account will report directly to New Relic. To view your GCP data: Go to one.newrelic.com > Infrastructure > GCP. For any of the integrations listed: Select an integration name to view data in a pre-configured dashboard. OR Select the Explore data icon to view GCP data. You can view and reuse the Insights NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Inventory, events, and dashboards for all services are available in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.97408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "sections": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> monitor the performance of popular products and services. New Relic&#x27;s <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) <em>integrations</em> let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures"
      },
      "id": "617d6e7e196a6777fef7c1a0"
    },
    {
      "sections": [
        "GCP integration metrics",
        "BETA FEATURE",
        "Google Cloud Metrics"
      ],
      "title": "GCP integration metrics",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "e1274b0eb01b312f7cb781a5b2210570379b1cfa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/gcp-integration-metrics/",
      "published_at": "2021-12-30T05:53:32Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Google Cloud Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine gcp.appengine.flex.cpu.utilization flex.cpu.Utilization GCP App Engine gcp.appengine.flex.disk.read_bytes_count flex.disk.ReadBytes GCP App Engine gcp.appengine.flex.disk.write_bytes_count flex.disk.WriteBytes GCP App Engine gcp.appengine.flex.network.received_bytes_count flex.network.ReceivedBytes GCP App Engine gcp.appengine.flex.network.sent_bytes_count flex.network.SentBytes GCP App Engine gcp.appengine.http.server.dos_intercept_count server.DosIntercepts GCP App Engine gcp.appengine.http.server.quota_denial_count server.QuotaDenials GCP App Engine gcp.appengine.http.server.response_count server.Responses GCP App Engine gcp.appengine.http.server.response_latencies server.ResponseLatenciesMilliseconds GCP App Engine gcp.appengine.http.server.response_style_count http.server.ResponseStyle GCP App Engine gcp.appengine.memcache.centi_mcu_count memcache.CentiMcu GCP App Engine gcp.appengine.memcache.operation_count memcache.Operations GCP App Engine gcp.appengine.memcache.received_bytes_count memcache.ReceivedBytes GCP App Engine gcp.appengine.memcache.sent_bytes_count memcache.SentBytes GCP App Engine gcp.appengine.system.cpu.usage system.cpu.Usage GCP App Engine gcp.appengine.system.instance_count system.Instances GCP App Engine gcp.appengine.system.memory.usage system.memory.UsageBytes GCP App Engine gcp.appengine.system.network.received_bytes_count system.network.ReceivedBytes GCP App Engine gcp.appengine.system.network.sent_bytes_count system.network.SentBytes GCP App Engine gcp.cloudtasks.api.request_count api.Requests GCP App Engine gcp.cloudtasks.queue.task_attempt_count queue.taskAttempts GCP App Engine gcp.cloudtasks.queue.task_attempt_delays queue.taskAttemptDelaysMilliseconds GCP BigQuery gcp.bigquery.storage.stored_bytes storage.StoredBytes GCP BigQuery gcp.bigquery.storage.table_count storage.Tables GCP BigQuery gcp.bigquery.query.count query.Count GCP BigQuery gcp.bigquery.query.execution_times query.ExecutionTimes GCP BigQuery gcp.bigquery.slots.allocated slots.Allocated GCP BigQuery gcp.bigquery.slots.allocated_for_project slots.AllocatedForProject GCP BigQuery gcp.bigquery.slots.allocated_for_project_and_job_type slots.AllocatedForProjectAndJobType GCP BigQuery gcp.bigquery.slots.allocated_for_reservation slots.AllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_allocated_for_reservation slots.TotalAllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_available slots.TotalAvailable GCP BigQuery gcp.bigquery.storage.uploaded_bytes storage.UploadedBytes GCP BigQuery gcp.bigquery.storage.uploaded_bytes_billed storage.UploadedBytesBilled GCP BigQuery gcp.bigquery.storage.uploaded_row_count storage.UploadedRows GCP Dataflow gcp.dataflow.job.billable_shuffle_data_processed job.BillableShuffleDataProcessed GCP Dataflow gcp.dataflow.job.current_num_vcpus job.CurrentNumVcpus GCP Dataflow gcp.dataflow.job.current_shuffle_slots job.CurrentShuffleSlots GCP Dataflow gcp.dataflow.job.data_watermark_age job.DataWatermarkAge GCP Dataflow gcp.dataflow.job.elapsed_time job.ElapsedTime GCP Dataflow gcp.dataflow.job.element_count job.Elements GCP Dataflow gcp.dataflow.job.estimated_byte_count job.EstimatedBytes GCP Dataflow gcp.dataflow.job.is_failed job.IsFailed GCP Dataflow gcp.dataflow.job.per_stage_data_watermark_age job.PerStageDataWatermarkAge GCP Dataflow gcp.dataflow.job.per_stage_system_lag job.PerStageSystemLag GCP Dataflow gcp.dataflow.job.system_lag job.SystemLag GCP Dataflow gcp.dataflow.job.total_memory_usage_time job.TotalMemoryUsageTime GCP Dataflow gcp.dataflow.job.total_pd_usage_time job.TotalPdUsageTime GCP Dataflow gcp.dataflow.job.total_shuffle_data_processed job.TotalShuffleDataProcessed GCP Dataflow gcp.dataflow.job.total_streaming_data_processed job.TotalStreamingDataProcessed GCP Dataflow gcp.dataflow.job.total_vcpu_time job.TotalVcpuTime GCP Dataflow gcp.dataflow.job.user_counter job.UserCounter GCP Dataproc gcp.dataproc.cluster.hdfs.datanodes cluster.hdfs.Datanodes GCP Dataproc gcp.dataproc.cluster.hdfs.storage_capacity cluster.hdfs.StorageCapacity GCP Dataproc gcp.dataproc.cluster.hdfs.storage_utilization cluster.hdfs.StorageUtilization GCP Dataproc gcp.dataproc.cluster.hdfs.unhealthy_blocks cluster.hdfs.UnhealthyBlocks GCP Dataproc gcp.dataproc.cluster.job.completion_time cluster.job.CompletionTime GCP Dataproc gcp.dataproc.cluster.job.duration cluster.job.Duration GCP Dataproc gcp.dataproc.cluster.job.failed_count cluster.job.Failures GCP Dataproc gcp.dataproc.cluster.job.running_count cluster.job.Running GCP Dataproc gcp.dataproc.cluster.job.submitted_count cluster.job.Submitted GCP Dataproc gcp.dataproc.cluster.operation.completion_time cluster.operation.CompletionTime GCP Dataproc gcp.dataproc.cluster.operation.duration cluster.operation.Duration GCP Dataproc gcp.dataproc.cluster.operation.failed_count cluster.operation.Failures GCP Dataproc gcp.dataproc.cluster.operation.running_count cluster.operation.Running GCP Dataproc gcp.dataproc.cluster.operation.submitted_count cluster.operation.Submitted GCP Dataproc gcp.dataproc.cluster.yarn.allocated_memory_percentage cluster.yarn.AllocatedMemoryPercentage GCP Dataproc gcp.dataproc.cluster.yarn.apps cluster.yarn.Apps GCP Dataproc gcp.dataproc.cluster.yarn.containers cluster.yarn.Containers GCP Dataproc gcp.dataproc.cluster.yarn.memory_size cluster.yarn.MemorySize GCP Dataproc gcp.dataproc.cluster.yarn.nodemanagers cluster.yarn.Nodemanagers GCP Dataproc gcp.dataproc.cluster.yarn.pending_memory_size cluster.yarn.PendingMemorySize GCP Dataproc gcp.dataproc.cluster.yarn.virtual_cores cluster.yarn.VirtualCores GCP Datastore gcp.datastore.api.request_count api.Requests GCP Datastore gcp.datastore.entity.read_sizes entity.ReadSizes GCP Datastore gcp.datastore.entity.write_sizes entity.WriteSizes GCP Datastore gcp.datastore.index.write_count index.Writes GCP Firebase Database gcp.firebasedatabase.io.database_load io.DatabaseLoad GCP Firebase Database gcp.firebasedatabase.io.persisted_bytes_count io.PersistedBytes GCP Firebase Database gcp.firebasedatabase.io.sent_responses_count io.SentResponses GCP Firebase Database gcp.firebasedatabase.io.utilization io.Utilization GCP Firebase Database gcp.firebasedatabase.network.active_connections network.ActiveConnections GCP Firebase Database gcp.firebasedatabase.network.api_hits_count network.ApiHits GCP Firebase Database gcp.firebasedatabase.network.broadcast_load network.BroadcastLoad GCP Firebase Database gcp.firebasedatabase.network.https_requests_count network.HttpsRequests GCP Firebase Database gcp.firebasedatabase.network.monthly_sent network.MonthlySent GCP Firebase Database gcp.firebasedatabase.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Database gcp.firebasedatabase.network.sent_bytes_count network.SentBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_and_protocol_bytes_count network.SentPayloadAndProtocolBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_bytes_count network.SentPayloadBytes GCP Firebase Database gcp.firebasedatabase.rules.evaluation_count rules.Evaluation GCP Firebase Database gcp.firebasedatabase.storage.limit storage.Limit GCP Firebase Database gcp.firebasedatabase.storage.total_bytes storage.TotalBytes GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent network.MonthlySent GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Hosting gcp.firebasehosting.network.sent_bytes_count network.SentBytes GCP Firebase Hosting gcp.firebasehosting.storage.limit storage.Limit GCP Firebase Hosting gcp.firebasehosting.storage.total_bytes storage.TotalBytes GCP Firebase Storage gcp.firebasestorage.rules.evaluation_count rules.Evaluation GCP Firestore gcp.firestore.api.request_count api.Request GCP Firestore gcp.firestore.document.delete_count document.Delete GCP Firestore gcp.firestore.document.read_count document.Read GCP Firestore gcp.firestore.document.write_count document.Write GCP Firestore gcp.firestore.network.active_connections network.ActiveConnections GCP Firestore gcp.firestore.network.snapshot_listeners network.SnapshotListeners GCP Firestore gcp.firestore.rules.evaluation_count rules.Evaluation GCP Cloud Functions gcp.cloudfunctions.function.execution_count function.Executions GCP Cloud Functions gcp.cloudfunctions.function.execution_times function.ExecutionTimeNanos GCP Cloud Functions gcp.cloudfunctions.function.user_memory_bytes function.UserMemoryBytes GCP Interconnect gcp.interconnect.network.interconnect.capacity network.interconnect.Capacity GCP Interconnect gcp.interconnect.network.interconnect.dropped_packets_count network.interconnect.DroppedPackets GCP Interconnect gcp.interconnect.network.interconnect.link.rx_power network.interconnect.link.RxPower GCP Interconnect gcp.interconnect.network.interconnect.link.tx_power network.interconnect.link.TxPower GCP Interconnect gcp.interconnect.network.interconnect.receive_errors_count network.interconnect.ReceiveErrors GCP Interconnect gcp.interconnect.network.interconnect.received_bytes_count network.interconnect.ReceivedBytes GCP Interconnect gcp.interconnect.network.interconnect.received_unicast_packets_count network.interconnect.ReceivedUnicastPackets GCP Interconnect gcp.interconnect.network.interconnect.send_errors_count network.interconnect.SendErrors GCP Interconnect gcp.interconnect.network.interconnect.sent_bytes_count network.interconnect.SentBytes GCP Interconnect gcp.interconnect.network.interconnect.sent_unicast_packets_count network.interconnect.SentUnicastPackets GCP Interconnect gcp.interconnect.network.attachment.capacity network.attachment.Capacity GCP Interconnect gcp.interconnect.network.attachment.received_bytes_count network.attachment.ReceivedBytes GCP Interconnect gcp.interconnect.network.attachment.received_packets_count network.attachment.ReceivedPackets GCP Interconnect gcp.interconnect.network.attachment.sent_bytes_count network.attachment.SentBytes GCP Interconnect gcp.interconnect.network.attachment.sent_packets_count network.attachment.SentPackets GCP Kubernetes Engine gcp.kubernetes.container.accelerator.duty_cycle container.accelerator.dutyCycle GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_total container.accelerator.memoryTotal GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_used container.accelerator.memoryUsed GCP Kubernetes Engine gcp.kubernetes.container.accelerator.request container.accelerator.request GCP Kubernetes Engine gcp.kubernetes.container.cpu.core_usage_time container.cpu.usageTime GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_cores container.cpu.limitCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_utilization container.cpu.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_cores container.cpu.requestCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_utilization container.cpu.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_bytes container.memory.limitBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_utilization container.memory.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.request_bytes container.memory.requestBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.request_utilization container.memory.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.used_bytes container.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.container.restart_count container.restartCount GCP Kubernetes Engine gcp.kubernetes.container.uptime container.uptime GCP Kubernetes Engine gcp.kubernetes.node_daemon.cpu.core_usage_time nodeDaemon.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node_daemon.memory.used_bytes nodeDaemon.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_cores node.cpu.allocatableCores GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_utilization node.cpu.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.cpu.core_usage_time node.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node.cpu.total_cores node.cpu.totalCores GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_bytes node.memory.allocatableBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_utilization node.memory.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.memory.total_bytes node.memory.totalBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.used_bytes node.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.network.received_bytes_count node.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.node.network.sent_bytes_count node.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.received_bytes_count pod.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.sent_bytes_count pod.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.volume.total_bytes pod.volume.totalBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.used_bytes pod.volume.usedBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.utilization pod.volume.utilization GCP Load Balancer gcp.loadbalancing.https.backend_latencies https.BackendLatencies GCP Load Balancer gcp.loadbalancing.https.backend_request_bytes_count https.BackendRequestBytes GCP Load Balancer gcp.loadbalancing.https.backend_request_count https.BackendRequests GCP Load Balancer gcp.loadbalancing.https.backend_response_bytes_count https.BackendResponseBytes GCP Load Balancer gcp.loadbalancing.https.frontend_tcp_rtt https.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.https.request_bytes_count https.RequestBytes GCP Load Balancer gcp.loadbalancing.https.request_count https.Requests GCP Load Balancer gcp.loadbalancing.https.response_bytes_count https.ResponseBytes GCP Load Balancer gcp.loadbalancing.https.total_latencies https.TotalLatencies GCP Load Balancer gcp.loadbalancing.l3.internal.egress_bytes_count l3.internal.EgressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.egress_packets_count l3.internal.EgressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_bytes_count l3.internal.IngressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_packets_count l3.internal.IngressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.rtt_latencies l3.internal.RttLatencies GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.closed_connections tcpSslProxy.ClosedConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.egress_bytes_count tcpSslProxy.EgressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.frontend_tcp_rtt tcpSslProxy.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.ingress_bytes_count tcpSslProxy.IngressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.new_connections tcpSslProxy.NewConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.open_connections tcpSslProxy.OpenConnections GCP Pub/Sub gcp.pubsub.subscription.backlog_bytes subscription.BacklogBytes GCP Pub/Sub gcp.pubsub.subscription.byte_cost subscription.ByteCost GCP Pub/Sub gcp.pubsub.subscription.config_updates_count subscription.ConfigUpdates GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_message_operation_count subscription.ModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_request_count subscription.ModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.num_outstanding_messages subscription.NumOutstandingMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages subscription.NumRetainedAckedMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages_by_region subscription.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_unacked_messages_by_region subscription.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_undelivered_messages subscription.NumUndeliveredMessages GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age subscription.OldestRetainedAckedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age_by_region subscription.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age subscription.OldestUnackedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age_by_region subscription.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.pull_ack_message_operation_count subscription.PullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_ack_request_count subscription.PullAckRequest GCP Pub/Sub gcp.pubsub.subscription.pull_message_operation_count subscription.PullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_request_count subscription.PullRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_count subscription.PushRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_latencies subscription.PushRequestLatencies GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes subscription.RetainedAckedBytes GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes_by_region subscription.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_message_operation_count subscription.StreamingPullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_request_count subscription.StreamingPullAckRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_message_operation_count subscription.StreamingPullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_message_operation_count subscription.StreamingPullModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_request_count subscription.StreamingPullModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_response_count subscription.StreamingPullResponse GCP Pub/Sub gcp.pubsub.subscription.unacked_bytes_by_region subscription.UnackedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.byte_cost topic.ByteCost GCP Pub/Sub gcp.pubsub.topic.config_updates_count topic.ConfigUpdates GCP Pub/Sub gcp.pubsub.topic.message_sizes topic.MessageSizes GCP Pub/Sub gcp.pubsub.topic.num_retained_acked_messages_by_region topic.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.num_unacked_messages_by_region topic.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_retained_acked_message_age_by_region topic.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_unacked_message_age_by_region topic.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.retained_acked_bytes_by_region topic.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.send_message_operation_count topic.SendMessageOperation GCP Pub/Sub gcp.pubsub.topic.send_request_count topic.SendRequest GCP Pub/Sub gcp.pubsub.topic.unacked_bytes_by_region topic.UnackedBytesByRegion GCP Router gcp.router.best_received_routes_count BestReceivedRoutes GCP Router gcp.router.bfd.control.receive_intervals bfd.control.ReceiveIntervals GCP Router gcp.router.bfd.control.received_packets_count bfd.control.ReceivedPackets GCP Router gcp.router.bfd.control.rejected_packets_count bfd.control.RejectedPackets GCP Router gcp.router.bfd.control.transmit_intervals bfd.control.TransmitIntervals GCP Router gcp.router.bfd.control.transmitted_packets_count bfd.control.TransmittedPackets GCP Router gcp.router.bfd.session_up bfd.SessionUp GCP Router gcp.router.bgp_sessions_down_count BgpSessionsDown GCP Router gcp.router.bgp_sessions_up_count BgpSessionsUp GCP Router gcp.router.bgp.received_routes_count bgp.ReceivedRoutes GCP Router gcp.router.bgp.sent_routes_count bgp.SentRoutes GCP Router gcp.router.bgp.session_up bgp.SessionUp GCP Router gcp.router.router_up RouterUp GCP Router gcp.router.sent_routes_count SentRoutes GCP Router gcp.router.nat.allocated_ports nat.AllocatedPorts GCP Router gcp.router.nat.closed_connections_count nat.ClosedConnections GCP Router gcp.router.nat.dropped_received_packets_count nat.DroppedReceivedPackets GCP Router gcp.router.nat.new_connections_count nat.NewConnections GCP Router gcp.router.nat.port_usage nat.PortUsage GCP Router gcp.router.nat.received_bytes_count nat.ReceivedBytes GCP Router gcp.router.nat.received_packets_count nat.ReceivedPackets GCP Router gcp.router.nat.sent_bytes_count nat.SentBytes GCP Router gcp.router.nat.sent_packets_count nat.SentPackets GCP Run gcp.run.container.billable_instance_time container.BillableInstanceTime GCP Run gcp.run.container.cpu.allocation_time container.cpu.AllocationTime GCP Run gcp.run.container.memory.allocation_time container.memory.AllocationTime GCP Run gcp.run.request_count Request GCP Run gcp.run.request_latencies RequestLatencies GCP Spanner gcp.spanner.api.received_bytes_count api.ReceivedBytes GCP Spanner gcp.spanner.api.request_count api.Requests GCP Spanner gcp.spanner.api.request_latencies api.RequestLatencies GCP Spanner gcp.spanner.instance.cpu.utilization instance.cpu.Utilization GCP Spanner gcp.spanner.instance.node_count instance.nodes GCP Spanner gcp.spanner.instance.session_count instance.sessions GCP Spanner gcp.spanner.instance.storage.used_bytes instance.storage.UsedBytes GCP Cloud SQL gcp.cloudsql.database.auto_failover_request_count database.AutoFailoverRequest GCP Cloud SQL gcp.cloudsql.database.available_for_failover database.AvailableForFailover GCP Cloud SQL gcp.cloudsql.database.cpu.reserved_cores database.cpu.ReservedCores GCP Cloud SQL gcp.cloudsql.database.cpu.usage_time database.cpu.UsageTime GCP Cloud SQL gcp.cloudsql.database.cpu.utilization database.cpu.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.bytes_used database.disk.BytesUsed GCP Cloud SQL gcp.cloudsql.database.disk.quota database.disk.Quota GCP Cloud SQL gcp.cloudsql.database.disk.read_ops_count database.disk.ReadOps GCP Cloud SQL gcp.cloudsql.database.disk.utilization database.disk.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.write_ops_count database.disk.WriteOps GCP Cloud SQL gcp.cloudsql.database.memory.quota database.memory.Quota GCP Cloud SQL gcp.cloudsql.database.memory.usage database.memory.Usage GCP Cloud SQL gcp.cloudsql.database.memory.utilization database.memory.Utilization GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_dirty database.mysql.InnodbBufferPoolPagesDirty GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_free database.mysql.InnodbBufferPoolPagesFree GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_total database.mysql.InnodbBufferPoolPagesTotal GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_data_fsyncs database.mysql.InnodbDataFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_os_log_fsyncs database.mysql.InnodbOsLogFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_read database.mysql.InnodbPagesRead GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_written database.mysql.InnodbPagesWritten GCP Cloud SQL gcp.cloudsql.database.mysql.queries database.mysql.Queries GCP Cloud SQL gcp.cloudsql.database.mysql.questions database.mysql.Questions GCP Cloud SQL gcp.cloudsql.database.mysql.received_bytes_count database.mysql.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.mysql.replication.seconds_behind_master database.mysql.replication.SecondsBehindMaster GCP Cloud SQL gcp.cloudsql.database.mysql.sent_bytes_count database.mysql.SentBytes GCP Cloud SQL gcp.cloudsql.database.network.connections database.network.Connections GCP Cloud SQL gcp.cloudsql.database.network.received_bytes_count database.network.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.network.sent_bytes_count database.network.SentBytes GCP Cloud SQL gcp.cloudsql.database.postgresql.num_backends database.postgresql.NumBackends GCP Cloud SQL gcp.cloudsql.database.postgresql.replication.replica_byte_lag database.postgresql.replication.ReplicaByteLag GCP Cloud SQL gcp.cloudsql.database.postgresql.transaction_count database.postgresql.Transaction GCP Cloud SQL gcp.cloudsql.database.up database.Up GCP Cloud SQL gcp.cloudsql.database.uptime database.Uptime GCP Cloud Storage gcp.storage.api.request_count api.Requests GCP Cloud Storage gcp.storage.network.received_bytes_count network.ReceivedBytes GCP Cloud Storage gcp.storage.network.sent_bytes_count network.SentBytes GCP VMs gcp.compute.firewall.dropped_bytes_count firewall.DroppedBytes GCP VMs gcp.compute.firewall.dropped_packets_count firewall.DroppedPackets GCP VMs gcp.compute.instance.cpu.reserved_cores instance.cpu.ReservedCores GCP VMs gcp.compute.instance.cpu.utilization instance.cpu.Utilization GCP VMs gcp.compute.instance.disk.read_bytes_count instance.disk.ReadBytes GCP VMs gcp.compute.instance.disk.read_ops_count instance.disk.ReadOps GCP VMs gcp.compute.instance.disk.write_bytes_count instance.disk.WriteBytes GCP VMs gcp.compute.instance.disk.write_ops_count instance.disk.WriteOps GCP VMs gcp.compute.instance.network.received_bytes_count instance.network.ReceivedBytes GCP VMs gcp.compute.instance.network.received_packets_count instance.network.ReceivedPackets GCP VMs gcp.compute.instance.network.sent_bytes_count instance.network.SentBytes GCP VMs gcp.compute.instance.network.sent_packets_count instance.network.SentPackets GCP VMs gcp.compute.instance.disk.throttled_read_bytes_count instance.disk.ThrottledReadBytes GCP VMs gcp.compute.instance.disk.throttled_read_ops_count instance.disk.ThrottledReadOps GCP VMs gcp.compute.instance.disk.throttled_write_bytes_count instance.disk.ThrottledWriteBytes GCP VMs gcp.compute.instance.disk.throttled_write_ops_count instance.disk.ThrottledWriteOps GCP VPC Access gcp.vpcaccess.connector.received_bytes_count connector.ReceivedBytes GCP VPC Access gcp.vpcaccess.connector.received_packets_count connector.ReceivedPackets GCP VPC Access gcp.vpcaccess.connector.sent_bytes_count connector.SentBytes GCP VPC Access gcp.vpcaccess.connector.sent_packets_count connector.SentPackets",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GCP <em>integration</em> metrics",
        "sections": "<em>Google</em> <em>Cloud</em> Metrics",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. <em>Google</em> <em>Cloud</em> Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine"
      },
      "id": "617d6e7e28ccbceb0c800c36"
    },
    {
      "sections": [
        "Integrations and custom roles",
        "Recommended role",
        "Optional role",
        "Important",
        "List of permissions",
        "Common permissions",
        "Service-specific permissions",
        "Permissions to link projects through the UI"
      ],
      "title": "Integrations and custom roles",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "7b590d0cf2c9600043ce210864affa858f99ad85",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/integrations-custom-roles/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To read the relevant data from your Google Cloud Platform (GCP) account, New Relic uses the Google Stackdriver API and also other specific services APIs. To access these APIs in your Google Cloud project, the New Relic authorized account needs to be granted a certain set of permissions; GCP uses roles to grant these permissions. Recommended role By default we highly recommend using the GCP primitive role Role Viewer, which grants \"permissions for read-only actions that do not affect your cloud infrastructure state, such as viewing (but not modifying) existing resources or data.\" This role is automatically managed by Google and updated when new Google Cloud services are released or modified. Optional role Alternatively, you can create your own custom role based on the list of permissions, which specifies the minimum set of permissions required to fetch data from each GCP integration. This will allow you to have more control over the permissions set for the New Relic authorized account. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom role, it is your responsibility to maintain it and ensure proper data is being collected. To customize your role you need to: Create a Google Cloud IAM Custom Role in each one of the GCP projects you want to monitor with New Relic. In each custom role, add the permissions that are specifically required for the cloud services you want to monitor according to the following list. Assign the custom role(s) to the New Relic authorized account. List of permissions Common permissions All integrations need the following permission: monitoring.timeSeries.list serviceusage.services.use Service-specific permissions For some GCP integrations, New Relic will also need the following permissions, mainly to collect labels and inventory attributes. Integration Permissions Google AppEngine n/a; Google App Engine does not require additional permissions. Google BigQuery bigquery.datasets.get bigquery.tables.get bigquery.tables.list Google Cloud Functions cloudfunctions.locations.list Google Cloud Load Balancing n/a; Google Cloud Load Balancing does not require additional permissions. Google Cloud Pub/Sub pubsub.subscriptions.get pubsub.subscriptions.list pubsub.topics.get pubsub.topics.list Google Cloud Spanner spanner.instances.list spanner.databases.list spanner.databases.getDdl Google Cloud SQL cloudsql.instances.list Google Cloud Storage storage.buckets.list Google Compute Engine compute.instances.list compute.disks.get compute.disks.list Google Kubernetes Engine container.clusters.list Permissions to link projects through the UI To be able to see the list of projects that you can link to New Relic through the UI, your New Relic authorized service account needs the following permissions: resourcemanager.projects.get monitoring.monitoredResourceDescriptors.list If you do not want to grant New Relic authorized account the permissions that are needed for the linking process through the UI, you have the following options: Assign the Role Viewer or Monitoring Viewer role initially to the authorized account to link Google Cloud projects to New Relic through the UI. After the projects are linked, assign a Google Cloud custom role to the authorized account. Use New Relic NerdGraph to link Google Cloud projects to New Relic. This does not involve listing the viewable projects. However, you must know the id of the project you want to monitor. For more information, see the NerdGraph GraphiQL cloud integrations API tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and custom roles",
        "sections": "<em>Integrations</em> and custom roles",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "To read the relevant data from your <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) account, New Relic uses the <em>Google</em> Stackdriver API and also other specific services APIs. To access these APIs in your <em>Google</em> <em>Cloud</em> project, the New Relic authorized account needs to be granted a certain set of permissions; GCP uses"
      },
      "id": "617dbb19196a67adbbf7d3fa"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/get-started/gcp-integration-metrics": [
    {
      "sections": [
        "Introduction to Google Cloud Platform integrations",
        "Connect GCP and New Relic",
        "View your GCP data"
      ],
      "title": "Introduction to Google Cloud Platform integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "20545af7b385b6343f3a02edb9c2941a1272742c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/introduction-google-cloud-platform-integrations/",
      "published_at": "2021-12-30T05:52:53Z",
      "updated_at": "2021-10-24T02:08:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations monitor the performance of popular products and services. New Relic's Google Cloud Platform (GCP) integrations let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures to connect your GCP service to New Relic. View your GCP data Once you follow the configuration process, data from your Google Cloud Platform account will report directly to New Relic. To view your GCP data: Go to one.newrelic.com > Infrastructure > GCP. For any of the integrations listed: Select an integration name to view data in a pre-configured dashboard. OR Select the Explore data icon to view GCP data. You can view and reuse the Insights NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Inventory, events, and dashboards for all services are available in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.97408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "sections": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> monitor the performance of popular products and services. New Relic&#x27;s <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) <em>integrations</em> let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures"
      },
      "id": "617d6e7e196a6777fef7c1a0"
    },
    {
      "sections": [
        "Integrations and custom roles",
        "Recommended role",
        "Optional role",
        "Important",
        "List of permissions",
        "Common permissions",
        "Service-specific permissions",
        "Permissions to link projects through the UI"
      ],
      "title": "Integrations and custom roles",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "7b590d0cf2c9600043ce210864affa858f99ad85",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/integrations-custom-roles/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To read the relevant data from your Google Cloud Platform (GCP) account, New Relic uses the Google Stackdriver API and also other specific services APIs. To access these APIs in your Google Cloud project, the New Relic authorized account needs to be granted a certain set of permissions; GCP uses roles to grant these permissions. Recommended role By default we highly recommend using the GCP primitive role Role Viewer, which grants \"permissions for read-only actions that do not affect your cloud infrastructure state, such as viewing (but not modifying) existing resources or data.\" This role is automatically managed by Google and updated when new Google Cloud services are released or modified. Optional role Alternatively, you can create your own custom role based on the list of permissions, which specifies the minimum set of permissions required to fetch data from each GCP integration. This will allow you to have more control over the permissions set for the New Relic authorized account. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom role, it is your responsibility to maintain it and ensure proper data is being collected. To customize your role you need to: Create a Google Cloud IAM Custom Role in each one of the GCP projects you want to monitor with New Relic. In each custom role, add the permissions that are specifically required for the cloud services you want to monitor according to the following list. Assign the custom role(s) to the New Relic authorized account. List of permissions Common permissions All integrations need the following permission: monitoring.timeSeries.list serviceusage.services.use Service-specific permissions For some GCP integrations, New Relic will also need the following permissions, mainly to collect labels and inventory attributes. Integration Permissions Google AppEngine n/a; Google App Engine does not require additional permissions. Google BigQuery bigquery.datasets.get bigquery.tables.get bigquery.tables.list Google Cloud Functions cloudfunctions.locations.list Google Cloud Load Balancing n/a; Google Cloud Load Balancing does not require additional permissions. Google Cloud Pub/Sub pubsub.subscriptions.get pubsub.subscriptions.list pubsub.topics.get pubsub.topics.list Google Cloud Spanner spanner.instances.list spanner.databases.list spanner.databases.getDdl Google Cloud SQL cloudsql.instances.list Google Cloud Storage storage.buckets.list Google Compute Engine compute.instances.list compute.disks.get compute.disks.list Google Kubernetes Engine container.clusters.list Permissions to link projects through the UI To be able to see the list of projects that you can link to New Relic through the UI, your New Relic authorized service account needs the following permissions: resourcemanager.projects.get monitoring.monitoredResourceDescriptors.list If you do not want to grant New Relic authorized account the permissions that are needed for the linking process through the UI, you have the following options: Assign the Role Viewer or Monitoring Viewer role initially to the authorized account to link Google Cloud projects to New Relic through the UI. After the projects are linked, assign a Google Cloud custom role to the authorized account. Use New Relic NerdGraph to link Google Cloud projects to New Relic. This does not involve listing the viewable projects. However, you must know the id of the project you want to monitor. For more information, see the NerdGraph GraphiQL cloud integrations API tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and custom roles",
        "sections": "<em>Integrations</em> and custom roles",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "To read the relevant data from your <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) account, New Relic uses the <em>Google</em> Stackdriver API and also other specific services APIs. To access these APIs in your <em>Google</em> <em>Cloud</em> project, the New Relic authorized account needs to be granted a certain set of permissions; GCP uses"
      },
      "id": "617dbb19196a67adbbf7d3fa"
    },
    {
      "sections": [
        "Polling intervals for GCP integrations",
        "New Relic polling intervals"
      ],
      "title": "Polling intervals for GCP integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "736e1c38fee306bf73f0535d27f7f7a80fdc685f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's GCP integrations query your GCP services according to a polling interval, which varies depending on the integration. Each polling interval by New Relic occurs for every GCP entity. New Relic polling intervals GCP integration New Relic polling interval Resolution App Engine 5 minutes 1 data point per minute BigQuery 5 minutes Resolution for this integration varies. See BigQuery metric data for more information. Cloud Functions 5 minutes 1 data point per minute Cloud Load Balancing 5 minutes 1 data point per minute Cloud Pub/Sub 5 minutes 1 data point per minute Cloud Spanner 5 minutes 1 data point per minute Cloud SQL 5 minutes 1 data point per minute Cloud Storage 5 minutes 1 data point per minute Compute Engine 5 minutes 1 data point per minute Kubernetes Engine 5 minutes 1 data point per minute",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Polling intervals for GCP <em>integrations</em>",
        "sections": "Polling intervals for GCP <em>integrations</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s GCP <em>integrations</em> query your GCP services according to a polling interval, which varies depending on the integration. Each polling interval by New Relic occurs for every GCP entity. New Relic polling intervals GCP integration New Relic polling interval Resolution App Engine 5 minutes 1"
      },
      "id": "617dab68196a6759c1f7df13"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/get-started/integrations-custom-roles": [
    {
      "sections": [
        "Introduction to Google Cloud Platform integrations",
        "Connect GCP and New Relic",
        "View your GCP data"
      ],
      "title": "Introduction to Google Cloud Platform integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "20545af7b385b6343f3a02edb9c2941a1272742c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/introduction-google-cloud-platform-integrations/",
      "published_at": "2021-12-30T05:52:53Z",
      "updated_at": "2021-10-24T02:08:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations monitor the performance of popular products and services. New Relic's Google Cloud Platform (GCP) integrations let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures to connect your GCP service to New Relic. View your GCP data Once you follow the configuration process, data from your Google Cloud Platform account will report directly to New Relic. To view your GCP data: Go to one.newrelic.com > Infrastructure > GCP. For any of the integrations listed: Select an integration name to view data in a pre-configured dashboard. OR Select the Explore data icon to view GCP data. You can view and reuse the Insights NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Inventory, events, and dashboards for all services are available in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.97406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "sections": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> monitor the performance of popular products and services. New Relic&#x27;s <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) <em>integrations</em> let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures"
      },
      "id": "617d6e7e196a6777fef7c1a0"
    },
    {
      "sections": [
        "GCP integration metrics",
        "BETA FEATURE",
        "Google Cloud Metrics"
      ],
      "title": "GCP integration metrics",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "e1274b0eb01b312f7cb781a5b2210570379b1cfa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/gcp-integration-metrics/",
      "published_at": "2021-12-30T05:53:32Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Google Cloud Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine gcp.appengine.flex.cpu.utilization flex.cpu.Utilization GCP App Engine gcp.appengine.flex.disk.read_bytes_count flex.disk.ReadBytes GCP App Engine gcp.appengine.flex.disk.write_bytes_count flex.disk.WriteBytes GCP App Engine gcp.appengine.flex.network.received_bytes_count flex.network.ReceivedBytes GCP App Engine gcp.appengine.flex.network.sent_bytes_count flex.network.SentBytes GCP App Engine gcp.appengine.http.server.dos_intercept_count server.DosIntercepts GCP App Engine gcp.appengine.http.server.quota_denial_count server.QuotaDenials GCP App Engine gcp.appengine.http.server.response_count server.Responses GCP App Engine gcp.appengine.http.server.response_latencies server.ResponseLatenciesMilliseconds GCP App Engine gcp.appengine.http.server.response_style_count http.server.ResponseStyle GCP App Engine gcp.appengine.memcache.centi_mcu_count memcache.CentiMcu GCP App Engine gcp.appengine.memcache.operation_count memcache.Operations GCP App Engine gcp.appengine.memcache.received_bytes_count memcache.ReceivedBytes GCP App Engine gcp.appengine.memcache.sent_bytes_count memcache.SentBytes GCP App Engine gcp.appengine.system.cpu.usage system.cpu.Usage GCP App Engine gcp.appengine.system.instance_count system.Instances GCP App Engine gcp.appengine.system.memory.usage system.memory.UsageBytes GCP App Engine gcp.appengine.system.network.received_bytes_count system.network.ReceivedBytes GCP App Engine gcp.appengine.system.network.sent_bytes_count system.network.SentBytes GCP App Engine gcp.cloudtasks.api.request_count api.Requests GCP App Engine gcp.cloudtasks.queue.task_attempt_count queue.taskAttempts GCP App Engine gcp.cloudtasks.queue.task_attempt_delays queue.taskAttemptDelaysMilliseconds GCP BigQuery gcp.bigquery.storage.stored_bytes storage.StoredBytes GCP BigQuery gcp.bigquery.storage.table_count storage.Tables GCP BigQuery gcp.bigquery.query.count query.Count GCP BigQuery gcp.bigquery.query.execution_times query.ExecutionTimes GCP BigQuery gcp.bigquery.slots.allocated slots.Allocated GCP BigQuery gcp.bigquery.slots.allocated_for_project slots.AllocatedForProject GCP BigQuery gcp.bigquery.slots.allocated_for_project_and_job_type slots.AllocatedForProjectAndJobType GCP BigQuery gcp.bigquery.slots.allocated_for_reservation slots.AllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_allocated_for_reservation slots.TotalAllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_available slots.TotalAvailable GCP BigQuery gcp.bigquery.storage.uploaded_bytes storage.UploadedBytes GCP BigQuery gcp.bigquery.storage.uploaded_bytes_billed storage.UploadedBytesBilled GCP BigQuery gcp.bigquery.storage.uploaded_row_count storage.UploadedRows GCP Dataflow gcp.dataflow.job.billable_shuffle_data_processed job.BillableShuffleDataProcessed GCP Dataflow gcp.dataflow.job.current_num_vcpus job.CurrentNumVcpus GCP Dataflow gcp.dataflow.job.current_shuffle_slots job.CurrentShuffleSlots GCP Dataflow gcp.dataflow.job.data_watermark_age job.DataWatermarkAge GCP Dataflow gcp.dataflow.job.elapsed_time job.ElapsedTime GCP Dataflow gcp.dataflow.job.element_count job.Elements GCP Dataflow gcp.dataflow.job.estimated_byte_count job.EstimatedBytes GCP Dataflow gcp.dataflow.job.is_failed job.IsFailed GCP Dataflow gcp.dataflow.job.per_stage_data_watermark_age job.PerStageDataWatermarkAge GCP Dataflow gcp.dataflow.job.per_stage_system_lag job.PerStageSystemLag GCP Dataflow gcp.dataflow.job.system_lag job.SystemLag GCP Dataflow gcp.dataflow.job.total_memory_usage_time job.TotalMemoryUsageTime GCP Dataflow gcp.dataflow.job.total_pd_usage_time job.TotalPdUsageTime GCP Dataflow gcp.dataflow.job.total_shuffle_data_processed job.TotalShuffleDataProcessed GCP Dataflow gcp.dataflow.job.total_streaming_data_processed job.TotalStreamingDataProcessed GCP Dataflow gcp.dataflow.job.total_vcpu_time job.TotalVcpuTime GCP Dataflow gcp.dataflow.job.user_counter job.UserCounter GCP Dataproc gcp.dataproc.cluster.hdfs.datanodes cluster.hdfs.Datanodes GCP Dataproc gcp.dataproc.cluster.hdfs.storage_capacity cluster.hdfs.StorageCapacity GCP Dataproc gcp.dataproc.cluster.hdfs.storage_utilization cluster.hdfs.StorageUtilization GCP Dataproc gcp.dataproc.cluster.hdfs.unhealthy_blocks cluster.hdfs.UnhealthyBlocks GCP Dataproc gcp.dataproc.cluster.job.completion_time cluster.job.CompletionTime GCP Dataproc gcp.dataproc.cluster.job.duration cluster.job.Duration GCP Dataproc gcp.dataproc.cluster.job.failed_count cluster.job.Failures GCP Dataproc gcp.dataproc.cluster.job.running_count cluster.job.Running GCP Dataproc gcp.dataproc.cluster.job.submitted_count cluster.job.Submitted GCP Dataproc gcp.dataproc.cluster.operation.completion_time cluster.operation.CompletionTime GCP Dataproc gcp.dataproc.cluster.operation.duration cluster.operation.Duration GCP Dataproc gcp.dataproc.cluster.operation.failed_count cluster.operation.Failures GCP Dataproc gcp.dataproc.cluster.operation.running_count cluster.operation.Running GCP Dataproc gcp.dataproc.cluster.operation.submitted_count cluster.operation.Submitted GCP Dataproc gcp.dataproc.cluster.yarn.allocated_memory_percentage cluster.yarn.AllocatedMemoryPercentage GCP Dataproc gcp.dataproc.cluster.yarn.apps cluster.yarn.Apps GCP Dataproc gcp.dataproc.cluster.yarn.containers cluster.yarn.Containers GCP Dataproc gcp.dataproc.cluster.yarn.memory_size cluster.yarn.MemorySize GCP Dataproc gcp.dataproc.cluster.yarn.nodemanagers cluster.yarn.Nodemanagers GCP Dataproc gcp.dataproc.cluster.yarn.pending_memory_size cluster.yarn.PendingMemorySize GCP Dataproc gcp.dataproc.cluster.yarn.virtual_cores cluster.yarn.VirtualCores GCP Datastore gcp.datastore.api.request_count api.Requests GCP Datastore gcp.datastore.entity.read_sizes entity.ReadSizes GCP Datastore gcp.datastore.entity.write_sizes entity.WriteSizes GCP Datastore gcp.datastore.index.write_count index.Writes GCP Firebase Database gcp.firebasedatabase.io.database_load io.DatabaseLoad GCP Firebase Database gcp.firebasedatabase.io.persisted_bytes_count io.PersistedBytes GCP Firebase Database gcp.firebasedatabase.io.sent_responses_count io.SentResponses GCP Firebase Database gcp.firebasedatabase.io.utilization io.Utilization GCP Firebase Database gcp.firebasedatabase.network.active_connections network.ActiveConnections GCP Firebase Database gcp.firebasedatabase.network.api_hits_count network.ApiHits GCP Firebase Database gcp.firebasedatabase.network.broadcast_load network.BroadcastLoad GCP Firebase Database gcp.firebasedatabase.network.https_requests_count network.HttpsRequests GCP Firebase Database gcp.firebasedatabase.network.monthly_sent network.MonthlySent GCP Firebase Database gcp.firebasedatabase.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Database gcp.firebasedatabase.network.sent_bytes_count network.SentBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_and_protocol_bytes_count network.SentPayloadAndProtocolBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_bytes_count network.SentPayloadBytes GCP Firebase Database gcp.firebasedatabase.rules.evaluation_count rules.Evaluation GCP Firebase Database gcp.firebasedatabase.storage.limit storage.Limit GCP Firebase Database gcp.firebasedatabase.storage.total_bytes storage.TotalBytes GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent network.MonthlySent GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Hosting gcp.firebasehosting.network.sent_bytes_count network.SentBytes GCP Firebase Hosting gcp.firebasehosting.storage.limit storage.Limit GCP Firebase Hosting gcp.firebasehosting.storage.total_bytes storage.TotalBytes GCP Firebase Storage gcp.firebasestorage.rules.evaluation_count rules.Evaluation GCP Firestore gcp.firestore.api.request_count api.Request GCP Firestore gcp.firestore.document.delete_count document.Delete GCP Firestore gcp.firestore.document.read_count document.Read GCP Firestore gcp.firestore.document.write_count document.Write GCP Firestore gcp.firestore.network.active_connections network.ActiveConnections GCP Firestore gcp.firestore.network.snapshot_listeners network.SnapshotListeners GCP Firestore gcp.firestore.rules.evaluation_count rules.Evaluation GCP Cloud Functions gcp.cloudfunctions.function.execution_count function.Executions GCP Cloud Functions gcp.cloudfunctions.function.execution_times function.ExecutionTimeNanos GCP Cloud Functions gcp.cloudfunctions.function.user_memory_bytes function.UserMemoryBytes GCP Interconnect gcp.interconnect.network.interconnect.capacity network.interconnect.Capacity GCP Interconnect gcp.interconnect.network.interconnect.dropped_packets_count network.interconnect.DroppedPackets GCP Interconnect gcp.interconnect.network.interconnect.link.rx_power network.interconnect.link.RxPower GCP Interconnect gcp.interconnect.network.interconnect.link.tx_power network.interconnect.link.TxPower GCP Interconnect gcp.interconnect.network.interconnect.receive_errors_count network.interconnect.ReceiveErrors GCP Interconnect gcp.interconnect.network.interconnect.received_bytes_count network.interconnect.ReceivedBytes GCP Interconnect gcp.interconnect.network.interconnect.received_unicast_packets_count network.interconnect.ReceivedUnicastPackets GCP Interconnect gcp.interconnect.network.interconnect.send_errors_count network.interconnect.SendErrors GCP Interconnect gcp.interconnect.network.interconnect.sent_bytes_count network.interconnect.SentBytes GCP Interconnect gcp.interconnect.network.interconnect.sent_unicast_packets_count network.interconnect.SentUnicastPackets GCP Interconnect gcp.interconnect.network.attachment.capacity network.attachment.Capacity GCP Interconnect gcp.interconnect.network.attachment.received_bytes_count network.attachment.ReceivedBytes GCP Interconnect gcp.interconnect.network.attachment.received_packets_count network.attachment.ReceivedPackets GCP Interconnect gcp.interconnect.network.attachment.sent_bytes_count network.attachment.SentBytes GCP Interconnect gcp.interconnect.network.attachment.sent_packets_count network.attachment.SentPackets GCP Kubernetes Engine gcp.kubernetes.container.accelerator.duty_cycle container.accelerator.dutyCycle GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_total container.accelerator.memoryTotal GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_used container.accelerator.memoryUsed GCP Kubernetes Engine gcp.kubernetes.container.accelerator.request container.accelerator.request GCP Kubernetes Engine gcp.kubernetes.container.cpu.core_usage_time container.cpu.usageTime GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_cores container.cpu.limitCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_utilization container.cpu.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_cores container.cpu.requestCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_utilization container.cpu.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_bytes container.memory.limitBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_utilization container.memory.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.request_bytes container.memory.requestBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.request_utilization container.memory.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.used_bytes container.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.container.restart_count container.restartCount GCP Kubernetes Engine gcp.kubernetes.container.uptime container.uptime GCP Kubernetes Engine gcp.kubernetes.node_daemon.cpu.core_usage_time nodeDaemon.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node_daemon.memory.used_bytes nodeDaemon.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_cores node.cpu.allocatableCores GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_utilization node.cpu.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.cpu.core_usage_time node.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node.cpu.total_cores node.cpu.totalCores GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_bytes node.memory.allocatableBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_utilization node.memory.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.memory.total_bytes node.memory.totalBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.used_bytes node.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.network.received_bytes_count node.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.node.network.sent_bytes_count node.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.received_bytes_count pod.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.sent_bytes_count pod.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.volume.total_bytes pod.volume.totalBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.used_bytes pod.volume.usedBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.utilization pod.volume.utilization GCP Load Balancer gcp.loadbalancing.https.backend_latencies https.BackendLatencies GCP Load Balancer gcp.loadbalancing.https.backend_request_bytes_count https.BackendRequestBytes GCP Load Balancer gcp.loadbalancing.https.backend_request_count https.BackendRequests GCP Load Balancer gcp.loadbalancing.https.backend_response_bytes_count https.BackendResponseBytes GCP Load Balancer gcp.loadbalancing.https.frontend_tcp_rtt https.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.https.request_bytes_count https.RequestBytes GCP Load Balancer gcp.loadbalancing.https.request_count https.Requests GCP Load Balancer gcp.loadbalancing.https.response_bytes_count https.ResponseBytes GCP Load Balancer gcp.loadbalancing.https.total_latencies https.TotalLatencies GCP Load Balancer gcp.loadbalancing.l3.internal.egress_bytes_count l3.internal.EgressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.egress_packets_count l3.internal.EgressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_bytes_count l3.internal.IngressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_packets_count l3.internal.IngressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.rtt_latencies l3.internal.RttLatencies GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.closed_connections tcpSslProxy.ClosedConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.egress_bytes_count tcpSslProxy.EgressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.frontend_tcp_rtt tcpSslProxy.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.ingress_bytes_count tcpSslProxy.IngressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.new_connections tcpSslProxy.NewConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.open_connections tcpSslProxy.OpenConnections GCP Pub/Sub gcp.pubsub.subscription.backlog_bytes subscription.BacklogBytes GCP Pub/Sub gcp.pubsub.subscription.byte_cost subscription.ByteCost GCP Pub/Sub gcp.pubsub.subscription.config_updates_count subscription.ConfigUpdates GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_message_operation_count subscription.ModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_request_count subscription.ModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.num_outstanding_messages subscription.NumOutstandingMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages subscription.NumRetainedAckedMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages_by_region subscription.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_unacked_messages_by_region subscription.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_undelivered_messages subscription.NumUndeliveredMessages GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age subscription.OldestRetainedAckedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age_by_region subscription.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age subscription.OldestUnackedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age_by_region subscription.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.pull_ack_message_operation_count subscription.PullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_ack_request_count subscription.PullAckRequest GCP Pub/Sub gcp.pubsub.subscription.pull_message_operation_count subscription.PullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_request_count subscription.PullRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_count subscription.PushRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_latencies subscription.PushRequestLatencies GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes subscription.RetainedAckedBytes GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes_by_region subscription.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_message_operation_count subscription.StreamingPullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_request_count subscription.StreamingPullAckRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_message_operation_count subscription.StreamingPullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_message_operation_count subscription.StreamingPullModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_request_count subscription.StreamingPullModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_response_count subscription.StreamingPullResponse GCP Pub/Sub gcp.pubsub.subscription.unacked_bytes_by_region subscription.UnackedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.byte_cost topic.ByteCost GCP Pub/Sub gcp.pubsub.topic.config_updates_count topic.ConfigUpdates GCP Pub/Sub gcp.pubsub.topic.message_sizes topic.MessageSizes GCP Pub/Sub gcp.pubsub.topic.num_retained_acked_messages_by_region topic.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.num_unacked_messages_by_region topic.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_retained_acked_message_age_by_region topic.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_unacked_message_age_by_region topic.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.retained_acked_bytes_by_region topic.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.send_message_operation_count topic.SendMessageOperation GCP Pub/Sub gcp.pubsub.topic.send_request_count topic.SendRequest GCP Pub/Sub gcp.pubsub.topic.unacked_bytes_by_region topic.UnackedBytesByRegion GCP Router gcp.router.best_received_routes_count BestReceivedRoutes GCP Router gcp.router.bfd.control.receive_intervals bfd.control.ReceiveIntervals GCP Router gcp.router.bfd.control.received_packets_count bfd.control.ReceivedPackets GCP Router gcp.router.bfd.control.rejected_packets_count bfd.control.RejectedPackets GCP Router gcp.router.bfd.control.transmit_intervals bfd.control.TransmitIntervals GCP Router gcp.router.bfd.control.transmitted_packets_count bfd.control.TransmittedPackets GCP Router gcp.router.bfd.session_up bfd.SessionUp GCP Router gcp.router.bgp_sessions_down_count BgpSessionsDown GCP Router gcp.router.bgp_sessions_up_count BgpSessionsUp GCP Router gcp.router.bgp.received_routes_count bgp.ReceivedRoutes GCP Router gcp.router.bgp.sent_routes_count bgp.SentRoutes GCP Router gcp.router.bgp.session_up bgp.SessionUp GCP Router gcp.router.router_up RouterUp GCP Router gcp.router.sent_routes_count SentRoutes GCP Router gcp.router.nat.allocated_ports nat.AllocatedPorts GCP Router gcp.router.nat.closed_connections_count nat.ClosedConnections GCP Router gcp.router.nat.dropped_received_packets_count nat.DroppedReceivedPackets GCP Router gcp.router.nat.new_connections_count nat.NewConnections GCP Router gcp.router.nat.port_usage nat.PortUsage GCP Router gcp.router.nat.received_bytes_count nat.ReceivedBytes GCP Router gcp.router.nat.received_packets_count nat.ReceivedPackets GCP Router gcp.router.nat.sent_bytes_count nat.SentBytes GCP Router gcp.router.nat.sent_packets_count nat.SentPackets GCP Run gcp.run.container.billable_instance_time container.BillableInstanceTime GCP Run gcp.run.container.cpu.allocation_time container.cpu.AllocationTime GCP Run gcp.run.container.memory.allocation_time container.memory.AllocationTime GCP Run gcp.run.request_count Request GCP Run gcp.run.request_latencies RequestLatencies GCP Spanner gcp.spanner.api.received_bytes_count api.ReceivedBytes GCP Spanner gcp.spanner.api.request_count api.Requests GCP Spanner gcp.spanner.api.request_latencies api.RequestLatencies GCP Spanner gcp.spanner.instance.cpu.utilization instance.cpu.Utilization GCP Spanner gcp.spanner.instance.node_count instance.nodes GCP Spanner gcp.spanner.instance.session_count instance.sessions GCP Spanner gcp.spanner.instance.storage.used_bytes instance.storage.UsedBytes GCP Cloud SQL gcp.cloudsql.database.auto_failover_request_count database.AutoFailoverRequest GCP Cloud SQL gcp.cloudsql.database.available_for_failover database.AvailableForFailover GCP Cloud SQL gcp.cloudsql.database.cpu.reserved_cores database.cpu.ReservedCores GCP Cloud SQL gcp.cloudsql.database.cpu.usage_time database.cpu.UsageTime GCP Cloud SQL gcp.cloudsql.database.cpu.utilization database.cpu.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.bytes_used database.disk.BytesUsed GCP Cloud SQL gcp.cloudsql.database.disk.quota database.disk.Quota GCP Cloud SQL gcp.cloudsql.database.disk.read_ops_count database.disk.ReadOps GCP Cloud SQL gcp.cloudsql.database.disk.utilization database.disk.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.write_ops_count database.disk.WriteOps GCP Cloud SQL gcp.cloudsql.database.memory.quota database.memory.Quota GCP Cloud SQL gcp.cloudsql.database.memory.usage database.memory.Usage GCP Cloud SQL gcp.cloudsql.database.memory.utilization database.memory.Utilization GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_dirty database.mysql.InnodbBufferPoolPagesDirty GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_free database.mysql.InnodbBufferPoolPagesFree GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_total database.mysql.InnodbBufferPoolPagesTotal GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_data_fsyncs database.mysql.InnodbDataFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_os_log_fsyncs database.mysql.InnodbOsLogFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_read database.mysql.InnodbPagesRead GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_written database.mysql.InnodbPagesWritten GCP Cloud SQL gcp.cloudsql.database.mysql.queries database.mysql.Queries GCP Cloud SQL gcp.cloudsql.database.mysql.questions database.mysql.Questions GCP Cloud SQL gcp.cloudsql.database.mysql.received_bytes_count database.mysql.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.mysql.replication.seconds_behind_master database.mysql.replication.SecondsBehindMaster GCP Cloud SQL gcp.cloudsql.database.mysql.sent_bytes_count database.mysql.SentBytes GCP Cloud SQL gcp.cloudsql.database.network.connections database.network.Connections GCP Cloud SQL gcp.cloudsql.database.network.received_bytes_count database.network.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.network.sent_bytes_count database.network.SentBytes GCP Cloud SQL gcp.cloudsql.database.postgresql.num_backends database.postgresql.NumBackends GCP Cloud SQL gcp.cloudsql.database.postgresql.replication.replica_byte_lag database.postgresql.replication.ReplicaByteLag GCP Cloud SQL gcp.cloudsql.database.postgresql.transaction_count database.postgresql.Transaction GCP Cloud SQL gcp.cloudsql.database.up database.Up GCP Cloud SQL gcp.cloudsql.database.uptime database.Uptime GCP Cloud Storage gcp.storage.api.request_count api.Requests GCP Cloud Storage gcp.storage.network.received_bytes_count network.ReceivedBytes GCP Cloud Storage gcp.storage.network.sent_bytes_count network.SentBytes GCP VMs gcp.compute.firewall.dropped_bytes_count firewall.DroppedBytes GCP VMs gcp.compute.firewall.dropped_packets_count firewall.DroppedPackets GCP VMs gcp.compute.instance.cpu.reserved_cores instance.cpu.ReservedCores GCP VMs gcp.compute.instance.cpu.utilization instance.cpu.Utilization GCP VMs gcp.compute.instance.disk.read_bytes_count instance.disk.ReadBytes GCP VMs gcp.compute.instance.disk.read_ops_count instance.disk.ReadOps GCP VMs gcp.compute.instance.disk.write_bytes_count instance.disk.WriteBytes GCP VMs gcp.compute.instance.disk.write_ops_count instance.disk.WriteOps GCP VMs gcp.compute.instance.network.received_bytes_count instance.network.ReceivedBytes GCP VMs gcp.compute.instance.network.received_packets_count instance.network.ReceivedPackets GCP VMs gcp.compute.instance.network.sent_bytes_count instance.network.SentBytes GCP VMs gcp.compute.instance.network.sent_packets_count instance.network.SentPackets GCP VMs gcp.compute.instance.disk.throttled_read_bytes_count instance.disk.ThrottledReadBytes GCP VMs gcp.compute.instance.disk.throttled_read_ops_count instance.disk.ThrottledReadOps GCP VMs gcp.compute.instance.disk.throttled_write_bytes_count instance.disk.ThrottledWriteBytes GCP VMs gcp.compute.instance.disk.throttled_write_ops_count instance.disk.ThrottledWriteOps GCP VPC Access gcp.vpcaccess.connector.received_bytes_count connector.ReceivedBytes GCP VPC Access gcp.vpcaccess.connector.received_packets_count connector.ReceivedPackets GCP VPC Access gcp.vpcaccess.connector.sent_bytes_count connector.SentBytes GCP VPC Access gcp.vpcaccess.connector.sent_packets_count connector.SentPackets",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GCP <em>integration</em> metrics",
        "sections": "<em>Google</em> <em>Cloud</em> Metrics",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. <em>Google</em> <em>Cloud</em> Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine"
      },
      "id": "617d6e7e28ccbceb0c800c36"
    },
    {
      "sections": [
        "Polling intervals for GCP integrations",
        "New Relic polling intervals"
      ],
      "title": "Polling intervals for GCP integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "736e1c38fee306bf73f0535d27f7f7a80fdc685f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's GCP integrations query your GCP services according to a polling interval, which varies depending on the integration. Each polling interval by New Relic occurs for every GCP entity. New Relic polling intervals GCP integration New Relic polling interval Resolution App Engine 5 minutes 1 data point per minute BigQuery 5 minutes Resolution for this integration varies. See BigQuery metric data for more information. Cloud Functions 5 minutes 1 data point per minute Cloud Load Balancing 5 minutes 1 data point per minute Cloud Pub/Sub 5 minutes 1 data point per minute Cloud Spanner 5 minutes 1 data point per minute Cloud SQL 5 minutes 1 data point per minute Cloud Storage 5 minutes 1 data point per minute Compute Engine 5 minutes 1 data point per minute Kubernetes Engine 5 minutes 1 data point per minute",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Polling intervals for GCP <em>integrations</em>",
        "sections": "Polling intervals for GCP <em>integrations</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s GCP <em>integrations</em> query your GCP services according to a polling interval, which varies depending on the integration. Each polling interval by New Relic occurs for every GCP entity. New Relic polling intervals GCP integration New Relic polling interval Resolution App Engine 5 minutes 1"
      },
      "id": "617dab68196a6759c1f7df13"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/get-started/introduction-google-cloud-platform-integrations": [
    {
      "sections": [
        "GCP integration metrics",
        "BETA FEATURE",
        "Google Cloud Metrics"
      ],
      "title": "GCP integration metrics",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "e1274b0eb01b312f7cb781a5b2210570379b1cfa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/gcp-integration-metrics/",
      "published_at": "2021-12-30T05:53:32Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Google Cloud Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine gcp.appengine.flex.cpu.utilization flex.cpu.Utilization GCP App Engine gcp.appengine.flex.disk.read_bytes_count flex.disk.ReadBytes GCP App Engine gcp.appengine.flex.disk.write_bytes_count flex.disk.WriteBytes GCP App Engine gcp.appengine.flex.network.received_bytes_count flex.network.ReceivedBytes GCP App Engine gcp.appengine.flex.network.sent_bytes_count flex.network.SentBytes GCP App Engine gcp.appengine.http.server.dos_intercept_count server.DosIntercepts GCP App Engine gcp.appengine.http.server.quota_denial_count server.QuotaDenials GCP App Engine gcp.appengine.http.server.response_count server.Responses GCP App Engine gcp.appengine.http.server.response_latencies server.ResponseLatenciesMilliseconds GCP App Engine gcp.appengine.http.server.response_style_count http.server.ResponseStyle GCP App Engine gcp.appengine.memcache.centi_mcu_count memcache.CentiMcu GCP App Engine gcp.appengine.memcache.operation_count memcache.Operations GCP App Engine gcp.appengine.memcache.received_bytes_count memcache.ReceivedBytes GCP App Engine gcp.appengine.memcache.sent_bytes_count memcache.SentBytes GCP App Engine gcp.appengine.system.cpu.usage system.cpu.Usage GCP App Engine gcp.appengine.system.instance_count system.Instances GCP App Engine gcp.appengine.system.memory.usage system.memory.UsageBytes GCP App Engine gcp.appengine.system.network.received_bytes_count system.network.ReceivedBytes GCP App Engine gcp.appengine.system.network.sent_bytes_count system.network.SentBytes GCP App Engine gcp.cloudtasks.api.request_count api.Requests GCP App Engine gcp.cloudtasks.queue.task_attempt_count queue.taskAttempts GCP App Engine gcp.cloudtasks.queue.task_attempt_delays queue.taskAttemptDelaysMilliseconds GCP BigQuery gcp.bigquery.storage.stored_bytes storage.StoredBytes GCP BigQuery gcp.bigquery.storage.table_count storage.Tables GCP BigQuery gcp.bigquery.query.count query.Count GCP BigQuery gcp.bigquery.query.execution_times query.ExecutionTimes GCP BigQuery gcp.bigquery.slots.allocated slots.Allocated GCP BigQuery gcp.bigquery.slots.allocated_for_project slots.AllocatedForProject GCP BigQuery gcp.bigquery.slots.allocated_for_project_and_job_type slots.AllocatedForProjectAndJobType GCP BigQuery gcp.bigquery.slots.allocated_for_reservation slots.AllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_allocated_for_reservation slots.TotalAllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_available slots.TotalAvailable GCP BigQuery gcp.bigquery.storage.uploaded_bytes storage.UploadedBytes GCP BigQuery gcp.bigquery.storage.uploaded_bytes_billed storage.UploadedBytesBilled GCP BigQuery gcp.bigquery.storage.uploaded_row_count storage.UploadedRows GCP Dataflow gcp.dataflow.job.billable_shuffle_data_processed job.BillableShuffleDataProcessed GCP Dataflow gcp.dataflow.job.current_num_vcpus job.CurrentNumVcpus GCP Dataflow gcp.dataflow.job.current_shuffle_slots job.CurrentShuffleSlots GCP Dataflow gcp.dataflow.job.data_watermark_age job.DataWatermarkAge GCP Dataflow gcp.dataflow.job.elapsed_time job.ElapsedTime GCP Dataflow gcp.dataflow.job.element_count job.Elements GCP Dataflow gcp.dataflow.job.estimated_byte_count job.EstimatedBytes GCP Dataflow gcp.dataflow.job.is_failed job.IsFailed GCP Dataflow gcp.dataflow.job.per_stage_data_watermark_age job.PerStageDataWatermarkAge GCP Dataflow gcp.dataflow.job.per_stage_system_lag job.PerStageSystemLag GCP Dataflow gcp.dataflow.job.system_lag job.SystemLag GCP Dataflow gcp.dataflow.job.total_memory_usage_time job.TotalMemoryUsageTime GCP Dataflow gcp.dataflow.job.total_pd_usage_time job.TotalPdUsageTime GCP Dataflow gcp.dataflow.job.total_shuffle_data_processed job.TotalShuffleDataProcessed GCP Dataflow gcp.dataflow.job.total_streaming_data_processed job.TotalStreamingDataProcessed GCP Dataflow gcp.dataflow.job.total_vcpu_time job.TotalVcpuTime GCP Dataflow gcp.dataflow.job.user_counter job.UserCounter GCP Dataproc gcp.dataproc.cluster.hdfs.datanodes cluster.hdfs.Datanodes GCP Dataproc gcp.dataproc.cluster.hdfs.storage_capacity cluster.hdfs.StorageCapacity GCP Dataproc gcp.dataproc.cluster.hdfs.storage_utilization cluster.hdfs.StorageUtilization GCP Dataproc gcp.dataproc.cluster.hdfs.unhealthy_blocks cluster.hdfs.UnhealthyBlocks GCP Dataproc gcp.dataproc.cluster.job.completion_time cluster.job.CompletionTime GCP Dataproc gcp.dataproc.cluster.job.duration cluster.job.Duration GCP Dataproc gcp.dataproc.cluster.job.failed_count cluster.job.Failures GCP Dataproc gcp.dataproc.cluster.job.running_count cluster.job.Running GCP Dataproc gcp.dataproc.cluster.job.submitted_count cluster.job.Submitted GCP Dataproc gcp.dataproc.cluster.operation.completion_time cluster.operation.CompletionTime GCP Dataproc gcp.dataproc.cluster.operation.duration cluster.operation.Duration GCP Dataproc gcp.dataproc.cluster.operation.failed_count cluster.operation.Failures GCP Dataproc gcp.dataproc.cluster.operation.running_count cluster.operation.Running GCP Dataproc gcp.dataproc.cluster.operation.submitted_count cluster.operation.Submitted GCP Dataproc gcp.dataproc.cluster.yarn.allocated_memory_percentage cluster.yarn.AllocatedMemoryPercentage GCP Dataproc gcp.dataproc.cluster.yarn.apps cluster.yarn.Apps GCP Dataproc gcp.dataproc.cluster.yarn.containers cluster.yarn.Containers GCP Dataproc gcp.dataproc.cluster.yarn.memory_size cluster.yarn.MemorySize GCP Dataproc gcp.dataproc.cluster.yarn.nodemanagers cluster.yarn.Nodemanagers GCP Dataproc gcp.dataproc.cluster.yarn.pending_memory_size cluster.yarn.PendingMemorySize GCP Dataproc gcp.dataproc.cluster.yarn.virtual_cores cluster.yarn.VirtualCores GCP Datastore gcp.datastore.api.request_count api.Requests GCP Datastore gcp.datastore.entity.read_sizes entity.ReadSizes GCP Datastore gcp.datastore.entity.write_sizes entity.WriteSizes GCP Datastore gcp.datastore.index.write_count index.Writes GCP Firebase Database gcp.firebasedatabase.io.database_load io.DatabaseLoad GCP Firebase Database gcp.firebasedatabase.io.persisted_bytes_count io.PersistedBytes GCP Firebase Database gcp.firebasedatabase.io.sent_responses_count io.SentResponses GCP Firebase Database gcp.firebasedatabase.io.utilization io.Utilization GCP Firebase Database gcp.firebasedatabase.network.active_connections network.ActiveConnections GCP Firebase Database gcp.firebasedatabase.network.api_hits_count network.ApiHits GCP Firebase Database gcp.firebasedatabase.network.broadcast_load network.BroadcastLoad GCP Firebase Database gcp.firebasedatabase.network.https_requests_count network.HttpsRequests GCP Firebase Database gcp.firebasedatabase.network.monthly_sent network.MonthlySent GCP Firebase Database gcp.firebasedatabase.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Database gcp.firebasedatabase.network.sent_bytes_count network.SentBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_and_protocol_bytes_count network.SentPayloadAndProtocolBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_bytes_count network.SentPayloadBytes GCP Firebase Database gcp.firebasedatabase.rules.evaluation_count rules.Evaluation GCP Firebase Database gcp.firebasedatabase.storage.limit storage.Limit GCP Firebase Database gcp.firebasedatabase.storage.total_bytes storage.TotalBytes GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent network.MonthlySent GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Hosting gcp.firebasehosting.network.sent_bytes_count network.SentBytes GCP Firebase Hosting gcp.firebasehosting.storage.limit storage.Limit GCP Firebase Hosting gcp.firebasehosting.storage.total_bytes storage.TotalBytes GCP Firebase Storage gcp.firebasestorage.rules.evaluation_count rules.Evaluation GCP Firestore gcp.firestore.api.request_count api.Request GCP Firestore gcp.firestore.document.delete_count document.Delete GCP Firestore gcp.firestore.document.read_count document.Read GCP Firestore gcp.firestore.document.write_count document.Write GCP Firestore gcp.firestore.network.active_connections network.ActiveConnections GCP Firestore gcp.firestore.network.snapshot_listeners network.SnapshotListeners GCP Firestore gcp.firestore.rules.evaluation_count rules.Evaluation GCP Cloud Functions gcp.cloudfunctions.function.execution_count function.Executions GCP Cloud Functions gcp.cloudfunctions.function.execution_times function.ExecutionTimeNanos GCP Cloud Functions gcp.cloudfunctions.function.user_memory_bytes function.UserMemoryBytes GCP Interconnect gcp.interconnect.network.interconnect.capacity network.interconnect.Capacity GCP Interconnect gcp.interconnect.network.interconnect.dropped_packets_count network.interconnect.DroppedPackets GCP Interconnect gcp.interconnect.network.interconnect.link.rx_power network.interconnect.link.RxPower GCP Interconnect gcp.interconnect.network.interconnect.link.tx_power network.interconnect.link.TxPower GCP Interconnect gcp.interconnect.network.interconnect.receive_errors_count network.interconnect.ReceiveErrors GCP Interconnect gcp.interconnect.network.interconnect.received_bytes_count network.interconnect.ReceivedBytes GCP Interconnect gcp.interconnect.network.interconnect.received_unicast_packets_count network.interconnect.ReceivedUnicastPackets GCP Interconnect gcp.interconnect.network.interconnect.send_errors_count network.interconnect.SendErrors GCP Interconnect gcp.interconnect.network.interconnect.sent_bytes_count network.interconnect.SentBytes GCP Interconnect gcp.interconnect.network.interconnect.sent_unicast_packets_count network.interconnect.SentUnicastPackets GCP Interconnect gcp.interconnect.network.attachment.capacity network.attachment.Capacity GCP Interconnect gcp.interconnect.network.attachment.received_bytes_count network.attachment.ReceivedBytes GCP Interconnect gcp.interconnect.network.attachment.received_packets_count network.attachment.ReceivedPackets GCP Interconnect gcp.interconnect.network.attachment.sent_bytes_count network.attachment.SentBytes GCP Interconnect gcp.interconnect.network.attachment.sent_packets_count network.attachment.SentPackets GCP Kubernetes Engine gcp.kubernetes.container.accelerator.duty_cycle container.accelerator.dutyCycle GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_total container.accelerator.memoryTotal GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_used container.accelerator.memoryUsed GCP Kubernetes Engine gcp.kubernetes.container.accelerator.request container.accelerator.request GCP Kubernetes Engine gcp.kubernetes.container.cpu.core_usage_time container.cpu.usageTime GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_cores container.cpu.limitCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_utilization container.cpu.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_cores container.cpu.requestCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_utilization container.cpu.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_bytes container.memory.limitBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_utilization container.memory.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.request_bytes container.memory.requestBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.request_utilization container.memory.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.used_bytes container.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.container.restart_count container.restartCount GCP Kubernetes Engine gcp.kubernetes.container.uptime container.uptime GCP Kubernetes Engine gcp.kubernetes.node_daemon.cpu.core_usage_time nodeDaemon.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node_daemon.memory.used_bytes nodeDaemon.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_cores node.cpu.allocatableCores GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_utilization node.cpu.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.cpu.core_usage_time node.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node.cpu.total_cores node.cpu.totalCores GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_bytes node.memory.allocatableBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_utilization node.memory.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.memory.total_bytes node.memory.totalBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.used_bytes node.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.network.received_bytes_count node.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.node.network.sent_bytes_count node.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.received_bytes_count pod.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.sent_bytes_count pod.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.volume.total_bytes pod.volume.totalBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.used_bytes pod.volume.usedBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.utilization pod.volume.utilization GCP Load Balancer gcp.loadbalancing.https.backend_latencies https.BackendLatencies GCP Load Balancer gcp.loadbalancing.https.backend_request_bytes_count https.BackendRequestBytes GCP Load Balancer gcp.loadbalancing.https.backend_request_count https.BackendRequests GCP Load Balancer gcp.loadbalancing.https.backend_response_bytes_count https.BackendResponseBytes GCP Load Balancer gcp.loadbalancing.https.frontend_tcp_rtt https.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.https.request_bytes_count https.RequestBytes GCP Load Balancer gcp.loadbalancing.https.request_count https.Requests GCP Load Balancer gcp.loadbalancing.https.response_bytes_count https.ResponseBytes GCP Load Balancer gcp.loadbalancing.https.total_latencies https.TotalLatencies GCP Load Balancer gcp.loadbalancing.l3.internal.egress_bytes_count l3.internal.EgressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.egress_packets_count l3.internal.EgressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_bytes_count l3.internal.IngressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_packets_count l3.internal.IngressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.rtt_latencies l3.internal.RttLatencies GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.closed_connections tcpSslProxy.ClosedConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.egress_bytes_count tcpSslProxy.EgressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.frontend_tcp_rtt tcpSslProxy.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.ingress_bytes_count tcpSslProxy.IngressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.new_connections tcpSslProxy.NewConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.open_connections tcpSslProxy.OpenConnections GCP Pub/Sub gcp.pubsub.subscription.backlog_bytes subscription.BacklogBytes GCP Pub/Sub gcp.pubsub.subscription.byte_cost subscription.ByteCost GCP Pub/Sub gcp.pubsub.subscription.config_updates_count subscription.ConfigUpdates GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_message_operation_count subscription.ModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_request_count subscription.ModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.num_outstanding_messages subscription.NumOutstandingMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages subscription.NumRetainedAckedMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages_by_region subscription.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_unacked_messages_by_region subscription.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_undelivered_messages subscription.NumUndeliveredMessages GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age subscription.OldestRetainedAckedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age_by_region subscription.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age subscription.OldestUnackedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age_by_region subscription.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.pull_ack_message_operation_count subscription.PullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_ack_request_count subscription.PullAckRequest GCP Pub/Sub gcp.pubsub.subscription.pull_message_operation_count subscription.PullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_request_count subscription.PullRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_count subscription.PushRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_latencies subscription.PushRequestLatencies GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes subscription.RetainedAckedBytes GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes_by_region subscription.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_message_operation_count subscription.StreamingPullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_request_count subscription.StreamingPullAckRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_message_operation_count subscription.StreamingPullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_message_operation_count subscription.StreamingPullModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_request_count subscription.StreamingPullModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_response_count subscription.StreamingPullResponse GCP Pub/Sub gcp.pubsub.subscription.unacked_bytes_by_region subscription.UnackedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.byte_cost topic.ByteCost GCP Pub/Sub gcp.pubsub.topic.config_updates_count topic.ConfigUpdates GCP Pub/Sub gcp.pubsub.topic.message_sizes topic.MessageSizes GCP Pub/Sub gcp.pubsub.topic.num_retained_acked_messages_by_region topic.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.num_unacked_messages_by_region topic.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_retained_acked_message_age_by_region topic.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_unacked_message_age_by_region topic.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.retained_acked_bytes_by_region topic.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.send_message_operation_count topic.SendMessageOperation GCP Pub/Sub gcp.pubsub.topic.send_request_count topic.SendRequest GCP Pub/Sub gcp.pubsub.topic.unacked_bytes_by_region topic.UnackedBytesByRegion GCP Router gcp.router.best_received_routes_count BestReceivedRoutes GCP Router gcp.router.bfd.control.receive_intervals bfd.control.ReceiveIntervals GCP Router gcp.router.bfd.control.received_packets_count bfd.control.ReceivedPackets GCP Router gcp.router.bfd.control.rejected_packets_count bfd.control.RejectedPackets GCP Router gcp.router.bfd.control.transmit_intervals bfd.control.TransmitIntervals GCP Router gcp.router.bfd.control.transmitted_packets_count bfd.control.TransmittedPackets GCP Router gcp.router.bfd.session_up bfd.SessionUp GCP Router gcp.router.bgp_sessions_down_count BgpSessionsDown GCP Router gcp.router.bgp_sessions_up_count BgpSessionsUp GCP Router gcp.router.bgp.received_routes_count bgp.ReceivedRoutes GCP Router gcp.router.bgp.sent_routes_count bgp.SentRoutes GCP Router gcp.router.bgp.session_up bgp.SessionUp GCP Router gcp.router.router_up RouterUp GCP Router gcp.router.sent_routes_count SentRoutes GCP Router gcp.router.nat.allocated_ports nat.AllocatedPorts GCP Router gcp.router.nat.closed_connections_count nat.ClosedConnections GCP Router gcp.router.nat.dropped_received_packets_count nat.DroppedReceivedPackets GCP Router gcp.router.nat.new_connections_count nat.NewConnections GCP Router gcp.router.nat.port_usage nat.PortUsage GCP Router gcp.router.nat.received_bytes_count nat.ReceivedBytes GCP Router gcp.router.nat.received_packets_count nat.ReceivedPackets GCP Router gcp.router.nat.sent_bytes_count nat.SentBytes GCP Router gcp.router.nat.sent_packets_count nat.SentPackets GCP Run gcp.run.container.billable_instance_time container.BillableInstanceTime GCP Run gcp.run.container.cpu.allocation_time container.cpu.AllocationTime GCP Run gcp.run.container.memory.allocation_time container.memory.AllocationTime GCP Run gcp.run.request_count Request GCP Run gcp.run.request_latencies RequestLatencies GCP Spanner gcp.spanner.api.received_bytes_count api.ReceivedBytes GCP Spanner gcp.spanner.api.request_count api.Requests GCP Spanner gcp.spanner.api.request_latencies api.RequestLatencies GCP Spanner gcp.spanner.instance.cpu.utilization instance.cpu.Utilization GCP Spanner gcp.spanner.instance.node_count instance.nodes GCP Spanner gcp.spanner.instance.session_count instance.sessions GCP Spanner gcp.spanner.instance.storage.used_bytes instance.storage.UsedBytes GCP Cloud SQL gcp.cloudsql.database.auto_failover_request_count database.AutoFailoverRequest GCP Cloud SQL gcp.cloudsql.database.available_for_failover database.AvailableForFailover GCP Cloud SQL gcp.cloudsql.database.cpu.reserved_cores database.cpu.ReservedCores GCP Cloud SQL gcp.cloudsql.database.cpu.usage_time database.cpu.UsageTime GCP Cloud SQL gcp.cloudsql.database.cpu.utilization database.cpu.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.bytes_used database.disk.BytesUsed GCP Cloud SQL gcp.cloudsql.database.disk.quota database.disk.Quota GCP Cloud SQL gcp.cloudsql.database.disk.read_ops_count database.disk.ReadOps GCP Cloud SQL gcp.cloudsql.database.disk.utilization database.disk.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.write_ops_count database.disk.WriteOps GCP Cloud SQL gcp.cloudsql.database.memory.quota database.memory.Quota GCP Cloud SQL gcp.cloudsql.database.memory.usage database.memory.Usage GCP Cloud SQL gcp.cloudsql.database.memory.utilization database.memory.Utilization GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_dirty database.mysql.InnodbBufferPoolPagesDirty GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_free database.mysql.InnodbBufferPoolPagesFree GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_total database.mysql.InnodbBufferPoolPagesTotal GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_data_fsyncs database.mysql.InnodbDataFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_os_log_fsyncs database.mysql.InnodbOsLogFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_read database.mysql.InnodbPagesRead GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_written database.mysql.InnodbPagesWritten GCP Cloud SQL gcp.cloudsql.database.mysql.queries database.mysql.Queries GCP Cloud SQL gcp.cloudsql.database.mysql.questions database.mysql.Questions GCP Cloud SQL gcp.cloudsql.database.mysql.received_bytes_count database.mysql.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.mysql.replication.seconds_behind_master database.mysql.replication.SecondsBehindMaster GCP Cloud SQL gcp.cloudsql.database.mysql.sent_bytes_count database.mysql.SentBytes GCP Cloud SQL gcp.cloudsql.database.network.connections database.network.Connections GCP Cloud SQL gcp.cloudsql.database.network.received_bytes_count database.network.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.network.sent_bytes_count database.network.SentBytes GCP Cloud SQL gcp.cloudsql.database.postgresql.num_backends database.postgresql.NumBackends GCP Cloud SQL gcp.cloudsql.database.postgresql.replication.replica_byte_lag database.postgresql.replication.ReplicaByteLag GCP Cloud SQL gcp.cloudsql.database.postgresql.transaction_count database.postgresql.Transaction GCP Cloud SQL gcp.cloudsql.database.up database.Up GCP Cloud SQL gcp.cloudsql.database.uptime database.Uptime GCP Cloud Storage gcp.storage.api.request_count api.Requests GCP Cloud Storage gcp.storage.network.received_bytes_count network.ReceivedBytes GCP Cloud Storage gcp.storage.network.sent_bytes_count network.SentBytes GCP VMs gcp.compute.firewall.dropped_bytes_count firewall.DroppedBytes GCP VMs gcp.compute.firewall.dropped_packets_count firewall.DroppedPackets GCP VMs gcp.compute.instance.cpu.reserved_cores instance.cpu.ReservedCores GCP VMs gcp.compute.instance.cpu.utilization instance.cpu.Utilization GCP VMs gcp.compute.instance.disk.read_bytes_count instance.disk.ReadBytes GCP VMs gcp.compute.instance.disk.read_ops_count instance.disk.ReadOps GCP VMs gcp.compute.instance.disk.write_bytes_count instance.disk.WriteBytes GCP VMs gcp.compute.instance.disk.write_ops_count instance.disk.WriteOps GCP VMs gcp.compute.instance.network.received_bytes_count instance.network.ReceivedBytes GCP VMs gcp.compute.instance.network.received_packets_count instance.network.ReceivedPackets GCP VMs gcp.compute.instance.network.sent_bytes_count instance.network.SentBytes GCP VMs gcp.compute.instance.network.sent_packets_count instance.network.SentPackets GCP VMs gcp.compute.instance.disk.throttled_read_bytes_count instance.disk.ThrottledReadBytes GCP VMs gcp.compute.instance.disk.throttled_read_ops_count instance.disk.ThrottledReadOps GCP VMs gcp.compute.instance.disk.throttled_write_bytes_count instance.disk.ThrottledWriteBytes GCP VMs gcp.compute.instance.disk.throttled_write_ops_count instance.disk.ThrottledWriteOps GCP VPC Access gcp.vpcaccess.connector.received_bytes_count connector.ReceivedBytes GCP VPC Access gcp.vpcaccess.connector.received_packets_count connector.ReceivedPackets GCP VPC Access gcp.vpcaccess.connector.sent_bytes_count connector.SentBytes GCP VPC Access gcp.vpcaccess.connector.sent_packets_count connector.SentPackets",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GCP <em>integration</em> metrics",
        "sections": "<em>Google</em> <em>Cloud</em> Metrics",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. <em>Google</em> <em>Cloud</em> Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine"
      },
      "id": "617d6e7e28ccbceb0c800c36"
    },
    {
      "sections": [
        "Integrations and custom roles",
        "Recommended role",
        "Optional role",
        "Important",
        "List of permissions",
        "Common permissions",
        "Service-specific permissions",
        "Permissions to link projects through the UI"
      ],
      "title": "Integrations and custom roles",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "7b590d0cf2c9600043ce210864affa858f99ad85",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/integrations-custom-roles/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To read the relevant data from your Google Cloud Platform (GCP) account, New Relic uses the Google Stackdriver API and also other specific services APIs. To access these APIs in your Google Cloud project, the New Relic authorized account needs to be granted a certain set of permissions; GCP uses roles to grant these permissions. Recommended role By default we highly recommend using the GCP primitive role Role Viewer, which grants \"permissions for read-only actions that do not affect your cloud infrastructure state, such as viewing (but not modifying) existing resources or data.\" This role is automatically managed by Google and updated when new Google Cloud services are released or modified. Optional role Alternatively, you can create your own custom role based on the list of permissions, which specifies the minimum set of permissions required to fetch data from each GCP integration. This will allow you to have more control over the permissions set for the New Relic authorized account. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom role, it is your responsibility to maintain it and ensure proper data is being collected. To customize your role you need to: Create a Google Cloud IAM Custom Role in each one of the GCP projects you want to monitor with New Relic. In each custom role, add the permissions that are specifically required for the cloud services you want to monitor according to the following list. Assign the custom role(s) to the New Relic authorized account. List of permissions Common permissions All integrations need the following permission: monitoring.timeSeries.list serviceusage.services.use Service-specific permissions For some GCP integrations, New Relic will also need the following permissions, mainly to collect labels and inventory attributes. Integration Permissions Google AppEngine n/a; Google App Engine does not require additional permissions. Google BigQuery bigquery.datasets.get bigquery.tables.get bigquery.tables.list Google Cloud Functions cloudfunctions.locations.list Google Cloud Load Balancing n/a; Google Cloud Load Balancing does not require additional permissions. Google Cloud Pub/Sub pubsub.subscriptions.get pubsub.subscriptions.list pubsub.topics.get pubsub.topics.list Google Cloud Spanner spanner.instances.list spanner.databases.list spanner.databases.getDdl Google Cloud SQL cloudsql.instances.list Google Cloud Storage storage.buckets.list Google Compute Engine compute.instances.list compute.disks.get compute.disks.list Google Kubernetes Engine container.clusters.list Permissions to link projects through the UI To be able to see the list of projects that you can link to New Relic through the UI, your New Relic authorized service account needs the following permissions: resourcemanager.projects.get monitoring.monitoredResourceDescriptors.list If you do not want to grant New Relic authorized account the permissions that are needed for the linking process through the UI, you have the following options: Assign the Role Viewer or Monitoring Viewer role initially to the authorized account to link Google Cloud projects to New Relic through the UI. After the projects are linked, assign a Google Cloud custom role to the authorized account. Use New Relic NerdGraph to link Google Cloud projects to New Relic. This does not involve listing the viewable projects. However, you must know the id of the project you want to monitor. For more information, see the NerdGraph GraphiQL cloud integrations API tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and custom roles",
        "sections": "<em>Integrations</em> and custom roles",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "To read the relevant data from your <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) account, New Relic uses the <em>Google</em> Stackdriver API and also other specific services APIs. To access these APIs in your <em>Google</em> <em>Cloud</em> project, the New Relic authorized account needs to be granted a certain set of permissions; GCP uses"
      },
      "id": "617dbb19196a67adbbf7d3fa"
    },
    {
      "sections": [
        "Polling intervals for GCP integrations",
        "New Relic polling intervals"
      ],
      "title": "Polling intervals for GCP integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "736e1c38fee306bf73f0535d27f7f7a80fdc685f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's GCP integrations query your GCP services according to a polling interval, which varies depending on the integration. Each polling interval by New Relic occurs for every GCP entity. New Relic polling intervals GCP integration New Relic polling interval Resolution App Engine 5 minutes 1 data point per minute BigQuery 5 minutes Resolution for this integration varies. See BigQuery metric data for more information. Cloud Functions 5 minutes 1 data point per minute Cloud Load Balancing 5 minutes 1 data point per minute Cloud Pub/Sub 5 minutes 1 data point per minute Cloud Spanner 5 minutes 1 data point per minute Cloud SQL 5 minutes 1 data point per minute Cloud Storage 5 minutes 1 data point per minute Compute Engine 5 minutes 1 data point per minute Kubernetes Engine 5 minutes 1 data point per minute",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Polling intervals for GCP <em>integrations</em>",
        "sections": "Polling intervals for GCP <em>integrations</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s GCP <em>integrations</em> query your GCP services according to a polling interval, which varies depending on the integration. Each polling interval by New Relic occurs for every GCP entity. New Relic polling intervals GCP integration New Relic polling interval Resolution App Engine 5 minutes 1"
      },
      "id": "617dab68196a6759c1f7df13"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations": [
    {
      "sections": [
        "Introduction to Google Cloud Platform integrations",
        "Connect GCP and New Relic",
        "View your GCP data"
      ],
      "title": "Introduction to Google Cloud Platform integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "20545af7b385b6343f3a02edb9c2941a1272742c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/introduction-google-cloud-platform-integrations/",
      "published_at": "2021-12-30T05:52:53Z",
      "updated_at": "2021-10-24T02:08:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations monitor the performance of popular products and services. New Relic's Google Cloud Platform (GCP) integrations let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures to connect your GCP service to New Relic. View your GCP data Once you follow the configuration process, data from your Google Cloud Platform account will report directly to New Relic. To view your GCP data: Go to one.newrelic.com > Infrastructure > GCP. For any of the integrations listed: Select an integration name to view data in a pre-configured dashboard. OR Select the Explore data icon to view GCP data. You can view and reuse the Insights NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Inventory, events, and dashboards for all services are available in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.97406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "sections": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> monitor the performance of popular products and services. New Relic&#x27;s <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) <em>integrations</em> let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures"
      },
      "id": "617d6e7e196a6777fef7c1a0"
    },
    {
      "sections": [
        "GCP integration metrics",
        "BETA FEATURE",
        "Google Cloud Metrics"
      ],
      "title": "GCP integration metrics",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "e1274b0eb01b312f7cb781a5b2210570379b1cfa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/gcp-integration-metrics/",
      "published_at": "2021-12-30T05:53:32Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Google Cloud Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine gcp.appengine.flex.cpu.utilization flex.cpu.Utilization GCP App Engine gcp.appengine.flex.disk.read_bytes_count flex.disk.ReadBytes GCP App Engine gcp.appengine.flex.disk.write_bytes_count flex.disk.WriteBytes GCP App Engine gcp.appengine.flex.network.received_bytes_count flex.network.ReceivedBytes GCP App Engine gcp.appengine.flex.network.sent_bytes_count flex.network.SentBytes GCP App Engine gcp.appengine.http.server.dos_intercept_count server.DosIntercepts GCP App Engine gcp.appengine.http.server.quota_denial_count server.QuotaDenials GCP App Engine gcp.appengine.http.server.response_count server.Responses GCP App Engine gcp.appengine.http.server.response_latencies server.ResponseLatenciesMilliseconds GCP App Engine gcp.appengine.http.server.response_style_count http.server.ResponseStyle GCP App Engine gcp.appengine.memcache.centi_mcu_count memcache.CentiMcu GCP App Engine gcp.appengine.memcache.operation_count memcache.Operations GCP App Engine gcp.appengine.memcache.received_bytes_count memcache.ReceivedBytes GCP App Engine gcp.appengine.memcache.sent_bytes_count memcache.SentBytes GCP App Engine gcp.appengine.system.cpu.usage system.cpu.Usage GCP App Engine gcp.appengine.system.instance_count system.Instances GCP App Engine gcp.appengine.system.memory.usage system.memory.UsageBytes GCP App Engine gcp.appengine.system.network.received_bytes_count system.network.ReceivedBytes GCP App Engine gcp.appengine.system.network.sent_bytes_count system.network.SentBytes GCP App Engine gcp.cloudtasks.api.request_count api.Requests GCP App Engine gcp.cloudtasks.queue.task_attempt_count queue.taskAttempts GCP App Engine gcp.cloudtasks.queue.task_attempt_delays queue.taskAttemptDelaysMilliseconds GCP BigQuery gcp.bigquery.storage.stored_bytes storage.StoredBytes GCP BigQuery gcp.bigquery.storage.table_count storage.Tables GCP BigQuery gcp.bigquery.query.count query.Count GCP BigQuery gcp.bigquery.query.execution_times query.ExecutionTimes GCP BigQuery gcp.bigquery.slots.allocated slots.Allocated GCP BigQuery gcp.bigquery.slots.allocated_for_project slots.AllocatedForProject GCP BigQuery gcp.bigquery.slots.allocated_for_project_and_job_type slots.AllocatedForProjectAndJobType GCP BigQuery gcp.bigquery.slots.allocated_for_reservation slots.AllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_allocated_for_reservation slots.TotalAllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_available slots.TotalAvailable GCP BigQuery gcp.bigquery.storage.uploaded_bytes storage.UploadedBytes GCP BigQuery gcp.bigquery.storage.uploaded_bytes_billed storage.UploadedBytesBilled GCP BigQuery gcp.bigquery.storage.uploaded_row_count storage.UploadedRows GCP Dataflow gcp.dataflow.job.billable_shuffle_data_processed job.BillableShuffleDataProcessed GCP Dataflow gcp.dataflow.job.current_num_vcpus job.CurrentNumVcpus GCP Dataflow gcp.dataflow.job.current_shuffle_slots job.CurrentShuffleSlots GCP Dataflow gcp.dataflow.job.data_watermark_age job.DataWatermarkAge GCP Dataflow gcp.dataflow.job.elapsed_time job.ElapsedTime GCP Dataflow gcp.dataflow.job.element_count job.Elements GCP Dataflow gcp.dataflow.job.estimated_byte_count job.EstimatedBytes GCP Dataflow gcp.dataflow.job.is_failed job.IsFailed GCP Dataflow gcp.dataflow.job.per_stage_data_watermark_age job.PerStageDataWatermarkAge GCP Dataflow gcp.dataflow.job.per_stage_system_lag job.PerStageSystemLag GCP Dataflow gcp.dataflow.job.system_lag job.SystemLag GCP Dataflow gcp.dataflow.job.total_memory_usage_time job.TotalMemoryUsageTime GCP Dataflow gcp.dataflow.job.total_pd_usage_time job.TotalPdUsageTime GCP Dataflow gcp.dataflow.job.total_shuffle_data_processed job.TotalShuffleDataProcessed GCP Dataflow gcp.dataflow.job.total_streaming_data_processed job.TotalStreamingDataProcessed GCP Dataflow gcp.dataflow.job.total_vcpu_time job.TotalVcpuTime GCP Dataflow gcp.dataflow.job.user_counter job.UserCounter GCP Dataproc gcp.dataproc.cluster.hdfs.datanodes cluster.hdfs.Datanodes GCP Dataproc gcp.dataproc.cluster.hdfs.storage_capacity cluster.hdfs.StorageCapacity GCP Dataproc gcp.dataproc.cluster.hdfs.storage_utilization cluster.hdfs.StorageUtilization GCP Dataproc gcp.dataproc.cluster.hdfs.unhealthy_blocks cluster.hdfs.UnhealthyBlocks GCP Dataproc gcp.dataproc.cluster.job.completion_time cluster.job.CompletionTime GCP Dataproc gcp.dataproc.cluster.job.duration cluster.job.Duration GCP Dataproc gcp.dataproc.cluster.job.failed_count cluster.job.Failures GCP Dataproc gcp.dataproc.cluster.job.running_count cluster.job.Running GCP Dataproc gcp.dataproc.cluster.job.submitted_count cluster.job.Submitted GCP Dataproc gcp.dataproc.cluster.operation.completion_time cluster.operation.CompletionTime GCP Dataproc gcp.dataproc.cluster.operation.duration cluster.operation.Duration GCP Dataproc gcp.dataproc.cluster.operation.failed_count cluster.operation.Failures GCP Dataproc gcp.dataproc.cluster.operation.running_count cluster.operation.Running GCP Dataproc gcp.dataproc.cluster.operation.submitted_count cluster.operation.Submitted GCP Dataproc gcp.dataproc.cluster.yarn.allocated_memory_percentage cluster.yarn.AllocatedMemoryPercentage GCP Dataproc gcp.dataproc.cluster.yarn.apps cluster.yarn.Apps GCP Dataproc gcp.dataproc.cluster.yarn.containers cluster.yarn.Containers GCP Dataproc gcp.dataproc.cluster.yarn.memory_size cluster.yarn.MemorySize GCP Dataproc gcp.dataproc.cluster.yarn.nodemanagers cluster.yarn.Nodemanagers GCP Dataproc gcp.dataproc.cluster.yarn.pending_memory_size cluster.yarn.PendingMemorySize GCP Dataproc gcp.dataproc.cluster.yarn.virtual_cores cluster.yarn.VirtualCores GCP Datastore gcp.datastore.api.request_count api.Requests GCP Datastore gcp.datastore.entity.read_sizes entity.ReadSizes GCP Datastore gcp.datastore.entity.write_sizes entity.WriteSizes GCP Datastore gcp.datastore.index.write_count index.Writes GCP Firebase Database gcp.firebasedatabase.io.database_load io.DatabaseLoad GCP Firebase Database gcp.firebasedatabase.io.persisted_bytes_count io.PersistedBytes GCP Firebase Database gcp.firebasedatabase.io.sent_responses_count io.SentResponses GCP Firebase Database gcp.firebasedatabase.io.utilization io.Utilization GCP Firebase Database gcp.firebasedatabase.network.active_connections network.ActiveConnections GCP Firebase Database gcp.firebasedatabase.network.api_hits_count network.ApiHits GCP Firebase Database gcp.firebasedatabase.network.broadcast_load network.BroadcastLoad GCP Firebase Database gcp.firebasedatabase.network.https_requests_count network.HttpsRequests GCP Firebase Database gcp.firebasedatabase.network.monthly_sent network.MonthlySent GCP Firebase Database gcp.firebasedatabase.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Database gcp.firebasedatabase.network.sent_bytes_count network.SentBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_and_protocol_bytes_count network.SentPayloadAndProtocolBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_bytes_count network.SentPayloadBytes GCP Firebase Database gcp.firebasedatabase.rules.evaluation_count rules.Evaluation GCP Firebase Database gcp.firebasedatabase.storage.limit storage.Limit GCP Firebase Database gcp.firebasedatabase.storage.total_bytes storage.TotalBytes GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent network.MonthlySent GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Hosting gcp.firebasehosting.network.sent_bytes_count network.SentBytes GCP Firebase Hosting gcp.firebasehosting.storage.limit storage.Limit GCP Firebase Hosting gcp.firebasehosting.storage.total_bytes storage.TotalBytes GCP Firebase Storage gcp.firebasestorage.rules.evaluation_count rules.Evaluation GCP Firestore gcp.firestore.api.request_count api.Request GCP Firestore gcp.firestore.document.delete_count document.Delete GCP Firestore gcp.firestore.document.read_count document.Read GCP Firestore gcp.firestore.document.write_count document.Write GCP Firestore gcp.firestore.network.active_connections network.ActiveConnections GCP Firestore gcp.firestore.network.snapshot_listeners network.SnapshotListeners GCP Firestore gcp.firestore.rules.evaluation_count rules.Evaluation GCP Cloud Functions gcp.cloudfunctions.function.execution_count function.Executions GCP Cloud Functions gcp.cloudfunctions.function.execution_times function.ExecutionTimeNanos GCP Cloud Functions gcp.cloudfunctions.function.user_memory_bytes function.UserMemoryBytes GCP Interconnect gcp.interconnect.network.interconnect.capacity network.interconnect.Capacity GCP Interconnect gcp.interconnect.network.interconnect.dropped_packets_count network.interconnect.DroppedPackets GCP Interconnect gcp.interconnect.network.interconnect.link.rx_power network.interconnect.link.RxPower GCP Interconnect gcp.interconnect.network.interconnect.link.tx_power network.interconnect.link.TxPower GCP Interconnect gcp.interconnect.network.interconnect.receive_errors_count network.interconnect.ReceiveErrors GCP Interconnect gcp.interconnect.network.interconnect.received_bytes_count network.interconnect.ReceivedBytes GCP Interconnect gcp.interconnect.network.interconnect.received_unicast_packets_count network.interconnect.ReceivedUnicastPackets GCP Interconnect gcp.interconnect.network.interconnect.send_errors_count network.interconnect.SendErrors GCP Interconnect gcp.interconnect.network.interconnect.sent_bytes_count network.interconnect.SentBytes GCP Interconnect gcp.interconnect.network.interconnect.sent_unicast_packets_count network.interconnect.SentUnicastPackets GCP Interconnect gcp.interconnect.network.attachment.capacity network.attachment.Capacity GCP Interconnect gcp.interconnect.network.attachment.received_bytes_count network.attachment.ReceivedBytes GCP Interconnect gcp.interconnect.network.attachment.received_packets_count network.attachment.ReceivedPackets GCP Interconnect gcp.interconnect.network.attachment.sent_bytes_count network.attachment.SentBytes GCP Interconnect gcp.interconnect.network.attachment.sent_packets_count network.attachment.SentPackets GCP Kubernetes Engine gcp.kubernetes.container.accelerator.duty_cycle container.accelerator.dutyCycle GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_total container.accelerator.memoryTotal GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_used container.accelerator.memoryUsed GCP Kubernetes Engine gcp.kubernetes.container.accelerator.request container.accelerator.request GCP Kubernetes Engine gcp.kubernetes.container.cpu.core_usage_time container.cpu.usageTime GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_cores container.cpu.limitCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_utilization container.cpu.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_cores container.cpu.requestCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_utilization container.cpu.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_bytes container.memory.limitBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_utilization container.memory.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.request_bytes container.memory.requestBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.request_utilization container.memory.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.used_bytes container.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.container.restart_count container.restartCount GCP Kubernetes Engine gcp.kubernetes.container.uptime container.uptime GCP Kubernetes Engine gcp.kubernetes.node_daemon.cpu.core_usage_time nodeDaemon.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node_daemon.memory.used_bytes nodeDaemon.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_cores node.cpu.allocatableCores GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_utilization node.cpu.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.cpu.core_usage_time node.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node.cpu.total_cores node.cpu.totalCores GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_bytes node.memory.allocatableBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_utilization node.memory.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.memory.total_bytes node.memory.totalBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.used_bytes node.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.network.received_bytes_count node.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.node.network.sent_bytes_count node.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.received_bytes_count pod.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.sent_bytes_count pod.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.volume.total_bytes pod.volume.totalBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.used_bytes pod.volume.usedBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.utilization pod.volume.utilization GCP Load Balancer gcp.loadbalancing.https.backend_latencies https.BackendLatencies GCP Load Balancer gcp.loadbalancing.https.backend_request_bytes_count https.BackendRequestBytes GCP Load Balancer gcp.loadbalancing.https.backend_request_count https.BackendRequests GCP Load Balancer gcp.loadbalancing.https.backend_response_bytes_count https.BackendResponseBytes GCP Load Balancer gcp.loadbalancing.https.frontend_tcp_rtt https.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.https.request_bytes_count https.RequestBytes GCP Load Balancer gcp.loadbalancing.https.request_count https.Requests GCP Load Balancer gcp.loadbalancing.https.response_bytes_count https.ResponseBytes GCP Load Balancer gcp.loadbalancing.https.total_latencies https.TotalLatencies GCP Load Balancer gcp.loadbalancing.l3.internal.egress_bytes_count l3.internal.EgressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.egress_packets_count l3.internal.EgressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_bytes_count l3.internal.IngressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_packets_count l3.internal.IngressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.rtt_latencies l3.internal.RttLatencies GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.closed_connections tcpSslProxy.ClosedConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.egress_bytes_count tcpSslProxy.EgressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.frontend_tcp_rtt tcpSslProxy.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.ingress_bytes_count tcpSslProxy.IngressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.new_connections tcpSslProxy.NewConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.open_connections tcpSslProxy.OpenConnections GCP Pub/Sub gcp.pubsub.subscription.backlog_bytes subscription.BacklogBytes GCP Pub/Sub gcp.pubsub.subscription.byte_cost subscription.ByteCost GCP Pub/Sub gcp.pubsub.subscription.config_updates_count subscription.ConfigUpdates GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_message_operation_count subscription.ModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_request_count subscription.ModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.num_outstanding_messages subscription.NumOutstandingMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages subscription.NumRetainedAckedMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages_by_region subscription.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_unacked_messages_by_region subscription.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_undelivered_messages subscription.NumUndeliveredMessages GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age subscription.OldestRetainedAckedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age_by_region subscription.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age subscription.OldestUnackedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age_by_region subscription.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.pull_ack_message_operation_count subscription.PullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_ack_request_count subscription.PullAckRequest GCP Pub/Sub gcp.pubsub.subscription.pull_message_operation_count subscription.PullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_request_count subscription.PullRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_count subscription.PushRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_latencies subscription.PushRequestLatencies GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes subscription.RetainedAckedBytes GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes_by_region subscription.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_message_operation_count subscription.StreamingPullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_request_count subscription.StreamingPullAckRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_message_operation_count subscription.StreamingPullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_message_operation_count subscription.StreamingPullModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_request_count subscription.StreamingPullModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_response_count subscription.StreamingPullResponse GCP Pub/Sub gcp.pubsub.subscription.unacked_bytes_by_region subscription.UnackedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.byte_cost topic.ByteCost GCP Pub/Sub gcp.pubsub.topic.config_updates_count topic.ConfigUpdates GCP Pub/Sub gcp.pubsub.topic.message_sizes topic.MessageSizes GCP Pub/Sub gcp.pubsub.topic.num_retained_acked_messages_by_region topic.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.num_unacked_messages_by_region topic.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_retained_acked_message_age_by_region topic.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_unacked_message_age_by_region topic.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.retained_acked_bytes_by_region topic.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.send_message_operation_count topic.SendMessageOperation GCP Pub/Sub gcp.pubsub.topic.send_request_count topic.SendRequest GCP Pub/Sub gcp.pubsub.topic.unacked_bytes_by_region topic.UnackedBytesByRegion GCP Router gcp.router.best_received_routes_count BestReceivedRoutes GCP Router gcp.router.bfd.control.receive_intervals bfd.control.ReceiveIntervals GCP Router gcp.router.bfd.control.received_packets_count bfd.control.ReceivedPackets GCP Router gcp.router.bfd.control.rejected_packets_count bfd.control.RejectedPackets GCP Router gcp.router.bfd.control.transmit_intervals bfd.control.TransmitIntervals GCP Router gcp.router.bfd.control.transmitted_packets_count bfd.control.TransmittedPackets GCP Router gcp.router.bfd.session_up bfd.SessionUp GCP Router gcp.router.bgp_sessions_down_count BgpSessionsDown GCP Router gcp.router.bgp_sessions_up_count BgpSessionsUp GCP Router gcp.router.bgp.received_routes_count bgp.ReceivedRoutes GCP Router gcp.router.bgp.sent_routes_count bgp.SentRoutes GCP Router gcp.router.bgp.session_up bgp.SessionUp GCP Router gcp.router.router_up RouterUp GCP Router gcp.router.sent_routes_count SentRoutes GCP Router gcp.router.nat.allocated_ports nat.AllocatedPorts GCP Router gcp.router.nat.closed_connections_count nat.ClosedConnections GCP Router gcp.router.nat.dropped_received_packets_count nat.DroppedReceivedPackets GCP Router gcp.router.nat.new_connections_count nat.NewConnections GCP Router gcp.router.nat.port_usage nat.PortUsage GCP Router gcp.router.nat.received_bytes_count nat.ReceivedBytes GCP Router gcp.router.nat.received_packets_count nat.ReceivedPackets GCP Router gcp.router.nat.sent_bytes_count nat.SentBytes GCP Router gcp.router.nat.sent_packets_count nat.SentPackets GCP Run gcp.run.container.billable_instance_time container.BillableInstanceTime GCP Run gcp.run.container.cpu.allocation_time container.cpu.AllocationTime GCP Run gcp.run.container.memory.allocation_time container.memory.AllocationTime GCP Run gcp.run.request_count Request GCP Run gcp.run.request_latencies RequestLatencies GCP Spanner gcp.spanner.api.received_bytes_count api.ReceivedBytes GCP Spanner gcp.spanner.api.request_count api.Requests GCP Spanner gcp.spanner.api.request_latencies api.RequestLatencies GCP Spanner gcp.spanner.instance.cpu.utilization instance.cpu.Utilization GCP Spanner gcp.spanner.instance.node_count instance.nodes GCP Spanner gcp.spanner.instance.session_count instance.sessions GCP Spanner gcp.spanner.instance.storage.used_bytes instance.storage.UsedBytes GCP Cloud SQL gcp.cloudsql.database.auto_failover_request_count database.AutoFailoverRequest GCP Cloud SQL gcp.cloudsql.database.available_for_failover database.AvailableForFailover GCP Cloud SQL gcp.cloudsql.database.cpu.reserved_cores database.cpu.ReservedCores GCP Cloud SQL gcp.cloudsql.database.cpu.usage_time database.cpu.UsageTime GCP Cloud SQL gcp.cloudsql.database.cpu.utilization database.cpu.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.bytes_used database.disk.BytesUsed GCP Cloud SQL gcp.cloudsql.database.disk.quota database.disk.Quota GCP Cloud SQL gcp.cloudsql.database.disk.read_ops_count database.disk.ReadOps GCP Cloud SQL gcp.cloudsql.database.disk.utilization database.disk.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.write_ops_count database.disk.WriteOps GCP Cloud SQL gcp.cloudsql.database.memory.quota database.memory.Quota GCP Cloud SQL gcp.cloudsql.database.memory.usage database.memory.Usage GCP Cloud SQL gcp.cloudsql.database.memory.utilization database.memory.Utilization GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_dirty database.mysql.InnodbBufferPoolPagesDirty GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_free database.mysql.InnodbBufferPoolPagesFree GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_total database.mysql.InnodbBufferPoolPagesTotal GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_data_fsyncs database.mysql.InnodbDataFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_os_log_fsyncs database.mysql.InnodbOsLogFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_read database.mysql.InnodbPagesRead GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_written database.mysql.InnodbPagesWritten GCP Cloud SQL gcp.cloudsql.database.mysql.queries database.mysql.Queries GCP Cloud SQL gcp.cloudsql.database.mysql.questions database.mysql.Questions GCP Cloud SQL gcp.cloudsql.database.mysql.received_bytes_count database.mysql.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.mysql.replication.seconds_behind_master database.mysql.replication.SecondsBehindMaster GCP Cloud SQL gcp.cloudsql.database.mysql.sent_bytes_count database.mysql.SentBytes GCP Cloud SQL gcp.cloudsql.database.network.connections database.network.Connections GCP Cloud SQL gcp.cloudsql.database.network.received_bytes_count database.network.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.network.sent_bytes_count database.network.SentBytes GCP Cloud SQL gcp.cloudsql.database.postgresql.num_backends database.postgresql.NumBackends GCP Cloud SQL gcp.cloudsql.database.postgresql.replication.replica_byte_lag database.postgresql.replication.ReplicaByteLag GCP Cloud SQL gcp.cloudsql.database.postgresql.transaction_count database.postgresql.Transaction GCP Cloud SQL gcp.cloudsql.database.up database.Up GCP Cloud SQL gcp.cloudsql.database.uptime database.Uptime GCP Cloud Storage gcp.storage.api.request_count api.Requests GCP Cloud Storage gcp.storage.network.received_bytes_count network.ReceivedBytes GCP Cloud Storage gcp.storage.network.sent_bytes_count network.SentBytes GCP VMs gcp.compute.firewall.dropped_bytes_count firewall.DroppedBytes GCP VMs gcp.compute.firewall.dropped_packets_count firewall.DroppedPackets GCP VMs gcp.compute.instance.cpu.reserved_cores instance.cpu.ReservedCores GCP VMs gcp.compute.instance.cpu.utilization instance.cpu.Utilization GCP VMs gcp.compute.instance.disk.read_bytes_count instance.disk.ReadBytes GCP VMs gcp.compute.instance.disk.read_ops_count instance.disk.ReadOps GCP VMs gcp.compute.instance.disk.write_bytes_count instance.disk.WriteBytes GCP VMs gcp.compute.instance.disk.write_ops_count instance.disk.WriteOps GCP VMs gcp.compute.instance.network.received_bytes_count instance.network.ReceivedBytes GCP VMs gcp.compute.instance.network.received_packets_count instance.network.ReceivedPackets GCP VMs gcp.compute.instance.network.sent_bytes_count instance.network.SentBytes GCP VMs gcp.compute.instance.network.sent_packets_count instance.network.SentPackets GCP VMs gcp.compute.instance.disk.throttled_read_bytes_count instance.disk.ThrottledReadBytes GCP VMs gcp.compute.instance.disk.throttled_read_ops_count instance.disk.ThrottledReadOps GCP VMs gcp.compute.instance.disk.throttled_write_bytes_count instance.disk.ThrottledWriteBytes GCP VMs gcp.compute.instance.disk.throttled_write_ops_count instance.disk.ThrottledWriteOps GCP VPC Access gcp.vpcaccess.connector.received_bytes_count connector.ReceivedBytes GCP VPC Access gcp.vpcaccess.connector.received_packets_count connector.ReceivedPackets GCP VPC Access gcp.vpcaccess.connector.sent_bytes_count connector.SentBytes GCP VPC Access gcp.vpcaccess.connector.sent_packets_count connector.SentPackets",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GCP <em>integration</em> metrics",
        "sections": "<em>Google</em> <em>Cloud</em> Metrics",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. <em>Google</em> <em>Cloud</em> Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine"
      },
      "id": "617d6e7e28ccbceb0c800c36"
    },
    {
      "sections": [
        "Integrations and custom roles",
        "Recommended role",
        "Optional role",
        "Important",
        "List of permissions",
        "Common permissions",
        "Service-specific permissions",
        "Permissions to link projects through the UI"
      ],
      "title": "Integrations and custom roles",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "7b590d0cf2c9600043ce210864affa858f99ad85",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/integrations-custom-roles/",
      "published_at": "2021-12-30T07:30:54Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To read the relevant data from your Google Cloud Platform (GCP) account, New Relic uses the Google Stackdriver API and also other specific services APIs. To access these APIs in your Google Cloud project, the New Relic authorized account needs to be granted a certain set of permissions; GCP uses roles to grant these permissions. Recommended role By default we highly recommend using the GCP primitive role Role Viewer, which grants \"permissions for read-only actions that do not affect your cloud infrastructure state, such as viewing (but not modifying) existing resources or data.\" This role is automatically managed by Google and updated when new Google Cloud services are released or modified. Optional role Alternatively, you can create your own custom role based on the list of permissions, which specifies the minimum set of permissions required to fetch data from each GCP integration. This will allow you to have more control over the permissions set for the New Relic authorized account. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom role, it is your responsibility to maintain it and ensure proper data is being collected. To customize your role you need to: Create a Google Cloud IAM Custom Role in each one of the GCP projects you want to monitor with New Relic. In each custom role, add the permissions that are specifically required for the cloud services you want to monitor according to the following list. Assign the custom role(s) to the New Relic authorized account. List of permissions Common permissions All integrations need the following permission: monitoring.timeSeries.list serviceusage.services.use Service-specific permissions For some GCP integrations, New Relic will also need the following permissions, mainly to collect labels and inventory attributes. Integration Permissions Google AppEngine n/a; Google App Engine does not require additional permissions. Google BigQuery bigquery.datasets.get bigquery.tables.get bigquery.tables.list Google Cloud Functions cloudfunctions.locations.list Google Cloud Load Balancing n/a; Google Cloud Load Balancing does not require additional permissions. Google Cloud Pub/Sub pubsub.subscriptions.get pubsub.subscriptions.list pubsub.topics.get pubsub.topics.list Google Cloud Spanner spanner.instances.list spanner.databases.list spanner.databases.getDdl Google Cloud SQL cloudsql.instances.list Google Cloud Storage storage.buckets.list Google Compute Engine compute.instances.list compute.disks.get compute.disks.list Google Kubernetes Engine container.clusters.list Permissions to link projects through the UI To be able to see the list of projects that you can link to New Relic through the UI, your New Relic authorized service account needs the following permissions: resourcemanager.projects.get monitoring.monitoredResourceDescriptors.list If you do not want to grant New Relic authorized account the permissions that are needed for the linking process through the UI, you have the following options: Assign the Role Viewer or Monitoring Viewer role initially to the authorized account to link Google Cloud projects to New Relic through the UI. After the projects are linked, assign a Google Cloud custom role to the authorized account. Use New Relic NerdGraph to link Google Cloud projects to New Relic. This does not involve listing the viewable projects. However, you must know the id of the project you want to monitor. For more information, see the NerdGraph GraphiQL cloud integrations API tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.40317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and custom roles",
        "sections": "<em>Integrations</em> and custom roles",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "To read the relevant data from your <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) account, New Relic uses the <em>Google</em> Stackdriver API and also other specific services APIs. To access these APIs in your <em>Google</em> <em>Cloud</em> project, the New Relic authorized account needs to be granted a certain set of permissions; GCP uses"
      },
      "id": "617dbb19196a67adbbf7d3fa"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/troubleshooting/gcp-integration-api-authentication-errors": [
    {
      "sections": [
        "Connect Google Cloud Platform services to New Relic",
        "Requirements",
        "Authorization options",
        "Service account (recommended)",
        "User account",
        "Connect GCP to New Relic infrastructure monitoring",
        "Tip",
        "Explore app data in New Relic",
        "Link multiple Google projects",
        "Unlink your GCP integrations"
      ],
      "title": "Connect Google Cloud Platform services to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "020b2d37cc7cc23be789226bb056c6f3a1964d11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/connect-google-cloud-platform-services-new-relic/",
      "published_at": "2021-12-30T05:52:53Z",
      "updated_at": "2021-10-24T02:06:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Google Cloud Platform (GCP) data with New Relic GCP integrations, connect your Google project to New Relic infrastructure monitoring. If you don't have one already, create a New Relic account. It's free, forever. Requirements These are the requirements for the authorization: GCP integration requirements Comments Monitoring In the GCP project API & Services Library settings, you must enable Google Stackdriver Monitoring API. Authorization For service account authorization (recommended): A user with Project IAM Admin role is needed to add the service account ID as a member in your GCP project. In the GCP project IAM & admin, the service account must have the Project Viewer role and the Service Usage Consumer role or, alternatively, a custom role. For user account authorization: The New Relic user that will integrate the GCP project must have a Google account and must be able to view the GCP project that New Relic will monitor. In the GCP project IAM & admin, the user must have the Project Viewer role. Please note that this authorization method will not allow New Relic to collect labels and other inventory attributes that can be useful for narrowing down your NRQL queries, dashboards and alerts. You can migrate the authorization method from user account to service account from the Manage services link in New Relic's user interface. Project name As part of the online setup process, you must identify Project name of the projects you want to monitor with New Relic. The UI workflow automatically lists active projects you can select. Permissions (only for user account authorization) New Relic requires a specific set of read-only permissions exclusively; this means that, for certain integrations, only partial inventory data will be available. Keep in mind that New Relic doesn't inherit your Google account's permissions and therefore is not authorized to perform any changes in the project. For more information about the API permissions that New Relic uses, see the Google documentation about scopes. Authorization options Integrating your GCP project with New Relic requires you to authorize New Relic to fetch monitoring data from your GCP project. You can choose between two authorization methods: Service accounts or User accounts. Service account (recommended) The service account authorization is recommended. If you authorize New Relic to fetch data through a service account, we will call your GCP project APIs using a service account ID and its associated public/private key pair. New Relic manages a specific Google service account for your New Relic account; you do not need to create it or manage the associated private key. Just add the service account ID as a member with viewing permissions in your project. If your organization uses a domain restriction constraint, you will have to update the policy to allow the New Relic domain, C02x1gp26. This authorization method is recommended, especially if your GCP project is managed by a team. It also guarantees that New Relic will collect labels and inventory attributes whenever possible. User account If you authorize New Relic to fetch data through a user account, New Relic will access your GCP project monitoring data on behalf of a particular Google user. The authorization process is achieved through an OAuth workflow, which redirects you from the New Relic UI to a Google authorization interface. However, since the authorization is linked to a particular Google user, this method is not recommended for GCP projects that are managed by large teams. Connect GCP to New Relic infrastructure monitoring To connect your Google account to New Relic with user account authorization: Go to one.newrelic.com > Infrastructure > GCP. At the top of Infrastructure's Google Cloud Services integrations page, select Add a GCP account. Choose Authorization Method: Select either Authorize a Service Account or Authorize a User Account, and follow the instructions in the UI to authorize New Relic. Add projects: Select the projects that you want New Relic to receive data from. Select services: From the list of available services for your GCP account, select the individual services you want New Relic to receive data from, or select all of the services. Tip These services will be enabled for all of the projects that you selected in the previous step. Once the setup process is finished, you can fine-tune the services that you want monitored for each project individually. To complete the setup process, select Finish. If you see API authentication errors, follow the troubleshooting procedures. Explore app data in New Relic After you authorize New Relic to integrate one or more of your Google project's services, New Relic starts monitoring your GCP data at regular polling intervals. After a few minutes, data will appear in the New Relic UI. To find and use your data, including links to dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP. Link multiple Google projects For your convenience, the setup process allows you to select more than one project at a time. After the first setup, if you need to monitor additional GCP projects with New Relic, you can repeat the procedure to connect your GCP services as many times as you need. Unlink your GCP integrations You can disable any of your GCP integrations any time and still keep your Google project connected to New Relic. If you want to... Do this Disable a GCP service monitoring To disconnect individual GCP services but keep the integration with New Relic for other GCP services in your Google account: Go to one.newrelic.com > Infrastructure > GCP and select Manage services. From your GCP account page, make changes to the checkbox options for available services and select Save changes. Unlink your project monitoring To uninstall all of your GCP services completely from New Relic Integrations, unlink your Google account: Go to one.newrelic.com > Infrastructure > GCP and select Manage services. From your GCP account page, select Unlink account and select Save changes. Clean your GCP Projects after unlinking New Relic To clean your GCP project after unlinking, follow these steps if you were using a service account: Open the GCP IAM Console. Select the project you want to unlink from New Relic and click Open. Select the service account that is used by New Relic. Click the Remove icon. Or follow these steps if you were using a user account: Open your Google user account settings. Open the Apps with access to your account section. Choose New Relic application. Choose Remove Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.78732,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Connect <em>Google</em> <em>Cloud</em> <em>Platform</em> services to New Relic",
        "sections": "Connect <em>Google</em> <em>Cloud</em> <em>Platform</em> services to New Relic",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "To start receiving <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) data with New Relic GCP <em>integrations</em>, connect your <em>Google</em> project to New Relic infrastructure monitoring. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Requirements These are the requirements for the authorization: GCP"
      },
      "id": "617dbadce7b9d2a21fc0559d"
    },
    {
      "sections": [
        "Introduction to Google Cloud Platform integrations",
        "Connect GCP and New Relic",
        "View your GCP data"
      ],
      "title": "Introduction to Google Cloud Platform integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "20545af7b385b6343f3a02edb9c2941a1272742c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/introduction-google-cloud-platform-integrations/",
      "published_at": "2021-12-30T05:52:53Z",
      "updated_at": "2021-10-24T02:08:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations monitor the performance of popular products and services. New Relic's Google Cloud Platform (GCP) integrations let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures to connect your GCP service to New Relic. View your GCP data Once you follow the configuration process, data from your Google Cloud Platform account will report directly to New Relic. To view your GCP data: Go to one.newrelic.com > Infrastructure > GCP. For any of the integrations listed: Select an integration name to view data in a pre-configured dashboard. OR Select the Explore data icon to view GCP data. You can view and reuse the Insights NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Inventory, events, and dashboards for all services are available in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.26602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "sections": "Introduction to <em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> monitor the performance of popular products and services. New Relic&#x27;s <em>Google</em> <em>Cloud</em> <em>Platform</em> (GCP) <em>integrations</em> let you monitor your GCP data in several New Relic features. Connect GCP and New Relic In order to obtain GCP data, follow standard procedures"
      },
      "id": "617d6e7e196a6777fef7c1a0"
    },
    {
      "sections": [
        "GCP integration metrics",
        "BETA FEATURE",
        "Google Cloud Metrics"
      ],
      "title": "GCP integration metrics",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "Get started"
      ],
      "external_id": "e1274b0eb01b312f7cb781a5b2210570379b1cfa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/get-started/gcp-integration-metrics/",
      "published_at": "2021-12-30T05:53:32Z",
      "updated_at": "2021-10-24T02:07:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Google Cloud Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine gcp.appengine.flex.cpu.utilization flex.cpu.Utilization GCP App Engine gcp.appengine.flex.disk.read_bytes_count flex.disk.ReadBytes GCP App Engine gcp.appengine.flex.disk.write_bytes_count flex.disk.WriteBytes GCP App Engine gcp.appengine.flex.network.received_bytes_count flex.network.ReceivedBytes GCP App Engine gcp.appengine.flex.network.sent_bytes_count flex.network.SentBytes GCP App Engine gcp.appengine.http.server.dos_intercept_count server.DosIntercepts GCP App Engine gcp.appengine.http.server.quota_denial_count server.QuotaDenials GCP App Engine gcp.appengine.http.server.response_count server.Responses GCP App Engine gcp.appengine.http.server.response_latencies server.ResponseLatenciesMilliseconds GCP App Engine gcp.appengine.http.server.response_style_count http.server.ResponseStyle GCP App Engine gcp.appengine.memcache.centi_mcu_count memcache.CentiMcu GCP App Engine gcp.appengine.memcache.operation_count memcache.Operations GCP App Engine gcp.appengine.memcache.received_bytes_count memcache.ReceivedBytes GCP App Engine gcp.appengine.memcache.sent_bytes_count memcache.SentBytes GCP App Engine gcp.appengine.system.cpu.usage system.cpu.Usage GCP App Engine gcp.appengine.system.instance_count system.Instances GCP App Engine gcp.appengine.system.memory.usage system.memory.UsageBytes GCP App Engine gcp.appengine.system.network.received_bytes_count system.network.ReceivedBytes GCP App Engine gcp.appengine.system.network.sent_bytes_count system.network.SentBytes GCP App Engine gcp.cloudtasks.api.request_count api.Requests GCP App Engine gcp.cloudtasks.queue.task_attempt_count queue.taskAttempts GCP App Engine gcp.cloudtasks.queue.task_attempt_delays queue.taskAttemptDelaysMilliseconds GCP BigQuery gcp.bigquery.storage.stored_bytes storage.StoredBytes GCP BigQuery gcp.bigquery.storage.table_count storage.Tables GCP BigQuery gcp.bigquery.query.count query.Count GCP BigQuery gcp.bigquery.query.execution_times query.ExecutionTimes GCP BigQuery gcp.bigquery.slots.allocated slots.Allocated GCP BigQuery gcp.bigquery.slots.allocated_for_project slots.AllocatedForProject GCP BigQuery gcp.bigquery.slots.allocated_for_project_and_job_type slots.AllocatedForProjectAndJobType GCP BigQuery gcp.bigquery.slots.allocated_for_reservation slots.AllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_allocated_for_reservation slots.TotalAllocatedForReservation GCP BigQuery gcp.bigquery.slots.total_available slots.TotalAvailable GCP BigQuery gcp.bigquery.storage.uploaded_bytes storage.UploadedBytes GCP BigQuery gcp.bigquery.storage.uploaded_bytes_billed storage.UploadedBytesBilled GCP BigQuery gcp.bigquery.storage.uploaded_row_count storage.UploadedRows GCP Dataflow gcp.dataflow.job.billable_shuffle_data_processed job.BillableShuffleDataProcessed GCP Dataflow gcp.dataflow.job.current_num_vcpus job.CurrentNumVcpus GCP Dataflow gcp.dataflow.job.current_shuffle_slots job.CurrentShuffleSlots GCP Dataflow gcp.dataflow.job.data_watermark_age job.DataWatermarkAge GCP Dataflow gcp.dataflow.job.elapsed_time job.ElapsedTime GCP Dataflow gcp.dataflow.job.element_count job.Elements GCP Dataflow gcp.dataflow.job.estimated_byte_count job.EstimatedBytes GCP Dataflow gcp.dataflow.job.is_failed job.IsFailed GCP Dataflow gcp.dataflow.job.per_stage_data_watermark_age job.PerStageDataWatermarkAge GCP Dataflow gcp.dataflow.job.per_stage_system_lag job.PerStageSystemLag GCP Dataflow gcp.dataflow.job.system_lag job.SystemLag GCP Dataflow gcp.dataflow.job.total_memory_usage_time job.TotalMemoryUsageTime GCP Dataflow gcp.dataflow.job.total_pd_usage_time job.TotalPdUsageTime GCP Dataflow gcp.dataflow.job.total_shuffle_data_processed job.TotalShuffleDataProcessed GCP Dataflow gcp.dataflow.job.total_streaming_data_processed job.TotalStreamingDataProcessed GCP Dataflow gcp.dataflow.job.total_vcpu_time job.TotalVcpuTime GCP Dataflow gcp.dataflow.job.user_counter job.UserCounter GCP Dataproc gcp.dataproc.cluster.hdfs.datanodes cluster.hdfs.Datanodes GCP Dataproc gcp.dataproc.cluster.hdfs.storage_capacity cluster.hdfs.StorageCapacity GCP Dataproc gcp.dataproc.cluster.hdfs.storage_utilization cluster.hdfs.StorageUtilization GCP Dataproc gcp.dataproc.cluster.hdfs.unhealthy_blocks cluster.hdfs.UnhealthyBlocks GCP Dataproc gcp.dataproc.cluster.job.completion_time cluster.job.CompletionTime GCP Dataproc gcp.dataproc.cluster.job.duration cluster.job.Duration GCP Dataproc gcp.dataproc.cluster.job.failed_count cluster.job.Failures GCP Dataproc gcp.dataproc.cluster.job.running_count cluster.job.Running GCP Dataproc gcp.dataproc.cluster.job.submitted_count cluster.job.Submitted GCP Dataproc gcp.dataproc.cluster.operation.completion_time cluster.operation.CompletionTime GCP Dataproc gcp.dataproc.cluster.operation.duration cluster.operation.Duration GCP Dataproc gcp.dataproc.cluster.operation.failed_count cluster.operation.Failures GCP Dataproc gcp.dataproc.cluster.operation.running_count cluster.operation.Running GCP Dataproc gcp.dataproc.cluster.operation.submitted_count cluster.operation.Submitted GCP Dataproc gcp.dataproc.cluster.yarn.allocated_memory_percentage cluster.yarn.AllocatedMemoryPercentage GCP Dataproc gcp.dataproc.cluster.yarn.apps cluster.yarn.Apps GCP Dataproc gcp.dataproc.cluster.yarn.containers cluster.yarn.Containers GCP Dataproc gcp.dataproc.cluster.yarn.memory_size cluster.yarn.MemorySize GCP Dataproc gcp.dataproc.cluster.yarn.nodemanagers cluster.yarn.Nodemanagers GCP Dataproc gcp.dataproc.cluster.yarn.pending_memory_size cluster.yarn.PendingMemorySize GCP Dataproc gcp.dataproc.cluster.yarn.virtual_cores cluster.yarn.VirtualCores GCP Datastore gcp.datastore.api.request_count api.Requests GCP Datastore gcp.datastore.entity.read_sizes entity.ReadSizes GCP Datastore gcp.datastore.entity.write_sizes entity.WriteSizes GCP Datastore gcp.datastore.index.write_count index.Writes GCP Firebase Database gcp.firebasedatabase.io.database_load io.DatabaseLoad GCP Firebase Database gcp.firebasedatabase.io.persisted_bytes_count io.PersistedBytes GCP Firebase Database gcp.firebasedatabase.io.sent_responses_count io.SentResponses GCP Firebase Database gcp.firebasedatabase.io.utilization io.Utilization GCP Firebase Database gcp.firebasedatabase.network.active_connections network.ActiveConnections GCP Firebase Database gcp.firebasedatabase.network.api_hits_count network.ApiHits GCP Firebase Database gcp.firebasedatabase.network.broadcast_load network.BroadcastLoad GCP Firebase Database gcp.firebasedatabase.network.https_requests_count network.HttpsRequests GCP Firebase Database gcp.firebasedatabase.network.monthly_sent network.MonthlySent GCP Firebase Database gcp.firebasedatabase.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Database gcp.firebasedatabase.network.sent_bytes_count network.SentBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_and_protocol_bytes_count network.SentPayloadAndProtocolBytes GCP Firebase Database gcp.firebasedatabase.network.sent_payload_bytes_count network.SentPayloadBytes GCP Firebase Database gcp.firebasedatabase.rules.evaluation_count rules.Evaluation GCP Firebase Database gcp.firebasedatabase.storage.limit storage.Limit GCP Firebase Database gcp.firebasedatabase.storage.total_bytes storage.TotalBytes GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent network.MonthlySent GCP Firebase Hosting gcp.firebasehosting.network.monthly_sent_limit network.MonthlySentLimit GCP Firebase Hosting gcp.firebasehosting.network.sent_bytes_count network.SentBytes GCP Firebase Hosting gcp.firebasehosting.storage.limit storage.Limit GCP Firebase Hosting gcp.firebasehosting.storage.total_bytes storage.TotalBytes GCP Firebase Storage gcp.firebasestorage.rules.evaluation_count rules.Evaluation GCP Firestore gcp.firestore.api.request_count api.Request GCP Firestore gcp.firestore.document.delete_count document.Delete GCP Firestore gcp.firestore.document.read_count document.Read GCP Firestore gcp.firestore.document.write_count document.Write GCP Firestore gcp.firestore.network.active_connections network.ActiveConnections GCP Firestore gcp.firestore.network.snapshot_listeners network.SnapshotListeners GCP Firestore gcp.firestore.rules.evaluation_count rules.Evaluation GCP Cloud Functions gcp.cloudfunctions.function.execution_count function.Executions GCP Cloud Functions gcp.cloudfunctions.function.execution_times function.ExecutionTimeNanos GCP Cloud Functions gcp.cloudfunctions.function.user_memory_bytes function.UserMemoryBytes GCP Interconnect gcp.interconnect.network.interconnect.capacity network.interconnect.Capacity GCP Interconnect gcp.interconnect.network.interconnect.dropped_packets_count network.interconnect.DroppedPackets GCP Interconnect gcp.interconnect.network.interconnect.link.rx_power network.interconnect.link.RxPower GCP Interconnect gcp.interconnect.network.interconnect.link.tx_power network.interconnect.link.TxPower GCP Interconnect gcp.interconnect.network.interconnect.receive_errors_count network.interconnect.ReceiveErrors GCP Interconnect gcp.interconnect.network.interconnect.received_bytes_count network.interconnect.ReceivedBytes GCP Interconnect gcp.interconnect.network.interconnect.received_unicast_packets_count network.interconnect.ReceivedUnicastPackets GCP Interconnect gcp.interconnect.network.interconnect.send_errors_count network.interconnect.SendErrors GCP Interconnect gcp.interconnect.network.interconnect.sent_bytes_count network.interconnect.SentBytes GCP Interconnect gcp.interconnect.network.interconnect.sent_unicast_packets_count network.interconnect.SentUnicastPackets GCP Interconnect gcp.interconnect.network.attachment.capacity network.attachment.Capacity GCP Interconnect gcp.interconnect.network.attachment.received_bytes_count network.attachment.ReceivedBytes GCP Interconnect gcp.interconnect.network.attachment.received_packets_count network.attachment.ReceivedPackets GCP Interconnect gcp.interconnect.network.attachment.sent_bytes_count network.attachment.SentBytes GCP Interconnect gcp.interconnect.network.attachment.sent_packets_count network.attachment.SentPackets GCP Kubernetes Engine gcp.kubernetes.container.accelerator.duty_cycle container.accelerator.dutyCycle GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_total container.accelerator.memoryTotal GCP Kubernetes Engine gcp.kubernetes.container.accelerator.memory_used container.accelerator.memoryUsed GCP Kubernetes Engine gcp.kubernetes.container.accelerator.request container.accelerator.request GCP Kubernetes Engine gcp.kubernetes.container.cpu.core_usage_time container.cpu.usageTime GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_cores container.cpu.limitCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.limit_utilization container.cpu.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_cores container.cpu.requestCores GCP Kubernetes Engine gcp.kubernetes.container.cpu.request_utilization container.cpu.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_bytes container.memory.limitBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.limit_utilization container.memory.limitUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.request_bytes container.memory.requestBytes GCP Kubernetes Engine gcp.kubernetes.container.memory.request_utilization container.memory.requestUtilization GCP Kubernetes Engine gcp.kubernetes.container.memory.used_bytes container.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.container.restart_count container.restartCount GCP Kubernetes Engine gcp.kubernetes.container.uptime container.uptime GCP Kubernetes Engine gcp.kubernetes.node_daemon.cpu.core_usage_time nodeDaemon.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node_daemon.memory.used_bytes nodeDaemon.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_cores node.cpu.allocatableCores GCP Kubernetes Engine gcp.kubernetes.node.cpu.allocatable_utilization node.cpu.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.cpu.core_usage_time node.cpu.coreUsageTime GCP Kubernetes Engine gcp.kubernetes.node.cpu.total_cores node.cpu.totalCores GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_bytes node.memory.allocatableBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.allocatable_utilization node.memory.allocatableUtilization GCP Kubernetes Engine gcp.kubernetes.node.memory.total_bytes node.memory.totalBytes GCP Kubernetes Engine gcp.kubernetes.node.memory.used_bytes node.memory.usedBytes GCP Kubernetes Engine gcp.kubernetes.node.network.received_bytes_count node.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.node.network.sent_bytes_count node.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.received_bytes_count pod.network.receivedBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.network.sent_bytes_count pod.network.sentBytesCount GCP Kubernetes Engine gcp.kubernetes.pod.volume.total_bytes pod.volume.totalBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.used_bytes pod.volume.usedBytes GCP Kubernetes Engine gcp.kubernetes.pod.volume.utilization pod.volume.utilization GCP Load Balancer gcp.loadbalancing.https.backend_latencies https.BackendLatencies GCP Load Balancer gcp.loadbalancing.https.backend_request_bytes_count https.BackendRequestBytes GCP Load Balancer gcp.loadbalancing.https.backend_request_count https.BackendRequests GCP Load Balancer gcp.loadbalancing.https.backend_response_bytes_count https.BackendResponseBytes GCP Load Balancer gcp.loadbalancing.https.frontend_tcp_rtt https.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.https.request_bytes_count https.RequestBytes GCP Load Balancer gcp.loadbalancing.https.request_count https.Requests GCP Load Balancer gcp.loadbalancing.https.response_bytes_count https.ResponseBytes GCP Load Balancer gcp.loadbalancing.https.total_latencies https.TotalLatencies GCP Load Balancer gcp.loadbalancing.l3.internal.egress_bytes_count l3.internal.EgressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.egress_packets_count l3.internal.EgressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_bytes_count l3.internal.IngressBytes GCP Load Balancer gcp.loadbalancing.l3.internal.ingress_packets_count l3.internal.IngressPackets GCP Load Balancer gcp.loadbalancing.l3.internal.rtt_latencies l3.internal.RttLatencies GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.closed_connections tcpSslProxy.ClosedConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.egress_bytes_count tcpSslProxy.EgressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.frontend_tcp_rtt tcpSslProxy.FrontendTcpRtt GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.ingress_bytes_count tcpSslProxy.IngressBytes GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.new_connections tcpSslProxy.NewConnections GCP Load Balancer gcp.loadbalancing.tcp_ssl_proxy.open_connections tcpSslProxy.OpenConnections GCP Pub/Sub gcp.pubsub.subscription.backlog_bytes subscription.BacklogBytes GCP Pub/Sub gcp.pubsub.subscription.byte_cost subscription.ByteCost GCP Pub/Sub gcp.pubsub.subscription.config_updates_count subscription.ConfigUpdates GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_message_operation_count subscription.ModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.mod_ack_deadline_request_count subscription.ModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.num_outstanding_messages subscription.NumOutstandingMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages subscription.NumRetainedAckedMessages GCP Pub/Sub gcp.pubsub.subscription.num_retained_acked_messages_by_region subscription.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_unacked_messages_by_region subscription.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.subscription.num_undelivered_messages subscription.NumUndeliveredMessages GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age subscription.OldestRetainedAckedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_retained_acked_message_age_by_region subscription.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age subscription.OldestUnackedMessageAge GCP Pub/Sub gcp.pubsub.subscription.oldest_unacked_message_age_by_region subscription.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.subscription.pull_ack_message_operation_count subscription.PullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_ack_request_count subscription.PullAckRequest GCP Pub/Sub gcp.pubsub.subscription.pull_message_operation_count subscription.PullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.pull_request_count subscription.PullRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_count subscription.PushRequest GCP Pub/Sub gcp.pubsub.subscription.push_request_latencies subscription.PushRequestLatencies GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes subscription.RetainedAckedBytes GCP Pub/Sub gcp.pubsub.subscription.retained_acked_bytes_by_region subscription.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_message_operation_count subscription.StreamingPullAckMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_ack_request_count subscription.StreamingPullAckRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_message_operation_count subscription.StreamingPullMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_message_operation_count subscription.StreamingPullModAckDeadlineMessageOperation GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_mod_ack_deadline_request_count subscription.StreamingPullModAckDeadlineRequest GCP Pub/Sub gcp.pubsub.subscription.streaming_pull_response_count subscription.StreamingPullResponse GCP Pub/Sub gcp.pubsub.subscription.unacked_bytes_by_region subscription.UnackedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.byte_cost topic.ByteCost GCP Pub/Sub gcp.pubsub.topic.config_updates_count topic.ConfigUpdates GCP Pub/Sub gcp.pubsub.topic.message_sizes topic.MessageSizes GCP Pub/Sub gcp.pubsub.topic.num_retained_acked_messages_by_region topic.NumRetainedAckedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.num_unacked_messages_by_region topic.NumUnackedMessagesByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_retained_acked_message_age_by_region topic.OldestRetainedAckedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.oldest_unacked_message_age_by_region topic.OldestUnackedMessageAgeByRegion GCP Pub/Sub gcp.pubsub.topic.retained_acked_bytes_by_region topic.RetainedAckedBytesByRegion GCP Pub/Sub gcp.pubsub.topic.send_message_operation_count topic.SendMessageOperation GCP Pub/Sub gcp.pubsub.topic.send_request_count topic.SendRequest GCP Pub/Sub gcp.pubsub.topic.unacked_bytes_by_region topic.UnackedBytesByRegion GCP Router gcp.router.best_received_routes_count BestReceivedRoutes GCP Router gcp.router.bfd.control.receive_intervals bfd.control.ReceiveIntervals GCP Router gcp.router.bfd.control.received_packets_count bfd.control.ReceivedPackets GCP Router gcp.router.bfd.control.rejected_packets_count bfd.control.RejectedPackets GCP Router gcp.router.bfd.control.transmit_intervals bfd.control.TransmitIntervals GCP Router gcp.router.bfd.control.transmitted_packets_count bfd.control.TransmittedPackets GCP Router gcp.router.bfd.session_up bfd.SessionUp GCP Router gcp.router.bgp_sessions_down_count BgpSessionsDown GCP Router gcp.router.bgp_sessions_up_count BgpSessionsUp GCP Router gcp.router.bgp.received_routes_count bgp.ReceivedRoutes GCP Router gcp.router.bgp.sent_routes_count bgp.SentRoutes GCP Router gcp.router.bgp.session_up bgp.SessionUp GCP Router gcp.router.router_up RouterUp GCP Router gcp.router.sent_routes_count SentRoutes GCP Router gcp.router.nat.allocated_ports nat.AllocatedPorts GCP Router gcp.router.nat.closed_connections_count nat.ClosedConnections GCP Router gcp.router.nat.dropped_received_packets_count nat.DroppedReceivedPackets GCP Router gcp.router.nat.new_connections_count nat.NewConnections GCP Router gcp.router.nat.port_usage nat.PortUsage GCP Router gcp.router.nat.received_bytes_count nat.ReceivedBytes GCP Router gcp.router.nat.received_packets_count nat.ReceivedPackets GCP Router gcp.router.nat.sent_bytes_count nat.SentBytes GCP Router gcp.router.nat.sent_packets_count nat.SentPackets GCP Run gcp.run.container.billable_instance_time container.BillableInstanceTime GCP Run gcp.run.container.cpu.allocation_time container.cpu.AllocationTime GCP Run gcp.run.container.memory.allocation_time container.memory.AllocationTime GCP Run gcp.run.request_count Request GCP Run gcp.run.request_latencies RequestLatencies GCP Spanner gcp.spanner.api.received_bytes_count api.ReceivedBytes GCP Spanner gcp.spanner.api.request_count api.Requests GCP Spanner gcp.spanner.api.request_latencies api.RequestLatencies GCP Spanner gcp.spanner.instance.cpu.utilization instance.cpu.Utilization GCP Spanner gcp.spanner.instance.node_count instance.nodes GCP Spanner gcp.spanner.instance.session_count instance.sessions GCP Spanner gcp.spanner.instance.storage.used_bytes instance.storage.UsedBytes GCP Cloud SQL gcp.cloudsql.database.auto_failover_request_count database.AutoFailoverRequest GCP Cloud SQL gcp.cloudsql.database.available_for_failover database.AvailableForFailover GCP Cloud SQL gcp.cloudsql.database.cpu.reserved_cores database.cpu.ReservedCores GCP Cloud SQL gcp.cloudsql.database.cpu.usage_time database.cpu.UsageTime GCP Cloud SQL gcp.cloudsql.database.cpu.utilization database.cpu.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.bytes_used database.disk.BytesUsed GCP Cloud SQL gcp.cloudsql.database.disk.quota database.disk.Quota GCP Cloud SQL gcp.cloudsql.database.disk.read_ops_count database.disk.ReadOps GCP Cloud SQL gcp.cloudsql.database.disk.utilization database.disk.Utilization GCP Cloud SQL gcp.cloudsql.database.disk.write_ops_count database.disk.WriteOps GCP Cloud SQL gcp.cloudsql.database.memory.quota database.memory.Quota GCP Cloud SQL gcp.cloudsql.database.memory.usage database.memory.Usage GCP Cloud SQL gcp.cloudsql.database.memory.utilization database.memory.Utilization GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_dirty database.mysql.InnodbBufferPoolPagesDirty GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_free database.mysql.InnodbBufferPoolPagesFree GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_buffer_pool_pages_total database.mysql.InnodbBufferPoolPagesTotal GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_data_fsyncs database.mysql.InnodbDataFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_os_log_fsyncs database.mysql.InnodbOsLogFsyncs GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_read database.mysql.InnodbPagesRead GCP Cloud SQL gcp.cloudsql.database.mysql.innodb_pages_written database.mysql.InnodbPagesWritten GCP Cloud SQL gcp.cloudsql.database.mysql.queries database.mysql.Queries GCP Cloud SQL gcp.cloudsql.database.mysql.questions database.mysql.Questions GCP Cloud SQL gcp.cloudsql.database.mysql.received_bytes_count database.mysql.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.mysql.replication.seconds_behind_master database.mysql.replication.SecondsBehindMaster GCP Cloud SQL gcp.cloudsql.database.mysql.sent_bytes_count database.mysql.SentBytes GCP Cloud SQL gcp.cloudsql.database.network.connections database.network.Connections GCP Cloud SQL gcp.cloudsql.database.network.received_bytes_count database.network.ReceivedBytes GCP Cloud SQL gcp.cloudsql.database.network.sent_bytes_count database.network.SentBytes GCP Cloud SQL gcp.cloudsql.database.postgresql.num_backends database.postgresql.NumBackends GCP Cloud SQL gcp.cloudsql.database.postgresql.replication.replica_byte_lag database.postgresql.replication.ReplicaByteLag GCP Cloud SQL gcp.cloudsql.database.postgresql.transaction_count database.postgresql.Transaction GCP Cloud SQL gcp.cloudsql.database.up database.Up GCP Cloud SQL gcp.cloudsql.database.uptime database.Uptime GCP Cloud Storage gcp.storage.api.request_count api.Requests GCP Cloud Storage gcp.storage.network.received_bytes_count network.ReceivedBytes GCP Cloud Storage gcp.storage.network.sent_bytes_count network.SentBytes GCP VMs gcp.compute.firewall.dropped_bytes_count firewall.DroppedBytes GCP VMs gcp.compute.firewall.dropped_packets_count firewall.DroppedPackets GCP VMs gcp.compute.instance.cpu.reserved_cores instance.cpu.ReservedCores GCP VMs gcp.compute.instance.cpu.utilization instance.cpu.Utilization GCP VMs gcp.compute.instance.disk.read_bytes_count instance.disk.ReadBytes GCP VMs gcp.compute.instance.disk.read_ops_count instance.disk.ReadOps GCP VMs gcp.compute.instance.disk.write_bytes_count instance.disk.WriteBytes GCP VMs gcp.compute.instance.disk.write_ops_count instance.disk.WriteOps GCP VMs gcp.compute.instance.network.received_bytes_count instance.network.ReceivedBytes GCP VMs gcp.compute.instance.network.received_packets_count instance.network.ReceivedPackets GCP VMs gcp.compute.instance.network.sent_bytes_count instance.network.SentBytes GCP VMs gcp.compute.instance.network.sent_packets_count instance.network.SentPackets GCP VMs gcp.compute.instance.disk.throttled_read_bytes_count instance.disk.ThrottledReadBytes GCP VMs gcp.compute.instance.disk.throttled_read_ops_count instance.disk.ThrottledReadOps GCP VMs gcp.compute.instance.disk.throttled_write_bytes_count instance.disk.ThrottledWriteBytes GCP VMs gcp.compute.instance.disk.throttled_write_ops_count instance.disk.ThrottledWriteOps GCP VPC Access gcp.vpcaccess.connector.received_bytes_count connector.ReceivedBytes GCP VPC Access gcp.vpcaccess.connector.received_packets_count connector.ReceivedPackets GCP VPC Access gcp.vpcaccess.connector.sent_bytes_count connector.SentBytes GCP VPC Access gcp.vpcaccess.connector.sent_packets_count connector.SentPackets",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.53109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GCP <em>integration</em> metrics",
        "sections": "<em>Google</em> <em>Cloud</em> Metrics",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. <em>Google</em> <em>Cloud</em> Metrics The following table contains the metrics we collect for GCP. Integration Dimensional Metric Name (new) Sample Metric Name (previous) GCP App Engine gcp.appengine.flex.cpu.reserved_cores flex.cpu.ReservedCores GCP App Engine"
      },
      "id": "617d6e7e28ccbceb0c800c36"
    }
  ],
  "/docs/infrastructure/host-integrations/get-started/introduction-host-integrations": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-12-31T01:42:58Z",
      "updated_at": "2021-12-25T15:23:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). macOS: 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, 2019, and 2022, and their service packs. Windows 10 and their service packs. macOS 10.15 (Catalina), 11 (Big Sur), 12 (Monterey). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.60458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Unique <em>hostname</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Before installing our infrastructure agent, make sure your system and any on-<em>host</em> <em>integrations</em> you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2021-12-31T01:40:19Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.66817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "After you sign up for a New Relic account (it&#x27;s free, forever!) and install any of our monitoring services, you can <em>start</em> working with your data. <em>Get</em> <em>started</em> quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    },
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.88141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/apache-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/cassandra-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/collectd-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/couchbase-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/f5-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65381,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration": [
    {
      "sections": [
        "Cloud services integrations",
        "AWS integrations",
        "GCP integrations",
        "Azure integrations"
      ],
      "title": "Cloud services integrations",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Instrument core services and applications"
      ],
      "external_id": "509277aa4f9f8ad66cf5f82a94104531df64c296",
      "image": "https://docs.newrelic.com/static/78ac85c1fc41f94776fce7235e327f01/69538/img-integration-aws%25402x.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/cloud-services-integrations/",
      "published_at": "2021-12-31T01:17:30Z",
      "updated_at": "2021-10-24T00:48:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 64.8916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cloud services <em>integrations</em>",
        "sections": "Cloud services <em>integrations</em>",
        "tags": "<em>Instrument</em> <em>everything</em>",
        "body": "With New Relic you can easily <em>instrument</em> <em>your</em> services in AWS, Google Cloud Platform, and Azure. AWS <em>integrations</em> Introduction to AWS <em>integrations</em> List of AWS <em>integrations</em> GCP <em>integrations</em> Introduction to GCP <em>integrations</em> List of GCP <em>integrations</em> Azure <em>integrations</em> Introduction to Azure <em>integrations</em> List of Azure <em>integrations</em>"
      },
      "id": "603e829ae7b9d20bb12a080c"
    },
    {
      "image": "https://docs.newrelic.com/static/d2a9c929c7541b67b6fe4c87844fc01b/ae694/prometheus_grafana_dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2020/08/create-grafana-dashboards-prometheus-data-stored-new-relic/",
      "sections": [
        "Create Grafana dashboards with Prometheus data stored in New Relic",
        "Step 1: Get data flowing into New Relic with the Prometheus remote write integration",
        "Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic"
      ],
      "published_at": "2021-12-30T22:01:15Z",
      "title": "Create Grafana dashboards with Prometheus data stored in New Relic",
      "updated_at": "2021-10-19T05:58:32Z",
      "type": "docs",
      "external_id": "da09ab47a2ac806ad3ed1fa67e3a02dd54394383",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’ve teamed up with Grafana Labs so you can use our platform as a data source for Prometheus metrics and see them in your existing dashboards, seamlessly tapping into the reliability, scale, and security provided by New Relic. Follow the steps below or use this more detailed walkthrough to send Prometheus data to New Relic, so that Grafana can populate your existing Prometheus-specific dashboards with that data. This process requires Prometheus version 2.15.0 or higher and Grafana version 6.7.0 or higher. You’ll also need to sign up for New Relic. Here's an example of how these Grafana dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to Instrument Everything – US or Instrument Everything – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get your remote_write URL. For more information on how to set up the Prometheus remote write integration, check out our docs. Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic For more information on how to configure New Relic as a Prometheus data source for Grafana, check out our docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 57.429165,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 1: Get data flowing into New Relic with the Prometheus remote write <em>integration</em>",
        "body": " dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to <em>Instrument</em> <em>Everything</em> – US or <em>Instrument</em> <em>Everything</em> – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get"
      },
      "id": "60445821e7b9d23b585799e4"
    },
    {
      "image": "",
      "url": "https://opensource.newrelic.com/",
      "sections": [
        "Open standards. Open instrumentation. Open collaboration.",
        "Instrumentation projects",
        "Projects that we support",
        "Explore our projects",
        "Projects we sponsor"
      ],
      "published_at": "2022-01-02T01:38:28Z",
      "title": "Home",
      "updated_at": "2021-11-13T01:38:17Z",
      "type": "opensource",
      "external_id": "b7edd20013fd77e66b76c01dd31fb2d8150d1b6e",
      "document_type": "page",
      "popularity": 1,
      "info": "",
      "body": "External Projects Highlighted Projects New Relic Projects Standards Menu External Projects Highlighted Projects New Relic Projects Standards Open standards. Open instrumentation. Open collaboration. We built this site to make it easy for you to explore the open source projects we maintain and the open standards projects we participate in. Learn more. Instrumentation projects Instrument everything with our open source agents, tools, and sdk's or see other highlighted collections. Explore open source instrumentation Projects that we support New Relic contributes resources to the development of these projects. Explore our projects Check out some of the products that we’re developing in open source or view all projects. Projects we sponsor New Relic supports 50+ organizations and developers. Find out more here.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 51.9911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Open standards. Open <em>instrumentation</em>. Open collaboration.",
        "body": " and the open standards projects we participate in. Learn more. Instrumentation projects <em>Instrument</em> <em>everything</em> with our open source agents, tools, and sdk&#x27;s or see other highlighted collections. Explore open source instrumentation Projects that we support New Relic contributes resources to the development"
      },
      "id": "5f3180f7196a6739fffbd71c"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/go-insights-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65381,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/haproxy-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.6538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/hashicorp-consul-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.6538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/jmx-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/kafka-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/memcached-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/microsoft-sql-server-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/mongodb-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21513,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.6525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21513,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.6525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-advanced-config": [
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.78471,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "<em>Configure</em> the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: <em>Advanced</em>: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.7832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "<em>Configure</em> the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: <em>Advanced</em>: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    },
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.87375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "<em>Configure</em> the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": "\\<em>integrations</em>.d\\, create a copy of the sample <em>configuration</em> file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the <em>configuration</em> settings. Restart the infrastructure agent. Tarball installation (<em>advanced</em>) You can also install"
      },
      "id": "617dacb6196a676aaef7dcf3"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21509,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "Varnish Cache monitoring integration",
        "Compatibility and requirements",
        "Quick start",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Configure the integration",
        "Important",
        "Varnish Cache instance settings",
        "Labels/Custom attributes",
        "Example configuration",
        "Configuration for Varnish 6+",
        "Find and use data",
        "Metric data",
        "Tip",
        "Varnish sample metrics",
        "Varnish lock sample metrics",
        "Varnish storage sample metrics",
        "Varnish mempool sample metrics",
        "Varnish backend sample metrics",
        "Inventory data",
        "Check the source code"
      ],
      "title": "Varnish Cache monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "bd83968529635dee50be7f9e1f3d8be4bf7028e2",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/varnish-cache-monitoring-integration/",
      "published_at": "2021-12-30T07:32:06Z",
      "updated_at": "2021-12-04T17:32:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Varnish Cache on-host integration collects and sends inventory and metrics from your Varnish Cache environment to New Relic so you can monitor its health. We collect metrics at the instance, lock, memory pool, storage, and backend levels. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with Varnish Cache 1.0 or higher. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent. Linux distribution or Windows version compatible with our infrastructure agent. Quick start Instrument your Varnish Cache environment quickly and send your telemetry data with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click one of these button to try it out. Guided install EU Guided install Our guided install uses the infrastructure agent to set up the Varnish Cache integration. Not only that, it discovers other applications and log sources running in your environment and then recommends which ones you should instrument. The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your Varnish Cache environment. Install and activate To install the Varnish Cache integration: Linux installation Follow the instructions for installing an integration, using the file name nri-varnish. Change directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp varnish-config.yml.sample varnish-config.yml Copy Edit the varnish-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-varnish .MSI installer image from: http://download.newrelic.com/infrastructure_agent/windows/integrations/nri-varnish/nri-varnish-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-varnish-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp varnish-config.yml.sample varnish-config.yml Copy Edit the varnish-config.yml file as described in the configuration settings. Restart the infrastructure agent. Additional notes: Advanced: It's also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings, refer to our Configuration Format document. Important If you are still using our legacy configuration/definition files please refer to this document for help. Specific settings related to Varnish are defined using the env section of the configuration file. These settings control the connection to your Varnish instance, as well as other security settings and features. The list of valid settings is described in the following section. Varnish Cache instance settings The Varnish Cache integration collects both metrics(M) and inventory(I) information. Check the Applies To column below to find which settings can be used for each specific collection: Setting Description Default Applies To INSTANCE_NAME User defined name to identify data from this instance in New Relic. Required. N/A M/I PARAMS_CONFIG_FILE The location of the varnish.params config file. If this argument is omitted, the following locations will be checked: /etc/default/varnish/varnish.params /etc/sysconfig/varnish/varnish.params Note: The location and name of the Varnish configuration file may vary. For details, see Different locations of the Varnish configuration file. For Varnish versions lower than 6, this parameter is not required and the integration should be set up for metrics collection only. See the example for Varnish 6. N/A I VARNISH_NAME Name used when executing the varnishd daemon with a custom -n flag. Optional. N/A M METRICS Set to true to enable metrics-only collection. false INVENTORY Set to true to enable inventory-only collection. false The varnish-config.yml commands accept the following arguments: The values for these settings can be defined in several ways: Adding the value directly in the config file. This is the most common way. Replacing the values from environment variables using the {{}} notation. This requires infrastructure agent v1.14.0+. Read more here. Using secrets management. Use this to protect sensitive information, such as passwords that would be exposed in plain text on the configuration file. For more information, see Secrets management. Labels/Custom attributes Environment variables can be used to control config settings, such as your license key, and are then passed through to the Infrastructure agent. For instructions on how to use this feature, see Configure the Infrastructure agent. You can further decorate your metrics using labels. Labels allow you to add key/value pairs attributes to your metrics which you can then use to query, filter or group your metrics on. Our default sample config file includes examples of labels but, as they are not mandatory, you can remove, modify or add new ones of your choice. labels: env: production role: varnish Copy Example configuration Example varnish-config.yml file configuration: Example configuration This is the very basic configuration to collect metrics and inventory : integrations: - name: nri-varnish env: INSTANCE_NAME: new_relic PARAMS_CONFIG_FILE: /etc/default/varnish/varnish.params interval: 15s labels: env: production role: varnish inventory_source: config/varnish Copy Configuration for Varnish 6+ This is a basic configuration for Varnish 6 or above. Only metrics will be collected because, starting in Varnish 6, the params file was deprecated. integrations: - name: nri-varnish env: INSTANCE_NAME: new_relic METRICS: true interval: 15s labels: env: production role: varnish inventory_source: config/varnish Copy For more about the general structure of on-host integration configuration, see Configuration. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > Third-party services and select one of the Varnish Cache integration links. In New Relic, Varnish Cache data is attached to the following Insights event type: VarnishSample VarnishLockSample VarnishStorageSample VarnishMempoolSample VarnishBackendSample For more on how to find and use your data, see Understand integration data. Metric data The Varnish Cache integration collects the following metric data attributes. Each metric name is prefixed with a category indicator and a period, such as bans. or main.. Tip A number of metrics are calculated as rates (per second) instead of totals as the metric names might suggest. For more details on which metrics are calculated as rates, refer to the spec.csv file. Varnish sample metrics These attributes can be found by querying the VarnishSample event types. Metric Description backend.connectionBusy Number of times the maximum connection has been reached. backend.connectionFails Number of failed connections to the backed. backend.connectionRecycles Number of backend connections that have been recycled. backend.connectionRetries Number of backend connections that have been retried. backend.connectionReuses Number of backend connections reuses. backend.connectionSuccess Number of successful backend connections, backend.connectionUnHealthy Number of backend connections that were not attempted due to ‘unhealthy’ backend status. backend.fetches Total number of backend fetches initiated. backend.requests Total number of backend connection requests made. bans.added Counter of bans added to ban list. bans.completed Number of bans marked ‘completed'. bans.cutoffLurkerKilled Number of objects killed by bans for cutoff (lurker). bans.deleted Counter of bans deleted from ban list. bans.dups Count of bans replaced by later identical bans. bans.fragmentationInBytes Extra bytes in persisted ban lists due to fragmentation. bans.lookupKilled Number of objects killed by bans during object lookup. bans.lookupTestsTested Count of how many tests and objects have been tested against each other during lookup. bans.lurkerCon Number of times the ban-lurker had to wait for lookups. bans.lurkerKilled Number of objects killed by the ban-lurker. bans.lurkerTested Count of how many bans and objects have been tested against each other by the ban-lurker. bans.lurkerTestsTested Count of how many tests and objects have been tested against each other during by the ban-lurker. bans.obj Number of bans using obj.* variables. These bans can possibly be washed by the ban-lurker. bans.persistedInBytes Bytes used by the persisted ban lists. bans.req Number of bans which use req.* variables. These bans can not be washed by the ban-lurker. bans.tested Count of how many bans and objects have been tested against each other during hash lookup. cache.graceHits Count of cache hits with grace. A cache hit with grace is a cache hit where the object is expired. These hits also included in the cache_hit counter. cache.hits Number of times an object has been delivered to a client without fetching it from a backend server. cache.misses Number of times the object was fetched from the backend before delivering it to the client. cache.missHits Number of times a hit object was returned for a miss response. cache.passHits Number of times a hit object was returned for a pass response. esi.errors Edge Side Includes (ESI) parsing errors (unlock). esi.warnings Edge Side Includes (ESI) parse warnings (unlock). fetch.bad The beresp.body length/fetch could not be determined. fetch.chuncked The beresp.body chunked. fetch.contentLength The beresp.body with content-length. fetch.eof The beresp.body with EOF. fetch.failed The beresp failed. fetch.head The beresp with no body because the request is HEAD. fetch.noBody The beresp with no body. fetch.noBody1xx The beresp with no body because of 1XX response. fetch.noBody204 The beresp with no body because of 204 response. fetch.noBody304 The beresp with no body because of 304 response. fetch.noThreadFail The beresp fetch failed, no thread available. hcb.inserts Number of critical bit tree-based hash (HCB) inserts. hcb.lock Number of HCB lookups with lock. hcb.noLock Number of HCB lookups without lock. lru.limited Number of times more storage space was needed, but limit was reached. lru.moved Number of move operations done on the LRU list. lru.nuked Number of least recently used (LRU) objects forcefully evicted from storage to make room for a new object. main.backends Number of backends. main.bans Count of bans. main.busyKilled Number of requests killed after sleep on busy objhdr. main.busySleep Number of requests sent to sleep on busy objhdr. main.busyWakeup Number of requests woken after sleep on busy objhdr. main.expired Number of expired objects. main.expiredMailed Number of objects mailed to expiry thread. main.expiredReceived Number of objects received by expiry thread. main.gunzip Number of gunzip operations. main.gunzipTest Number of test gunzip operations. main.gzip Number of gzip operations. main.objectcores Number of objectcore structs made. main.objectheads Number of objected structs made. main.objects Number of object structs made. main.passedRequests Total pass-ed requests seen. main.pipeSessions Total pipe sessions seen. main.pools Number of thread pools. main.purgeObjects Number of purged objects. main.purgeOperations Number of purge operations executed. main.reqDropped Number of requests dropped. main.sessions Total number of sessions seen. main.sessQueueLength Length of session queue waiting for threads. main.summs Number of times per-thread statistics were summed into the global counters. main.syntheticResponses Total synthethic responses made. main.threads Total number of threads. main.threadsCreated Total number of threads created in all pools. main.threadsDestroyed Total number of threads destroyed in all pools. main.threadsFailed Number of times creating a thread failed. main.threadsLimited Number of times more threads were needed, but limit was reached in a thread pool. main.unresurrectedObjects Number of unresurrected objects. main.uptimeInMilliseconds The child process uptime, in milliseconds. main.vclAvailable Number of Varnish Configuration Languages (VCL) available. main.vclDiscarded Number of discarded VCLs. main.vclFails Number of VCL failures. main.vclLoaded Number of loaded VCLs in total. main.vmodsLoaded Number of loaded Varnish modules (VMOD). mgt.childDied Number of times the child process has died due to signals. mgt.childDump Number of times the child process has produced core dumps. mgt.childExit Number of times the child process has been cleanly stopped. mgt.childPanic Number of times the management process has caught a child panic. mgt.childStart Number of times the child process has been started. mgt.childStop Number of times the child process has been cleanly stopped. mgt.uptimeInMilliseconds The management process uptime, in milliseconds. net.400Errors Number of client requests received, subject to 400 errors. net.417Errors Number of client requests received, subject to 417 errors net.httpOverflow Number of HTTP header overflows. net.pipe.inInBytes Total number of bytes forwarded from clients in pipe sessions. net.pipe.outInBytes Total number of bytes forwarded to clients in pipe sessions. net.pipereq.headerInBytes Total request bytes received for piped sessions. net.request.bodyInBytes Total request body transmitted, in bytes. net.request.headerInBytes Total request headers transmitted, in bytes. net.requests Number of good client requests received. net.response.bodyInBytes Total response body transmitted, in bytes. net.response.headerInBytes Total response headers transmitted, in bytes. sess.backendClose Number of session closes with the error RESP_CLOSE, (Backend/VCL requested close). sess.badClose Number of session closes with the error Error RX_BAD, (Received bad req/resp). sess.bodyFailClose Number of session closes with the error Error RX_BODY, (Failure receiving req.body). sess.clientClose Number of session closes with the error REM_CLOSE, (Client closed). sess.clientReqClose Number of session closes with the error REQ_CLOSE, (Client requested close). sess.closed Total number of sessions closed. sess.closedError Total number of sessions closed with errors. sess.dropped Number of sessions dropped for thread. sess.eofTxnClose Number of session closes with the error TX_EOF, (EOF transmission). sess.errorTxnClose Number of session closes with the error TX_ERROR, (Error transaction). sess.herd Number of times the timeout_linger triggered. sess.junkClose Number of session closes with the error RX_JUNK, (Received junk data). sess.overflowClose Number of session closes with the error RX_OVERFLOW, (Received buffer overflow). sess.overloadClose Number of session closes with the error OVERLOAD, (Out of some resource). sess.pipeOverflowClose Number of session closes with the error PIPE_OVERFLOW, (Session pipe overflow). sess.pipeTxnClose Number of session closes with the error TX_PIPE, (Piped transaction). sess.queued Number of sessions queued for thread. sess.readAhead Session Read Ahead. sess.requestHTTP10Close Number of session closes with the error REQ_HTTP10, (Proto < HTTP/1.1). sess.requestHTTP20Close Number of session closes with the error REQ_HTTP20, (HTTP2 not accepted). sess.shortRangeClose Number of session closes with the error RANGE_SHORT, (Insufficient data for range). sess.timeoutClose Number of session closes with the error RX_TIMEOUT, (Receive timeout). sess.vclFailClose Number of session closes with the error VCL_FAILURE, (VCL failure). session.connections Count of sessions successfully accepted. session.drops Count of sessions silently dropped due to lack of worker thread. session.fail Count of failures to accept TCP connection. shm.contentions Number of shared memory (SHM) MTX contentions. shm.cycles Number of SHM cycles through buffer. shm.flushes Number of SHM flushes due to overflow. shm.records Number of SHM records. shm.writes Number of SHM writes. workspace.backendOverflow Number of times we ran out of space in workspace_backend. workspace.clientOverflow Number of times we ran out of space in workspace_client. workspace.deliveryFail Delivery failed due to insufficient workspace. workspace.sessionOverflow Number of times we ran out of space in workspace_session. workspace.threadOverflow Number of times we ran out of space in workspace_thread. Varnish lock sample metrics These attributes can be found by querying the VarnishLockSample event types in Insights. Metric Description lock.created Count of created locks. lock.destroyed Count of destroyed locks. lock.locks Count of lock operations. Varnish storage sample metrics These attributes can be found by querying the VarnishStorageSample event type. Metric Description storage.allocFails Number of times the storage has failed to provide a storage segment. storage.allocInBytes Number of total bytes allocated by this storage. storage.allocOustanding Number of storage allocations outstanding. storage.allocReqs Number of times the storage has been asked to provide a storage segment. storage.availableInBytes Number of bytes left in the storage. storage.freeInBytes Number of total bytes returned to this storage. storage.outstandingInBytes Number of bytes allocated from the storage. Varnish mempool sample metrics These attributes can be found by querying the VarnishMempoolSample event types in Insights. Metric Description mempool.allocatedSizeInBytes Allocated size of memory pool, in bytes. mempool.allocs Memory pool allocations. mempool.frees Number of memory pools free. mempool.live Number of memory pools in use. mempool.pool Count in memory pool. mempool.ranDry Pool ran dry. mempool.recycles Recycled from pool. mempool.requestSizeInBytes Request size of memory pool, in bytes. mempool.surplus Too many for pool. mempool.timeouts Timed out from pool. mempool.tooSmall Too small to recycle. Varnish backend sample metrics These attributes can be found by querying the VarnishBackendSample event type. Metric Description backend.busyFetches Fetches not attempted due to backend being busy. backend.connections Number of concurrent connections to the backend. backend.connectionsFailed Number of backend connections failed. backend.connectionsNotAttempted Number of backend connection opens not attempted. backend.happy Happy health probes. backend.unhealtyFetches Fetches not attempted due to backend being unhealthy net.backend.pipeHeaderInBytes Total request bytes sent for piped sessions. net.backend.pipeInInBytes Total number of bytes forwarded from backend in pipe sessions. net.backend.pipeOutInBytes Total number of bytes forwarded to backend in pipe sessions. net.backend.requestBodyInBytes Total backend request body bytes sent. net.backend.requestHeaderInBytes Total backend request header bytes sent. net.backend.requests Number of backend requests sent, net.backend.responseBodyInBytes Total backend response body bytes received. net.backend.responseHeaderInBytes Total backend response header bytes received. Inventory data The Varnish Cache integration captures the configuration parameters. It parses the varnish.params configuration file for all parameters that are active. The data is available on the Inventory page, under the config/varnish source. For more about inventory data, see Understand integration data. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.95828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Varnish Cache monitoring <em>integration</em>",
        "sections": "Varnish Cache monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": ". Restart the infrastructure agent. Additional notes: Advanced: It&#x27;s also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update"
      },
      "id": "617dac7b28ccbcc6307ff095"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/nagios-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21509,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/nfs-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21504,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-advanced-config": [
    {
      "sections": [
        "MySQL's integration advanced configuration",
        "MySQL Instance Settings",
        "Metrics",
        "Default metrics",
        "Extended metrics",
        "Extended innodb metrics",
        "Extended myisam metrics",
        "Extended slave cluster metrics",
        "Inventory",
        "System metadata"
      ],
      "title": "MySQL's integration advanced configuration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list",
        "Advanced configuration"
      ],
      "external_id": "7d74a4b91a915c5dae17f0828dd9e0e91406bab2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-advanced-config/",
      "published_at": "2021-12-30T21:51:25Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The MySQL integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. MySQL Instance Settings The MySQL integration collects both Metrics and Inventory information. In the table, use the Applies to column for the settings available to each collection: Setting Description Default Applies to HOSTNAME Hostname or IP where MySQL is running. localhost Metrics/Inventory PORT Port on which MySQL server is listening. 3306 Metrics/Inventory USERNAME Username for accessing the MySQL server. N/A Metrics/Inventory PASSWORD Password for the given user. N/A Metrics/Inventory SOCKET Path to Unix socket file on which MySQL server is listening. Use this instead of Hostname/Port. N/A Metrics/Inventory DATABASE Name of the database to be monitored. If omitted all databases will be monitored. N/A Metrics/Inventory USE_TLS Use TLS when communicating with the MySQL server. false Metrics/Inventory INSECURE_SKIP_VERIFY Disable server name verification when connecting over TLS. false Metrics/Inventory OLD_PASSWORDS Use old password hashing method. false Metrics/Inventory EXTRA_CONNECTION_URL_ARGS Specify extra connection parameters as attr1=val1&attr2=val2. N/A Metrics/Inventory EXTENDED_METRICS Captures an extended set of metrics. This also enables the capture of slave metrics. false Metrics EXTENDED_INNODB_METRICS Captures additional innodb metrics. false Metrics EXTENDED_MY_ISAM_METRICS Captures additional MyISAM metrics. false Metrics REMOTE_MONITORING Enable multi-tenancy monitoring. Read more about remote monitoring. true Metrics/Inventory METRICS Set to true to enable metrics-only collection. false INVENTORY Set to true to enable inventory-only collection. false The values for these settings can be defined in several ways: Add the value directly to the configuration file. This is the most common way. Replace the values from environment variables using the {{}} notation. This requires infrastructure agent 1.14.0+. For more on this, see more on infrastructure agent passthrough environment variables. Use secrets management to protect sensible information, such as passwords, so that it's not exposed in plain text on the configuration file. For more information, see secrets management. Metrics The MySQL integration collects the following metrics: Default metrics Extended metrics Extended innodb metrics Extended myisam metrics Extended slave cluster metrics Default metrics These metrics are captured by default: Name Description cluster.slaveRunning Boolean. 1 if this server is a replication slave that is connected to a replication master, and both the I/O and SQL threads are running; otherwise, it is 0. For metrics reported if enabled, see replication slave metrics. db.handlerRollbackPerSecond Rate of requests for a storage engine to perform a rollback operation, per second. db.innodb.bufferPoolPagesData Number of pages in the InnoDB buffer pool containing data. db.innodb.bufferPoolPagesFree Number of free pages in the InnoDB buffer pool. db.innodb.bufferPoolPagesTotal Total number of pages of the InnoDB buffer pool. db.innodb.dataReadBytesPerSecond Rate at which data is read from InnoDB tables in bytes per second. db.innodb.dataWrittenBytesPerSecond Rate at which data is written to InnoDB tables in bytes per second. db.innodb.logWaitsPerSecond Number of times that the log buffer was too small and a wait was required for it to be flushed before continuing, in waits per second. db.innodb.rowLockCurrentWaits Number of row locks currently being waited for by operations on InnoDB tables. db.innodb.rowLockTimeAvg Average time to acquire a row lock for InnoDB tables, in milliseconds. db.innodb.rowLockWaitsPerSecond Number of times operations on InnoDB tables had to wait for a row lock per second. db.openedTablesPerSecond Number of files that have been opened with my_open() (a mysys library function) per second. Parts of the server that open files without using this function do not increment the count. db.openFiles Number of files that are open. This count includes regular files opened by the server. It does not include other types of files such as sockets or pipes. db.openTables Number of tables that are open. db.qCacheFreeMemoryBytes Amount of free memory in bytes for the query cache. db.qCacheHitRatio Percentage of queries that are retrieved from the cache. db.qCacheNotCachedPerSecond Number of noncached queries (not cacheable, or not cached due to the query_cache_type setting) per second. db.qCacheUtilization Percentage of query cache memory that is being used. db.tablesLocksWaitedPerSecond Number of times per second that a request for a table lock could not be granted immediately and a wait was needed. net.abortedClientsPerSecond Number of connections per second that were aborted because the client died without closing the connection properly. net.abortedConnectsPerSecond Number of failed attempts to connect to the MySQL server, per second. net.bytesReceivedPerSecond Byte throughput received from all clients, per second. net.bytesSentPerSecond Byte throughput sent to all clients, per second. net.connectionErrorsMaxConnectionsPerSecond Rate per second at which connections were refused because the server max_connections limit was reached. net.connectionsPerSecond Number of connection attempts per second. net.maxUsedConnections Maximum number of connections that have been in use simultaneously since the server started. net.threadsConnected Number of currently open connections. net.threadsRunning Number of threads that are not sleeping. query.comCommitPerSecond Number of COMMIT statements executed per second. query.comDeletePerSecond Number of DELETE statements executed per second. query.comDeleteMultiPerSecond Number of DELETE statements that use the multiple-table syntax executed per second. query.comInsertPerSecond Number of INSERT statements executed per second. query.comInsertSelectPerSecond Number of INSERT SELECT statements executed per second. query.comReplaceSelectPerSecond Number of REPLACE SELECT statements executed per second. query.comRollbackPerSecond Number of ROLLBACK statements executed per second. query.comSelectPerSecond Number of SELECT statements executed per second. query.comUpdateMultiPerSecond Number of UPDATE statements that use the multiple-table syntax executed per second. query.comUpdatePerSecond Number of UPDATE statements executed per second. query.preparedStmtCountPerSecond Current number of prepared statements per second. (The maximum number of statements is given by the max_prepared_stmt_count system variable.) query.queriesPerSecond Total number of statements executed by the server per second, including statements executed within stored programs. query.questionsPerSecond Number of statements executed by the server per second, limited to only those sent by clients. query.slowQueriesPerSecond Number of queries per second that have taken more than long_query_time seconds. This counter increments regardless of whether the slow query log is enabled. Extended metrics Additional metrics captured when extended_metrics is enabled (set to 1 in the configuration file): Name Description db.createdTmpDiskTablesPerSecond Number of internal on-disk temporary tables created per second by the server while executing statements. db.createdTmpFilesPerSecond Number of temporary files created per second by mysqld. db.createdTmpTablesPerSecond Number of internal temporary tables created per second by the server while executing statements. db.handlerDeletePerSecond Number of times per second that rows have been deleted from tables. db.handlerReadFirstPerSecond Number of times per second the first entry in an index was read. db.handlerReadKeyPerSecond Number of requests per second to read a row based on a key. db.handlerReadRndNextPerSecond Number of requests per second to read the next row in the data file. db.handlerReadRndPerSecond Number of requests per second to read a row based on a fixed position. db.handlerUpdatePerSecond Number of requests per second to update a row in a table. db.handlerWritePerSecond Number of requests per second to insert a row in a table. db.maxExecutionTimeExceededPerSecond Number of SELECT statements per second for which the execution timeout was exceeded. db.qCacheFreeBlocks Number of free memory blocks in the query cache. db.qCacheHitsPerSecond Number of query cache hits per second. db.qCacheInserts Number of queries added to the query cache. db.qCacheLowmemPrunesPerSecond Number of queries per second that were deleted from the query cache because of low memory. db.qCacheQueriesInCachePerSecond Number of queries per second registered in the query cache. db.qCacheTotalBlocks Total number of blocks in the query cache. db.selectFullJoinPerSecond Number of joins that perform table scans because they do not use indexes, per second. db.selectFullJoinRangePerSecond Number of joins per second that used a range search on a reference table. db.selectRangeCheckPerSecond Number of joins per second without keys that check for key usage after each row. db.selectRangePerSecond Number of joins per second that used ranges on the first table. db.sortMergePassesPerSecond Number of merge passes that the sort algorithm has had to do, per second. db.sortRangePerSecond Number of sorts per second that were done using ranges. db.sortRowsPerSecond Number of sorted rows per second. db.sortScanPerSecond Number of sorts that were done by scanning the table, per second. db.tableOpenCacheHitsPerSecond Number of hits per second for open tables cache lookups. db.tableOpenCacheMissesPerSecond Number of misses per second for open tables cache lookups. db.tableOpenCacheOverflowsPerSecond Number of overflows per second for the open tables cache. db.threadCacheMissRate Percent of threads that need to be created to handle new connections because there are not enough threads available in the cache. db.threadsCached Number of threads in the thread cache. db.threadsCreatedPerSecond Number of threads per second created to handle connections. Extended innodb metrics Additional metrics captured when extended_innodb_metrics is enabled (set to 1 in the configuration file): Name Description db.innodb.bufferPoolPagesDirty Current number of dirty pages in the InnoDB buffer pool. db.innodb.bufferPoolPagesFlushedPerSecond Number of requests per second to flush pages from the InnoDB buffer pool. db.innodb.bufferPoolReadAheadEvictedPerSecond Number of pages per second read into the InnoDB buffer pool by the read-ahead background thread that were subsequently evicted without having been accessed by queries. db.innodb.bufferPoolReadAheadPerSecond Number of pages per second read into the InnoDB buffer pool by the read-ahead background thread. db.innodb.bufferPoolReadAheadRndPerSecond Number of “random” read-aheads per second initiated by InnoDB. This happens when a query scans a large portion of a table but in random order. db.innodb.bufferPoolReadRequestsPerSecond Number of logical read requests per second. db.innodb.bufferPoolReadsPerSecond Number of logical reads that InnoDB could not satisfy from the buffer pool, and had to read directly from disk, per second. db.innodb.bufferPoolWaitFreePerSecond Number of times per second a read or write to InnoDB had to wait because there were not clean pages available in the buffer pool. db.innodb.bufferPoolWriteRequestsPerSecond Number of writes per second done to the InnoDB buffer pool. db.innodb.dataFsyncsPerSecond Number of fsync() operations per second. db.innodb.dataPendingFsyncs Current number of pending fsync() operations. db.innodb.dataPendingReads Current number of pending reads. db.innodb.dataPendingWrites Current number of pending writes. db.innodb.dataReadsPerSecond Number of data reads (OS file reads) per second. db.innodb.dataWritesPerSecond Number of data writes per second. db.innodb.logWriteRequestsPerSecond Number of write requests for the InnoDB redo log per second. db.innodb.logWritesPerSecond Number of physical writes per second to the InnoDB redo log file. db.innodb.numOpenFiles Number of files InnoDB currently holds open. db.innodb.osLogFsyncsPerSecond Number of fsync() writes per second done to the InnoDB redo log files. db.innodb.osLogPendingFsyncs Number of pending fsync() operations for the InnoDB redo log files. db.innodb.osLogPendingWrites Number of pending writes per second to the InnoDB redo log files. db.innodb.osLogWrittenBytesPerSecond rate Number of bytes written per second to the InnoDB redo log files. db.innodb.pagesCreatedPerSecond The number of pages created per second by operations on InnoDB tables. db.innodb.pagesReadPerSecond Number of pages read per second from the InnoDB buffer pool by operations on InnoDB tables. db.innodb.pagesWrittenPerSecond Number of pages written per second by operations on InnoDB tables. db.innodb.rowsDeletedPerSecond Number of rows deleted per second from InnoDB tables. db.innodb.rowsInsertedPerSecond Number of rows per second inserted into InnoDB tables. db.innodb.rowsReadPerSecond Number of rows per second read from InnoDB tables. db.innodb.rowsUpdatedPerSecond Number of rows per second updated in InnoDB tables. Extended myisam metrics Additional metrics captured when extended_myisam_metrics is enabled in the configuration file: Name Description db.myisam.keyBlocksNotFlushed Number of key blocks in the MyISAM key cache that have changed but have not yet been flushed to disk. db.myisam.keyCacheUtilization Percentage of the key cache that is being used. db.myisam.keyReadRequestsPerSecond Number of requests to read a key block from the MyISAM key cache, per second. db.myisam.keyReadsPerSecond Number of physical reads of a key block from disk into the MyISAM key cache, per second. db.myisam.keyWriteRequestsPerSecond Number of requests per second to write a key block to the MyISAM key cache. db.myisam.keyWritesPerSecond Number of physical writes of a key block from the MyISAM key cache to disk, per second. Extended slave cluster metrics Additional metrics captured when the extended metrics flag is enabled in the configuration file and the cluster.slaveRunning metric is returning a value of 1. Check the MySQL Documentation for more details. Name Description db.relayLogSpace Total combined number of bytes for all existing relay log files. cluster.lastIOErrno Error number of the most recent error that caused the I/O thread to stop. cluster.lastIOError Error message of the most recent error that caused the I/O thread to stop. cluster.lastSQLErrno Error number of the most recent error that caused the SQL thread to stop. cluster.lastSQLError Error message of the most recent error that caused the SQL thread to stop. cluster.slaveIORunning Status of whether the I/O thread is started and has connected successfully to the master. The values can be Yes, No, or Connecting. cluster.slaveSQLRunning Status of whether the SQL thread is started. The values can be Yes or No. cluster.secondsBehindMaster Difference in seconds between the slave’s clock time and the timestamp of the query when it was recorded in the master’s binary log. When the slave is not correctly connected to the master, this metric won’t be reported. cluster.masterLogFile Name of the master binary log file from which the I/O thread is currently reading. cluster.readMasterLogPos Position in the current master binary log file up to which the I/O thread has read. cluster.relayMasterLogFile Name of the master binary log file containing the most recent event executed by the SQL thread. cluster.execMasterLogPos Position in the current master binary log file to which the SQL thread has read and executed, marking the start of the next transaction or event to be processed. Inventory The MySQL integration captures the configuration parameters of the MySQL node returned by SHOW GLOBAL VARIABLES. The data is available on the Inventory page, under the config/mysql source. System metadata The MySQL integration collects the following metadata attributes about your MySQL system: Name Description software.edition software.edition takes the value of the MySQL version_comment variable. software.version The MySQL server version. cluster.nodeType Either master or slave, depending on the role of the MySQL node being monitored.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.18439,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL&#x27;s <em>integration</em> <em>advanced</em> <em>configuration</em>",
        "sections": "MySQL&#x27;s <em>integration</em> <em>advanced</em> <em>configuration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " in several ways: Add the value directly to the <em>configuration</em> file. This is the most common way. Replace the values from environment variables using the {{}} notation. This requires infrastructure agent 1.14.0+. For more on this, see more on infrastructure agent passthrough environment variables. Use"
      },
      "id": "61ac559ee7b9d2201d0e7bdd"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.39857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "<em>Configure</em> the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: <em>Advanced</em>: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.39757,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "<em>Configure</em> the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: <em>Advanced</em>: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    },
    {
      "sections": [
        "Varnish Cache monitoring integration",
        "Compatibility and requirements",
        "Quick start",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Configure the integration",
        "Important",
        "Varnish Cache instance settings",
        "Labels/Custom attributes",
        "Example configuration",
        "Configuration for Varnish 6+",
        "Find and use data",
        "Metric data",
        "Tip",
        "Varnish sample metrics",
        "Varnish lock sample metrics",
        "Varnish storage sample metrics",
        "Varnish mempool sample metrics",
        "Varnish backend sample metrics",
        "Inventory data",
        "Check the source code"
      ],
      "title": "Varnish Cache monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "bd83968529635dee50be7f9e1f3d8be4bf7028e2",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/varnish-cache-monitoring-integration/",
      "published_at": "2021-12-30T07:32:06Z",
      "updated_at": "2021-12-04T17:32:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Varnish Cache on-host integration collects and sends inventory and metrics from your Varnish Cache environment to New Relic so you can monitor its health. We collect metrics at the instance, lock, memory pool, storage, and backend levels. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with Varnish Cache 1.0 or higher. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent. Linux distribution or Windows version compatible with our infrastructure agent. Quick start Instrument your Varnish Cache environment quickly and send your telemetry data with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click one of these button to try it out. Guided install EU Guided install Our guided install uses the infrastructure agent to set up the Varnish Cache integration. Not only that, it discovers other applications and log sources running in your environment and then recommends which ones you should instrument. The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your Varnish Cache environment. Install and activate To install the Varnish Cache integration: Linux installation Follow the instructions for installing an integration, using the file name nri-varnish. Change directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp varnish-config.yml.sample varnish-config.yml Copy Edit the varnish-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-varnish .MSI installer image from: http://download.newrelic.com/infrastructure_agent/windows/integrations/nri-varnish/nri-varnish-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-varnish-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp varnish-config.yml.sample varnish-config.yml Copy Edit the varnish-config.yml file as described in the configuration settings. Restart the infrastructure agent. Additional notes: Advanced: It's also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings, refer to our Configuration Format document. Important If you are still using our legacy configuration/definition files please refer to this document for help. Specific settings related to Varnish are defined using the env section of the configuration file. These settings control the connection to your Varnish instance, as well as other security settings and features. The list of valid settings is described in the following section. Varnish Cache instance settings The Varnish Cache integration collects both metrics(M) and inventory(I) information. Check the Applies To column below to find which settings can be used for each specific collection: Setting Description Default Applies To INSTANCE_NAME User defined name to identify data from this instance in New Relic. Required. N/A M/I PARAMS_CONFIG_FILE The location of the varnish.params config file. If this argument is omitted, the following locations will be checked: /etc/default/varnish/varnish.params /etc/sysconfig/varnish/varnish.params Note: The location and name of the Varnish configuration file may vary. For details, see Different locations of the Varnish configuration file. For Varnish versions lower than 6, this parameter is not required and the integration should be set up for metrics collection only. See the example for Varnish 6. N/A I VARNISH_NAME Name used when executing the varnishd daemon with a custom -n flag. Optional. N/A M METRICS Set to true to enable metrics-only collection. false INVENTORY Set to true to enable inventory-only collection. false The varnish-config.yml commands accept the following arguments: The values for these settings can be defined in several ways: Adding the value directly in the config file. This is the most common way. Replacing the values from environment variables using the {{}} notation. This requires infrastructure agent v1.14.0+. Read more here. Using secrets management. Use this to protect sensitive information, such as passwords that would be exposed in plain text on the configuration file. For more information, see Secrets management. Labels/Custom attributes Environment variables can be used to control config settings, such as your license key, and are then passed through to the Infrastructure agent. For instructions on how to use this feature, see Configure the Infrastructure agent. You can further decorate your metrics using labels. Labels allow you to add key/value pairs attributes to your metrics which you can then use to query, filter or group your metrics on. Our default sample config file includes examples of labels but, as they are not mandatory, you can remove, modify or add new ones of your choice. labels: env: production role: varnish Copy Example configuration Example varnish-config.yml file configuration: Example configuration This is the very basic configuration to collect metrics and inventory : integrations: - name: nri-varnish env: INSTANCE_NAME: new_relic PARAMS_CONFIG_FILE: /etc/default/varnish/varnish.params interval: 15s labels: env: production role: varnish inventory_source: config/varnish Copy Configuration for Varnish 6+ This is a basic configuration for Varnish 6 or above. Only metrics will be collected because, starting in Varnish 6, the params file was deprecated. integrations: - name: nri-varnish env: INSTANCE_NAME: new_relic METRICS: true interval: 15s labels: env: production role: varnish inventory_source: config/varnish Copy For more about the general structure of on-host integration configuration, see Configuration. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > Third-party services and select one of the Varnish Cache integration links. In New Relic, Varnish Cache data is attached to the following Insights event type: VarnishSample VarnishLockSample VarnishStorageSample VarnishMempoolSample VarnishBackendSample For more on how to find and use your data, see Understand integration data. Metric data The Varnish Cache integration collects the following metric data attributes. Each metric name is prefixed with a category indicator and a period, such as bans. or main.. Tip A number of metrics are calculated as rates (per second) instead of totals as the metric names might suggest. For more details on which metrics are calculated as rates, refer to the spec.csv file. Varnish sample metrics These attributes can be found by querying the VarnishSample event types. Metric Description backend.connectionBusy Number of times the maximum connection has been reached. backend.connectionFails Number of failed connections to the backed. backend.connectionRecycles Number of backend connections that have been recycled. backend.connectionRetries Number of backend connections that have been retried. backend.connectionReuses Number of backend connections reuses. backend.connectionSuccess Number of successful backend connections, backend.connectionUnHealthy Number of backend connections that were not attempted due to ‘unhealthy’ backend status. backend.fetches Total number of backend fetches initiated. backend.requests Total number of backend connection requests made. bans.added Counter of bans added to ban list. bans.completed Number of bans marked ‘completed'. bans.cutoffLurkerKilled Number of objects killed by bans for cutoff (lurker). bans.deleted Counter of bans deleted from ban list. bans.dups Count of bans replaced by later identical bans. bans.fragmentationInBytes Extra bytes in persisted ban lists due to fragmentation. bans.lookupKilled Number of objects killed by bans during object lookup. bans.lookupTestsTested Count of how many tests and objects have been tested against each other during lookup. bans.lurkerCon Number of times the ban-lurker had to wait for lookups. bans.lurkerKilled Number of objects killed by the ban-lurker. bans.lurkerTested Count of how many bans and objects have been tested against each other by the ban-lurker. bans.lurkerTestsTested Count of how many tests and objects have been tested against each other during by the ban-lurker. bans.obj Number of bans using obj.* variables. These bans can possibly be washed by the ban-lurker. bans.persistedInBytes Bytes used by the persisted ban lists. bans.req Number of bans which use req.* variables. These bans can not be washed by the ban-lurker. bans.tested Count of how many bans and objects have been tested against each other during hash lookup. cache.graceHits Count of cache hits with grace. A cache hit with grace is a cache hit where the object is expired. These hits also included in the cache_hit counter. cache.hits Number of times an object has been delivered to a client without fetching it from a backend server. cache.misses Number of times the object was fetched from the backend before delivering it to the client. cache.missHits Number of times a hit object was returned for a miss response. cache.passHits Number of times a hit object was returned for a pass response. esi.errors Edge Side Includes (ESI) parsing errors (unlock). esi.warnings Edge Side Includes (ESI) parse warnings (unlock). fetch.bad The beresp.body length/fetch could not be determined. fetch.chuncked The beresp.body chunked. fetch.contentLength The beresp.body with content-length. fetch.eof The beresp.body with EOF. fetch.failed The beresp failed. fetch.head The beresp with no body because the request is HEAD. fetch.noBody The beresp with no body. fetch.noBody1xx The beresp with no body because of 1XX response. fetch.noBody204 The beresp with no body because of 204 response. fetch.noBody304 The beresp with no body because of 304 response. fetch.noThreadFail The beresp fetch failed, no thread available. hcb.inserts Number of critical bit tree-based hash (HCB) inserts. hcb.lock Number of HCB lookups with lock. hcb.noLock Number of HCB lookups without lock. lru.limited Number of times more storage space was needed, but limit was reached. lru.moved Number of move operations done on the LRU list. lru.nuked Number of least recently used (LRU) objects forcefully evicted from storage to make room for a new object. main.backends Number of backends. main.bans Count of bans. main.busyKilled Number of requests killed after sleep on busy objhdr. main.busySleep Number of requests sent to sleep on busy objhdr. main.busyWakeup Number of requests woken after sleep on busy objhdr. main.expired Number of expired objects. main.expiredMailed Number of objects mailed to expiry thread. main.expiredReceived Number of objects received by expiry thread. main.gunzip Number of gunzip operations. main.gunzipTest Number of test gunzip operations. main.gzip Number of gzip operations. main.objectcores Number of objectcore structs made. main.objectheads Number of objected structs made. main.objects Number of object structs made. main.passedRequests Total pass-ed requests seen. main.pipeSessions Total pipe sessions seen. main.pools Number of thread pools. main.purgeObjects Number of purged objects. main.purgeOperations Number of purge operations executed. main.reqDropped Number of requests dropped. main.sessions Total number of sessions seen. main.sessQueueLength Length of session queue waiting for threads. main.summs Number of times per-thread statistics were summed into the global counters. main.syntheticResponses Total synthethic responses made. main.threads Total number of threads. main.threadsCreated Total number of threads created in all pools. main.threadsDestroyed Total number of threads destroyed in all pools. main.threadsFailed Number of times creating a thread failed. main.threadsLimited Number of times more threads were needed, but limit was reached in a thread pool. main.unresurrectedObjects Number of unresurrected objects. main.uptimeInMilliseconds The child process uptime, in milliseconds. main.vclAvailable Number of Varnish Configuration Languages (VCL) available. main.vclDiscarded Number of discarded VCLs. main.vclFails Number of VCL failures. main.vclLoaded Number of loaded VCLs in total. main.vmodsLoaded Number of loaded Varnish modules (VMOD). mgt.childDied Number of times the child process has died due to signals. mgt.childDump Number of times the child process has produced core dumps. mgt.childExit Number of times the child process has been cleanly stopped. mgt.childPanic Number of times the management process has caught a child panic. mgt.childStart Number of times the child process has been started. mgt.childStop Number of times the child process has been cleanly stopped. mgt.uptimeInMilliseconds The management process uptime, in milliseconds. net.400Errors Number of client requests received, subject to 400 errors. net.417Errors Number of client requests received, subject to 417 errors net.httpOverflow Number of HTTP header overflows. net.pipe.inInBytes Total number of bytes forwarded from clients in pipe sessions. net.pipe.outInBytes Total number of bytes forwarded to clients in pipe sessions. net.pipereq.headerInBytes Total request bytes received for piped sessions. net.request.bodyInBytes Total request body transmitted, in bytes. net.request.headerInBytes Total request headers transmitted, in bytes. net.requests Number of good client requests received. net.response.bodyInBytes Total response body transmitted, in bytes. net.response.headerInBytes Total response headers transmitted, in bytes. sess.backendClose Number of session closes with the error RESP_CLOSE, (Backend/VCL requested close). sess.badClose Number of session closes with the error Error RX_BAD, (Received bad req/resp). sess.bodyFailClose Number of session closes with the error Error RX_BODY, (Failure receiving req.body). sess.clientClose Number of session closes with the error REM_CLOSE, (Client closed). sess.clientReqClose Number of session closes with the error REQ_CLOSE, (Client requested close). sess.closed Total number of sessions closed. sess.closedError Total number of sessions closed with errors. sess.dropped Number of sessions dropped for thread. sess.eofTxnClose Number of session closes with the error TX_EOF, (EOF transmission). sess.errorTxnClose Number of session closes with the error TX_ERROR, (Error transaction). sess.herd Number of times the timeout_linger triggered. sess.junkClose Number of session closes with the error RX_JUNK, (Received junk data). sess.overflowClose Number of session closes with the error RX_OVERFLOW, (Received buffer overflow). sess.overloadClose Number of session closes with the error OVERLOAD, (Out of some resource). sess.pipeOverflowClose Number of session closes with the error PIPE_OVERFLOW, (Session pipe overflow). sess.pipeTxnClose Number of session closes with the error TX_PIPE, (Piped transaction). sess.queued Number of sessions queued for thread. sess.readAhead Session Read Ahead. sess.requestHTTP10Close Number of session closes with the error REQ_HTTP10, (Proto < HTTP/1.1). sess.requestHTTP20Close Number of session closes with the error REQ_HTTP20, (HTTP2 not accepted). sess.shortRangeClose Number of session closes with the error RANGE_SHORT, (Insufficient data for range). sess.timeoutClose Number of session closes with the error RX_TIMEOUT, (Receive timeout). sess.vclFailClose Number of session closes with the error VCL_FAILURE, (VCL failure). session.connections Count of sessions successfully accepted. session.drops Count of sessions silently dropped due to lack of worker thread. session.fail Count of failures to accept TCP connection. shm.contentions Number of shared memory (SHM) MTX contentions. shm.cycles Number of SHM cycles through buffer. shm.flushes Number of SHM flushes due to overflow. shm.records Number of SHM records. shm.writes Number of SHM writes. workspace.backendOverflow Number of times we ran out of space in workspace_backend. workspace.clientOverflow Number of times we ran out of space in workspace_client. workspace.deliveryFail Delivery failed due to insufficient workspace. workspace.sessionOverflow Number of times we ran out of space in workspace_session. workspace.threadOverflow Number of times we ran out of space in workspace_thread. Varnish lock sample metrics These attributes can be found by querying the VarnishLockSample event types in Insights. Metric Description lock.created Count of created locks. lock.destroyed Count of destroyed locks. lock.locks Count of lock operations. Varnish storage sample metrics These attributes can be found by querying the VarnishStorageSample event type. Metric Description storage.allocFails Number of times the storage has failed to provide a storage segment. storage.allocInBytes Number of total bytes allocated by this storage. storage.allocOustanding Number of storage allocations outstanding. storage.allocReqs Number of times the storage has been asked to provide a storage segment. storage.availableInBytes Number of bytes left in the storage. storage.freeInBytes Number of total bytes returned to this storage. storage.outstandingInBytes Number of bytes allocated from the storage. Varnish mempool sample metrics These attributes can be found by querying the VarnishMempoolSample event types in Insights. Metric Description mempool.allocatedSizeInBytes Allocated size of memory pool, in bytes. mempool.allocs Memory pool allocations. mempool.frees Number of memory pools free. mempool.live Number of memory pools in use. mempool.pool Count in memory pool. mempool.ranDry Pool ran dry. mempool.recycles Recycled from pool. mempool.requestSizeInBytes Request size of memory pool, in bytes. mempool.surplus Too many for pool. mempool.timeouts Timed out from pool. mempool.tooSmall Too small to recycle. Varnish backend sample metrics These attributes can be found by querying the VarnishBackendSample event type. Metric Description backend.busyFetches Fetches not attempted due to backend being busy. backend.connections Number of concurrent connections to the backend. backend.connectionsFailed Number of backend connections failed. backend.connectionsNotAttempted Number of backend connection opens not attempted. backend.happy Happy health probes. backend.unhealtyFetches Fetches not attempted due to backend being unhealthy net.backend.pipeHeaderInBytes Total request bytes sent for piped sessions. net.backend.pipeInInBytes Total number of bytes forwarded from backend in pipe sessions. net.backend.pipeOutInBytes Total number of bytes forwarded to backend in pipe sessions. net.backend.requestBodyInBytes Total backend request body bytes sent. net.backend.requestHeaderInBytes Total backend request header bytes sent. net.backend.requests Number of backend requests sent, net.backend.responseBodyInBytes Total backend response body bytes received. net.backend.responseHeaderInBytes Total backend response header bytes received. Inventory data The Varnish Cache integration captures the configuration parameters. It parses the varnish.params configuration file for all parameters that are active. The data is available on the Inventory page, under the config/varnish source. For more about inventory data, see Understand integration data. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.95825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Varnish Cache monitoring <em>integration</em>",
        "sections": "Varnish Cache monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": ". Restart the infrastructure agent. Additional notes: Advanced: It&#x27;s also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update"
      },
      "id": "617dac7b28ccbcc6307ff095"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/oracle-database-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/perfmon-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/port-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/postgresql-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.2149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/powerdns-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.2149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/rabbitmq-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.6524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/redis-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.6524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/snmp-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/statsd-monitoring-integration-version-2": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/unix-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21475,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65361,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/varnish-cache-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21475,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65361,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/vmware-tanzu-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21475,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65361,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration": [
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.6536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    },
    {
      "sections": [
        "Varnish Cache monitoring integration",
        "Compatibility and requirements",
        "Quick start",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Configure the integration",
        "Important",
        "Varnish Cache instance settings",
        "Labels/Custom attributes",
        "Example configuration",
        "Configuration for Varnish 6+",
        "Find and use data",
        "Metric data",
        "Tip",
        "Varnish sample metrics",
        "Varnish lock sample metrics",
        "Varnish storage sample metrics",
        "Varnish mempool sample metrics",
        "Varnish backend sample metrics",
        "Inventory data",
        "Check the source code"
      ],
      "title": "Varnish Cache monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "bd83968529635dee50be7f9e1f3d8be4bf7028e2",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/varnish-cache-monitoring-integration/",
      "published_at": "2021-12-30T07:32:06Z",
      "updated_at": "2021-12-04T17:32:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Varnish Cache on-host integration collects and sends inventory and metrics from your Varnish Cache environment to New Relic so you can monitor its health. We collect metrics at the instance, lock, memory pool, storage, and backend levels. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with Varnish Cache 1.0 or higher. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent. Linux distribution or Windows version compatible with our infrastructure agent. Quick start Instrument your Varnish Cache environment quickly and send your telemetry data with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click one of these button to try it out. Guided install EU Guided install Our guided install uses the infrastructure agent to set up the Varnish Cache integration. Not only that, it discovers other applications and log sources running in your environment and then recommends which ones you should instrument. The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your Varnish Cache environment. Install and activate To install the Varnish Cache integration: Linux installation Follow the instructions for installing an integration, using the file name nri-varnish. Change directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp varnish-config.yml.sample varnish-config.yml Copy Edit the varnish-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-varnish .MSI installer image from: http://download.newrelic.com/infrastructure_agent/windows/integrations/nri-varnish/nri-varnish-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-varnish-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp varnish-config.yml.sample varnish-config.yml Copy Edit the varnish-config.yml file as described in the configuration settings. Restart the infrastructure agent. Additional notes: Advanced: It's also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings, refer to our Configuration Format document. Important If you are still using our legacy configuration/definition files please refer to this document for help. Specific settings related to Varnish are defined using the env section of the configuration file. These settings control the connection to your Varnish instance, as well as other security settings and features. The list of valid settings is described in the following section. Varnish Cache instance settings The Varnish Cache integration collects both metrics(M) and inventory(I) information. Check the Applies To column below to find which settings can be used for each specific collection: Setting Description Default Applies To INSTANCE_NAME User defined name to identify data from this instance in New Relic. Required. N/A M/I PARAMS_CONFIG_FILE The location of the varnish.params config file. If this argument is omitted, the following locations will be checked: /etc/default/varnish/varnish.params /etc/sysconfig/varnish/varnish.params Note: The location and name of the Varnish configuration file may vary. For details, see Different locations of the Varnish configuration file. For Varnish versions lower than 6, this parameter is not required and the integration should be set up for metrics collection only. See the example for Varnish 6. N/A I VARNISH_NAME Name used when executing the varnishd daemon with a custom -n flag. Optional. N/A M METRICS Set to true to enable metrics-only collection. false INVENTORY Set to true to enable inventory-only collection. false The varnish-config.yml commands accept the following arguments: The values for these settings can be defined in several ways: Adding the value directly in the config file. This is the most common way. Replacing the values from environment variables using the {{}} notation. This requires infrastructure agent v1.14.0+. Read more here. Using secrets management. Use this to protect sensitive information, such as passwords that would be exposed in plain text on the configuration file. For more information, see Secrets management. Labels/Custom attributes Environment variables can be used to control config settings, such as your license key, and are then passed through to the Infrastructure agent. For instructions on how to use this feature, see Configure the Infrastructure agent. You can further decorate your metrics using labels. Labels allow you to add key/value pairs attributes to your metrics which you can then use to query, filter or group your metrics on. Our default sample config file includes examples of labels but, as they are not mandatory, you can remove, modify or add new ones of your choice. labels: env: production role: varnish Copy Example configuration Example varnish-config.yml file configuration: Example configuration This is the very basic configuration to collect metrics and inventory : integrations: - name: nri-varnish env: INSTANCE_NAME: new_relic PARAMS_CONFIG_FILE: /etc/default/varnish/varnish.params interval: 15s labels: env: production role: varnish inventory_source: config/varnish Copy Configuration for Varnish 6+ This is a basic configuration for Varnish 6 or above. Only metrics will be collected because, starting in Varnish 6, the params file was deprecated. integrations: - name: nri-varnish env: INSTANCE_NAME: new_relic METRICS: true interval: 15s labels: env: production role: varnish inventory_source: config/varnish Copy For more about the general structure of on-host integration configuration, see Configuration. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > Third-party services and select one of the Varnish Cache integration links. In New Relic, Varnish Cache data is attached to the following Insights event type: VarnishSample VarnishLockSample VarnishStorageSample VarnishMempoolSample VarnishBackendSample For more on how to find and use your data, see Understand integration data. Metric data The Varnish Cache integration collects the following metric data attributes. Each metric name is prefixed with a category indicator and a period, such as bans. or main.. Tip A number of metrics are calculated as rates (per second) instead of totals as the metric names might suggest. For more details on which metrics are calculated as rates, refer to the spec.csv file. Varnish sample metrics These attributes can be found by querying the VarnishSample event types. Metric Description backend.connectionBusy Number of times the maximum connection has been reached. backend.connectionFails Number of failed connections to the backed. backend.connectionRecycles Number of backend connections that have been recycled. backend.connectionRetries Number of backend connections that have been retried. backend.connectionReuses Number of backend connections reuses. backend.connectionSuccess Number of successful backend connections, backend.connectionUnHealthy Number of backend connections that were not attempted due to ‘unhealthy’ backend status. backend.fetches Total number of backend fetches initiated. backend.requests Total number of backend connection requests made. bans.added Counter of bans added to ban list. bans.completed Number of bans marked ‘completed'. bans.cutoffLurkerKilled Number of objects killed by bans for cutoff (lurker). bans.deleted Counter of bans deleted from ban list. bans.dups Count of bans replaced by later identical bans. bans.fragmentationInBytes Extra bytes in persisted ban lists due to fragmentation. bans.lookupKilled Number of objects killed by bans during object lookup. bans.lookupTestsTested Count of how many tests and objects have been tested against each other during lookup. bans.lurkerCon Number of times the ban-lurker had to wait for lookups. bans.lurkerKilled Number of objects killed by the ban-lurker. bans.lurkerTested Count of how many bans and objects have been tested against each other by the ban-lurker. bans.lurkerTestsTested Count of how many tests and objects have been tested against each other during by the ban-lurker. bans.obj Number of bans using obj.* variables. These bans can possibly be washed by the ban-lurker. bans.persistedInBytes Bytes used by the persisted ban lists. bans.req Number of bans which use req.* variables. These bans can not be washed by the ban-lurker. bans.tested Count of how many bans and objects have been tested against each other during hash lookup. cache.graceHits Count of cache hits with grace. A cache hit with grace is a cache hit where the object is expired. These hits also included in the cache_hit counter. cache.hits Number of times an object has been delivered to a client without fetching it from a backend server. cache.misses Number of times the object was fetched from the backend before delivering it to the client. cache.missHits Number of times a hit object was returned for a miss response. cache.passHits Number of times a hit object was returned for a pass response. esi.errors Edge Side Includes (ESI) parsing errors (unlock). esi.warnings Edge Side Includes (ESI) parse warnings (unlock). fetch.bad The beresp.body length/fetch could not be determined. fetch.chuncked The beresp.body chunked. fetch.contentLength The beresp.body with content-length. fetch.eof The beresp.body with EOF. fetch.failed The beresp failed. fetch.head The beresp with no body because the request is HEAD. fetch.noBody The beresp with no body. fetch.noBody1xx The beresp with no body because of 1XX response. fetch.noBody204 The beresp with no body because of 204 response. fetch.noBody304 The beresp with no body because of 304 response. fetch.noThreadFail The beresp fetch failed, no thread available. hcb.inserts Number of critical bit tree-based hash (HCB) inserts. hcb.lock Number of HCB lookups with lock. hcb.noLock Number of HCB lookups without lock. lru.limited Number of times more storage space was needed, but limit was reached. lru.moved Number of move operations done on the LRU list. lru.nuked Number of least recently used (LRU) objects forcefully evicted from storage to make room for a new object. main.backends Number of backends. main.bans Count of bans. main.busyKilled Number of requests killed after sleep on busy objhdr. main.busySleep Number of requests sent to sleep on busy objhdr. main.busyWakeup Number of requests woken after sleep on busy objhdr. main.expired Number of expired objects. main.expiredMailed Number of objects mailed to expiry thread. main.expiredReceived Number of objects received by expiry thread. main.gunzip Number of gunzip operations. main.gunzipTest Number of test gunzip operations. main.gzip Number of gzip operations. main.objectcores Number of objectcore structs made. main.objectheads Number of objected structs made. main.objects Number of object structs made. main.passedRequests Total pass-ed requests seen. main.pipeSessions Total pipe sessions seen. main.pools Number of thread pools. main.purgeObjects Number of purged objects. main.purgeOperations Number of purge operations executed. main.reqDropped Number of requests dropped. main.sessions Total number of sessions seen. main.sessQueueLength Length of session queue waiting for threads. main.summs Number of times per-thread statistics were summed into the global counters. main.syntheticResponses Total synthethic responses made. main.threads Total number of threads. main.threadsCreated Total number of threads created in all pools. main.threadsDestroyed Total number of threads destroyed in all pools. main.threadsFailed Number of times creating a thread failed. main.threadsLimited Number of times more threads were needed, but limit was reached in a thread pool. main.unresurrectedObjects Number of unresurrected objects. main.uptimeInMilliseconds The child process uptime, in milliseconds. main.vclAvailable Number of Varnish Configuration Languages (VCL) available. main.vclDiscarded Number of discarded VCLs. main.vclFails Number of VCL failures. main.vclLoaded Number of loaded VCLs in total. main.vmodsLoaded Number of loaded Varnish modules (VMOD). mgt.childDied Number of times the child process has died due to signals. mgt.childDump Number of times the child process has produced core dumps. mgt.childExit Number of times the child process has been cleanly stopped. mgt.childPanic Number of times the management process has caught a child panic. mgt.childStart Number of times the child process has been started. mgt.childStop Number of times the child process has been cleanly stopped. mgt.uptimeInMilliseconds The management process uptime, in milliseconds. net.400Errors Number of client requests received, subject to 400 errors. net.417Errors Number of client requests received, subject to 417 errors net.httpOverflow Number of HTTP header overflows. net.pipe.inInBytes Total number of bytes forwarded from clients in pipe sessions. net.pipe.outInBytes Total number of bytes forwarded to clients in pipe sessions. net.pipereq.headerInBytes Total request bytes received for piped sessions. net.request.bodyInBytes Total request body transmitted, in bytes. net.request.headerInBytes Total request headers transmitted, in bytes. net.requests Number of good client requests received. net.response.bodyInBytes Total response body transmitted, in bytes. net.response.headerInBytes Total response headers transmitted, in bytes. sess.backendClose Number of session closes with the error RESP_CLOSE, (Backend/VCL requested close). sess.badClose Number of session closes with the error Error RX_BAD, (Received bad req/resp). sess.bodyFailClose Number of session closes with the error Error RX_BODY, (Failure receiving req.body). sess.clientClose Number of session closes with the error REM_CLOSE, (Client closed). sess.clientReqClose Number of session closes with the error REQ_CLOSE, (Client requested close). sess.closed Total number of sessions closed. sess.closedError Total number of sessions closed with errors. sess.dropped Number of sessions dropped for thread. sess.eofTxnClose Number of session closes with the error TX_EOF, (EOF transmission). sess.errorTxnClose Number of session closes with the error TX_ERROR, (Error transaction). sess.herd Number of times the timeout_linger triggered. sess.junkClose Number of session closes with the error RX_JUNK, (Received junk data). sess.overflowClose Number of session closes with the error RX_OVERFLOW, (Received buffer overflow). sess.overloadClose Number of session closes with the error OVERLOAD, (Out of some resource). sess.pipeOverflowClose Number of session closes with the error PIPE_OVERFLOW, (Session pipe overflow). sess.pipeTxnClose Number of session closes with the error TX_PIPE, (Piped transaction). sess.queued Number of sessions queued for thread. sess.readAhead Session Read Ahead. sess.requestHTTP10Close Number of session closes with the error REQ_HTTP10, (Proto < HTTP/1.1). sess.requestHTTP20Close Number of session closes with the error REQ_HTTP20, (HTTP2 not accepted). sess.shortRangeClose Number of session closes with the error RANGE_SHORT, (Insufficient data for range). sess.timeoutClose Number of session closes with the error RX_TIMEOUT, (Receive timeout). sess.vclFailClose Number of session closes with the error VCL_FAILURE, (VCL failure). session.connections Count of sessions successfully accepted. session.drops Count of sessions silently dropped due to lack of worker thread. session.fail Count of failures to accept TCP connection. shm.contentions Number of shared memory (SHM) MTX contentions. shm.cycles Number of SHM cycles through buffer. shm.flushes Number of SHM flushes due to overflow. shm.records Number of SHM records. shm.writes Number of SHM writes. workspace.backendOverflow Number of times we ran out of space in workspace_backend. workspace.clientOverflow Number of times we ran out of space in workspace_client. workspace.deliveryFail Delivery failed due to insufficient workspace. workspace.sessionOverflow Number of times we ran out of space in workspace_session. workspace.threadOverflow Number of times we ran out of space in workspace_thread. Varnish lock sample metrics These attributes can be found by querying the VarnishLockSample event types in Insights. Metric Description lock.created Count of created locks. lock.destroyed Count of destroyed locks. lock.locks Count of lock operations. Varnish storage sample metrics These attributes can be found by querying the VarnishStorageSample event type. Metric Description storage.allocFails Number of times the storage has failed to provide a storage segment. storage.allocInBytes Number of total bytes allocated by this storage. storage.allocOustanding Number of storage allocations outstanding. storage.allocReqs Number of times the storage has been asked to provide a storage segment. storage.availableInBytes Number of bytes left in the storage. storage.freeInBytes Number of total bytes returned to this storage. storage.outstandingInBytes Number of bytes allocated from the storage. Varnish mempool sample metrics These attributes can be found by querying the VarnishMempoolSample event types in Insights. Metric Description mempool.allocatedSizeInBytes Allocated size of memory pool, in bytes. mempool.allocs Memory pool allocations. mempool.frees Number of memory pools free. mempool.live Number of memory pools in use. mempool.pool Count in memory pool. mempool.ranDry Pool ran dry. mempool.recycles Recycled from pool. mempool.requestSizeInBytes Request size of memory pool, in bytes. mempool.surplus Too many for pool. mempool.timeouts Timed out from pool. mempool.tooSmall Too small to recycle. Varnish backend sample metrics These attributes can be found by querying the VarnishBackendSample event type. Metric Description backend.busyFetches Fetches not attempted due to backend being busy. backend.connections Number of concurrent connections to the backend. backend.connectionsFailed Number of backend connections failed. backend.connectionsNotAttempted Number of backend connection opens not attempted. backend.happy Happy health probes. backend.unhealtyFetches Fetches not attempted due to backend being unhealthy net.backend.pipeHeaderInBytes Total request bytes sent for piped sessions. net.backend.pipeInInBytes Total number of bytes forwarded from backend in pipe sessions. net.backend.pipeOutInBytes Total number of bytes forwarded to backend in pipe sessions. net.backend.requestBodyInBytes Total backend request body bytes sent. net.backend.requestHeaderInBytes Total backend request header bytes sent. net.backend.requests Number of backend requests sent, net.backend.responseBodyInBytes Total backend response body bytes received. net.backend.responseHeaderInBytes Total backend response header bytes received. Inventory data The Varnish Cache integration captures the configuration parameters. It parses the varnish.params configuration file for all parameters that are active. The data is available on the Inventory page, under the config/varnish source. For more about inventory data, see Understand integration data. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.95816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Varnish Cache monitoring <em>integration</em>",
        "sections": "Varnish Cache monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": ". Restart the infrastructure agent. Additional notes: Advanced: It&#x27;s also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update"
      },
      "id": "617dac7b28ccbcc6307ff095"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/windows-services-integration": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-1121/",
      "sections": [
        "Infrastructure agent v1.12.1",
        "Notes",
        "Added",
        "Fixed"
      ],
      "published_at": "2021-12-30T16:19:43Z",
      "title": "Infrastructure agent v1.12.1",
      "updated_at": "2021-03-13T03:15:26Z",
      "type": "docs",
      "external_id": "93e606131035b520d2d5f6be4220698349929793",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes A new version of the agent has been released. Follow standard procedures to update your Infrastructure agent. Added Beta version (v0.1.0-beta) of nri-winservices is now packaged with the agent. For more information, see the Windows services integration documentation. Fixed d35cbe7 Fixed the sending of heartbeat samples to New Relic. 6503df0 Inventory is now fully re-sent if the host has been offline for 24 hours or if the agent ID changes. 4ccd9ff Fixed issue where running Docker auto discovery was leaking file descriptors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 461.3467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Notes A new version of the agent has been released. Follow standard procedures to update your Infrastructure agent. Added Beta version (v0.1.0-beta) of nri-winservices is now packaged with the agent. For more information, see the <em>Windows</em> <em>services</em> <em>integration</em> documentation. Fixed d35cbe7 Fixed"
      },
      "id": "6044211fe7b9d21ae05799cb"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-12-31T01:42:58Z",
      "updated_at": "2021-12-25T15:23:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). macOS: 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, 2019, and 2022, and their service packs. Windows 10 and their service packs. macOS 10.15 (Catalina), 11 (Big Sur), 12 (Monterey). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 83.83568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ": Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) <em>Windows</em>: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-12-30T09:10:10Z",
      "updated_at": "2021-11-13T08:47:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. If not already installed, install our Kubernetes integration. Upgrade the installation to include the New Relic Metrics Adapter with the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace --reuse-values \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following example is a Helm values file that enable the metrics adapter on the nri-bundle chart installation, and configures the nginx_average_requests metric: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose default is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 76.89196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Integrations</em>",
        "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and <em>services</em> in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/infrastructure/host-integrations/host-integrations-list/zookeeper-monitoring-integration": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.21466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.65234,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "MySQL monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em> <em>list</em>",
        "body": " Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk": [
    {
      "sections": [
        "Introduction to Infrastructure Integrations SDK",
        "Important",
        "What is the Integrations SDK?",
        "What data can you report with an on-host integration?",
        "Create a custom integration"
      ],
      "title": "Introduction to Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "217ca641457b01d0758e376c7aac10169a96a0c0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T20:38:05Z",
      "updated_at": "2021-10-24T01:11:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways New Relic lets you create your own integration: General telemetry (metrics, traces) solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. If you have New Relic Infrastructure, you can use our lightweight Flex integration tool (recommended) or use our Integrations SDK to build a complete Infrastructure on-host integration. Important New Relic is transitioning to rely on open source standards like Prometheus for future on-host integrations. Though the infrastructure SDK is the foundation of that transition, some of the tutorials and tools around this SDK might not be up-to-date with the latest developments. What is the Integrations SDK? Our Infrastructure Integrations SDK lets you build an on-host integration that reports custom data from your hosts or services. That data can then be found in New Relic Infrastructure and can be used to create custom queries and charts. What data can you report with an on-host integration? When you build an integration using the Integrations SDK, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning something that reports data to New Relic (for example: a local host, a load balancer, or a database). A single integration can report data from multiple entities, which gives you the ability to report data from more than one service or host instance. There are three types of data an entity can generate: Metrics: Metric data is used for numerical measurement data. Examples: how many requests are in a queue, or the number of hits on a database per minute. Metric data from a custom integration can be queried and used to create dashboards. Inventory: Live system state and configuration information. This data will show up on the Infrastructure Inventory UI page. Events: Events are used to record important activities on a system. Examples: a service starting or a new table being created. Event data will be shown in the Infrastructure Events UI page. Create a custom integration To create an integration using the Integrations SDK, use these resources: See the Go language build tools and tutorial. The tutorial walks you through creating a Redis integration in Go. (Note: Go is not required; it's just the language for which we provide additional build tools. For more information, see Integrations SDK requirements.) See the integration file structure documentation, which describes the files required to create an integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.18329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " Relic <em>Infrastructure</em> and can be used to <em>create</em> custom queries and charts. What data can you report with an on-host integration? When you build an integration using the <em>Integrations</em> <em>SDK</em>, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning"
      },
      "id": "617dc024e7b9d272ccc03d1d"
    },
    {
      "sections": [
        "Go language integration tutorial and build tools",
        "Integrations tutorial",
        "Important",
        "Tip",
        "Go language integration building package"
      ],
      "title": "Go language integration tutorial and build tools",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "d7e22325dd0a89184df3f494b3e711b80c2dbcb3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools/",
      "published_at": "2021-12-30T17:12:43Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. Integrations tutorial Important The following tutorial is based on integrations using the SDK integration protocol v3. Find more information about the integration protocol v4 in the Github repository. The Go language integration-building tutorial on GitHub gives step-by-step procedures for building a Go language integration that reports Redis data. The tutorial shows how to build an integration using the Linux command line, but you can use the same techniques for a Windows integration with a standard Go install and PowerShell. The make command will not work with PowerShell, but you can use the Go commands inside it as a guide for building your integration. Tip You can create an on-host integration in any language, but Go is the language New Relic uses for its own integrations and build tools. To create an integration in another language, adhere to the integration file structures and JSON output requirements. Go language integration building package The tutorial relies on a New Relic Go language integration-building library package, which provides a set of useful Go functions and data structures. The package gives you tools that: Generate a \"scaffold\" integration structure with all the required fields. Read values from command-line arguments or environment variables. Generate and print JSON data to stdout. For information about file formats and JSON output specifications, see File requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.18298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go language <em>integration</em> tutorial and build tools",
        "sections": "<em>Integrations</em> tutorial",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. <em>Integrations</em> tutorial Important The following tutorial is based on <em>integrations</em>"
      },
      "id": "617dc06428ccbc5eeb7ffb3e"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.76573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools": [
    {
      "sections": [
        "Introduction to Infrastructure Integrations SDK",
        "Important",
        "What is the Integrations SDK?",
        "What data can you report with an on-host integration?",
        "Create a custom integration"
      ],
      "title": "Introduction to Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "217ca641457b01d0758e376c7aac10169a96a0c0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T20:38:05Z",
      "updated_at": "2021-10-24T01:11:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways New Relic lets you create your own integration: General telemetry (metrics, traces) solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. If you have New Relic Infrastructure, you can use our lightweight Flex integration tool (recommended) or use our Integrations SDK to build a complete Infrastructure on-host integration. Important New Relic is transitioning to rely on open source standards like Prometheus for future on-host integrations. Though the infrastructure SDK is the foundation of that transition, some of the tutorials and tools around this SDK might not be up-to-date with the latest developments. What is the Integrations SDK? Our Infrastructure Integrations SDK lets you build an on-host integration that reports custom data from your hosts or services. That data can then be found in New Relic Infrastructure and can be used to create custom queries and charts. What data can you report with an on-host integration? When you build an integration using the Integrations SDK, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning something that reports data to New Relic (for example: a local host, a load balancer, or a database). A single integration can report data from multiple entities, which gives you the ability to report data from more than one service or host instance. There are three types of data an entity can generate: Metrics: Metric data is used for numerical measurement data. Examples: how many requests are in a queue, or the number of hits on a database per minute. Metric data from a custom integration can be queried and used to create dashboards. Inventory: Live system state and configuration information. This data will show up on the Infrastructure Inventory UI page. Events: Events are used to record important activities on a system. Examples: a service starting or a new table being created. Event data will be shown in the Infrastructure Events UI page. Create a custom integration To create an integration using the Integrations SDK, use these resources: See the Go language build tools and tutorial. The tutorial walks you through creating a Redis integration in Go. (Note: Go is not required; it's just the language for which we provide additional build tools. For more information, see Integrations SDK requirements.) See the integration file structure documentation, which describes the files required to create an integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.18329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " Relic <em>Infrastructure</em> and can be used to <em>create</em> custom queries and charts. What data can you report with an on-host integration? When you build an integration using the <em>Integrations</em> <em>SDK</em>, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning"
      },
      "id": "617dc024e7b9d272ccc03d1d"
    },
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0b11df7fe7973b78788dc86507e41a387516e42c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T21:52:10Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.18298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "617dc06328ccbcd5847fff32"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.76572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0b11df7fe7973b78788dc86507e41a387516e42c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T21:52:10Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.18298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "617dc06328ccbcd5847fff32"
    },
    {
      "sections": [
        "Go language integration tutorial and build tools",
        "Integrations tutorial",
        "Important",
        "Tip",
        "Go language integration building package"
      ],
      "title": "Go language integration tutorial and build tools",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "d7e22325dd0a89184df3f494b3e711b80c2dbcb3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools/",
      "published_at": "2021-12-30T17:12:43Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. Integrations tutorial Important The following tutorial is based on integrations using the SDK integration protocol v3. Find more information about the integration protocol v4 in the Github repository. The Go language integration-building tutorial on GitHub gives step-by-step procedures for building a Go language integration that reports Redis data. The tutorial shows how to build an integration using the Linux command line, but you can use the same techniques for a Windows integration with a standard Go install and PowerShell. The make command will not work with PowerShell, but you can use the Go commands inside it as a guide for building your integration. Tip You can create an on-host integration in any language, but Go is the language New Relic uses for its own integrations and build tools. To create an integration in another language, adhere to the integration file structures and JSON output requirements. Go language integration building package The tutorial relies on a New Relic Go language integration-building library package, which provides a set of useful Go functions and data structures. The package gives you tools that: Generate a \"scaffold\" integration structure with all the required fields. Read values from command-line arguments or environment variables. Generate and print JSON data to stdout. For information about file formats and JSON output specifications, see File requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.18298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go language <em>integration</em> tutorial and build tools",
        "sections": "<em>Integrations</em> tutorial",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. <em>Integrations</em> tutorial Important The following tutorial is based on <em>integrations</em>"
      },
      "id": "617dc06428ccbc5eeb7ffb3e"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.76572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0b11df7fe7973b78788dc86507e41a387516e42c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T21:52:10Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.70317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "617dc06328ccbcd5847fff32"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.8333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "7e8d85bc046e3d56a101cc5e33a77af2dd439d8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-12-30T21:54:38Z",
      "updated_at": "2021-10-30T22:01:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.1492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "617dc0d028ccbc83007ffc4f"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integration-executable-file-json-specifications": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0b11df7fe7973b78788dc86507e41a387516e42c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T21:52:10Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.70316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "617dc06328ccbcd5847fff32"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.83328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "7e8d85bc046e3d56a101cc5e33a77af2dd439d8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-12-30T21:54:38Z",
      "updated_at": "2021-10-30T22:01:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.1492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "617dc0d028ccbc83007ffc4f"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integration-files": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0b11df7fe7973b78788dc86507e41a387516e42c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T21:52:10Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.70316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "617dc06328ccbcd5847fff32"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.83328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "7e8d85bc046e3d56a101cc5e33a77af2dd439d8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-12-30T21:54:38Z",
      "updated_at": "2021-10-30T22:01:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.1492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "617dc0d028ccbc83007ffc4f"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0b11df7fe7973b78788dc86507e41a387516e42c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T21:52:10Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.70316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "617dc06328ccbcd5847fff32"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.83328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "7e8d85bc046e3d56a101cc5e33a77af2dd439d8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-12-30T21:54:38Z",
      "updated_at": "2021-10-30T22:01:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.14919,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "617dc0d028ccbc83007ffc4f"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0b11df7fe7973b78788dc86507e41a387516e42c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T21:52:10Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.70316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "617dc06328ccbcd5847fff32"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "7e8d85bc046e3d56a101cc5e33a77af2dd439d8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-12-30T21:54:38Z",
      "updated_at": "2021-10-30T22:01:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.14919,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "617dc0d028ccbc83007ffc4f"
    },
    {
      "sections": [
        "On-host integration executable file: JSON specifications",
        "Executable file requirements",
        "File placement",
        "Integration protocol v4: Example JSON output",
        "Integration protocol v3: Example JSON output",
        "JSON: General specifications",
        "General output and JSON formatting",
        "Errors and logging",
        "Exit/close of executable",
        "JSON: Header",
        "JSON: Entities",
        "Loopback address replacement on entity names",
        "JSON: Metric, inventory, and event data",
        "Important",
        "Metric data",
        "Event data",
        "Inventory data"
      ],
      "title": "On-host integration executable file: JSON specifications",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "f8a03eb3e346e4b403c4f5bea5228ce4ea69dfe9",
      "image": "https://docs.newrelic.com/static/de6d60d8375ae15068eea2d7d28b9e3f/ade6e/new-relic-integrations-sdk-data-structure.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integration-executable-file-json-specifications/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-10-24T01:15:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using our Integrations SDK for infrastructure monitoring to build a custom on-host integration, the integration will consist of at least three files: an executable file and at least one configuration file. The executable file generates JSON data that is consumed by the infrastructure monitoring agent and sent to New Relic. We refer to the JSON object as the SDK integration protocol. Executable file requirements The executable can be any file that runs from a command-line interface; for example: A shell script A scripting language script A compiled binary The only requirement of your executable file is that it exports JSON data, in a single line format, that meets the specifications in this document. Recommendation: Use Go to create integrations; it's the language we use to create on-host integrations and the integration building tools. However, you can create an integration in any language. File placement The executable file goes in this directory: Linux: /var/db/newrelic-infra/custom-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Integration protocol v4: Example JSON output The following section explains the new JSON schema (integration protocol v4). The SDK v4 only supports this new protocol version. These are the most important changes: A new integration object at the top level. The entity and metrics objects have been modified. See the v3 to v4 migration guide for more information. { \"protocol_version\":\"4\", # protocol version number \"integration\":{ # this data will be added to all metrics and events as attributes, # and also sent as inventory \"name\":\"integration name\", \"version\":\"integration version\" }, \"data\":[ # List of objects containing entities, metrics, events and inventory { \"entity\":{ # this object is optional. If it's not provided, then the Entity will get # the same entity ID as the agent that executes the integration. \"name\":\"redis:192.168.100.200:1234\", # unique entity name per customer account \"type\":\"RedisInstance\", # entity's category \"displayName\":\"my redis instance\", # human readable name \"metadata\":{} # can hold general metadata or tags. Both are key-value pairs that will # be also added as attributes to all metrics and events }, \"metrics\":[ # list of metrics using the dimensional metric format { \"name\":\"redis.metric1\", \"type\":\"count\", # gauge, count, summary, cumulative-count, rate or cumulative-rate \"value\":93, \"attributes\":{} # set of key-value pairs that define the dimensions of the metric } ], \"inventory\":{...}, # Inventory remains the same \"events\":[...] # Events remain the same } ] } Copy Integration protocol v3: Example JSON output The JSON includes: A header, with basic integration data (name, version) A data list, which includes one or more entities reporting data (metric, inventory, and/or event data) This diagram shows this structure: Here is an example JSON output (formatted with line breaks for readability). Definitions and specifications follow this example: { \"name\": \"my.company.integration\", \"protocol_version\": \"3\", \"integration_version\": \"x.y.z\", \"data\": [ { \"entity\": { \"name\": \"my_garage\", \"type\": \"building\", \"id_attributes\": [ { \"key\": \"environment\", \"value\": \"production\" }, { \"key\": \"node\", \"value\": \"master\" } ] }, \"metrics\": [ { \"temperature\": 25.3, \"humidity\": 0.45, \"displayName\": \"my_garage\", \"entityName\": \"building:my_garage\", \"event_type\": \"BuildingStatus\" } ], \"inventory\": { \"out_door\": { \"status\": \"open\" } }, \"events\": [] }, { \"entity\": { \"name\": \"my_family_car\", \"type\": \"car\", \"id_attributes\": [ { \"key\": \"environment\", \"value\": \"production\" }, { \"key\": \"node\", \"value\": \"master\" } ] }, \"metrics\": [ { \"speed\": 95, \"fuel\": 768, \"displayName\": \"my_family_car\", \"entityName\": \"car:my_family_car\", \"event_type\": \"VehicleStatus\" } ], \"inventory\": { \"motor\": { \"brand\": \"renault\", \"cc\": 1800 } }, \"events\": [ { \"category\": \"gear\", \"summary\": \"gear has been changed\" } ], \"add_hostname\": true } ] } Copy JSON: General specifications Here are general specifications for the JSON output: General output and JSON formatting Data is emitted to stdout (standard output) in JSON format. The agent will treat stdout and stderr file descriptors as line-wise buffers. Use standard JSON, not \"pretty printed\" JSON, for the output. Recommendation: Include an optional command line switch (for example, --pretty) to make JSON \"pretty printed\" for debugging purposes. Errors and logging Error and debug information must be emitted to stderr (standard error). Follow New Relic's recommendations and best practices for integration logging. Exit/close of executable The exit code must exit with a 0 status code and follow platform-specific conventions. For example: Linux: 0 == EX_OK Windows: 0 == ERROR_SUCCESS If the executable exits with a non-zero status, the agent will discard any data from stdout and write a message to its log file with the name of the integration, the exit code, and any diagnostic information it can gather. JSON: Header Here's an example of the first part of an on-host integration's JSON output: \"name\":\"com.myorg.nginx\", \"protocol_version\":\"3\", \"integration_version\":\"1.0.0\", \"data\": [ {entities}...] Copy A minimal payload would be a JSON object with only the header fields. Recommendation: If there is no data to collect, use the program return code and log messages written to stderr. JSON header fields Description name Required. Must be identical to the name field in the configuration file. Recommendation: Use reverse domain names to generate unique integration names. protocol_version Required. The version number of the exchange protocol between the integration and the agent that the integration executable is using. The current version is 3. This protocol requires Infrastructure agent 1.2.25 or higher. Protocol 2 requires Infrastructure agent 1.0.859 or higher. Protocol 1 is compatible with all agents. For more information, see SDK changes. integration_version Optional. The integration version. Used to track the integration version running on each host. An integration can have more than one executable. Therefore this is not simply the executable's version. data Required for reporting data. A list containing the data reported from one or more entities. JSON: Entities Inside the data list of the JSON output are one or more entities. The entity entry fields include: Entity JSON fields Description entity Required. Entity data or properties. metrics Optional. Entity related metric list. inventory Optional. Entity related inventory items. events Optional. Entity related event list. add_hostname Optional. Boolean. If true, the entity metrics will be decorated with the hostname. Inside the data list of the JSON output are one or more entities and their data. The entity entry has two fields: Entity data JSON fields Description name Required. The identifier/name of the entity. Recommendation: Use reverse domain names to generate unique integration names. type Required. The kind of entity. It will be used by the Infrastructure agent as a namespace to compose a unique identifier in conjunction with the name. id_attributes Optional. A list of key-value attributes that provide uniqueness to an entity. They are attached to the name in the form of key=value to ease readability, provide extra information, and improve entity name uniqueness. Identifier attributes are useful when the entity name is not enough to work as a unique identifier, or when it doesn't provide enough meaningful information. For example: [ { \"key\": \"service\", \"value\": \"mysql\" }, { \"key\": \"role\", \"value\": \"master\" }, ... ] Copy Loopback address replacement on entity names As of Infrastructure agent version 1.2.25 or higher, protocol v3 improves remote entities uniqueness by adding local address replacement on entity names at agent level. When several remote entities have their name based on an endpoint (either ip or hostname), and this name contains loopback addresses, there are two problems: This localhost value does not provide valuable info without more context. The name could collide with other service being named with a local address. This happens when: Endpoints names are like localhost:port. Ports tend to be the same for a given service; for example, 3306 for Mysql. On incoming protocol v3 data, the Infrastructure agent replaces loopback addresses on the entity name (and key) with the first available item of the following list: Cloud provider instance ID, retrieved by the agent if applicable Display name, set via the display_name agent config option Hostname, as retrieved by the agent For example, if an integration using protocol v3 returns an entity with the name localhost:3306, and the agent is running on bare metal (doesn’t have cloud provider instance ID), the display_name has not been set, and the hostname is prod-mysql-01, then the agent will replace the localhost and produce the entity name prod-mysql-01:3306. The Infrastructure agent enables loopback address replacement automatically for v3 integration protocol. You can also enable this for v2 via the agent configuration flag replace_v2_loopback_entity_names. In this case all the integrations being run by the agent using v2 will have their names replaced whenever they carry a local address. JSON: Metric, inventory, and event data Data values follow the executable file header. You can record three data types: Metrics Events Inventory Important From the perspective of New Relic Dashboards, the infrastructure metrics and events are both classified as event data types. To find both metrics and events, use the Insights Event data explorer, not the Metric data explorer. Metric data Infrastructure metric data typically is used for simple numeric data; for example: Count of MySQL requests in a queue per second Count of active connections to a specific system per minute Besides associated metadata, a metric is essentially just a metric name and a numeric value. To view this data, use the New Relic Insights Event data explorer. Here's an example of an entity's metric data JSON: [ { \"event_type\":\"MyorgNginxSample\", \"net.connectionsActive\": 54, # metric data (a key/value pair) \"net.requestsPerSecond\": 21, # metric data (a key/value pair) \"net.reading\": 23, # metric data (a key/value pair) } ] Copy JSON metric data field Description event_type Required. event_type defines where the metrics will be stored. Each set of metrics is stored as a sample inside the specified event type. Each integration must store its data in its own event type. If you are generating multiple types of samples from the same integration, use different event types for each. Recommendation: To ensure the event types used by your integration are unique, prefix the event type with your company name or acronym. For example, if your custom integration captures Cassandra node metrics and Cassandra column family metrics as different samples, store them in different event types, such as MyOrgCassandraSample and MyOrgCassandraColumnFamilySample. If the event type does not exist, it will be created automatically when New Relic receives data from your integration and make it available in the UI. One or more metric data key/value pairs Required (at least one). A metric measurement containing a name (key) and its value. Make sure these generally conform to the entity type's specification for maximum compatibility with Infrastructure features. Recommendation: Prefix your metric with a category to help when navigating through metrics in the New Relic UI. New Relic integrations currently use: net: Number of connections, web server requests, bytes transmitted over the network, etc.; for example, net.connectionsActive. query: Metrics directly related to database queries; for example, query.comInsertPerSecond. db: Internal database metrics; for example, db.openTables. Use multilevel prefixes for additional grouping when it makes sense; for example, db.innodb.bufferPoolPagesFree. Use the innerCamelCase naming format; for example: net.requestsPerSecond. Use a metric name as close to the original one as possible while respecting the other specifications. For example: Original name: Qcache_hits Metric name: db.qCacheHits Measurement unit Recommendation: Specify the measurement unit using a unit suffix if it is not already included in the original metric name, as in the following examples: Percentages: Use Percent; for example: cpuUtilPercent. Rates: Use a format such as PerSecond. Seconds is the standard rate measurement, but you can also use other units, such as PerMinute or PerDay. Byte measurements: Use Bytes. Recommendation: If a metric is captured in a different unit, such as Megabytes, convert it to Bytes. For example: db.allMemtablesOffHeapSizeBytes. Time measurements: Use Milliseconds. Recommendation: If a metric is captured in a different unit, such as Seconds, convert it to Milliseconds. For example: query.readLatency50thPercentileMilliseconds Value Use a string or a number (integer or float). Strings can be used as associated metadata, allowing data to be filtered in the New Relic UI. A boolean would need to be expressed as either a string (\"true\", \"false\") or an integer (1, 0). Do not use complex types of values, such as arrays or hashes. Event data Infrastructure event data represents arbitrary, one-off messages for key activities on a system; for example: Starting up a specific service Creating a new table You can view this data in the Infrastructure Events page and Infrastructure events heatmap. You can also query the InfrastructureEvent event type in Insights. Here's an example of an integration's event data JSON payload, which follows the header JSON, and field definitions. [ { \"summary\":\"More than 10 request errors logged in the last 5 minutes\", \"category\": \"notifications\" } ] Copy JSON event field Description summary Required. The message to be sent. Use a simple string. category Optional. String value of one of the existing categories used in the Infrastructure product, or a new category. The default value is notifications. Examples of categories: applications automation configuration metadata notifications os packages services sessions system users Inventory data Infrastructure inventory data captures live state system information; for example: Configuration data System versions installed Other system metadata You can view this data in the Infrastructure Inventory page and Infrastructure events heatmap. You can also query data related to inventory changes in Insights. The inventory data type is a hash of one or more JSON sub-objects containing: A unique inventory id key (required): The inventory item's identifier. This is used in combination with the integration's prefix to create a path to the inventory item's data. Like paths combine across entities and show possible variance. This ID points to a hash. A hash of key/value pairs, one per inventory attribute. At least one is required. Keys should be strings. Values may either be a scalar type (string or number) or another hash object of key/values. New Relic supports hierarchy, but the final value nodes must be a scalar. Here's an example of an integration's inventory data JSON: { \"events/worker_connections\": { \"value\": 1024 }, \"http/gzip\" : { \"value\": \"on\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.90192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> executable file: JSON <em>specifications</em>",
        "sections": "On-host <em>integration</em> executable file: JSON <em>specifications</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "When using our <em>Integrations</em> <em>SDK</em> for <em>infrastructure</em> monitoring to build a custom on-host integration, the integration will consist of at least three files: an executable file and at least one configuration file. The executable file generates JSON data that is consumed by the <em>infrastructure</em>"
      },
      "id": "617dc09e64441f0a22fbde01"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0b11df7fe7973b78788dc86507e41a387516e42c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-12-30T21:52:10Z",
      "updated_at": "2021-10-24T01:10:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.70316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "617dc06328ccbcd5847fff32"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.83328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    },
    {
      "sections": [
        "On-host integration executable file: JSON specifications",
        "Executable file requirements",
        "File placement",
        "Integration protocol v4: Example JSON output",
        "Integration protocol v3: Example JSON output",
        "JSON: General specifications",
        "General output and JSON formatting",
        "Errors and logging",
        "Exit/close of executable",
        "JSON: Header",
        "JSON: Entities",
        "Loopback address replacement on entity names",
        "JSON: Metric, inventory, and event data",
        "Important",
        "Metric data",
        "Event data",
        "Inventory data"
      ],
      "title": "On-host integration executable file: JSON specifications",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "f8a03eb3e346e4b403c4f5bea5228ce4ea69dfe9",
      "image": "https://docs.newrelic.com/static/de6d60d8375ae15068eea2d7d28b9e3f/ade6e/new-relic-integrations-sdk-data-structure.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integration-executable-file-json-specifications/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-10-24T01:15:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using our Integrations SDK for infrastructure monitoring to build a custom on-host integration, the integration will consist of at least three files: an executable file and at least one configuration file. The executable file generates JSON data that is consumed by the infrastructure monitoring agent and sent to New Relic. We refer to the JSON object as the SDK integration protocol. Executable file requirements The executable can be any file that runs from a command-line interface; for example: A shell script A scripting language script A compiled binary The only requirement of your executable file is that it exports JSON data, in a single line format, that meets the specifications in this document. Recommendation: Use Go to create integrations; it's the language we use to create on-host integrations and the integration building tools. However, you can create an integration in any language. File placement The executable file goes in this directory: Linux: /var/db/newrelic-infra/custom-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Integration protocol v4: Example JSON output The following section explains the new JSON schema (integration protocol v4). The SDK v4 only supports this new protocol version. These are the most important changes: A new integration object at the top level. The entity and metrics objects have been modified. See the v3 to v4 migration guide for more information. { \"protocol_version\":\"4\", # protocol version number \"integration\":{ # this data will be added to all metrics and events as attributes, # and also sent as inventory \"name\":\"integration name\", \"version\":\"integration version\" }, \"data\":[ # List of objects containing entities, metrics, events and inventory { \"entity\":{ # this object is optional. If it's not provided, then the Entity will get # the same entity ID as the agent that executes the integration. \"name\":\"redis:192.168.100.200:1234\", # unique entity name per customer account \"type\":\"RedisInstance\", # entity's category \"displayName\":\"my redis instance\", # human readable name \"metadata\":{} # can hold general metadata or tags. Both are key-value pairs that will # be also added as attributes to all metrics and events }, \"metrics\":[ # list of metrics using the dimensional metric format { \"name\":\"redis.metric1\", \"type\":\"count\", # gauge, count, summary, cumulative-count, rate or cumulative-rate \"value\":93, \"attributes\":{} # set of key-value pairs that define the dimensions of the metric } ], \"inventory\":{...}, # Inventory remains the same \"events\":[...] # Events remain the same } ] } Copy Integration protocol v3: Example JSON output The JSON includes: A header, with basic integration data (name, version) A data list, which includes one or more entities reporting data (metric, inventory, and/or event data) This diagram shows this structure: Here is an example JSON output (formatted with line breaks for readability). Definitions and specifications follow this example: { \"name\": \"my.company.integration\", \"protocol_version\": \"3\", \"integration_version\": \"x.y.z\", \"data\": [ { \"entity\": { \"name\": \"my_garage\", \"type\": \"building\", \"id_attributes\": [ { \"key\": \"environment\", \"value\": \"production\" }, { \"key\": \"node\", \"value\": \"master\" } ] }, \"metrics\": [ { \"temperature\": 25.3, \"humidity\": 0.45, \"displayName\": \"my_garage\", \"entityName\": \"building:my_garage\", \"event_type\": \"BuildingStatus\" } ], \"inventory\": { \"out_door\": { \"status\": \"open\" } }, \"events\": [] }, { \"entity\": { \"name\": \"my_family_car\", \"type\": \"car\", \"id_attributes\": [ { \"key\": \"environment\", \"value\": \"production\" }, { \"key\": \"node\", \"value\": \"master\" } ] }, \"metrics\": [ { \"speed\": 95, \"fuel\": 768, \"displayName\": \"my_family_car\", \"entityName\": \"car:my_family_car\", \"event_type\": \"VehicleStatus\" } ], \"inventory\": { \"motor\": { \"brand\": \"renault\", \"cc\": 1800 } }, \"events\": [ { \"category\": \"gear\", \"summary\": \"gear has been changed\" } ], \"add_hostname\": true } ] } Copy JSON: General specifications Here are general specifications for the JSON output: General output and JSON formatting Data is emitted to stdout (standard output) in JSON format. The agent will treat stdout and stderr file descriptors as line-wise buffers. Use standard JSON, not \"pretty printed\" JSON, for the output. Recommendation: Include an optional command line switch (for example, --pretty) to make JSON \"pretty printed\" for debugging purposes. Errors and logging Error and debug information must be emitted to stderr (standard error). Follow New Relic's recommendations and best practices for integration logging. Exit/close of executable The exit code must exit with a 0 status code and follow platform-specific conventions. For example: Linux: 0 == EX_OK Windows: 0 == ERROR_SUCCESS If the executable exits with a non-zero status, the agent will discard any data from stdout and write a message to its log file with the name of the integration, the exit code, and any diagnostic information it can gather. JSON: Header Here's an example of the first part of an on-host integration's JSON output: \"name\":\"com.myorg.nginx\", \"protocol_version\":\"3\", \"integration_version\":\"1.0.0\", \"data\": [ {entities}...] Copy A minimal payload would be a JSON object with only the header fields. Recommendation: If there is no data to collect, use the program return code and log messages written to stderr. JSON header fields Description name Required. Must be identical to the name field in the configuration file. Recommendation: Use reverse domain names to generate unique integration names. protocol_version Required. The version number of the exchange protocol between the integration and the agent that the integration executable is using. The current version is 3. This protocol requires Infrastructure agent 1.2.25 or higher. Protocol 2 requires Infrastructure agent 1.0.859 or higher. Protocol 1 is compatible with all agents. For more information, see SDK changes. integration_version Optional. The integration version. Used to track the integration version running on each host. An integration can have more than one executable. Therefore this is not simply the executable's version. data Required for reporting data. A list containing the data reported from one or more entities. JSON: Entities Inside the data list of the JSON output are one or more entities. The entity entry fields include: Entity JSON fields Description entity Required. Entity data or properties. metrics Optional. Entity related metric list. inventory Optional. Entity related inventory items. events Optional. Entity related event list. add_hostname Optional. Boolean. If true, the entity metrics will be decorated with the hostname. Inside the data list of the JSON output are one or more entities and their data. The entity entry has two fields: Entity data JSON fields Description name Required. The identifier/name of the entity. Recommendation: Use reverse domain names to generate unique integration names. type Required. The kind of entity. It will be used by the Infrastructure agent as a namespace to compose a unique identifier in conjunction with the name. id_attributes Optional. A list of key-value attributes that provide uniqueness to an entity. They are attached to the name in the form of key=value to ease readability, provide extra information, and improve entity name uniqueness. Identifier attributes are useful when the entity name is not enough to work as a unique identifier, or when it doesn't provide enough meaningful information. For example: [ { \"key\": \"service\", \"value\": \"mysql\" }, { \"key\": \"role\", \"value\": \"master\" }, ... ] Copy Loopback address replacement on entity names As of Infrastructure agent version 1.2.25 or higher, protocol v3 improves remote entities uniqueness by adding local address replacement on entity names at agent level. When several remote entities have their name based on an endpoint (either ip or hostname), and this name contains loopback addresses, there are two problems: This localhost value does not provide valuable info without more context. The name could collide with other service being named with a local address. This happens when: Endpoints names are like localhost:port. Ports tend to be the same for a given service; for example, 3306 for Mysql. On incoming protocol v3 data, the Infrastructure agent replaces loopback addresses on the entity name (and key) with the first available item of the following list: Cloud provider instance ID, retrieved by the agent if applicable Display name, set via the display_name agent config option Hostname, as retrieved by the agent For example, if an integration using protocol v3 returns an entity with the name localhost:3306, and the agent is running on bare metal (doesn’t have cloud provider instance ID), the display_name has not been set, and the hostname is prod-mysql-01, then the agent will replace the localhost and produce the entity name prod-mysql-01:3306. The Infrastructure agent enables loopback address replacement automatically for v3 integration protocol. You can also enable this for v2 via the agent configuration flag replace_v2_loopback_entity_names. In this case all the integrations being run by the agent using v2 will have their names replaced whenever they carry a local address. JSON: Metric, inventory, and event data Data values follow the executable file header. You can record three data types: Metrics Events Inventory Important From the perspective of New Relic Dashboards, the infrastructure metrics and events are both classified as event data types. To find both metrics and events, use the Insights Event data explorer, not the Metric data explorer. Metric data Infrastructure metric data typically is used for simple numeric data; for example: Count of MySQL requests in a queue per second Count of active connections to a specific system per minute Besides associated metadata, a metric is essentially just a metric name and a numeric value. To view this data, use the New Relic Insights Event data explorer. Here's an example of an entity's metric data JSON: [ { \"event_type\":\"MyorgNginxSample\", \"net.connectionsActive\": 54, # metric data (a key/value pair) \"net.requestsPerSecond\": 21, # metric data (a key/value pair) \"net.reading\": 23, # metric data (a key/value pair) } ] Copy JSON metric data field Description event_type Required. event_type defines where the metrics will be stored. Each set of metrics is stored as a sample inside the specified event type. Each integration must store its data in its own event type. If you are generating multiple types of samples from the same integration, use different event types for each. Recommendation: To ensure the event types used by your integration are unique, prefix the event type with your company name or acronym. For example, if your custom integration captures Cassandra node metrics and Cassandra column family metrics as different samples, store them in different event types, such as MyOrgCassandraSample and MyOrgCassandraColumnFamilySample. If the event type does not exist, it will be created automatically when New Relic receives data from your integration and make it available in the UI. One or more metric data key/value pairs Required (at least one). A metric measurement containing a name (key) and its value. Make sure these generally conform to the entity type's specification for maximum compatibility with Infrastructure features. Recommendation: Prefix your metric with a category to help when navigating through metrics in the New Relic UI. New Relic integrations currently use: net: Number of connections, web server requests, bytes transmitted over the network, etc.; for example, net.connectionsActive. query: Metrics directly related to database queries; for example, query.comInsertPerSecond. db: Internal database metrics; for example, db.openTables. Use multilevel prefixes for additional grouping when it makes sense; for example, db.innodb.bufferPoolPagesFree. Use the innerCamelCase naming format; for example: net.requestsPerSecond. Use a metric name as close to the original one as possible while respecting the other specifications. For example: Original name: Qcache_hits Metric name: db.qCacheHits Measurement unit Recommendation: Specify the measurement unit using a unit suffix if it is not already included in the original metric name, as in the following examples: Percentages: Use Percent; for example: cpuUtilPercent. Rates: Use a format such as PerSecond. Seconds is the standard rate measurement, but you can also use other units, such as PerMinute or PerDay. Byte measurements: Use Bytes. Recommendation: If a metric is captured in a different unit, such as Megabytes, convert it to Bytes. For example: db.allMemtablesOffHeapSizeBytes. Time measurements: Use Milliseconds. Recommendation: If a metric is captured in a different unit, such as Seconds, convert it to Milliseconds. For example: query.readLatency50thPercentileMilliseconds Value Use a string or a number (integer or float). Strings can be used as associated metadata, allowing data to be filtered in the New Relic UI. A boolean would need to be expressed as either a string (\"true\", \"false\") or an integer (1, 0). Do not use complex types of values, such as arrays or hashes. Event data Infrastructure event data represents arbitrary, one-off messages for key activities on a system; for example: Starting up a specific service Creating a new table You can view this data in the Infrastructure Events page and Infrastructure events heatmap. You can also query the InfrastructureEvent event type in Insights. Here's an example of an integration's event data JSON payload, which follows the header JSON, and field definitions. [ { \"summary\":\"More than 10 request errors logged in the last 5 minutes\", \"category\": \"notifications\" } ] Copy JSON event field Description summary Required. The message to be sent. Use a simple string. category Optional. String value of one of the existing categories used in the Infrastructure product, or a new category. The default value is notifications. Examples of categories: applications automation configuration metadata notifications os packages services sessions system users Inventory data Infrastructure inventory data captures live state system information; for example: Configuration data System versions installed Other system metadata You can view this data in the Infrastructure Inventory page and Infrastructure events heatmap. You can also query data related to inventory changes in Insights. The inventory data type is a hash of one or more JSON sub-objects containing: A unique inventory id key (required): The inventory item's identifier. This is used in combination with the integration's prefix to create a path to the inventory item's data. Like paths combine across entities and show possible variance. This ID points to a hash. A hash of key/value pairs, one per inventory attribute. At least one is required. Keys should be strings. Values may either be a scalar type (string or number) or another hash object of key/values. New Relic supports hierarchy, but the final value nodes must be a scalar. Here's an example of an integration's inventory data JSON: { \"events/worker_connections\": { \"value\": 1024 }, \"http/gzip\" : { \"value\": \"on\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.90192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> executable file: JSON <em>specifications</em>",
        "sections": "On-host <em>integration</em> executable file: JSON <em>specifications</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "When using our <em>Integrations</em> <em>SDK</em> for <em>infrastructure</em> monitoring to build a custom on-host integration, the integration will consist of at least three files: an executable file and at least one configuration file. The executable file generates JSON data that is consumed by the <em>infrastructure</em>"
      },
      "id": "617dc09e64441f0a22fbde01"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes": [
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2021-12-30T21:54:38Z",
      "updated_at": "2021-10-24T01:19:36Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom New Relic Infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the Infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the Infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the Infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.58891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing <em>Infrastructure</em> <em>integration</em> data",
        "sections": "Not seeing <em>Infrastructure</em> <em>integration</em> data",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem You created a custom New Relic <em>Infrastructure</em> on-host integration using the <em>Integrations</em> <em>SDK</em>, but you&#x27;re not seeing data in the <em>Infrastructure</em> UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic <em>Infrastructure</em>&#x27;s integration requirements. After"
      },
      "id": "617db89228ccbc29ac7fe921"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "6fedd9b84d0f4b23754b412b0e5af112ab91ab48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-12-30T21:53:00Z",
      "updated_at": "2021-10-24T01:14:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.22069,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "617dc09e64441f0ffefbd7bd"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.59494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    }
  ],
  "/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data": [
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "354ea97c221e2f16bd727afbd555d27258301e4c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-12-30T21:54:19Z",
      "updated_at": "2021-10-24T01:17:59Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.6051,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "617dc0d0196a6788d7f7e440"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "6fedd9b84d0f4b23754b412b0e5af112ab91ab48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-12-30T21:53:00Z",
      "updated_at": "2021-10-24T01:14:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.22069,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "617dc09e64441f0ffefbd7bd"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration",
        "Assisted method",
        "Redis",
        "Microsoft SQL",
        "Manual method"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "d37e2a37e3f117a7c277dc97d933ca9db353f230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-12-30T21:53:55Z",
      "updated_at": "2021-11-14T16:38:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, use one of the following methods: Assisted method Using the New Relic CLI, run the following command to automatically convert your old definition/configuration files to the new configuration format: bash Copy $ newrelic agent config migrateV3toV4 -d /path/definitionFile -c /path/configFile -o /path/outputFile Examples: Redis The path used below is the default location for Linux based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 \\ -d /var/db/newrelic-infra/newrelic-integrations/redis-definition.yml \\ -c /etc/newrelic-infra/integrations.d/redis-config.yml \\ -o /etc/newrelic-infra/integrations.d/redis.yml Copy Microsoft SQL The path used below is the default location for Windows based integrations. You may need to adjust the path if you are using a custom location: newrelic agent config migrateV3toV4 ^ -d 'C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\mssql-definition.yml' ^ -c 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql-config.yml' ^ -o 'C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\mssql.yml' Copy Manual method To convert the integration file manually: Rename the instances top-level section to integrations. Remove the integration_name top-level section, and add it to each integration entry. You are no longer required to keep a separate file for each integration type, and you can group your legacy integration entries in the same file as other integrations. Here's an example of the new version of the Apache integration configuration: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Important Please note that the older configuration format doesn't support hot reloading. Therefore, you need to restart the Infrastructure agent to remove the old integrations configuration. Otherwise, the old instances will coexist with the new ones.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.59492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "617dc09ee7b9d2a21fc062e6"
    }
  ],
  "/docs/infrastructure/host-integrations/installation/container-auto-discovery-host-integrations": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.78902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "Linux <em>installation</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux <em>installation</em> Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the <em>integrations</em> folder"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "<em>Install</em> and activate the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " Monitor service running on ECS. Kubernetes <em>installation</em> See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.8158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "<em>Install</em> and activate the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    }
  ],
  "/docs/infrastructure/host-integrations/installation/install-infrastructure-host-integrations": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.78899,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "Linux <em>installation</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux <em>installation</em> Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the <em>integrations</em> folder"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "<em>Install</em> and activate the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " Monitor service running on ECS. Kubernetes <em>installation</em> See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.81578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "<em>Install</em> and activate the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    }
  ],
  "/docs/infrastructure/host-integrations/installation/secrets-management": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.78899,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "Linux <em>installation</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux <em>installation</em> Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the <em>integrations</em> folder"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "<em>Install</em> and activate the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " Monitor service running on ECS. Kubernetes <em>installation</em> See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.81578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "<em>Install</em> and activate the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    }
  ],
  "/docs/infrastructure/host-integrations/installation/update-infrastructure-host-integration-package": [
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.78896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "Linux <em>installation</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux <em>installation</em> Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the <em>integrations</em> folder"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL monitoring <em>integration</em>",
        "sections": "<em>Install</em> and activate the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " Monitor service running on ECS. Kubernetes <em>installation</em> See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.81577,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "<em>Install</em> and activate the <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    }
  ],
  "/docs/infrastructure/host-integrations/open-source-host-integrations-list/f5-open-source-integration": [
    {
      "sections": [
        "F5 monitoring integration",
        "Compatibility and requirements",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Enable your F5 instance",
        "Tip",
        "Configure the integration",
        "F5 instance settings",
        "Labels/custom attributes",
        "Example configurations",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Environment variables replacement",
        "Metrics-only with partition filtering",
        "Multi-instance monitoring",
        "Find and use data",
        "Metric data",
        "System sample metrics",
        "Virtual server sample metrics",
        "Pool sample metrics",
        "Pool member sample metrics",
        "Node sample metrics",
        "Inventory data",
        "Pool Inventory",
        "Node inventory",
        "Pool Member Inventory",
        "Virtual Server Inventory",
        "System Inventory",
        "Application Inventory",
        "Check the source code"
      ],
      "title": "F5 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "42d77722b01396822e02cf3ef78160a7a66ecd72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/f5-monitoring-integration/",
      "published_at": "2021-12-30T10:33:43Z",
      "updated_at": "2021-10-24T00:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our F5 BIG-IP integration collects and sends inventory and metrics from your F5 BIG-IP instance to our platform, where you can aggregate and visualize key performance metrics. We collect data at the system, application, pool, pool member, virtual server, and node levels. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with F5 BIG-IP 11.6 or higher. Before installing the integration, make sure that you meet the following requirements: Install the infrastructure agent. Linux distribution or Windows version compatible with the infrastructure agent. F5 BIG-IP user account with Auditor-level access user privileges and iControl REST API access permissions. Install and activate To install the F5 BIG-IP integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-f5. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp f5-config.yml.sample f5-config.yml Copy Edit the f5-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-f5 MSI installer image from: http://download.newrelic.com/infrastructure_agent/windows/integrations/nri-f5/nri-f5-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-f5-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: copy f5-config.yml.sample f5-config.yml Copy Edit the f5-config.yml file as described in the configuration settings. Restart the infrastructure agent. Additional notes: We recommend you install the integration on a separate server and monitor F5 remotely. Advanced: It's also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. Enable your F5 instance Create a new F5 BIG-IP user and assign user permissions: Create a user account with, at minimum, Auditor-level access permissions. For instructions on how to do this, see the official F5 documentation. Once the user has been created, assign the user iControl REST user permissions. Tip Administrator-level permissions may be required to collect some system sample metrics or system inventory configuration data. For more information on user permission levels, see the official F5 documentation on user role access descriptions. Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see monitor services running on Kubernetes. If enabled via Amazon ECS, see monitor services running on ECS. If installed via on-host, edit the config in the integration's YAML config file, f5-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations, such as interval, timeout, and inventory_source, among others. For more on these common settings, see our list of configuration properties document. If you're still using our legacy configuration/definition files, see on-host integrations standard configuration format. Specific settings related to F5 are defined using the env section of the configuration file. These settings control the connection to your F5 instance, as well as other security settings and features. F5 instance settings The F5 integration collects both metrics(M) and inventory(I) information. In the table, use the Applies To column for the settings available to each collection: Setting Description Default Applies to HOSTNAME Hostname or IP where F5 is running. localhost M/I PORT Port on which F5 API is listening. 443 M/I USERNAME Username for accessing F5 API. N/A M/I PASSWORD Password for the given user. N/A M/I CA_BUNDLE_FILE Location of SSL certificate on the host. Only required if USE_SSL is true. N/A M/I CA_BUNDLE_DIR Alternative Certificate Authority bundle directory. N/A M/I TIMEOUT Timeout for requests, in seconds. 30 M/I PARTITION_FILTER A JSON array of BIG-IP partitions to collect from. See this metrics-only with partition filtering example. [\"Common\"] M MAX_CONCURRENT_REQUESTS Maximum number of requests running concurrently. 10 M METRICS Set to true to enable metrics-only collection. false INVENTORY Set to true to enable inventory-only collection. false You can define these setting values in different ways, depending on your preference and need: Add the value directly in the config file. This is the most common way. Replace the values from environment variables using the {{}} notation. This requires Infrastructure agent v1.14.0+. Read more on using passthrough or see the environment variables replacement example. Use secrets management to protect sensitive information, such as passwords, that would be exposed in plain text in the configuration file. For more information, read more about using secrets management. Labels/custom attributes You can also decorate your metrics using labels. Labels allow you to add key/value pair attributes to your metrics, which you can then use to query, filter, or group your metrics. Our default sample config file includes examples of labels. You can remove, modify, or add new ones of your choice. labels: env: production role: load_balancer Copy Example configurations Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-f5 env: HOSTNAME: localhost PORT: 443 USERNAME: f5_user PASSWORD: f5_password interval: 15s labels: environment: production inventory_source: config/f5 Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 15 seconds and inventory every 60 seconds: integrations: - name: nri-f5 env: METRICS: true HOSTNAME: localhost PORT: 443 USERNAME: f5_user PASSWORD: f5_password interval: 15s labels: environment: production - name: nri-f5 env: INVENTORY: true HOSTNAME: localhost PORT: 443 USERNAME: f5_user PASSWORD: f5_password interval: 60s labels: environment: production inventory_source: config/f5 Copy Environment variables replacement In this configuration, the environment variable F5_HOST populates the HOSTNAME setting of the integration: integrations: - name: nri-f5 env: METRICS: \"true\" HOSTNAME: {{F5_HOST}} PORT: 443 USERNAME: f5_user PASSWORD: f5_password interval: 15s labels: env: production role: load_balancer Copy Metrics-only with partition filtering This configuration only collects metrics and adds \"MyOtherPartition\" to the list of partitions to be sampled. By default, the integration only samples the \"Common\" partition: integrations: - name: nri-f5 env: METRICS: \"true\" HOSTNAME: {{F5_HOST}} PORT: 443 USERNAME: f5_user PASSWORD: f5_password PARTITION_FILTER: '[\"Common\",\"MyOtherPartition\"]' interval: 15s labels: env: production role: load_balancer Copy Multi-instance monitoring This configuration monitors multiple F5 servers from the same integration. The first instance (HOSTNAME: 1st_f5_host) collects metrics and inventory, while the second instance (HOSTNAME: 2nd_f5_host) only collects metrics. integrations: - name: nri-f5 env: METRICS: \"true\" HOSTNAME: 1st_f5_host PORT: 443 USERNAME: f5_user PASSWORD: f5_password interval: 15s labels: env: production role: load_balancer - name: nri-f5 env: INVENTORY: \"true\" HOSTNAME: 1st_f5_host PORT: 443 USERNAME: f5_user PASSWORD: f5_password interval: 60s labels: env: production role: load_balancer inventory_source: config/f5 - name: nri-f5 env: METRICS: \"true\" HOSTNAME: 2nd_f5_host PORT: 443 USERNAME: f5_user PASSWORD: f5_password interval: 15s labels: env: production role: load_balancer Copy Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Third-party services and select one of the F5 BIG-IP integration links. In New Relic Insights, F5 BIG-IP data is attached to the following Insights event types: F5BigIpSystemSample F5BigIpVirtualServerSample F5BigIpPoolSample F5BigIpPoolMemberSample F5BigIpNodeSample For more on how to find and use your data, see Understand integration data. Metric data The F5 BIG-IP integration collects the following metric data attributes. Some metric name are prefixed with a category indicator and a period, such as system., virtualserver., or pool.. System sample metrics These attributes can be found by querying the F5BigIpSystemSample event types. Metric Description system.cpuIdleTicksPerSecond Amount of CPU ticks that the CPU was idle per second. Requires Administrator-level user permissions to collect. system.cpuIdleUtilization Average percentage of time the CPU is idle. system.cpuInterruptRequestUtilization Average percentage of time the CPU is handling interrupt requests. system.cpuIOWaitUtilization Average percentage of time the CPU is waiting on IO. system.cpuNiceLevelUtilization Average percentage of time the CPU is handling nice level processes. system.cpuSoftInterruptRequestUtilization Average percentage of time the CPU is handling soft interrupt requests. system.cpuStolenUtilization Average percentage of time the CPU is handling reclaimed cycles by the hypervisor. system.cpuSystemTicksPerSecond Amount of CPU ticks used by the kernel processes per second. Requires Administrator-level user permissions to collect. system.cpuSystemUtilization Average percentage of time the CPU is used by the kernel. system.cpuUserTicksPerSecond Amount of CPU ticks used by user processes per second. Requires Administrator-level user permissions to collect. system.cpuUserUtilization Average percentage of time the CPU is used by user processes. system.memoryFreeInBytes Total amount of memory free, in bytes. system.memoryTotalInBytes Total amount of memory, in bytes. Requires Administrator-level user permissions to collect. system.memoryUsedInBytes Total amount of memory used, in bytes. Requires Administrator-level user permissions to collect. system.otherMemoryFreeInBytes Free memory reserved for control plane processes, in bytes. system.otherMemoryTotalInBytes Total memory reserved for control plane processes, in bytes. system.otherMemoryUsedInBytes Used memory reserved for control plane processes, in bytes. system.swapFreeInBytes Swap space free, in bytes. system.swapTotalInBytes Swap space total, in bytes. system.swapUsedInBytes Swap space used, in bytes. system.tmmMemoryFreeInBytes Free memory reserved for Traffic Management Microkernel (TMM), in bytes. system.tmmMemoryTotalInBytes Total memory reserved for Traffic Management Microkernel (TMM), in bytes. system.tmmMemoryUsedInBytes Used memory reserved for Traffic Management Microkernel (TMM), in bytes. Virtual server sample metrics These attributes can be found by querying the F5BigIpVirtualServerSample event types in Insights. Metric Description virtualserver.avaibilityState The BIG-IP defined availability. Options: 0 = Offline 1 = Unknown 2 = Online virtualserver.clientsideConnectionsPerSecond The rate of connections created through the client side of the object per second. virtualserver.cmpEnabled Indicates whether or not Cluster Multiprocessing (CMP) is enabled. virtualserver.cmpEnableMode Shows the Cluster Multiprocessing (CMP) mode indicators. Options: CMP disabled = none, disable, or single. CMP enabled = enable or all. virtualserver.connections The current number of connections from BIG-IP. virtualserver.csMaxConnDur Maximum connection duration from the client side of the object. virtualserver.csMinConnDur Minimum connection duration from the client side of the object. virtualserver.enabled The current enabled state. Options: 0 = Disabled 1 = Enabled virtualserver.ephemeralBytesInPerSecond Total number of bytes in through the ephemeral port per second. virtualserver.ephemeralBytesOutPerSecond Total number of bytes out through the ephemeral port per second. virtualserver.ephemeralConnectionsPerSecond The rate of connection creation through the ephemeral port per second. virtualserver.ephemeralCurrentConnections The current number of connections through the ephemeral port. virtualserver.ephemeralEvictedConnectionsPerSecond The number of connections that are evicted through the ephemeral port per second. virtualserver.ephemeralMaxConnections Maximum number of connections through the ephemeral port. virtualserver.ephemeralPacketsReceivedPerSecond The number of packets in through the ephemeral port per second. virtualserver.ephemeralPacketsSentPerSecond The number of packets out through the ephemeral port per second. virtualserver.ephemeralSlowKilledPerSecond The number of slow connections that are killed through the ephemeral port per second. virtualserver.evictedConnsPerSecond The rate of connections evicted per second. virtualserver.inDataInBytes The amount of data received from the BIG-IP virtual server, in bytes. virtualserver.outDataInBytes The amount of data sent to the BIG-IP virtual server, in bytes. virtualserver.packetsReceived The number of packets received from the BIG-IP virtual server. virtualserver.packetsSent The number of packets sent to the BIG-IP virtual server. virtualserver.requests The number of requests in the last collection interval to BIG-IP. virtualserver.slowKilledPerSecond The number of slow connections killed through the client side of the object per second. virtualserver.statusReason An explanation of the current status. virtualserver.usageRatio The usage ratio for the virtual server. Pool sample metrics These attributes can be found by querying the F5BigIpPoolSample event types in Insights. Metric Description pool.activeMembers The number of active pool members. pool.availabilityState The current availability state. Options: 0 = Offline 1 = Unknown 2 = Online pool.connections The current number of connections. pool.connqAgeEdm The queue age exponential-decaying max. pool.connqAgeEma The queue age exponential-moving average. pool.connqAgeHead The current queue age head. pool.connqAgeMax The queue age all-time max. pool.connqAllAgeEdm The sum of pool member queue age exponential-decaying max. pool.connqAllAgeEma The sum of pool member queue age exponential-moving average. pool.connqAllAgeHead The sum of pool member queue age head. pool.connqAllAgeMax The sum of pool member queue age all-time max. pool.connqAllDepth The sum of pool member depth. pool.connqDepth The queue depth. pool.currentConnections The current connections. pool.enabled The current enabled state, can be user defined. Options: 0 = Disabled 1 = Enabled pool.inDataInBytes The amount of data received from the BIG-IP pool, in bytes. pool.minActiveMembers Pool minimum active members. pool.outDataInBytes The amount of data sent to the BIG-IP pool, in bytes. pool.packetsReceived The number of packets received from the BIG-IP pool. pool.packetsSent The number of packets sent to the BIG-IP pool. pool.requests The total number of requests to the pool. pool.statusReason Textual property explaining the overall health reason. Pool member sample metrics These attributes can be found by querying the F5BigIpPoolMemberSample event types in Insights. Metric Description member.availabilityState The current availability from the BIG-IP system. Options: 0 = Offline 1 = Unknown 2 = Online member.connections The current connections. member.enabled Enabled state of the pool member with regards to the parent pool. Options: 0 = Disabled 1 = Enabled member.inDataInBytes The amount of data received from the BIG-IP pool member, in bytes. member.monitorStatus The status of the monitor. Options: 0 = Down 1 = Unchecked 2 = Any other status member.outDataInBytes The amount of data sent to the BIG-IP pool member, in bytes. member.packetsReceived The number of packets received from the BIG-IP pool member. member.packetsSent The number of packets sent to the BIG-IP pool member. member.requests The current number of requests over the last collection interval. member.sessions The current session count. member.sessionStatus The current session health status. Options: 0 = Disabled 1 = Enabled member.state The current state. Options: 0 = Down 1 = Up member.statusReason Explanation of the current status. Node sample metrics These attributes can be found by querying the F5BigIpNodeSample event types in Insights. Metric Description node.availabilityState The current BIG-IP availability state to the node. Options: 0 = Offline 1 = Unknown 2 = Online node.connections The current number of network connections from BIG-IP. node.connectionsPerSecond The number of connections made per second. node.enabled The current BIG-IP enabled state. Options: 0 = Disabled 1 = Enabled , node.inDataInBytes The amount of data received from the BIG-IP node, in bytes. node.monitorStatus The current health monitor rule status. Options: 0 = Down 1 = Unchecked 2 = Any other status node.outDataInBytes The amount of data sent to the BIG-IP node, in bytes. node.packetsReceived The number of packets received from the BIG-IP node. node.packetsSent The number of packets sent to the BIG-IP node. node.requests The current number of requests over the last collection from BIG-IP. node.sessions The current number of sessions. node.sessionStatus The current status of the session. Options: 0 = Disabled 1 = Enabled node.statusReason BIG-IP reason for the current status. Inventory data The F5 BIG-IP integration also collects configuration data at system, application, pool, pool member, virtual server, and node levels. The data is available on the Infrastructure Inventory page, under the config/f5 source. For more about inventory data, see Understand integration data. The integration captures data for the following F5 BIG-IP configuration parameters: Pool Inventory Metric Description currentLoadMode Current load balancing mode. description User defined description. kind Kind of pool. maxConnections Current max number of connections seen at one point. monitorRule Current health monitoring rule applied. Node inventory Metric Description address BIG-IP network address to send to the node. fqdn FQDN of node. kind Type of Node in BIG-IP. maxConnections Current highest number of network connections reported from BIG-IP. monitorRule BIG-IP Health Monitor rule. Pool Member Inventory Metric Description kind Type of Pool member. maxConnections Current highest number of network connections reported from BIG-IP. monitorRule BIG-IP health monitor rule. nodeName Name of the node the pool member is using. poolName Name of the pool the pool member belongs. port Port the pool member listens on. Virtual Server Inventory Metric Description applicationService Current application service assigned. destination Destination address picked up by BIG-IP. kind Type of virtual server. maxConnections Current highest number of network connections reported from BIG-IP. name User defined name. pool Pool the virtual server uses for load balancing. System Inventory Metric Description chassisSerialNumber Chassis Serial Number for the current device. Requires Access Administrator-level user permissions to collect. platform Platform of the current device. Requires Access Administrator-level user permissions to collect. product Product Name for the current device. Requires Access Administrator-level user permissions to collect. Application Inventory Metric Description deviceGroup Device group running application service. kind BIG-IP Defined type. name User defined name. poolToUse Server side pool load balancing requests. template Template applied to application including security and monitoring rules. templateModified Indicator of modifications made to out of the box template. trafficGroup Current traffic group to which service is applied. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.53552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>F5</em> monitoring <em>integration</em>",
        "sections": "<em>F5</em> monitoring <em>integration</em>",
        "tags": "<em>Integrations</em>",
        "body": ". Inventory data The <em>F5</em> BIG-IP <em>integration</em> also collects configuration data at system, application, pool, pool member, virtual server, and node levels. The data is available on the Infrastructure Inventory page, under the config&#x2F;<em>f5</em> <em>source</em>. For more about inventory data, see Understand <em>integration</em> data"
      },
      "id": "617da73328ccbc1ed5801193"
    },
    {
      "sections": [
        "Dimensional metric equivalents for the agent and on-host integrations",
        "BETA FEATURE"
      ],
      "title": "Dimensional metric equivalents for the agent and on-host integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-12-30T22:00:35Z",
      "updated_at": "2021-11-26T06:28:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. In the past, our infrastructure agent and on-host integrations have reported metrics as attributes attached to events, also known as \"sample data.\" We have now made these metrics also available as dimensional metrics, a data format that allows for improved analysis and aggregation over time. The following table presents the equivalent dimensional metric names for our infrastructure agent and for our on-host integrations. For tips on how to query dimensional metrics, see Query dimensional metrics. Integration Dimensional metric name (new) Sample metric name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTim",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.0578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Dimensional metric equivalents <em>for</em> the agent and on-host <em>integrations</em>",
        "sections": "Dimensional metric equivalents <em>for</em> the agent and on-host <em>integrations</em>",
        "body": " elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes <em>F5</em> <em>f5</em>.node.availabilityState node.availabilityState <em>F5</em> <em>f5</em>.node.connections node.connections <em>F5</em> <em>f5</em>.node.connectionsPerSecond node.connectionsPerSecond <em>F5</em> <em>f5</em>.node.enabled node.enabled <em>F5</em> <em>f5</em>.node.inDataInBytesPerSecond node.inDataInBytesPerSecond <em>F5</em>"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Request queue server configuration examples",
        "Apache",
        "Nginx",
        "F5 load balancers",
        "Network timing"
      ],
      "title": "Request queue server configuration examples",
      "type": "docs",
      "tags": [
        "APM",
        "APM UI pages",
        "Features"
      ],
      "external_id": "c7a069b8875af411530a34aaef67155d20d7fb19",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/applications-menu/features/request-queue-server-configuration-examples/",
      "published_at": "2021-12-30T05:29:28Z",
      "updated_at": "2021-07-09T08:23:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to report request queuing, New Relic agents depend on an HTTP header set by the front-end web server (such as Apache or Nginx) or load balancer (such as HAProxy or F5). These examples use the X-Request-Start header, since it is has broader support across platforms. If this does not work with your server configuration for request queuing, try using the X-Queue-Start header. The syntax should otherwise be the same. Apache Apache's mod_headers module includes a %t variable that is formatted correctly. To enable request queue reporting, add this code to your Apache config: RequestHeader set X-Request-Start \"%t\" Copy Nginx If you are using Nginx version 1.2.6 or higher and the latest version of the Ruby, Python, or PHP agent, Nginx can easily be configured to report queue time. (For Nginx versions 1.2.6 or lower, you must recompile Nginx with a module or patch.) Configuring with Nginx 1.2.6 or higher uses the ${msec} variable, which is a number in seconds with milliseconds resolution. For more information, see http://nginx.org/en/docs/http/ngx_http_core_module.html#variables. Add the appropriate information to your Nginx config: Nginx configuration Values General Nginx use proxy_set_header X-Request-Start \"t=${msec}\"; Copy Passenger Version 5 or higher: >passenger_set_header X-REQUEST-START \"t=${msec}\"; Copy Older versions: passenger_set_cgi_param X_REQUEST_START \"t=${msec}\"; Copy fastcgi fastcgi_param HTTP_X_REQUEST_START \"t=${msec}\"; Copy uWSGI uwsgi_param HTTP_X_REQUEST_START \"t=${msec}\"; Copy F5 load balancers For F5 load balancers, use this configuration snippet: when HTTP_REQUEST_SEND { # TCL 8.4 so we have to calculate the time in millisecond resolution # Calculation from: https://groups.google.com/forum/? fromgroups=#!topic/comp.lang.tcl/tV9H6TDv0t8 set secs [clock seconds] set ms [clock clicks -milliseconds] set base [expr { $secs * 1000 }] set fract [expr { $ms - $base }] if { $fract >= 1000 } { set diff [expr { $fract / 1000 }] incr secs $diff incr fract [expr { -1000 * $diff }] } set micros [format \"%d%03d000\" $secs $fract] # Want this header inserted as if coming from the client clientside { HTTP::header insert X-Request-Start \"t=${micros}\" } } Copy Network timing Even with request queuing configured, the front-end server's setup can still affect network time in your browser data. This is because the front-end server does not add the queuing time header until after it actually accepts and processes the request. The queuing time headers can never account for backlog in the listener socket used to accept requests. For example, if the front-end server's configuration results in a backlog of requests that queue in the listener socket, page load timing will show an increase in network time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.02357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>F5</em> load balancers",
        "tags": "<em>Features</em>",
        "body": "In order to report request queuing, New Relic agents depend on an HTTP header set by the front-end web server (such as Apache or Nginx) or load balancer (such as HAProxy or <em>F5</em>). These examples use the X-Request-Start header, since it is has broader support across platforms. If this does not work"
      },
      "id": "603eb84a28ccbc1734eba7a5"
    }
  ],
  "/docs/infrastructure/host-integrations/open-source-host-integrations-list/memcached-open-source-integration": [
    {
      "sections": [
        "New Relic guided install overview",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "78c43fb865811c44f388f0601e0fb5f7da82fe87",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/new-relic-guided-install-overview/",
      "published_at": "2021-12-30T20:03:34Z",
      "updated_at": "2021-12-14T03:50:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you haven't already, sign up for a free New Relic account so you can instrument your systems and send telemetry data to New Relic. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. Or, if your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 517.9838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "On-host <em>integration</em> (OHI) recipes",
        "body": " haproxy-<em>open</em>-<em>source</em>-<em>integration</em> HashiCorp Consul newrelic install -n hashicorp-consul-<em>open</em>-<em>source</em>-<em>integration</em> <em>Memcached</em> newrelic install -n <em>memcached</em>-<em>open</em>-<em>source</em>-<em>integration</em> Microsoft SQL Server (Windows only) newrelic install -n mssql-server-<em>integration</em>-installer MongoDB newrelic install -n mongodb"
      },
      "id": "61b8148c64441fb9d3d703b5"
    },
    {
      "sections": [
        "Introduction to OpenTelemetry with New Relic",
        "Benefits of OpenTelemetry",
        "Should I use OpenTelemetry instrumentation or New Relic agents?",
        "OpenTelemetry: A work in progress",
        "New Relic's APM agents",
        "How OpenTelemetry works with New Relic",
        "Important",
        "Traces",
        "Metrics",
        "Logs",
        "Next steps"
      ],
      "title": "Introduction to OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "67818451ffb7594e3c27526f4082bd1bc007bc51",
      "image": "",
      "url": "https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic/",
      "published_at": "2021-12-30T03:36:05Z",
      "updated_at": "2021-12-20T05:36:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Are you already familiar with OpenTelemetry and want to begin the setup? Check out our quick start: Quick start If you don't have one already, create a New Relic account. It's free, forever. If you're just getting acquainted with OpenTelemetry, this is what we'll explore here: Benefits of OpenTelemetry Should I use OpenTelemetry or New Relic agents? How OpenTelemetry works with New Relic Benefits of OpenTelemetry OpenTelemetry provides a secure, vendor-neutral specification for service instrumentation so that you can export data to distinct backends of your choice, such as New Relic. OpenTelemetry offers a single set of APIs and libraries that standardize how you collect and transfer telemetry data for your services. The following components make up the OpenTelemetry project: Specifications for the core pillars of observability to drive consistency across all projects. New Relic supports all of these signals: traces, metrics, and logs (see details below) APIs that contain interfaces and implementations based on the specifications SDKs (reference implementations of the APIs) created specifically for languages like Java, Python, Go, Erlang, and more Collectors that offer a vendor-agnostic implementation for processing and exporting Exporters that enable you to send data to a backend of your choice The components of OpenTelemetry work together to create some distinct advantages for capturing telemetry data: Feature Description Ubiquitous instrumentation A single, open standard of instrumentation provides better coverage and flexibility as engineers from all over the world contribute to the instrumentation. Future proof As the instrumentation gets built into libraries and frameworks, and as more vendors move to support this open standard, you can be confident that you won’t need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into OpenTelemetry or add instrumentation directly to source code, ensuring end users can easily monitor these new technologies. Simplified choice You don’t need to decide which instrumentation option to use (a proprietary option or one of the other open standards). Cross-platform compatibility OpenTelemetry supports a variety of languages and backends. It represents a vendor-neutral path for capturing and transmitting telemetry to backends without altering existing instrumentation. Streamlined observability It is easier for vendors to support and test against a single standard as they don’t need to develop their own agents or collectors. High dimensionality OpenTelemetry uses dimensional metrics, so you can filter and facet on more aspects of the data, such as AWS regions, Kubernetes clusters, or service versions. Dimensional metrics also lead to less time between occurrence and reporting. Should I use OpenTelemetry instrumentation or New Relic agents? As you consider OpenTelemetry, you may also be looking at New Relic APM agents that also capture telemetry data. As you'd expect, there is a lot of overlap between features available from OpenTelemetry agents and SDKs versus those available from New Relic APM agents. This is especially true if you're interested in distributed tracing telemetry data. The choice you make depends on what you need. We recommend that you explore both New Relic and OpenTelemetry instrumentation or discuss this with us in our CNCF Slack channel to decide what works best for you. OpenTelemetry: A work in progress OpenTelemetry is still an emerging standard, so your choices may be affected by what's available. You can check on the current state of the specification at the OpenTelemetry site. The current state of language-specific OpenTelemetry APIs and SDKs varies: some languages are still pre-alpha and may be missing instructions on how to instrument your service. Most languages have some implementation of traces that is sufficient to start exporting data to New Relic. Check out this table in GitHub that provides an overview of the state of OpenTelemetry specification compliance for each language. For languages that New Relic does not currently provide an agent or SDK, OpenTelemetry may offer you a good alternative. Also, in cases where you want explicit control over sampling of your telemetry data, OpenTelemetry provides a lot of flexibility. As OpenTelemetry matures, New Relic will continue to support new OpenTelemetry data models and to provide a curated UI experience for our customers. New Relic's APM agents In general, New Relic's APM agents will collect more telemetry data for your services, and they offer a wide range of configuration options and an extensive set of auto-instrumentation capabilities. New Relic's APM agents offer detailed transaction trace visibility for individual services. They also offer predefined sampling to balance the performance impact of your instrumentation against the need to capture enough data to gain helpful insights. How OpenTelemetry works with New Relic New Relic supports the native OpenTelemetry Protocol (OTLP) for exporting telemetry data. This allows you to use the vendor neutral components developed by the OpenTelemetry community to export your data to New Relic. The following tables show the supported features for each telemetry signal. If you have questions about these or have an unsupported use case, please contact us in our CNCF Slack channel, and watch this page for future updates. Important New Relic's exporters for OpenTelemetry are now deprecated in favor of exporting data to New Relic using OTLP. Traces New Relic offers support for the OTLP ingest of trace signals. The maturity of the upstream specification is stable. OpenTelemetry traces and spans are compatible with New Relic traces and spans. OpenTelemetry spans optionally include attributes (name-value pairs) and resource attributes which map directly to dimensions that can be used to facet or filter span data at query time. OpenTelemetry span metadata (for example, name, kind, and trace_id) also map directly to dimensions on NewRelic spans. At this time, New Relic does not support span links or array attributes. For details, see the Traces section of our best practices guide. Feature Supported Span events ✅ Span linking ❌ Array of primitives (homogeneous) ❌ Metrics New Relic offers support for the OTLP ingest of metric signals. Note that the maturity of the upstream specification is experimental. We intend to follow potentially breaking upstream changes. Here are the OpenTelemetry data types we support and their associated mappings. For details, see the Metrics section of our best practices guide. Metric Type Supported Delta sums ✅ Cumulative sums ✅ Gauges ✅ Delta histograms ✅ Summary ✅ Cumulative histograms ❌ Exemplars ❌ Array of primitives (homogeneous) ❌ Logs New Relic offers support for the OTLP ingest of log signals. Note that the maturity of the upstream specification is experimental. We intend to follow potentially breaking upstream changes. OpenTelemetry logs are compatible with New Relic logs. OpenTelemetry logs optionally include attributes (name-value pairs) and resource attributes which map directly to dimensions that can be used to facet or filter log data at query time. OpenTelemetry log metadata (for example, name, severity_text, and trace_id) also map directly to dimensions on New Relic logs. NewRelic currently supports all OpenTelemetry log message types except for arrays. For more details, see the Logs section of our best practices guide. Feature Supported Description LogRecord body ✅ Supported types: string, boolean, int, double, bytes LogRecord attributes ✅ Supported types: string, boolean, int, double, bytes LogRecord fields ✅ Examples: name, severity_text, trace_id Array messages ❌ Array attributes ❌ Next steps Follow the OpenTelemetry quick start to help you get started. You'll also want to review the best practices guide for getting the most out of the data you export to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.00618,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "sections": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> telemetry <em>integrations</em>",
        "body": " won’t need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into <em>Open</em>Telemetry or add instrumentation directly to <em>source</em> code, ensuring end users can easily monitor these new technologies. Simplified choice You don’t need"
      },
      "id": "6174afe1e7b9d2748213b3a6"
    },
    {
      "sections": [
        "Troubleshooting OpenTelemetry with New Relic",
        "OpenTelemetry data sent via OTLP is not queryable",
        "Problem",
        "Solution",
        "Important",
        "OpenTelemetry entities or relationships are missing",
        "Tip"
      ],
      "title": "Troubleshooting OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "9478cc98ba9216af5ad8c74883abdf14565a21a4",
      "image": "https://docs.newrelic.com/static/93271ff8121b09ca17395fdf3f27e700/c1b63/otlp-troubleshooting-facet-query.png",
      "url": "https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-troubleshooting/",
      "published_at": "2021-12-30T07:49:15Z",
      "updated_at": "2021-12-04T16:46:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Troubleshooting OpenTelemetry with New Relic may just be a matter of making sure you are following best practices, but sometimes you may need to take additional steps to diagnose your issues. Here are some examples of specific problems you might encounter, along with steps and tools to resolve them. OpenTelemetry data sent via OTLP is not queryable Problem You sent OpenTelemetry metrics, logs, or traces using OTLP and are unable to view the data. Before digging deeper, make sure you've checked the following: The OTLP endpoint configured matches one of our documented endpoints, is properly formatted, and includes the official default port, 4317. Sending OTLP data via port 443 is not supported at this time. Please note the specific endpoint for FedRAMP compliance, if applicable. The outbound traffic is not restricted by a firewall. Our Networks document explains domains and network blocks that you may need to explicitly allow. The client is configured to use TLS 1.2 or higher and the request includes the api-key header with a valid New Relic account (ingest) license key. Requests include valid protobuf payloads and use gRPC and HTTP/2 transport, preferably with gzip compression enabled. Sending protobuf or JSON-encoded payloads over HTTP/1.1 is not supported at this time. Client output and logs do not indicate 4xx or 5xx response codes are being returned. Solution There are number of tools you can use to validate the successful delivery of telemetry data to our platform. A good first step is to check the data management hub to facet data ingest and determine how much data is arriving from various sources. You can also use the data explorer or query builder to look for data faceted by instrumentation.provider or newrelic.source attributes: FROM Log, Metric, Span SELECT datapointcount() WHERE instrumentation.provider = 'opentelemetry' FACET instrumentation.provider, newrelic.source Copy This query should tell you whether data is arriving via OTLP. If the data you expect is not present, try removing the WHERE clause or checking for integration errors. Querying NrIntegrationError events can help you determine whether you have configuration or format issues or if you've run into our platform limits. Important The ingest limits for metrics, logs, and traces via OTLP are the same as our other data ingest API limits. Various parts of the New Relic UI rely on the presence of specific attributes to function properly. You can use the NRQL console feature in many places to check the WHERE or FACET clauses of the query for required attributes. You can also edit those clauses and re-run the query to determine whether there is data present with those attributes missing. Examples of required attributes include service.name and service.instance.id. For a more complete list of examples, see resources. OpenTelemetry entities or relationships are missing Problem You sent OpenTelemetry data from a service or infrastructure component and either the entity or its relationships are missing or incorrect. Solution OpenTelemetry entities will be synthesized based on the public rules described for the EXT-SERVICE entity type. The standard rule to match relies on the presence of the service.name dimension which follows the OpenTelemetry semantic conventions. To set the service.name with the OpenTelemetry Java SDK, include it in your resource: var resource = Resource.getDefault() .merge(Resource.builder().put(SERVICE_NAME, serviceName).build()); Copy Depending on the SDK, you may also set the service.name by declaring it in the OTEL_RESOURCE_ATTRIBUTES or OTEL_SERVICE_NAME environment variables. For Logs, you can use a structured log template to inject the service.name. Here are some log examples: Setting the service name Logs in context with Log4j2 Tip For more OpenTelemetry examples with New Relic, visit the newrelic-opentelemetry-examples repository on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.51317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting <em>OpenTelemetry</em> with New Relic",
        "sections": "Troubleshooting <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> telemetry <em>integrations</em>",
        "body": " datapointcount() WHERE instrumentation.provider = &#x27;opentelemetry&#x27; FACET instrumentation.provider, newrelic.<em>source</em> Copy This query should tell you whether data is arriving via OTLP. If the data you expect is not present, try removing the WHERE clause or checking for <em>integration</em> errors. Querying"
      },
      "id": "618e863f196a67bd4ce723da"
    }
  ],
  "/docs/infrastructure/host-integrations/troubleshooting/not-seeing-host-integration-data": [
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2021-12-31T01:40:19Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.86505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "body": " monitoring Windows Kubernetes Prometheus On-<em>host</em> <em>integrations</em> (for services like NGINX, StatsD, MySQL, etc.) AWS cloud <em>integrations</em> Azure cloud <em>integrations</em> Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn&#x27;t require installation, except"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    },
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.79083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "Run integrations manually",
        "Problem",
        "Solution",
        "Kafka",
        "RabbitMQ",
        "MSSQL",
        "Oracle",
        "JMX"
      ],
      "title": "Run integrations manually",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "Troubleshooting"
      ],
      "external_id": "9ed6aa2e5abf677209a6b713736e837151c9a973",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/troubleshooting/run-integrations-manually/",
      "published_at": "2021-12-30T07:35:26Z",
      "updated_at": "2021-12-04T17:35:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You want to know if an integration is gathering metrics or not. To diagnose it, run the integration manually. Solution Use the following commands to run your integrations manually: Kafka echo 'kafka.network:type=RequestMetrics,name=*,request=*’ | nrjmx -host host -port port Copy RabbitMQ Basic connect test: ./bin/nri-rabbitmq -hostname rabbitmqhost -username user -password password Copy Non-default port connect test: ./bin/nri-rabbitmq -hostname rabbitmqhost -username user -password password -port port_number Copy MSSQL Basic connect test: .\\bin\\nri-mssql -hostname sqlhost -username user -password password Copy Instance connect test: .\\bin\\nri-mssql -hostname sqlhost -username user -password password -instance instance_name Copy Non-default port connect test: .\\bin\\nri-mssql -hostname sqlhost -username user -password password -port port_number Copy Oracle ORACLE_HOME=/path/to/oracle/home /var/db/newrelic-infra/newrelic-integrations/bin/nri-oracledb -username user -password password -hostname host -port port -service_name name -verbose Copy JMX echo 'java.lang:type=GarbageCollector,name=*' | nrjmx -d -hostname localipv4 -port port_number -username user -password password --verbose true Copy For more, see troubleshooting via jmxterm. All integrations allow the following options: -help: Display the list of allowed parameters -pretty: Outputs pretty formatted JSON",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.90639,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Run <em>integrations</em> manually",
        "sections": "Run <em>integrations</em> manually",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": "Problem You want to know if an integration is gathering metrics or not. To diagnose it, run the integration manually. Solution Use the following commands to run your <em>integrations</em> manually: Kafka echo &#x27;kafka.network:type=RequestMetrics,name=*,request=*’ | nrjmx -<em>host</em> <em>host</em> -port port Copy RabbitMQ"
      },
      "id": "617dace628ccbcc6307ff1d3"
    }
  ],
  "/docs/infrastructure/host-integrations/troubleshooting/pass-infrastructure-agent-parameters-host-integration": [
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2021-12-31T01:40:19Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.86496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "body": " monitoring Windows Kubernetes Prometheus On-<em>host</em> <em>integrations</em> (for services like NGINX, StatsD, MySQL, etc.) AWS cloud <em>integrations</em> Azure cloud <em>integrations</em> Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn&#x27;t require installation, except"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    },
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.7908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "Run integrations manually",
        "Problem",
        "Solution",
        "Kafka",
        "RabbitMQ",
        "MSSQL",
        "Oracle",
        "JMX"
      ],
      "title": "Run integrations manually",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "Troubleshooting"
      ],
      "external_id": "9ed6aa2e5abf677209a6b713736e837151c9a973",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/troubleshooting/run-integrations-manually/",
      "published_at": "2021-12-30T07:35:26Z",
      "updated_at": "2021-12-04T17:35:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You want to know if an integration is gathering metrics or not. To diagnose it, run the integration manually. Solution Use the following commands to run your integrations manually: Kafka echo 'kafka.network:type=RequestMetrics,name=*,request=*’ | nrjmx -host host -port port Copy RabbitMQ Basic connect test: ./bin/nri-rabbitmq -hostname rabbitmqhost -username user -password password Copy Non-default port connect test: ./bin/nri-rabbitmq -hostname rabbitmqhost -username user -password password -port port_number Copy MSSQL Basic connect test: .\\bin\\nri-mssql -hostname sqlhost -username user -password password Copy Instance connect test: .\\bin\\nri-mssql -hostname sqlhost -username user -password password -instance instance_name Copy Non-default port connect test: .\\bin\\nri-mssql -hostname sqlhost -username user -password password -port port_number Copy Oracle ORACLE_HOME=/path/to/oracle/home /var/db/newrelic-infra/newrelic-integrations/bin/nri-oracledb -username user -password password -hostname host -port port -service_name name -verbose Copy JMX echo 'java.lang:type=GarbageCollector,name=*' | nrjmx -d -hostname localipv4 -port port_number -username user -password password --verbose true Copy For more, see troubleshooting via jmxterm. All integrations allow the following options: -help: Display the list of allowed parameters -pretty: Outputs pretty formatted JSON",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.90637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Run <em>integrations</em> manually",
        "sections": "Run <em>integrations</em> manually",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": "Problem You want to know if an integration is gathering metrics or not. To diagnose it, run the integration manually. Solution Use the following commands to run your <em>integrations</em> manually: Kafka echo &#x27;kafka.network:type=RequestMetrics,name=*,request=*’ | nrjmx -<em>host</em> <em>host</em> -port port Copy RabbitMQ"
      },
      "id": "617dace628ccbcc6307ff1d3"
    }
  ],
  "/docs/infrastructure/host-integrations/troubleshooting/run-integrations-manually": [
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2021-12-31T01:40:19Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.86496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "body": " monitoring Windows Kubernetes Prometheus On-<em>host</em> <em>integrations</em> (for services like NGINX, StatsD, MySQL, etc.) AWS cloud <em>integrations</em> Azure cloud <em>integrations</em> Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn&#x27;t require installation, except"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    },
    {
      "sections": [
        "VMware vSphere monitoring integration",
        "Why it matters",
        "Compatibility and requirements",
        "Important",
        "Install and activate",
        "Linux installation",
        "Windows installation",
        "Tarball installation (advanced)",
        "Configure the integration",
        "Enable and configure performance metrics (Beta)",
        "Caution",
        "Tip",
        "Collect vSphere events (Beta)",
        "Collect snapshots data (Beta)",
        "Collect vSphere tags (Beta)",
        "Filter resources by tags (Beta)",
        "Example configuration",
        "Update your integration",
        "View and use data",
        "Metric data",
        "VSphereHostSample",
        "VSphereVmSample",
        "VSphereDatastoreSample",
        "VSphereDatacenterSample",
        "VSphereResourcePoolSample",
        "VSphereClusterSample",
        "VSphereSnapshotVmSample"
      ],
      "title": "VMware vSphere monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ab80d0e38fcc2851aa2c18034e0d191c6d77910e",
      "image": "https://docs.newrelic.com/static/a5b511bbd58392771e7ee8472579bc01/8c557/infrastructure-ohi-vmware-vsphere_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/vmware-vsphere-monitoring-integration/",
      "published_at": "2021-12-30T07:33:13Z",
      "updated_at": "2021-12-20T10:25:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's VMware vSphere integration helps you understand the health and performance of your vSphere environment. You can: Query data to get insights on the performance on your hypervisors, virtual machines, and more. Go from high level views down to the most granular data. vSphere data visualized in a New Relic dashboard includes operating systems, status, average CPU and memory consumption, and more. Our integration uses the vSphere API to collect metrics and events generated by all vSphere's components, and forwards the data to our platform via the infrastructure agent. Why it matters With our vSphere integration you can: Instrument and monitor multiple vSphere instances using the same account. Collect data on snapshots, VMs, hosts, resource pools, clusters, and datastores, including tags. Monitor the health of your hypervisors and VMs using our charts and dashboards. Use the data retrieved to monitor key performance and key capacity scaling indicators. Set alerts based on any metrics collected from vCenter. Create workloads to group resources and focus on key data. You can create workloads using data collected via the vSphere integration. Compatibility and requirements Our integration is compatible with VMware vSphere 6.5 or higher. Before installing the integration, make sure that you meet the following requirements: Infrastructure agent installed on a host vCenter service account having at least read-only global permissions with the propagate to children option checked Important Large environments: In environments with more than 800 virtual machines, the integration cannot report all data and may fail. We offer a workaround that will preserve all metrics and events, but it will disable entity registration. To apply the workaround, add the following environment variable to the configuration file: EVENTS: true METRICS: true Copy Install and activate To install the vSphere integration, choose your setup: Linux installation Follow the instructions for installing an integration, using the file name nri-vsphere. Change the directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy of the sample configuration file: sudo cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Windows installation Download the nri-vsphere MSI installer image from: download.newrelic.com/infrastructure_agent/windows/integrations/nri-vsphere/nri-vsphere-amd64.msi To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\nri-vsphere-amd64.msi Copy In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: cp vsphere-config.yml.sample vsphere-config.yml Copy Edit the vsphere-config.yml file as described in the configuration settings. Restart the infrastructure agent. Tarball installation (advanced) You can also install the integration from a tarball file. This gives you full control over the installation and configuration process. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. To configure the vSphere integration, you must define the URL of the vSphere API endpoint, and your vSphere username and password. For configuration examples, see the sample configuration files. Some vSphere integration features are optional and can be enabled via configuration settings. In addition, with secrets management, you can configure on-host integrations with New Relic's infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. Enable and configure performance metrics (Beta) Performance metrics provide a better understanding of the current status of VMware resources and can be collected in addition to the metrics collected by default;and included in the samples;described at the bottom of the page. All metrics collected are included in the corresponding sample with the perf. prefix attached to the name. For example, net.packetsRx.summation is collected and sent as perf.net.packetsRx.summation. To collect vSphere performance metrics, use the ENABLE_VSPHERE_PERF_METRICS environment variable. Data is collected according to the settings in the vsphere-performance.metrics configuration file. You can override the location of the performance metrics config file using PERF_METRIC_FILE environment variable. Notice that the integration follows VMware's data collection levels (1 to 4). When ENABLE_VSPHERE_PERF_METRICS is set, all level 1 metrics are collected. The data collection level of the performance metrics collected can be modified using PERF_LEVEL. Each metric in the config file can be commented out and new ones can be added if needed. Caution Collection of performance data can increase the load in vCenter and the time needed by to collect data. We recommended to only include the metrics you need in the configuration file. To fine-tune data collection, the number of entities and metrics retrieved per request can be modified using BATCH_SIZE_PERF_ENTITIES and BATCH_SIZE_PERF_METRICS. Tip For more information on vSphere performance metrics, see the VMware documentation. Collect vSphere events (Beta) To collect vSphere events, use the ENABLE_VSPHERE_EVENTS environment variable. The integration collects events between the current time and the last fetched event for each datacenter. It stores the information regarding the last fetched event in a cache that is updated after each execution. Events are only available if the integration is connected to a vCenter and not directly to an ESXi host. The number of events collected per request can be tuned by modifying EVENTS_PAGE_SIZE, which is set to 100 by default. Events are available in the Events page and can be queried via NRQL as InfrastructureEvent under vSphereEvent. Here is an example of vSphere events data: \"summary\": \"User dcui@127.0.0.1 logged out (login time: Tuesday, 14 July, 2020 08:32:09 AM, number of API invocations: 0, user agent: VMware-client/6.5.0)\", \"vSphereEvent.computeResource\": \"cluster1\", \"vSphereEvent.datacenter\": \"Prod Datacenter\", \"vSphereEvent.date\": \"Tue, 14 Jul 2020 09:03:51 UTC\", \"vSphereEvent.host\": \"192.168.0.230\", \"vSphereEvent.userName\": \"dcui\" Copy Collect snapshots data (Beta) To collect snapshot data, use the ENABLE_VSPHERE_SNAPSHOTS environment variable. Snapshot data can be found in VSphereSnapshotVmSample. Collected data covers total and unique space occupied by disk and memory files, snapshot tree, and creation time. You can use this information to create NRQL queries, dashboards, and alerts, since it's linked to the corresponding virtual machine entity. Collect vSphere tags (Beta) To collect vSphere tags, use the ENABLE_VSPHERE_TAGS environment variable. Tags are available as attributes in the corresponding entity sample as label.tagCategory:tagName. If two tags of the same category are assigned to a resource, they are added to a unique attribute separated by a pipe character. For example: label.tagCategory:tagName|tagName2. Tags can be used to run NRQL queries, filter entities in the New Relic Explorer, and to create dashboards and alerts. Filter resources by tags (Beta) Resource filtering allows you to specify which resources you want to monitor by declaring a set of tags that resources must have in order to be monitored. Resources require a match on any (one or more) of the filter tags in order to be included. If none of the resource tags match any of the filter tags, no information about that resource is sent to New Relic. To use filtering resources by tag you need to have the ENABLE_VSPHERE_TAGS environment variable enabled. A tag filter expression is a space-separated list of pairs of strings with the format category=name. For example, to only retrieve resources with a tag category region and include regions us and eu use a filter expression like: region=us region=eu INCLUDE_TAGS: > region=us region=eu Copy To enable resource filtering by tag, edit your integration configuration file and add the option INCLUDE_TAGS with the filter expression you want. Caution Note that datacenter resources acting as the root of the resource tree MUST have tags attached AND match the filter expression in order for other child resources to be fetched. Important If you connect the integration directly to the ESXi host, vCenter data is not available (for example, events, tags, or datacenter metadata). Example configuration Here are examples of the vSphere integration configuration, including performance metrics: vsphere-config.yml.sample (Linux) vsphere-win-config.yml.sample (Windows) vsphere-performance.metrics (Performance metrics) For more information, see our documentation about the general structure of on-host integration configurations. Important The configuration option inventory_source is not compatible with this integration. Update your integration On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. View and use data Data from this service is reported to an integration dashboard. You can query this data for troubleshooting purposes or to create charts and dashboards. vSphere data is attached to these event types: VSphereHostSample VSphereClusterSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereSnapshotVmSample Performance data is enabled and configured separately (see Enable and configure performance metrics). For more on how to view and use your data, see Understand integration data. Metric data The vSphere integration provides metric data attached to the following New Relic events: VSphereHostSample VSphereVmSample VSphereDatastoreSample VSphereDatacenterSample VSphereResourcePoolSample VSphereClusterSample VSphereSnapshotVmSample VSphereHostSample Name Description cpu.totalMHz Sum of the MHz for all the individual cores on the host cpu.coreMHz Speed of the CPU cores cpu.available Amount of free CPU MHz in the host cpu.overallUsage CPU usage across all cores on the host in MHz cpu.percent Percentage of CPU utilization in the host cpu.cores Number of physical CPU cores on the host. Physical CPU cores are the processors contained by a CPU package cpu.threads Number of physical CPU threads on the host disk.totalMiB Total capacity of disks mounted in host, in MiB mem.free Amount of available memory in the host, in MiB mem.usage Amount of used memory in the host, in MiB mem.size Total memory capacity of the host, in MiB vmCount Number of virtual machines in the host hypervisorHostname Name of the host uuid The hardware BIOS identification datacenterName Name of the datacenter related to the host clusterName Name of the cluster related to the host resourcePoolNameList List of names of the resource pools related to the host datastoreNameList List of names of datastores related to the host datacenterLocation Datacenter location networkNameList List of names of networks related to the host overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem connectionState The host connection state: connected: Connected to the server. For ESX Server, this is the default setting. disconnected: The user has explicitly taken the host down. VirtualCenter does not expect to receive heartbeats from the host. The next time a heartbeat is received, the host is moved to the connected state again and an event is logged. notResponding: VirtualCenter is not receiving heartbeats from the server. The state automatically changes to connected once heartbeats are received again. This state is typically used to trigger an alarm on the host. inMaintenanceMode The flag to indicate whether or not the host is in maintenance mode. This flag is set when the host has entered the maintenance mode. It is not set during the entering phase of maintenance mode. inQuarantineMode The flag to indicate whether or not the host is in quarantine mode. InfraUpdateHa will recommend to set this flag based on the HealthUpdates received by the HealthUpdateProviders configured for the cluster. A host that is reported as degraded will be recommended to enter quarantine mode, while a host that is reported as healthy will be recommended to exit quarantine mode. Execution of these recommended actions will set this flag. Hosts in quarantine mode will be avoided by vSphere DRS as long as the increased consolidation in the cluster does not negatively affect VM performance. powerState The host power state: poweredOff: The host was specifically powered off by the user through VirtualCenter. This state is not a cetain state, because after VirtualCenter issues the command to power off the host, the host might crash, or kill all the processes but fail to power off. poweredOn: The host is powered on. A host that is entering standby mode entering is also in this state. standBy: The host was specifically put in standby mode, either explicitly by the user or automatically by DPM. This state is not a certain state, because after VirtualCenter issues the command to put the host in standby state, the host might crash, or kill all the processes but fail to power off. A host that is exiting standby mode s also in this state. unknown: If the host is disconnected or notResponding, we know its power state, so the host is marked as unknown. standbyMode The host’s standby mode. The property is only populated by vCenter server. If queried directly from the ESX host, the property is unset. entering: The host is entering standby mode. exiting: The host is exiting standby mode. in: The host is in standby mode. none: The host is not in standby mode, and it is not in the process of entering or exiting standby mode. cryptoState Encryption state of the host. Valid values are enumerated by the CryptoState type: incapable: The host is not safe for receiving sensitive material. prepared: The host is prepared for receiving sensitive material but does not have a host key set yet. safe: The host is crypto safe and has a host key set. bootTime The time when the host was booted. VSphereVmSample Name Description mem.size Memory size of the virtual machine, in MiB mem.usage Guest memory utilization statistics, in MiB. This is also known as active guest memory. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.free Guest memory available, in MiB. The value can range between 0 and the configured memory size of the virtual machine. Valid while the virtual machine is running. mem.ballooned The size of the balloon driver in the virtual machine, in MiB. The host will inflate the balloon driver to reclaim physical memory from the virtual machine. This is a sign that there is memory pressure on the host. mem.swapped The portion of memory, in MiB, that is granted to this virtual machine from the host's swap space. This is a sign that there is memory pressure on the host. mem.swappedSsd The amount of memory swapped to fast disk device such as SSD, in MiB cpu.allocationLimit Resource limits for CPU, in MHz. If set to -1, there is no fixed allocation limit. cpu.overallUsage Basic CPU performance statistics, in MHz. Valid while the virtual machine is running. cpu.hostUsagePercent Percent of the host CPU used by the virtual machine. In case a limit is configured, the percentage is calculated by taking the limit as the total. cpu.cores Number of processors in the virtual machine disk.totalMiB Total storage space, committed to this virtual machine across all datastores, in MiB ipAddress Primary guest IP address, if available ipAddresses List of IPs associated with the VM (except ipAddress). A pipe or vertical bar character (|) is used as a separator. connectionState Indicates whether or not the virtual machine is available for management: connected: Server has access to the virtual machine. disconnected: Server is currently disconnected from the virtual machine, since its host is disconnected. inaccessible: One or more of the virtual machine configuration files are inaccessible. invalid: The virtual machine configuration format is invalid. orphaned: The virtual machine is no longer registered on its associated host. powerState The current power state of the virtual machine: poweredOff, poweredOn, or suspended. guestHeartbeatStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. operatingSystem Operating system of the virtual machine guestFullName Guest operating system full name, if available from guest tools hypervisorHostname Name of the host where the virtual machine is running instanceUuid Unique identification of the virtual machine datacenterName Name of the datacenter clusterName Name of the cluster resourcePoolNameList List of names of the resource pools datastoreNameList List of names of datastores networkNameList List of names of networks datacenterLocation Datacenter location overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. disk.suspendMemory Size of the snapshot file (bytes). disk.suspendMemoryUnique Size of the snapshot file, unique blocks (bytes). disk.totalUncommittedMiB Additional storage space potentially used by this virtual machine on all datastores. Essentially an aggregate of the property uncommitted across all datastores that this virtual machine is located on (Mebibytes). disk.totalUnsharedMiB Total storage space occupied by the virtual machine across all datastores, that is not shared with any other virtual machine (Mebibytes). mem.hostUsage Host memory usage (Mebibytes). resourcePoolName Resource Pool Name. vmConfigName Vm Config Name. vmHostname Vm Hostname. VSphereDatastoreSample Name Description capacity Maximum capacity of this datastore, in GiB, if accessible is true freeSpace Available space of this datastore, in GiB, if accessible is true uncommitted Total additional storage space, potentially used by all virtual machines on this datastore, in GiB, if accessible is true vmCount Number of virtual machines attached to the datastore datacenterLocation Datacenter location datacenterName Datacenter name hostCount Number of hosts attached to the datastore overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. accessible Connectivity status of the datastore. If this is set to false, the datastore is not accessible. url Unique locator for the datastore, if accessible is true fileSystemType Type of file system volume, such as VMFS or NFS name Name of the datastore nas.remoteHost Host that runs the NFS/CIFS server nas.remotePath Remote path of NFS/CIFS mount point VSphereDatacenterSample Name Description datastore.totalUsedGiB Total used space in the datastores, in GiB datastore.totalFreeGiB Total free space in the datastores, in GiB datastore.totalGiB Total size of the datastores, in GiB cpu.cores Total CPU count per datacenter cpu.overallUsagePercentage Total CPU usage, in percentage cpu.overallUsage Total CPU usage, in MHz cpu.totalMHz Total CPU capacity, in MHz mem.usage Total memory usage, in MiB mem.size Total memory, in MiB mem.usagePercentage Total memory usage as percentage clusters Total cluster count per datacenter resourcePools Total resource pools per datacenter datastores Total datastores per datacenter networks Total network adapter count per datacenter overallStatus gray: Status is unknown green: Entity is OK yellow: Entity might have a problem red: Entity definitely has a problem hostCount Total host system count per datacenter vmCount Total virtual machines count per datacenter VSphereResourcePoolSample Name Description cpu.TotalMHz Resource pool CPU total capacity, in MHz cpu.overallUsage Resource pool CPU usage, in MHz mem.size Resource pool total memory reserved, in MiB mem.usage Resource pool memory usage, in MiB mem.free Resource pool memory available, in MiB mem.ballooned Size of the balloon driver in the resource pool, in MiB mem.swapped Portion of memory, in MiB, that is granted to this resource pool from the host's swap space vmCount Number of virtual machines in the resource pool overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. resourcePoolName Name of the resource pool datacenterLocation Datacenter location datacenterName Name of the datacenter clusterName Name of the cluster VSphereClusterSample Name Description cpu.totalEffectiveMHz Effective CPU resources, in MHz, available to virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. cpu.totalMHz Aggregated CPU resources of all hosts, in MHz. It does not filter out cpu used by system or related to hosts under maintenance. cpu.cores Number of physical CPU cores. Physical CPU cores are the processors contained by a CPU package. cpu.threads Aggregated number of CPU threads. mem.size Aggregated memory resources of all hosts, in MiB. It does not filter out memory used by system or related to hosts under maintenance. mem.effectiveSize Effective memory resources, in MiB, available to run virtual machines. This is the aggregated effective resource level from all running hosts. Hosts that are in maintenance mode or are unresponsive are not counted. Resources used by the VMware Service Console are not included in the aggregate. This value represents the amount of resources available for the root resource pool for running virtual machines. effectiveHosts Total number of effective hosts. This number exclude hosts under maintenance. hosts Total number of hosts overallStatus gray: Status is unknown. green: Entity is OK. yellow: Entity might have a problem. red: Entity definitely has a problem. datastoreList List of datastore used by the cluster. A pipe or vertical bar character (|) is used as a separator. hostList List of hosts belonging to the cluster. A pipe or vertical bar character (|) is used as a separator. networkList List of networks attached to the cluster. A pipe or vertical bar character (|) is used as a separator. drsConfig.vmotionRate Threshold for generated ClusterRecommendations. DRS generates only those recommendations that are above the specified vmotionRate. Ratings vary from 1 to 5. This setting applies to manual, partiallyAutomated, and fullyAutomated DRS clusters. dasConfig.restartPriorityTimeout Maximum time the lower priority VMs should wait for the higher priority VMs to be ready (Seconds). datacenterName Datacenter name. datacenterLocation Datacenter location. drsConfig.enabled Flag indicating whether or not the service is enabled. drsConfig.enableVmBehaviorOverrides Flag that dictates whether DRS Behavior overrides for individual virtual machines (ClusterDrsVmConfigInfo) are enabled. drsConfig.defaultVmBehavior Specifies the cluster-wide default DRS behavior for virtual machines. You can override the default behavior for a virtual machine by using the ClusterDrsVmConfigInfo object. dasConfig.enabled Flag to indicate whether or not vSphere HA feature is enabled. dasConfig.admissionControlEnabled Flag that determines whether strict admission control is enabled dasConfig.isolationResponse Indicates whether or not the virtual machine should be powered off if a host determines that it is isolated from the rest of the compute resource. dasConfig.restartPriority Restart priority for a virtual machine. dasConfig.hostMonitoring Determines whether HA restarts virtual machines after a host fails. dasConfig.vmMonitoring Level of HA Virtual Machine Health Monitoring Service. dasConfig.vmComponentProtecting This property indicates if vSphere HA VM Component Protection service is enabled. dasConfig.hbDatastoreCandidatePolicy The policy on what datastores will be used by vCenter Server to choose heartbeat datastores: allFeasibleDs, allFeasibleDsWithUserPreference, userSelectedDs VSphereSnapshotVmSample Name Description snapshotTreeInfo Tree info for the snapshot. Es: Cluster:Vm:Snapshot1:Snapshot2 name Snapshot name creationTime Snapshot creation time powerState The power state of the virtual machine when this snapshot was taken snapshotId The unique identifier that distinguishes this snapshot from other snapshots of the virtual machine quiesced Flag to indicate whether or not the snapshot was created with the \"quiesce\" option, ensuring a consistent state of the file system backupManifest The relative path from the snapshotDirectory pointing to the backup manifest. Available for certain quiesced snapshots only description Description of the snapshot replaySupported Flag to indicate whether this snapshot is associated with a recording session on the virtual machine that can be replayed totalMemoryInDisk Total size of memory in disk. totalUniqueMemoryInDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store memory. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. totalDisk Total size of snapshot files in disk totalUniqueDisk Total size of the file corresponding to the file blocks that were allocated uniquely to store snapshot data in disk. In other words, if the underlying storage supports sharing of file blocks across disk files, the property corresponds to the size of the file blocks that were allocated only in context of this file. It does not include shared blocks that were allocated in other files. This property will be unset if the underlying implementation is unable to compute this information. datastorePathDisk Disk file path in the datastore datastorePathMemory Memory file path in the datastore",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.7908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "VMware vSphere monitoring <em>integration</em>",
        "sections": "VMware vSphere monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " settings. In addition, with secrets management, you can configure on-<em>host</em> <em>integrations</em> with New Relic&#x27;s infrastructure monitoring agent to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. Enable and configure performance"
      },
      "id": "617dacb6196a676aaef7dcf3"
    },
    {
      "sections": [
        "NGINX monitoring integration",
        "Important",
        "Compatibility and requirements",
        "Enabling your NGINX Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Amazon ECS installation",
        "Kubernetes installation",
        "nginx-config.yml sample files",
        "Basic configuration",
        "HTTP Basic authentication",
        "Metrics with only one self-signed certificate",
        "Environment variables replacement",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "NGINX monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "411a85528ddc65a2f04f7c05659e4b6695c9400a",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/",
      "published_at": "2021-12-30T21:52:12Z",
      "updated_at": "2021-12-05T06:01:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our NGINX integration collects and sends inventory and metrics from your NGINX server to our platform, where you can see data on connections and client requests so that you can find the source of any problems. To install the NGINX monitoring integration, you must run through the following steps: Enabling your NGINX Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Important For best results, regularly update the integration package and the infrastructure agent. Compatibility and requirements Our integration is compatible with both NGINX Open Source and NGINX Plus. Before installing the integration, ensure you meet the following requirements: A New Relic account. Don't have one? Sign up for free! No credit card required. NGINX extension enabled, as described in the Configure the integration section. If NGINX is not running on Kubernetes or Amazon ECS, you must install the infrastructure agent on a Linux OS host that's running NGINX. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your NGINX Server To capture data from the NGINX integration, you must first enable and configure the applicable extension module: For NGINX Open Source, see HTTP stub status module. For NGINX Plus, see HTTP status module and HTTP API module. Configure the integration There are several ways to configure the integration, depending on how it was installed: If it was enabled via Kubernetes, see Monitor services running on Kubernetes. If it was enabled via Amazon ECS, see Monitor services running on ECS. If it was installed on-host, edit the integration's nginx-config.yml configuration file. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. The options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations such as interval, timeout, or inventory_source. To read about these common settings, see configuration format. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Specific settings related to NGINX are defined using the env section of the configuration file. These settings control the connection to your NGINX instance as well as other security settings and features. The list of valid settings is described in the next section of this document. Install and activate the integration To install the NGINX integration, follow the instructions for your environment: Linux installation Install the infrastructure agent, and use nri-nginx as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp nginx-config.yml.sample nginx-config.yml Edit the nginx-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. nginx-config.yml sample files Basic configuration This is the very basic configuration to collect Metrics and Inventory from your localhost: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy HTTP Basic authentication This configuration collects Metrics and Inventory from your localhost protected with basic authentication. Replace the username and password on the STATUS_URL with your credentials: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://username:password@127.0.0.1/status STATUS_MODULE: discover REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: http://username:password@127.0.0.1/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx Copy Metrics with only one self-signed certificate In this configuration we only have 1 integration block with METRICS: true to collect only metrics and added VALIDATE_CERTS: false to prevent validation of the server's SSL certificate when using a self-signed one: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://my_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Environment variables replacement In this configuration we are using the environment variable NGINX_STATUS to populate the STATUS_URL setting of the integration: integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: {{NGINX_STATUS}} STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Multi-instance monitoring In this configuration we are monitoring multiple NGINX servers from the same integration. For the first instance (STATUS_URL: https://1st_nginx_host/status) we are collecting metrics and inventory while for the second instance (STATUS_URL: https://2nd_nginx_host/status) we will only collect metrics. integrations: - name: nri-nginx env: METRICS: \"true\" STATUS_URL: https://1st_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer - name: nri-nginx env: INVENTORY: \"true\" STATUS_URL: https://1st_nginx_host/status CONFIG_PATH: /etc/nginx/nginx.conf REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/nginx - name: nri-nginx env: METRICS: \"true\" STATUS_URL: http://2nd_nginx_host/status STATUS_MODULE: discover VALIDATE_CERTS: false REMOTE_MONITORING: true interval: 30s labels: env: production role: load_balancer Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics that are attached to the NginxSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: NGINX's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.73079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NGINX monitoring <em>integration</em>",
        "sections": "NGINX monitoring <em>integration</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " See Monitor service running on Kubernetes. Additional notes: Advanced: <em>Integrations</em> are also available in tarball format to allow for install outside of a package manager. On-<em>host</em> <em>integrations</em> do not automatically update. For best results, regularly update the integration package"
      },
      "id": "61ac559d196a6703e2d1085f"
    }
  ],
  "/docs/infrastructure/host-integrations/understand-use-data/host-integration-data-collection-reporting": [
    {
      "sections": [
        "Remote monitoring in on-host integrations",
        "Important",
        "Effects of activating remote_monitoring",
        "Alert verification",
        "New entity attributes",
        "Changes in recorded metrics",
        "Unrecorded attributes",
        "Updated hostname"
      ],
      "title": "Remote monitoring in on-host integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "Understand and use data"
      ],
      "external_id": "a9d45e7df90e6cbccb96e76c0bd4dacadc40a2a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/understand-use-data/remote-monitoring-host-integrations/",
      "published_at": "2021-12-30T10:37:25Z",
      "updated_at": "2021-10-24T01:23:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "From a New Relic perspective, entity is a broad concept. An entity is anything New Relic can identify that has data you can monitor. Integrations can be configured to create their own entity, called a remote entity, by setting the remote_monitoring option to true. If set to false, an integration will be considered a local entity, and the data related to it will be attached to the host entity that the agent creates. Remote monitoring requires infrastructure agent version 1.2.25 or higher. For the Apache, Cassandra, MySQL, NGINX, and Redis integrations, remote monitoring (and multi-tenancy) is enabled by activating the configuration parameter remote_monitoring. Important If your Apache, Cassandra, MySQL, NGINX, or Redis service is located in the same host as the agent, when you activate remote monitoring the resulting entity will be considered as remote, regardless of its actual location. This may affect alerts, alter attributes, and have other effects, as explained here. Effects of activating remote_monitoring By enabling remote_monitoring, the integration becomes a different entity which is no longer attached to the infrastructure agent. As a result, the following items may be affected: Alert verification Enabling remote monitoring can affect your configured alerts in case they are using any of the values that are affected by this new feature. We strongly recommend checking your existing alerts to make sure they keep on working as expected. New entity attributes These attributes are modified in the resulting entity: Display name: New entity unique key (instead of using the display name) Entity GUID: New entity GUID Entity ID: New entity ID Entity key: New entity unique key (instead of using the display name) External key: Using integration entity name (instead of using the agent display) Changes in recorded metrics When remote monitoring is enabled, we will add the hostname and port values to all metrics. If the nricluster name or nriservice are defined in the integration configuration file, they will also be decorated. Unrecorded attributes Since the integration is now an independent entity which is not attached to the agent, the following agent attributes are not collected: agentName agentVersion coreCount criticalViolationCount fullHostname instanceType kernelVersion linuxDistribution entityType operatingSystem processorCount systemMemoryBytes warningViolationCount Your custom attributes Updated hostname For the ApacheSample, RedisSample, CassandraSample, and NginxSample integration metrics, we will use the integration configuration hostname instead of the short hostname from the agent. When the integration hostname is a loopback address, the agent will replace it in order to guarantee uniqueness.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.84477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Remote monitoring in <em>on</em>-<em>host</em> <em>integrations</em>",
        "sections": "Remote monitoring in <em>on</em>-<em>host</em> <em>integrations</em>",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": " will be considered a local entity, and the <em>data</em> related to it will be attached to the <em>host</em> entity that the agent creates. Remote monitoring requires infrastructure agent version 1.2.25 or higher. For the Apache, Cassandra, MySQL, NGINX, and Redis <em>integrations</em>, remote monitoring (and multi-tenancy"
      },
      "id": "617dbc6c28ccbcf3bf7ff9c0"
    },
    {
      "sections": [
        "Find and use your Kubernetes data",
        "Query Kubernetes data",
        "Event types",
        "Manage alerts",
        "Create an alert condition",
        "Use the predefined alert types and thresholds",
        "Select alert notifications",
        "Pod alert notification example",
        "Container resource notification example",
        "Create alert conditions using NRQL",
        "Kubernetes attributes and metrics",
        "Node data",
        "Namespace data",
        "Deployment data",
        "ReplicaSet data",
        "DaemonSet data",
        "StatefulSet data",
        "Pod data",
        "Cluster data",
        "Container data",
        "Volume data",
        "API server data",
        "Controller manager data",
        "Scheduler data",
        "ETCD data",
        "Endpoint data",
        "Service data",
        "Horizontal Pod Autoscaler data",
        "Kubernetes metadata in APM-monitored applications",
        "For more help"
      ],
      "title": "Find and use your Kubernetes data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Understand and use data"
      ],
      "external_id": "636617521998343c5bb96b0500843229b9263712",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data/",
      "published_at": "2021-12-30T09:11:39Z",
      "updated_at": "2021-10-24T03:11:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own charts and query all your Kubernetes integration data using the query builder and the NerdGraph API. Our integration collects Kubernetes data by instrumenting the container orchestration layer. For a simpler and more visual experience, use the cluster explorer. one.newrelic.com > Dashboards: Using the query builder you can query your Kubernetes data and create clear visualizations. Query Kubernetes data The simplest way to query your Kubernetes data is using the query builder, which accepts NRQL queries. Alternatively, you can use the NerdGraph API to retrieve Kubernetes data. Event types Kubernetes data is attached to the following event types: Event name Type of Kubernetes data Available since K8sNodeSample Node data v1.0.0 K8sNamespaceSample Namespace data v1.0.0 K8sDeploymentSample Deployment data v1.0.0 K8sReplicasetSample ReplicaSet data v1.0.0 K8sDaemonsetSample DaemonSet data v1.13.0 K8sStatefulsetSample StatefulSet data v1.13.0 K8sPodSample Pod data v1.0.0 K8sClusterSample Cluster data v1.0.0 K8sContainerSample Container data v1.0.0 K8sVolumeSample Volume data v1.0.0 K8sApiServerSample API server data v1.11.0 K8sControllerManagerSample Controller manager data v1.11.0 K8sSchedulerSample Scheduler data v1.11.0 K8sEtcdSample ETCD data v1.11.0 K8sEndpointSample Endpoint data v1.13.0 K8sServiceSample Service data v1.13.0 K8sHpaSample Horizontal Pod Autoscaler data v2.3.0 Manage alerts You can be notified about alert violations for your Kubernetes data: Create an alert condition To create an alert condition for the Kubernetes integration: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Kubernetes, then select Create alert condition. To filter the alert to Kubernetes entities that only have the chosen attributes, select Filter. Select the threshold settings. For more on the Trigger an alert when... options, see Alert types. Select an existing alert policy, or create a new one. Select Create. When an alert condition's threshold is triggered, New Relic sends a notification to the policy's notification channels. Use the predefined alert types and thresholds The Kubernetes integration comes with its own alert policy and alert conditions. To see what the predefined alert conditions are, see Kubernetes integration: Predefined alert policy. In addition, you can create an alert condition for any metric collected by any New Relic integration you use, including the Kubernetes integration: Select the alert type Integrations. From the Select a data source dropdown, select a Kubernetes (K8s) data source. Select alert notifications When an alert condition's threshold is triggered, New Relic sends a message to the notification channel(s) chosen in the alert policy. Depending on the type of notification, you may have the following options: View the incident. Acknowledge the incident. Go to a chart of the incident data by selecting the identifier name. The entity identifier that triggered the alert appears near the top of the notification message. The format of the identifier depends on the alert type: Available pods are less than desired pods alerts: K8s:CLUSTER_NAME:PARENT_NAMESPACE:replicaset:REPLICASET_NAME Copy CPU or memory usage alerts: K8s:CLUSTER_NAME:PARENT_NAMESPACE:POD_NAME:container:CONTAINER_NAME Copy Here are some examples. Pod alert notification example For Available pods are less than desired pods alerts, the ID of the ReplicaSet triggering the issue might look like this: k8s:beam-production:default:replicaset:nginx-deployment-1623441481 Copy This identifier contains the following information: Cluster name: beam-production Parent namespace: default ReplicaSet name: nginx-deployment-1623441481 Container resource notification example For container CPU or memory usage alerts, the entity might look like this: k8s:beam-production:kube-system:kube-state-metrics-797bb87c75-zncwn:container:kube-state-metrics Copy This identifier contains the following information: Cluster name: beam-production Parent namespace: kube-system Pod namespace: kube-state-metrics-797bb87c75-zncwn Container name: kube-state-metrics Create alert conditions using NRQL Follow standard procedures to create alert conditions for NRQL queries. Kubernetes attributes and metrics The Kubernetes integration collects the following metrics and other attributes. Node data Query the K8sNodeSample event for node data: Node attribute Description allocatableCpuCores Node allocatable CPU cores allocatableMemoryBytes Node allocatable memory bytes allocatablePods Node allocatable pods allocatableEphemeralStorageBytes Node allocatable ephemeral-storage bytes capacityCpuCores Node CPU capacity capacityMemoryBytes Node memory capacity (in bytes) capacityPods Pod capacity of the node capacityEphemeralStorageBytes Node ephemeral-storage capacity clusterName Name that you assigned to the cluster when you installed the Kubernetes integration condition.{conditionName}={conditionValue} Status of the current observed node condition. The reported conditions can vary depending on your Kubernetes flavor and installed operators. Examples of common conditions are: Ready, DiskPressure, MemoryPressure, PIDPressure and NetworkUnavailable. Condition values can be 1 (true), 0 (false), or -1 (unknown). cpuUsedCoreMilliseconds Node CPU usage measured in core milliseconds cpuUsedCores Node CPU usage measured in cores cpuRequestedCores Total amount of CPU cores requested allocatableCpuCoresUtilization Percentage of CPU cores actually used with respect to the CPU cores allocatable fsAvailableBytes Bytes available in the node filesystem fsCapacityBytes Total capacity of the node filesystem in bytes fsInodes Total number of inodes in the node filesystem fsInodesFree Free inodes in the node filesystem fsInodesUsed Used inodes in the node filesystem fsUsedBytes Used bytes in the node filesystem fsCapacityUtilization Percentage of used bytes in the node filesystem with respect to the capacity memoryAvailableBytes Bytes of memory available in the node memoryMajorPageFaultsPerSecond Number of major page faults per second in the node memoryPageFaults Number of page faults in the node memoryRssBytes Bytes of rss memory memoryUsedBytes Bytes of memory used memoryWorkingSetBytes Bytes of memory in the working set memoryRequestedBytes Total amount of requested memory allocatableMemoryUtilization Percentage of bytes of memory in the working set with respect to the node allocatable memory net.errorCountPerSecond Number of errors per second while receiving/transmitting over the network nodeName Host name that the pod is running on runtimeAvailableBytes Bytes available to the container runtime filesystem runtimeCapacityBytes Total capacity assigned to the container runtime filesystem in bytes runtimeInodes Total number of inodes in the container runtime filesystem runtimeInodesFree Free inodes in the container runtime filesystem runtimeInodesUsed Used inodes in the container runtime filesystem runtimeUsedBytes Used bytes in the container runtime filesystem unschedulable Status of node schedulability of new pods. Its value can be 0 (false) or 1 (true) label.LABEL_NAME Labels associated with your node, so you can filter and query for specific nodes Namespace data Query the K8sNamespaceSample event for namespace data: Namespace attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of the namespace when it was created namespace Name of the namespace to be used as an identifier label.LABEL_NAME Labels associated with your namespace, so you can filter and query for specific namespaces status Current status of the namespace. The value can be Active or Terminated Deployment data Query the K8sDeploymentSample event for deployment data: Deployment attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the deployment was created deploymentName Name of the deployment to be used as an identifier namespace Name of the namespace that the deployment belongs to label.LABEL_NAME Labels associated with your deployment, so you can filter and query for specific deployments podsAvailable Number of replicas that are currently available podsDesired Number of replicas that you defined in the deployment podsTotal Total number of replicas that are currently running podsUnavailable Number of replicas that are currently unavailable podsUpdated Number of replicas that have been updated to achieve the desired state of the deployment podsMissing Total number of replicas that are missing (number of desired replicas, podsDesired, minus the total number of replicas, podsTotal) ReplicaSet data Query the K8sReplicasetSample event for ReplicaSet data: Replica attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the ReplicaSet was created deploymentName Name of the deployment to be used as an identifier namespace Name of the namespace that the ReplicaSet belongs to observedGeneration Integer representing generation observed by the ReplicaSet podsDesired Number of replicas that you defined in the deployment podsFullyLabeled Number of pods that have labels that match the ReplicaSet pod template labels podsReady Number of replicas that are ready for this ReplicaSet podsTotal Total number of replicas that are currently running podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) replicasetName Name of the ReplicaSet to be used as an identifier DaemonSet data Query the K8sDaemonsetSample event for DaemonSet data: DaemonSet attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the DaemonSet was created namespaceName Name of the namespace that the DaemonSet belongs to label.LABEL_NAME Labels associated with your DaemonSet, so you can filter and query for specific DaemonSet daemonsetName Name associated with the DaemonSet podsDesired The number of nodes that should be running the daemon pod podsScheduled The number of nodes running at least one daemon pod and are supposed to podsAvailable The number of nodes that should be running the daemon pod and have one or more of the daemon pod running and available podsReady The number of nodes that should be running the daemon pod and have one or more of the daemon pod running and ready podsUnavailable The number of nodes that should be running the daemon pod and have none of the daemon pod running and available podsMisscheduled The number of nodes running a daemon pod but are not supposed to podsUpdatedScheduled The total number of nodes that are running updated daemon pod podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) metadataGeneration Sequence number representing a specific generation of the desired state StatefulSet data Query the K8sStatefulsetSample event for StatefulSet data: StatefulSet attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the StatefulSet was created namespaceName Name of the namespace that the StatefulSet belongs to label.LABEL_NAME Labels associated with your StatefulSet, so you can filter and query for specific StatefulSet statefulsetName Name associated with the StatefulSet podsDesired Number of desired pods for a StatefulSet podsReady The number of ready replicas per StatefulSet podsCurrent The number of current replicas per StatefulSet podsTotal The number of replicas per StatefulSet podsUpdated The number of updated replicas per StatefulSet podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) observedGeneration The generation observed by the StatefulSet controller metadataGeneration Sequence number representing a specific generation of the desired state for the StatefulSet currentRevision Indicates the version of the StatefulSet used to generate pods in the sequence. Value range: between 0 and podsCurrent updateRevision Indicates the version of the StatefulSet used to generate pods in the sequence. Value range: between podsDesired-podsUpdated and podsDesired Pod data Query the K8sPodSample event for pod data: Pod attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the pod was created in epoch seconds createdBy Name of the Kubernetes object that created the pod. For example, newrelic-infra createdKind Kind of Kubernetes object that created the pod. For example, DaemonSet. deploymentName Name of the deployment to be used as an identifier isReady Boolean representing whether or not the pod is ready to serve requests isScheduled Boolean representing whether or not the pod has been scheduled to run on a node label.LABEL_NAME Labels associated with your pod, so you can filter and query for specific pods message Details related to the last pod status change namespace Name of the namespace that the pod belongs to net.errorCountPerSecond Number of errors per second while receiving/transmitting over the network net.errorsPerSecond Number of errors per second net.rxBytesPerSecond Number of bytes per second received over the network net.txBytesPerSecond Number of bytes per second transmitted over the network nodeIP Host IP address that the pod is running on nodeName Host name that the pod is running on podIP IP address of the pod. If it doesn't have an IP, it'll be empty podName Name of the pod to be used as an identifier reason Reason why the pod is in the current status startTime Timestamp of when the pod started running in epoch seconds status Current status of the pod. Value can be Pending, Running, Succeeded, Failed, Unknown Cluster data Query the K8sClusterSample event to see cluster data: Cluster attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration clusterK8sVersion Kubernetes version that the cluster is running Container data Query the K8sContainerSample event for container data: Container attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration containerID Unique ID associated with the container. If you are running Docker, this is the Docker container id containerImage Name of the image that the container is running containerImageID Unique ID associated with the image that the container is running containerName Name associated with the container cpuLimitCores Integer representing limit CPU cores defined for the container in the pod specification cpuRequestedCores Requested CPU cores defined for the container in the pod specification cpuUsedCores CPU cores actually used by the container cpuCoresUtilization Percentage of CPU cores actually used by the container with respect to the CPU limit specified. This percentage is based on this calculation: (cpuUsedCores / cpuLimitCores) * 100 requestedCpuCoresUtilization Percentage of CPU cores actually used by the container with respect to the CPU request specified deploymentName Name of the deployment to be used as an identifier isReady Boolean. Whether or not the container's readiness check succeeded label.LABEL_NAME Labels associated with your container, so you can filter and query for specific containers memoryLimitBytes Integer representing limit bytes of memory defined for the container in the pod specification memoryRequestedBytes Integer. Requested bytes of memory defined for the container in the pod specification memoryUsedBytes Integer. Bytes of memory actually used by the container memoryUtilization Percentage of memory actually used by the container with respect to the memory limit specified requestedMemoryUtilization Percentage of memory actually used by the container with respect to the memory request specified memoryWorkingSetBytes Integer. Bytes of memory in the working set memoryWorkingSetUtilization Percentage of working set memory actually used by the container with respect to the memory limit specified requestedMemoryWorkingSetUtilization Percentage of working set memory actually used by the container with respect to the memory request specified namespace Name of the namespace that the container belongs to nodeIP Host IP address the container is running on nodeName Host name that the container is running on podName Name of the pod that the container is in, to be used as an identifier reason Provides a reason why the container is in the current status restartCount Number of times the container has been restarted status Current status of the container. Value can be Running, Terminated, or Unknown containerCpuCfsPeriodsDelta Delta change of elapsed enforcement period intervals containerCpuCfsThrottledPeriodsDelta Delta change of throttled period intervals containerCpuCfsThrottledSecondsDelta Delta change of duration the container has been throttled, in seconds containerCpuCfsPeriodsTotal Total number of elapsed enforcement period intervals containerCpuCfsThrottledPeriodsTotal Total number of throttled period intervals containerCpuCfsThrottledSecondsTotal Total time duration the container has been throttled, in seconds containerMemoryMappedFileBytes Total size of memory mapped files used by this container, in bytes Volume data Query the K8sVolumeSample event for volume data: Volume attribute Description volumeName Name that you assigned to the volume at creation clusterName Cluster where the volume is configured namespace Namespace where the volume is configured podName The pod that the volume is attached to. The Kubernetes monitoring integration lists Volumes that are attached to a pod persistent If this is a persistent volume, this value is set to true pvcNamespace Namespace where the Persistent Volume Claim is configured pvcName Name that you assigned to the Persistent Volume Claim at creation fsCapacityBytes Capacity of the volume, in bytes fsUsedBytes Usage of the volume, in bytes fsAvailableBytes Capacity available of the volume, in bytes fsUsedPercent Usage of the volume in percentage fsInodes Total inodes of the volume fsInodesUsed inodes used in the volume fsInodesFree inodes available in the volume Volume data is available for volume plugins that implement the MetricsProvider interface: AWSElasticBlockStore AzureDisk AzureFile Cinder Flexvolume Flocker GCEPersistentDisk GlusterFS iSCSI StorageOS VsphereVolume API server data Query the K8sApiServerSample event to see API Server data. For more information, see Configure control plane monitoring: API server attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent, in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist apiserverRequestDelta_verb_VERB_code_CODE Difference of the number of apiserver requests, broken out for each verb and HTTP response code apiserverRequestRate_verb_VERB_code_CODE Rate of apiserver requests, broken out for each verb and HTTP response code restClientRequestsDelta_code_CODE_method_METHOD Difference of the number of HTTP requests, partitioned by method and code restClientRequestsRate_code_CODE_method_METHOD Rate of the number of HTTP requests, partitioned by method and code etcdObjectCounts_resource_RESOURCE-KIND Number of stored objects at the time of last check, split by kind Controller manager data Query the K8sControllerManagerSample event to see Controller manager data. For more information, see Configure control plane monitoring: Controller manager attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist workqueueAddsDelta_name_WORK-QUEUE-NAME Difference of the total number of adds handled by workqueue workqueueDepth_name_WORK-QUEUE-NAME Current depth of workqueue workqueueRetriesDelta_name_WORK-QUEUE-NAME Difference of the total number of retries handled by workqueue leaderElectionMasterStatus Gauge of if the reporting system is master of the relevant lease, 0 indicates backup, 1 indicates master Scheduler data Query the K8sSchedulerSample event in New Relic Insights to see Scheduler data. For more information, see Configure control plane monitoring: Scheduler attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist leaderElectionMasterStatus Gauge of if the reporting system is master of the relevant lease, 0 indicates backup, 1 indicates master httpRequestDurationMicroseconds_handler_HANDLER_quantile_QUANTILE The HTTP request latencies in microseconds, per quantile httpRequestDurationMicroseconds_handler_HANDLER_sum The sum of the HTTP request latencies, in microseconds httpRequestDurationMicroseconds_handler_HANDLER_count The number of observed HTTP requests events restClientRequestsDelta_code_CODE_host_HOST_method_METHOD Difference of the number of HTTP requests, partitioned by status code, method, and host restClientRequestsRate_code_CODE_host_HOST_method_METHOD Rate of the number of HTTP requests, partitioned by status code, method, and host schedulerScheduleAttemptsDelta_result_RESULT Difference of the number of attempts to schedule pods, by the result. unschedulable means a pod could not be scheduled, while error means an internal scheduler problem schedulerScheduleAttemptsRate_result_RESULT Rate of the number of attempts to schedule pods, by the result. unschedulable means a pod could not be scheduled, while error means an internal scheduler problem schedulerSchedulingDurationSeconds_operation_OPERATION_quantile_QUANTILE Scheduling latency in seconds split by sub-parts of the scheduling operation schedulerSchedulingDurationSeconds_operation_OPERATION_sum The sum of scheduling latency in seconds split by sub-parts of the scheduling operation schedulerSchedulingDurationSeconds_operation_OPERATION_count The number of observed events of schedulings split by sub-parts of the scheduling operation. schedulerPreemptionAttemptsDelta Difference of the total preemption attempts in the cluster till now schedulerPodPreemptionVictims Number of selected preemption victims ETCD data Query the K8sEtcdSample event to see ETCD data. For more information, see Configure control plane monitoring: ETCD attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist etcdServerHasLeader Whether or not a leader exists. 1 is existence, 0 is not etcdServerLeaderChangesSeenDelta Difference of the number of leader changes seen etcdMvccDbTotalSizeInBytes Total size of the underlying database physically allocated, in bytes etcdServerProposalsCommittedDelta Difference of the total number of consensus proposals committed etcdServerProposalsCommittedRate Rate of the total number of consensus proposals committed etcdServerProposalsAppliedDelta Difference of the total number of consensus proposals applied etcdServerProposalsAppliedRate Rate of the total number of consensus proposals applied etcdServerProposalsPending The current number of pending proposals to commit etcdServerProposalsFailedDelta Difference of the total number of failed proposals seen etcdServerProposalsFailedRate Rate of the total number of failed proposals seen processOpenFds Number of open file descriptors processMaxFds Maximum number of open file descriptors processFdsUtilization Percentage open file descriptors with respect to the maximum number that can be opened etcdNetworkClientGrpcReceivedBytesRate Rate of the total number of bytes received from gRPC clients etcdNetworkClientGrpcSentBytesRate Rate of the total number of bytes sent to gRPC clients Endpoint data Query the K8sEndpointSample event in New Relic Insights for endpoint data: Endpoint attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the endpoint was created namespaceName Name of the namespace that the endpoint belongs to endpointName Name associated with the endpoint label.LABEL_NAME Labels associated with your endpoint, so you can filter and query for specific endpoints addressAvailable Number of addresses available in endpoint addressNotReady Number of addresses not ready in endpoint Service data Query the K8sServiceSample event for service data: Service attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the service was created namespaceName Name of the namespace that the service belongs to label.LABEL_NAME Labels associated with your service, so you can filter and query for specific service serviceName Name associated with the service loadBalancerIP The IP of the external load balancer, if Spectype is LoadBalancer. externalName The external name value, if Spectype is ExternalName clusterIP The internal cluster IP, if Spectype is ClusterIP specType Type of the service selector.LABEL_NAME The label selector that this service targets Horizontal Pod Autoscaler data Query the K8sHpaSample event in New Relic Insights for Horizontal Pod Autoscaler data: HPA attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration label.LABEL_NAME Labels associated with your HPA, so you can filter and query for specific autoscaler currentReplicas Current number of replicas of pods managed by this autoscaler desiredReplicas Desired number of replicas of pods managed by this autoscaler minReplicas Lower limit for the number of pods that can be set by the autoscaler, 1 by default maxReplicas Upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than minReplicas targetMetric The metric specifications used by this autoscaler when calculating the desired replica count isAble Boolean representing whether or not the autoscaler is able to fetch and update scales, as well as whether or not any backoff-related conditions would prevent scaling isActive Boolean representing whether or not the autoscaler is enabled (if it's able to calculate the desired scales) isLimited Boolean representing whether or not the autoscaler is capped, either up or down, by the maximum or minimum replicas configured labels Number of Kubernetes labels converted to Prometheus labels metadataGeneration The generation observed by the HorizontalPodAutoscaler controller Kubernetes metadata in APM-monitored applications By linking your applications with Kubernetes, the following attributes are added to application trace and distributed trace: nodeName containerName podName clusterName deploymentName namespaceName For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.37712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>and</em> <em>use</em> your Kubernetes <em>data</em>",
        "sections": "Find <em>and</em> <em>use</em> your Kubernetes <em>data</em>",
        "tags": "<em>Understand</em> <em>and</em> <em>use</em> <em>data</em>",
        "body": " Relic integration you <em>use</em>, including the Kubernetes integration: Select the alert type <em>Integrations</em>. From the Select a <em>data</em> source dropdown, select a Kubernetes (K8s) <em>data</em> source. Select alert notifications When an alert condition&#x27;s threshold is triggered, New Relic sends a message to the notification"
      },
      "id": "617d58a9196a6775cbf7c43d"
    },
    {
      "sections": [
        "Navigate the Kubernetes cluster explorer",
        "Meet the cluster explorer",
        "Cluster dashboard",
        "Cluster explorer node table",
        "Search and filter your cluster data",
        "Browse your Kubernetes events"
      ],
      "title": "Navigate the Kubernetes cluster explorer",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Understand and use data"
      ],
      "external_id": "f4e8acd0df7b51805faba3774684718822b93431",
      "image": "https://docs.newrelic.com/static/34f90215b59ab8d7b4ec986bbb110805/9b7bd/nr1-cluster-explorer-node-tooltip.png",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/kubernetes-cluster-explorer/",
      "published_at": "2021-12-30T07:02:12Z",
      "updated_at": "2021-10-24T03:11:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes cluster explorer uses the data collected by the Kubernetes integration to show the status of your cluster, from the control plane to nodes and pods. You can find out about the health of each entity, explore logs, and see how your apps are performing. With the Events integration, everything that happens in your cluster becomes visible, and logs brought in using the logs plugin are also available. Meet the cluster explorer The cluster explorer represents your most relevant cluster data on a chart with the shape of a ship's wheel — which is also Kubernetes' logo. Outer ring: Contains up to 24 nodes of your cluster, the most relevant based on the amount of alerts. Hover over each node to check resource consumption and the percentage of allocable pods used. Inner rings: Contain the pods ( ) of each node. Pods with active alerts are shown in the third innermost ring, and pods that are pending or unable to run are in the center. Hover the mouse over each node or pod to get a quick overview of its resource usage. You can click each node and pod to view its resource usage over time or to get more information about its health and active alerts. Colors are based on predefined alert conditions: Yellow pods have active warning alerts, while red pods have active critical alerts. one.newrelic.com > Kubernetes cluster explorer: Click any pod to get more information about its status and health, and to dig deeper into application data and traces, logs, and events. Click a node to see the following data: Pod statistics CPU, memory, and storage consumption against allocatable amounts Amount of pods used by the node against the allocatable amount of pods For each pod, depending on the integrations and features you've enabled, you can see: Pod status and metadata, including namespace and deployment Container status and statistics Active alerts (both warning and critical) Kubernetes events that happened in that pod APM data and traces (if you've linked your APM data) A link to the pods' and containers' logs, collected using the Kubernetes plugin for New Relic Logs Cluster and control plane statistics are always visible on the left side. Cluster dashboard The cluster dashboard can be accessed at any time from the cluster explorer by clicking Kubernetes dashboard. It provides a curated dashboard experience for your Kubernetes cluster. one.newrelic.com > Kubernetes cluster explorer > Kubernetes dashboard: The Kubernetes dashboard can be accessed from the Kubernetes cluster explorer. It shows useful Kubernetes metric data. Cluster explorer node table Below the cluster explorer is the node table, which shows all the nodes of the cluster, namespace, or deployment. Like all other usage indicators, the table shows consumption against allocatable resources. Search and filter your cluster data The main way to modify the data view in the cluster explorer is by using the top bar to search for specific attributes or values. All the attributes and values collected by the Kubernetes integration can be combined to narrow down the cluster view. one.newrelic.com > Kubernetes cluster explorer: All your Kubernetes cluster's attributes and data points can be used to filter the cluster explorer view. You can also change the time frame using the time picker in the upper right corner. The Auto-refresh box turns the cluster explorer into a real-time dashboard that refreshes every 60 seconds. one.newrelic.com > Kubernetes cluster explorer: The time picker lets you select several predefined time spans. To reload the data every minute, check the auto-refresh box. Browse your Kubernetes events If you’ve enabled the Kubernetes events integration, you can click the Events tab to browse everything that happened in your cluster, from warnings to normal events. To set it up, select the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into logs and infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.3771,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Search <em>and</em> filter your cluster <em>data</em>",
        "tags": "<em>Understand</em> <em>and</em> <em>use</em> <em>data</em>",
        "body": " a node to see the following <em>data</em>: Pod statistics CPU, memory, and storage consumption against allocatable amounts Amount of pods used by the node against the allocatable amount of pods For each pod, depending on the <em>integrations</em> and features you&#x27;ve enabled, you can see: Pod status and metadata"
      },
      "id": "617daf22196a670f66f7bddd"
    }
  ],
  "/docs/infrastructure/host-integrations/understand-use-data/remote-monitoring-host-integrations": [
    {
      "sections": [
        "On-host integration data collection and reporting",
        "Data collection and reporting process",
        "File structure and specifications"
      ],
      "title": "On-host integration data collection and reporting",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "Understand and use data"
      ],
      "external_id": "d8d2680dcd67f4094b6a243a5a643080bca9248f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/understand-use-data/host-integration-data-collection-reporting/",
      "published_at": "2021-12-30T10:37:25Z",
      "updated_at": "2021-10-24T01:22:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how New Relic on-host integrations collect and report data to New Relic. Data collection and reporting process This is how an infrastructure on-host integration sends data to New Relic: On startup, the infrastructure agent scans the directory that contains the integration's definition files. The infrastructure agent registers every integration executable defined in the definition file. The agent scans a dedicated directory for integration configuration files. If those config files specify integrations that have been registered with the infrastructure agent, the agent sets up and schedules the integrations. At the scheduled interval (the default is 15 seconds), the agent harvests the data from the integration and prepares it for transmission. Every 60 seconds, it sends that data to New Relic, along with any other infrastructure data. After a successful collection pass, the integration executable exits. File structure and specifications Understanding the file structure of New Relic on-host integrations can help you customize your integration, understand and use your data, and troubleshoot problems. On-host integrations adhere to a set of open source specifications, allowing anyone to build their own infrastructure on-host integration. For an explanation of these file specifications, see File specs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.34373,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>On</em>-<em>host</em> <em>integration</em> <em>data</em> collection <em>and</em> reporting",
        "sections": "<em>On</em>-<em>host</em> <em>integration</em> <em>data</em> collection <em>and</em> reporting",
        "tags": "<em>On</em>-<em>host</em> <em>integrations</em>",
        "body": ", the integration executable exits. File structure and specifications Understanding the file structure of New Relic on-<em>host</em> <em>integrations</em> can help you customize your integration, <em>understand</em> and <em>use</em> your <em>data</em>, and troubleshoot problems. On-<em>host</em> <em>integrations</em> adhere to a set of open source specifications, allowing anyone to build their own infrastructure on-<em>host</em> integration. For an explanation of these file specifications, see File specs."
      },
      "id": "617d6f8d28ccbca08b80083a"
    },
    {
      "sections": [
        "Navigate the Kubernetes cluster explorer",
        "Meet the cluster explorer",
        "Cluster dashboard",
        "Cluster explorer node table",
        "Search and filter your cluster data",
        "Browse your Kubernetes events"
      ],
      "title": "Navigate the Kubernetes cluster explorer",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Understand and use data"
      ],
      "external_id": "f4e8acd0df7b51805faba3774684718822b93431",
      "image": "https://docs.newrelic.com/static/34f90215b59ab8d7b4ec986bbb110805/9b7bd/nr1-cluster-explorer-node-tooltip.png",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/kubernetes-cluster-explorer/",
      "published_at": "2021-12-30T07:02:12Z",
      "updated_at": "2021-10-24T03:11:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes cluster explorer uses the data collected by the Kubernetes integration to show the status of your cluster, from the control plane to nodes and pods. You can find out about the health of each entity, explore logs, and see how your apps are performing. With the Events integration, everything that happens in your cluster becomes visible, and logs brought in using the logs plugin are also available. Meet the cluster explorer The cluster explorer represents your most relevant cluster data on a chart with the shape of a ship's wheel — which is also Kubernetes' logo. Outer ring: Contains up to 24 nodes of your cluster, the most relevant based on the amount of alerts. Hover over each node to check resource consumption and the percentage of allocable pods used. Inner rings: Contain the pods ( ) of each node. Pods with active alerts are shown in the third innermost ring, and pods that are pending or unable to run are in the center. Hover the mouse over each node or pod to get a quick overview of its resource usage. You can click each node and pod to view its resource usage over time or to get more information about its health and active alerts. Colors are based on predefined alert conditions: Yellow pods have active warning alerts, while red pods have active critical alerts. one.newrelic.com > Kubernetes cluster explorer: Click any pod to get more information about its status and health, and to dig deeper into application data and traces, logs, and events. Click a node to see the following data: Pod statistics CPU, memory, and storage consumption against allocatable amounts Amount of pods used by the node against the allocatable amount of pods For each pod, depending on the integrations and features you've enabled, you can see: Pod status and metadata, including namespace and deployment Container status and statistics Active alerts (both warning and critical) Kubernetes events that happened in that pod APM data and traces (if you've linked your APM data) A link to the pods' and containers' logs, collected using the Kubernetes plugin for New Relic Logs Cluster and control plane statistics are always visible on the left side. Cluster dashboard The cluster dashboard can be accessed at any time from the cluster explorer by clicking Kubernetes dashboard. It provides a curated dashboard experience for your Kubernetes cluster. one.newrelic.com > Kubernetes cluster explorer > Kubernetes dashboard: The Kubernetes dashboard can be accessed from the Kubernetes cluster explorer. It shows useful Kubernetes metric data. Cluster explorer node table Below the cluster explorer is the node table, which shows all the nodes of the cluster, namespace, or deployment. Like all other usage indicators, the table shows consumption against allocatable resources. Search and filter your cluster data The main way to modify the data view in the cluster explorer is by using the top bar to search for specific attributes or values. All the attributes and values collected by the Kubernetes integration can be combined to narrow down the cluster view. one.newrelic.com > Kubernetes cluster explorer: All your Kubernetes cluster's attributes and data points can be used to filter the cluster explorer view. You can also change the time frame using the time picker in the upper right corner. The Auto-refresh box turns the cluster explorer into a real-time dashboard that refreshes every 60 seconds. one.newrelic.com > Kubernetes cluster explorer: The time picker lets you select several predefined time spans. To reload the data every minute, check the auto-refresh box. Browse your Kubernetes events If you’ve enabled the Kubernetes events integration, you can click the Events tab to browse everything that happened in your cluster, from warnings to normal events. To set it up, select the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into logs and infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.3771,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Search <em>and</em> filter your cluster <em>data</em>",
        "tags": "<em>Understand</em> <em>and</em> <em>use</em> <em>data</em>",
        "body": " a node to see the following <em>data</em>: Pod statistics CPU, memory, and storage consumption against allocatable amounts Amount of pods used by the node against the allocatable amount of pods For each pod, depending on the <em>integrations</em> and features you&#x27;ve enabled, you can see: Pod status and metadata"
      },
      "id": "617daf22196a670f66f7bddd"
    },
    {
      "sections": [
        "Find and use your Kubernetes data",
        "Query Kubernetes data",
        "Event types",
        "Manage alerts",
        "Create an alert condition",
        "Use the predefined alert types and thresholds",
        "Select alert notifications",
        "Pod alert notification example",
        "Container resource notification example",
        "Create alert conditions using NRQL",
        "Kubernetes attributes and metrics",
        "Node data",
        "Namespace data",
        "Deployment data",
        "ReplicaSet data",
        "DaemonSet data",
        "StatefulSet data",
        "Pod data",
        "Cluster data",
        "Container data",
        "Volume data",
        "API server data",
        "Controller manager data",
        "Scheduler data",
        "ETCD data",
        "Endpoint data",
        "Service data",
        "Horizontal Pod Autoscaler data",
        "Kubernetes metadata in APM-monitored applications",
        "For more help"
      ],
      "title": "Find and use your Kubernetes data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Understand and use data"
      ],
      "external_id": "636617521998343c5bb96b0500843229b9263712",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data/",
      "published_at": "2021-12-30T09:11:39Z",
      "updated_at": "2021-10-24T03:11:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own charts and query all your Kubernetes integration data using the query builder and the NerdGraph API. Our integration collects Kubernetes data by instrumenting the container orchestration layer. For a simpler and more visual experience, use the cluster explorer. one.newrelic.com > Dashboards: Using the query builder you can query your Kubernetes data and create clear visualizations. Query Kubernetes data The simplest way to query your Kubernetes data is using the query builder, which accepts NRQL queries. Alternatively, you can use the NerdGraph API to retrieve Kubernetes data. Event types Kubernetes data is attached to the following event types: Event name Type of Kubernetes data Available since K8sNodeSample Node data v1.0.0 K8sNamespaceSample Namespace data v1.0.0 K8sDeploymentSample Deployment data v1.0.0 K8sReplicasetSample ReplicaSet data v1.0.0 K8sDaemonsetSample DaemonSet data v1.13.0 K8sStatefulsetSample StatefulSet data v1.13.0 K8sPodSample Pod data v1.0.0 K8sClusterSample Cluster data v1.0.0 K8sContainerSample Container data v1.0.0 K8sVolumeSample Volume data v1.0.0 K8sApiServerSample API server data v1.11.0 K8sControllerManagerSample Controller manager data v1.11.0 K8sSchedulerSample Scheduler data v1.11.0 K8sEtcdSample ETCD data v1.11.0 K8sEndpointSample Endpoint data v1.13.0 K8sServiceSample Service data v1.13.0 K8sHpaSample Horizontal Pod Autoscaler data v2.3.0 Manage alerts You can be notified about alert violations for your Kubernetes data: Create an alert condition To create an alert condition for the Kubernetes integration: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Kubernetes, then select Create alert condition. To filter the alert to Kubernetes entities that only have the chosen attributes, select Filter. Select the threshold settings. For more on the Trigger an alert when... options, see Alert types. Select an existing alert policy, or create a new one. Select Create. When an alert condition's threshold is triggered, New Relic sends a notification to the policy's notification channels. Use the predefined alert types and thresholds The Kubernetes integration comes with its own alert policy and alert conditions. To see what the predefined alert conditions are, see Kubernetes integration: Predefined alert policy. In addition, you can create an alert condition for any metric collected by any New Relic integration you use, including the Kubernetes integration: Select the alert type Integrations. From the Select a data source dropdown, select a Kubernetes (K8s) data source. Select alert notifications When an alert condition's threshold is triggered, New Relic sends a message to the notification channel(s) chosen in the alert policy. Depending on the type of notification, you may have the following options: View the incident. Acknowledge the incident. Go to a chart of the incident data by selecting the identifier name. The entity identifier that triggered the alert appears near the top of the notification message. The format of the identifier depends on the alert type: Available pods are less than desired pods alerts: K8s:CLUSTER_NAME:PARENT_NAMESPACE:replicaset:REPLICASET_NAME Copy CPU or memory usage alerts: K8s:CLUSTER_NAME:PARENT_NAMESPACE:POD_NAME:container:CONTAINER_NAME Copy Here are some examples. Pod alert notification example For Available pods are less than desired pods alerts, the ID of the ReplicaSet triggering the issue might look like this: k8s:beam-production:default:replicaset:nginx-deployment-1623441481 Copy This identifier contains the following information: Cluster name: beam-production Parent namespace: default ReplicaSet name: nginx-deployment-1623441481 Container resource notification example For container CPU or memory usage alerts, the entity might look like this: k8s:beam-production:kube-system:kube-state-metrics-797bb87c75-zncwn:container:kube-state-metrics Copy This identifier contains the following information: Cluster name: beam-production Parent namespace: kube-system Pod namespace: kube-state-metrics-797bb87c75-zncwn Container name: kube-state-metrics Create alert conditions using NRQL Follow standard procedures to create alert conditions for NRQL queries. Kubernetes attributes and metrics The Kubernetes integration collects the following metrics and other attributes. Node data Query the K8sNodeSample event for node data: Node attribute Description allocatableCpuCores Node allocatable CPU cores allocatableMemoryBytes Node allocatable memory bytes allocatablePods Node allocatable pods allocatableEphemeralStorageBytes Node allocatable ephemeral-storage bytes capacityCpuCores Node CPU capacity capacityMemoryBytes Node memory capacity (in bytes) capacityPods Pod capacity of the node capacityEphemeralStorageBytes Node ephemeral-storage capacity clusterName Name that you assigned to the cluster when you installed the Kubernetes integration condition.{conditionName}={conditionValue} Status of the current observed node condition. The reported conditions can vary depending on your Kubernetes flavor and installed operators. Examples of common conditions are: Ready, DiskPressure, MemoryPressure, PIDPressure and NetworkUnavailable. Condition values can be 1 (true), 0 (false), or -1 (unknown). cpuUsedCoreMilliseconds Node CPU usage measured in core milliseconds cpuUsedCores Node CPU usage measured in cores cpuRequestedCores Total amount of CPU cores requested allocatableCpuCoresUtilization Percentage of CPU cores actually used with respect to the CPU cores allocatable fsAvailableBytes Bytes available in the node filesystem fsCapacityBytes Total capacity of the node filesystem in bytes fsInodes Total number of inodes in the node filesystem fsInodesFree Free inodes in the node filesystem fsInodesUsed Used inodes in the node filesystem fsUsedBytes Used bytes in the node filesystem fsCapacityUtilization Percentage of used bytes in the node filesystem with respect to the capacity memoryAvailableBytes Bytes of memory available in the node memoryMajorPageFaultsPerSecond Number of major page faults per second in the node memoryPageFaults Number of page faults in the node memoryRssBytes Bytes of rss memory memoryUsedBytes Bytes of memory used memoryWorkingSetBytes Bytes of memory in the working set memoryRequestedBytes Total amount of requested memory allocatableMemoryUtilization Percentage of bytes of memory in the working set with respect to the node allocatable memory net.errorCountPerSecond Number of errors per second while receiving/transmitting over the network nodeName Host name that the pod is running on runtimeAvailableBytes Bytes available to the container runtime filesystem runtimeCapacityBytes Total capacity assigned to the container runtime filesystem in bytes runtimeInodes Total number of inodes in the container runtime filesystem runtimeInodesFree Free inodes in the container runtime filesystem runtimeInodesUsed Used inodes in the container runtime filesystem runtimeUsedBytes Used bytes in the container runtime filesystem unschedulable Status of node schedulability of new pods. Its value can be 0 (false) or 1 (true) label.LABEL_NAME Labels associated with your node, so you can filter and query for specific nodes Namespace data Query the K8sNamespaceSample event for namespace data: Namespace attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of the namespace when it was created namespace Name of the namespace to be used as an identifier label.LABEL_NAME Labels associated with your namespace, so you can filter and query for specific namespaces status Current status of the namespace. The value can be Active or Terminated Deployment data Query the K8sDeploymentSample event for deployment data: Deployment attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the deployment was created deploymentName Name of the deployment to be used as an identifier namespace Name of the namespace that the deployment belongs to label.LABEL_NAME Labels associated with your deployment, so you can filter and query for specific deployments podsAvailable Number of replicas that are currently available podsDesired Number of replicas that you defined in the deployment podsTotal Total number of replicas that are currently running podsUnavailable Number of replicas that are currently unavailable podsUpdated Number of replicas that have been updated to achieve the desired state of the deployment podsMissing Total number of replicas that are missing (number of desired replicas, podsDesired, minus the total number of replicas, podsTotal) ReplicaSet data Query the K8sReplicasetSample event for ReplicaSet data: Replica attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the ReplicaSet was created deploymentName Name of the deployment to be used as an identifier namespace Name of the namespace that the ReplicaSet belongs to observedGeneration Integer representing generation observed by the ReplicaSet podsDesired Number of replicas that you defined in the deployment podsFullyLabeled Number of pods that have labels that match the ReplicaSet pod template labels podsReady Number of replicas that are ready for this ReplicaSet podsTotal Total number of replicas that are currently running podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) replicasetName Name of the ReplicaSet to be used as an identifier DaemonSet data Query the K8sDaemonsetSample event for DaemonSet data: DaemonSet attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the DaemonSet was created namespaceName Name of the namespace that the DaemonSet belongs to label.LABEL_NAME Labels associated with your DaemonSet, so you can filter and query for specific DaemonSet daemonsetName Name associated with the DaemonSet podsDesired The number of nodes that should be running the daemon pod podsScheduled The number of nodes running at least one daemon pod and are supposed to podsAvailable The number of nodes that should be running the daemon pod and have one or more of the daemon pod running and available podsReady The number of nodes that should be running the daemon pod and have one or more of the daemon pod running and ready podsUnavailable The number of nodes that should be running the daemon pod and have none of the daemon pod running and available podsMisscheduled The number of nodes running a daemon pod but are not supposed to podsUpdatedScheduled The total number of nodes that are running updated daemon pod podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) metadataGeneration Sequence number representing a specific generation of the desired state StatefulSet data Query the K8sStatefulsetSample event for StatefulSet data: StatefulSet attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the StatefulSet was created namespaceName Name of the namespace that the StatefulSet belongs to label.LABEL_NAME Labels associated with your StatefulSet, so you can filter and query for specific StatefulSet statefulsetName Name associated with the StatefulSet podsDesired Number of desired pods for a StatefulSet podsReady The number of ready replicas per StatefulSet podsCurrent The number of current replicas per StatefulSet podsTotal The number of replicas per StatefulSet podsUpdated The number of updated replicas per StatefulSet podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) observedGeneration The generation observed by the StatefulSet controller metadataGeneration Sequence number representing a specific generation of the desired state for the StatefulSet currentRevision Indicates the version of the StatefulSet used to generate pods in the sequence. Value range: between 0 and podsCurrent updateRevision Indicates the version of the StatefulSet used to generate pods in the sequence. Value range: between podsDesired-podsUpdated and podsDesired Pod data Query the K8sPodSample event for pod data: Pod attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the pod was created in epoch seconds createdBy Name of the Kubernetes object that created the pod. For example, newrelic-infra createdKind Kind of Kubernetes object that created the pod. For example, DaemonSet. deploymentName Name of the deployment to be used as an identifier isReady Boolean representing whether or not the pod is ready to serve requests isScheduled Boolean representing whether or not the pod has been scheduled to run on a node label.LABEL_NAME Labels associated with your pod, so you can filter and query for specific pods message Details related to the last pod status change namespace Name of the namespace that the pod belongs to net.errorCountPerSecond Number of errors per second while receiving/transmitting over the network net.errorsPerSecond Number of errors per second net.rxBytesPerSecond Number of bytes per second received over the network net.txBytesPerSecond Number of bytes per second transmitted over the network nodeIP Host IP address that the pod is running on nodeName Host name that the pod is running on podIP IP address of the pod. If it doesn't have an IP, it'll be empty podName Name of the pod to be used as an identifier reason Reason why the pod is in the current status startTime Timestamp of when the pod started running in epoch seconds status Current status of the pod. Value can be Pending, Running, Succeeded, Failed, Unknown Cluster data Query the K8sClusterSample event to see cluster data: Cluster attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration clusterK8sVersion Kubernetes version that the cluster is running Container data Query the K8sContainerSample event for container data: Container attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration containerID Unique ID associated with the container. If you are running Docker, this is the Docker container id containerImage Name of the image that the container is running containerImageID Unique ID associated with the image that the container is running containerName Name associated with the container cpuLimitCores Integer representing limit CPU cores defined for the container in the pod specification cpuRequestedCores Requested CPU cores defined for the container in the pod specification cpuUsedCores CPU cores actually used by the container cpuCoresUtilization Percentage of CPU cores actually used by the container with respect to the CPU limit specified. This percentage is based on this calculation: (cpuUsedCores / cpuLimitCores) * 100 requestedCpuCoresUtilization Percentage of CPU cores actually used by the container with respect to the CPU request specified deploymentName Name of the deployment to be used as an identifier isReady Boolean. Whether or not the container's readiness check succeeded label.LABEL_NAME Labels associated with your container, so you can filter and query for specific containers memoryLimitBytes Integer representing limit bytes of memory defined for the container in the pod specification memoryRequestedBytes Integer. Requested bytes of memory defined for the container in the pod specification memoryUsedBytes Integer. Bytes of memory actually used by the container memoryUtilization Percentage of memory actually used by the container with respect to the memory limit specified requestedMemoryUtilization Percentage of memory actually used by the container with respect to the memory request specified memoryWorkingSetBytes Integer. Bytes of memory in the working set memoryWorkingSetUtilization Percentage of working set memory actually used by the container with respect to the memory limit specified requestedMemoryWorkingSetUtilization Percentage of working set memory actually used by the container with respect to the memory request specified namespace Name of the namespace that the container belongs to nodeIP Host IP address the container is running on nodeName Host name that the container is running on podName Name of the pod that the container is in, to be used as an identifier reason Provides a reason why the container is in the current status restartCount Number of times the container has been restarted status Current status of the container. Value can be Running, Terminated, or Unknown containerCpuCfsPeriodsDelta Delta change of elapsed enforcement period intervals containerCpuCfsThrottledPeriodsDelta Delta change of throttled period intervals containerCpuCfsThrottledSecondsDelta Delta change of duration the container has been throttled, in seconds containerCpuCfsPeriodsTotal Total number of elapsed enforcement period intervals containerCpuCfsThrottledPeriodsTotal Total number of throttled period intervals containerCpuCfsThrottledSecondsTotal Total time duration the container has been throttled, in seconds containerMemoryMappedFileBytes Total size of memory mapped files used by this container, in bytes Volume data Query the K8sVolumeSample event for volume data: Volume attribute Description volumeName Name that you assigned to the volume at creation clusterName Cluster where the volume is configured namespace Namespace where the volume is configured podName The pod that the volume is attached to. The Kubernetes monitoring integration lists Volumes that are attached to a pod persistent If this is a persistent volume, this value is set to true pvcNamespace Namespace where the Persistent Volume Claim is configured pvcName Name that you assigned to the Persistent Volume Claim at creation fsCapacityBytes Capacity of the volume, in bytes fsUsedBytes Usage of the volume, in bytes fsAvailableBytes Capacity available of the volume, in bytes fsUsedPercent Usage of the volume in percentage fsInodes Total inodes of the volume fsInodesUsed inodes used in the volume fsInodesFree inodes available in the volume Volume data is available for volume plugins that implement the MetricsProvider interface: AWSElasticBlockStore AzureDisk AzureFile Cinder Flexvolume Flocker GCEPersistentDisk GlusterFS iSCSI StorageOS VsphereVolume API server data Query the K8sApiServerSample event to see API Server data. For more information, see Configure control plane monitoring: API server attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent, in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist apiserverRequestDelta_verb_VERB_code_CODE Difference of the number of apiserver requests, broken out for each verb and HTTP response code apiserverRequestRate_verb_VERB_code_CODE Rate of apiserver requests, broken out for each verb and HTTP response code restClientRequestsDelta_code_CODE_method_METHOD Difference of the number of HTTP requests, partitioned by method and code restClientRequestsRate_code_CODE_method_METHOD Rate of the number of HTTP requests, partitioned by method and code etcdObjectCounts_resource_RESOURCE-KIND Number of stored objects at the time of last check, split by kind Controller manager data Query the K8sControllerManagerSample event to see Controller manager data. For more information, see Configure control plane monitoring: Controller manager attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist workqueueAddsDelta_name_WORK-QUEUE-NAME Difference of the total number of adds handled by workqueue workqueueDepth_name_WORK-QUEUE-NAME Current depth of workqueue workqueueRetriesDelta_name_WORK-QUEUE-NAME Difference of the total number of retries handled by workqueue leaderElectionMasterStatus Gauge of if the reporting system is master of the relevant lease, 0 indicates backup, 1 indicates master Scheduler data Query the K8sSchedulerSample event in New Relic Insights to see Scheduler data. For more information, see Configure control plane monitoring: Scheduler attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist leaderElectionMasterStatus Gauge of if the reporting system is master of the relevant lease, 0 indicates backup, 1 indicates master httpRequestDurationMicroseconds_handler_HANDLER_quantile_QUANTILE The HTTP request latencies in microseconds, per quantile httpRequestDurationMicroseconds_handler_HANDLER_sum The sum of the HTTP request latencies, in microseconds httpRequestDurationMicroseconds_handler_HANDLER_count The number of observed HTTP requests events restClientRequestsDelta_code_CODE_host_HOST_method_METHOD Difference of the number of HTTP requests, partitioned by status code, method, and host restClientRequestsRate_code_CODE_host_HOST_method_METHOD Rate of the number of HTTP requests, partitioned by status code, method, and host schedulerScheduleAttemptsDelta_result_RESULT Difference of the number of attempts to schedule pods, by the result. unschedulable means a pod could not be scheduled, while error means an internal scheduler problem schedulerScheduleAttemptsRate_result_RESULT Rate of the number of attempts to schedule pods, by the result. unschedulable means a pod could not be scheduled, while error means an internal scheduler problem schedulerSchedulingDurationSeconds_operation_OPERATION_quantile_QUANTILE Scheduling latency in seconds split by sub-parts of the scheduling operation schedulerSchedulingDurationSeconds_operation_OPERATION_sum The sum of scheduling latency in seconds split by sub-parts of the scheduling operation schedulerSchedulingDurationSeconds_operation_OPERATION_count The number of observed events of schedulings split by sub-parts of the scheduling operation. schedulerPreemptionAttemptsDelta Difference of the total preemption attempts in the cluster till now schedulerPodPreemptionVictims Number of selected preemption victims ETCD data Query the K8sEtcdSample event to see ETCD data. For more information, see Configure control plane monitoring: ETCD attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist etcdServerHasLeader Whether or not a leader exists. 1 is existence, 0 is not etcdServerLeaderChangesSeenDelta Difference of the number of leader changes seen etcdMvccDbTotalSizeInBytes Total size of the underlying database physically allocated, in bytes etcdServerProposalsCommittedDelta Difference of the total number of consensus proposals committed etcdServerProposalsCommittedRate Rate of the total number of consensus proposals committed etcdServerProposalsAppliedDelta Difference of the total number of consensus proposals applied etcdServerProposalsAppliedRate Rate of the total number of consensus proposals applied etcdServerProposalsPending The current number of pending proposals to commit etcdServerProposalsFailedDelta Difference of the total number of failed proposals seen etcdServerProposalsFailedRate Rate of the total number of failed proposals seen processOpenFds Number of open file descriptors processMaxFds Maximum number of open file descriptors processFdsUtilization Percentage open file descriptors with respect to the maximum number that can be opened etcdNetworkClientGrpcReceivedBytesRate Rate of the total number of bytes received from gRPC clients etcdNetworkClientGrpcSentBytesRate Rate of the total number of bytes sent to gRPC clients Endpoint data Query the K8sEndpointSample event in New Relic Insights for endpoint data: Endpoint attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the endpoint was created namespaceName Name of the namespace that the endpoint belongs to endpointName Name associated with the endpoint label.LABEL_NAME Labels associated with your endpoint, so you can filter and query for specific endpoints addressAvailable Number of addresses available in endpoint addressNotReady Number of addresses not ready in endpoint Service data Query the K8sServiceSample event for service data: Service attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the service was created namespaceName Name of the namespace that the service belongs to label.LABEL_NAME Labels associated with your service, so you can filter and query for specific service serviceName Name associated with the service loadBalancerIP The IP of the external load balancer, if Spectype is LoadBalancer. externalName The external name value, if Spectype is ExternalName clusterIP The internal cluster IP, if Spectype is ClusterIP specType Type of the service selector.LABEL_NAME The label selector that this service targets Horizontal Pod Autoscaler data Query the K8sHpaSample event in New Relic Insights for Horizontal Pod Autoscaler data: HPA attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration label.LABEL_NAME Labels associated with your HPA, so you can filter and query for specific autoscaler currentReplicas Current number of replicas of pods managed by this autoscaler desiredReplicas Desired number of replicas of pods managed by this autoscaler minReplicas Lower limit for the number of pods that can be set by the autoscaler, 1 by default maxReplicas Upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than minReplicas targetMetric The metric specifications used by this autoscaler when calculating the desired replica count isAble Boolean representing whether or not the autoscaler is able to fetch and update scales, as well as whether or not any backoff-related conditions would prevent scaling isActive Boolean representing whether or not the autoscaler is enabled (if it's able to calculate the desired scales) isLimited Boolean representing whether or not the autoscaler is capped, either up or down, by the maximum or minimum replicas configured labels Number of Kubernetes labels converted to Prometheus labels metadataGeneration The generation observed by the HorizontalPodAutoscaler controller Kubernetes metadata in APM-monitored applications By linking your applications with Kubernetes, the following attributes are added to application trace and distributed trace: nodeName containerName podName clusterName deploymentName namespaceName For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.3771,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>and</em> <em>use</em> your Kubernetes <em>data</em>",
        "sections": "Find <em>and</em> <em>use</em> your Kubernetes <em>data</em>",
        "tags": "<em>Understand</em> <em>and</em> <em>use</em> <em>data</em>",
        "body": " Relic integration you <em>use</em>, including the Kubernetes integration: Select the alert type <em>Integrations</em>. From the Select a <em>data</em> source dropdown, select a Kubernetes (K8s) <em>data</em> source. Select alert notifications When an alert condition&#x27;s threshold is triggered, New Relic sends a message to the notification"
      },
      "id": "617d58a9196a6775cbf7c43d"
    }
  ],
  "/docs/infrastructure/index": [
    {
      "sections": [
        "Incorrect data reported",
        "Problem",
        "Troubleshooting",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows"
      ],
      "title": "Incorrect data reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "84b37d403b5c2b8c8c9d8d9220254d77852c49ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-data-reported/",
      "published_at": "2021-12-31T01:42:57Z",
      "updated_at": "2021-12-30T06:51:15Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows unexpected data for some of the events, metrics or attributes collected from the infrastructure agent. Troubleshooting Infrastructure supports trace-level logging that can be enabled on-demand to help troubleshooting complex scenarios. The following trace flags can be configured in order to print all events and metrics send to Telemetry Data Platform. This setting generates a lot of data very quickly, we recommend only enabling it for troubleshooting purposes. Edit the newrelic-infra.yml configuration file and add required flags. For example: verbose: 1 log_file: /path/myfile.log trace: # v3.submission enables detailed logging for events, examples: SystemSample, NetworkSample, etc. - v3.submission # dm.submission - dm.submission Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10, or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Identify the new trace log lines to confirm the data being sent to the Telemetry Data Platform. Log example when v3.submission is enabled: time=\"2021-12-28T09:27:28Z\" level=debug msg=\"Sending events to metrics-ingest.\" component=MetricsIngestSender key=... numEvents=3 postCount=1 timestamps=\"[2021-01-01 09:27:28 +0000 UTC]\" time=\"2021-12-28T09:27:28Z\" level=debug msg=\"Preparing metrics post.\" component=MetricsIngestSender postCount=1 time=\"2021-12-28T09:27:28Z\" level=trace msg=\"[{\\\"EntityID\\\":111,\\\"IsAgent\\\":true,\\\"Events\\\":[{\\\"eventType\\\":\\\"SystemSample\\\",\\\"timestamp\\\":1640683648,\\\"entityKey\\\":\\\"...\\\",\\\"cpuPercent\\\":0.2004008016032026, ...}]\" feature=v3.submission time=\"2021-12-28T09:27:29Z\" level=debug msg=\"Metrics post succeeded.\" component=MetricsIngestSender postCount=1 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 66.81633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> monitoring UI shows unexpected data for some of the events, metrics or attributes collected from the <em>infrastructure</em> agent. Troubleshooting <em>Infrastructure</em> supports trace-level logging that can be enabled on-demand to help troubleshooting complex"
      },
      "id": "61cd56e3e7b9d25b3e7f54c3"
    },
    {
      "sections": [
        "Infrastructure agent overhead",
        "Linux single-task host",
        "Linux Docker host",
        "Windows host",
        "Linux ARM64 host",
        "Manage data",
        "Resource utilization"
      ],
      "title": "Infrastructure agent overhead",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "cd4b0d49bf6d11a12ff3a8357b223786b4c3f881",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead/",
      "published_at": "2021-12-30T10:44:50Z",
      "updated_at": "2021-12-25T15:24:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host's workload, particularly on the number of processes running on the host. This is because the agent collects detailed data from each individual process. As a general guideline, New Relic has collected benchmarks for some common types of hosts: Linux single-task host The agent has very low performance overhead on a classic, single-task host. For example, a server running Apache, Unicorn, or a single Java application. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Operating system: CentOS 7 For this type of classic, single-task host, typical usage is: CPU: about 0.3% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Linux Docker host The agent has very low performance overhead on a host running Docker, with exact usage depending on the number of Docker containers your machine hosts, and whether those processes are long- or short-lived. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Number of containers: 25 containers, about 100 long-lived processes running in containers Operating system: CentOS 7 For this type of Docker host, typical usage is: CPU: about 0.8% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Windows host The agent has very low performance overhead on a typical Windows host serving web apps and running the Windows/IIS stack. Our benchmarks for this type of host are based on an Amazon EC2 t2.small: vCPUs: 1 Memory: 2.0 GB Storage: 30.0 GB Operating system: Windows Server 2012 R2 For this type of Windows host, typical usage is: CPU: 2 to 3% Resident Memory: 30 MB Storage on disk: about 50 MB Linux ARM64 host The agent has similar performance overhead on an ARM64 (Graviton 2) host on EC2 when compared with AMD64 machines. The benchmark is based on Amazon EC2 t3.2xlarge vs. t4g.2xlarge instances. Amazon Linux 2 EC2 instance with infrastructure agent default settings: CPU: about 0.1% on ARM vs 0.13% AMD Virtual memory: about 0.75GB ARM vs 1 GB AMD Resident memory: 20MB ARM vs 22 MB AMD We are always improving the performance of the infrastructure agent. If you see unusually high agent performance overhead, get support at support.newrelic.com. Manage data To learn how to adjust how much data our infrastructure monitoring ingests and reports, see Manage infrastructure data. Resource utilization On Linux systems, infrastructure is installed with default settings for each supported service manager. A memory limit of 1 Gigabyte is enforced. Please consider reviewing and adjusting the default configuration based on your system requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.842045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent overhead",
        "sections": "<em>Infrastructure</em> agent overhead",
        "tags": "<em>Infrastructure</em>",
        "body": "The <em>infrastructure</em> agent is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host&#x27;s workload, particularly on the number of processes running on the host. This is because the agent collects detailed"
      },
      "id": "6043fa3464441f329a378f18"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-12-31T01:42:58Z",
      "updated_at": "2021-12-25T15:23:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). macOS: 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, 2019, and 2022, and their service packs. Windows 10 and their service packs. macOS 10.15 (Catalina), 11 (Big Sur), 12 (Monterey). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 48.841393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> agent",
        "sections": "Requirements for the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em>",
        "body": "Before installing our <em>infrastructure</em> agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The <em>infrastructure</em> agent supports these processor architectures"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    }
  ],
  "/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition": [
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-12-30T11:01:58Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.85384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-12-30T11:01:59Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.43727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-12-30T11:01:12Z",
      "updated_at": "2021-07-27T13:58:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances on one host This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.43648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances"
      },
      "id": "603eb49128ccbca939eba74a"
    }
  ],
  "/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/verify-your-alerts-after-activating-remote-monitoring": [
    {
      "sections": [
        "Remote monitoring in on-host integrations",
        "Important",
        "Effects of activating remote_monitoring",
        "Alert verification",
        "New entity attributes",
        "Changes in recorded metrics",
        "Unrecorded attributes",
        "Updated hostname"
      ],
      "title": "Remote monitoring in on-host integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "Understand and use data"
      ],
      "external_id": "a9d45e7df90e6cbccb96e76c0bd4dacadc40a2a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/understand-use-data/remote-monitoring-host-integrations/",
      "published_at": "2021-12-30T10:37:25Z",
      "updated_at": "2021-10-24T01:23:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "From a New Relic perspective, entity is a broad concept. An entity is anything New Relic can identify that has data you can monitor. Integrations can be configured to create their own entity, called a remote entity, by setting the remote_monitoring option to true. If set to false, an integration will be considered a local entity, and the data related to it will be attached to the host entity that the agent creates. Remote monitoring requires infrastructure agent version 1.2.25 or higher. For the Apache, Cassandra, MySQL, NGINX, and Redis integrations, remote monitoring (and multi-tenancy) is enabled by activating the configuration parameter remote_monitoring. Important If your Apache, Cassandra, MySQL, NGINX, or Redis service is located in the same host as the agent, when you activate remote monitoring the resulting entity will be considered as remote, regardless of its actual location. This may affect alerts, alter attributes, and have other effects, as explained here. Effects of activating remote_monitoring By enabling remote_monitoring, the integration becomes a different entity which is no longer attached to the infrastructure agent. As a result, the following items may be affected: Alert verification Enabling remote monitoring can affect your configured alerts in case they are using any of the values that are affected by this new feature. We strongly recommend checking your existing alerts to make sure they keep on working as expected. New entity attributes These attributes are modified in the resulting entity: Display name: New entity unique key (instead of using the display name) Entity GUID: New entity GUID Entity ID: New entity ID Entity key: New entity unique key (instead of using the display name) External key: Using integration entity name (instead of using the agent display) Changes in recorded metrics When remote monitoring is enabled, we will add the hostname and port values to all metrics. If the nricluster name or nriservice are defined in the integration configuration file, they will also be decorated. Unrecorded attributes Since the integration is now an independent entity which is not attached to the agent, the following agent attributes are not collected: agentName agentVersion coreCount criticalViolationCount fullHostname instanceType kernelVersion linuxDistribution entityType operatingSystem processorCount systemMemoryBytes warningViolationCount Your custom attributes Updated hostname For the ApacheSample, RedisSample, CassandraSample, and NginxSample integration metrics, we will use the integration configuration hostname instead of the short hostname from the agent. When the integration hostname is a loopback address, the agent will replace it in order to guarantee uniqueness.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.67314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Remote</em> <em>monitoring</em> in on-host integrations",
        "sections": "<em>Remote</em> <em>monitoring</em> in on-host integrations",
        "body": " be affected: <em>Alert</em> verification Enabling <em>remote</em> <em>monitoring</em> can affect <em>your</em> configured <em>alerts</em> in case they are using any of the values that are affected by this new feature. We strongly recommend checking <em>your</em> existing <em>alerts</em> to make sure they keep on working as expected. New entity attributes"
      },
      "id": "617dbc6c28ccbcf3bf7ff9c0"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/drop-data-using-nerdgraph/",
      "sections": [
        "Drop data using NerdGraph",
        "Overview",
        "Requirements",
        "Create drop data rule",
        "Caution",
        "NRQL restrictions",
        "Example drop rules",
        "Drop two event types",
        "Drop events meeting certain criteria",
        "Drop sensitive attributes while maintaining the rest of the data",
        "Verify your drop rule works",
        "View rules",
        "Delete drop rules",
        "Audit drop rule history",
        "Cautions when dropping data",
        "Drop attributes on dimensional metric rollups",
        "Beta Feature",
        "Usage",
        "Restrictions",
        "Learn more"
      ],
      "published_at": "2021-12-30T07:57:46Z",
      "title": "Drop data using NerdGraph",
      "updated_at": "2021-12-30T07:57:46Z",
      "type": "docs",
      "external_id": "4a400ac08bcc55060e9d037de79c012af6b618e9",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to manage your data ingest is to set up data dropping rules. For data that supports data dropping, you can: Filter out unimportant low-value data Filter out potentially sensitive data Overview When you set up data dropping rules, only data from that point onward is affected. Existing data that has already been ingested cannot be edited or deleted. Learn more in this NerdBytes video (7:09 minutes): Besides using NerdGraph, other ways to drop data include: If you're using Prometheus remote write, see Drop Prometheus remote write data. If you're reporting logs, you can drop log data via the UI. Requirements The ability to create and edit drop filter rules depends on which user model you're on: New Relic One user model: you must be assigned a role with \"NRQL drop rules\" capabilities. Original user model: you must have an Admin role. Currently the following data types can be targeted for data dropping: APM-reported events Browser-reported events Mobile-reported events Synthetics-reported events Custom events (like those generated by the APM agent APIs or the Event API) Log data (you can also use the UI to drop data) Distributed tracing spans Default infrastructure monitoring events and infrastructure integrations events, with this exception: Downsampled SystemSample, ProcessSample, NetworkSample and StorageSample with time windows longer than 59 minutes can't be dropped. This data doesn't count towards your data ingest. Dimensional metrics, with these caveats: Billing impacts: for New Relic One pricing, dropped data is not billable. For original pricing, dropped data is billable. For metrics generated by the events-to-metrics service: drop rules won't work but these metrics can be stopped or attributes pruned by disabling or re-configuring the events-to-metric rule. Support for additional types are planned for the future. Create drop data rule Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, please review caution information below. To drop data, create a NerdGraph-format drop rule that includes: A NRQL string that specifies what data types to drop An action type specifying how to apply the NRQL string You can form and make the call in the NerdGraph explorer. There are two ways to drop data: Drop entire data types or a data subset (with optional filter). This uses the DROP_DATA action type and uses NRQL of the form: SELECT * FROM DATA_TYPE_1, DATA_TYPE_2 (WHERE OPTIONAL_FILTER) Copy For this type of drop rule, you cannot use anything other than * in the SELECT clause. Drop attributes from data types (with optional filter). This uses the DROP_ATTRIBUTES action type and uses NRQL of the form: SELECT dropAttr1, dropAttr2 FROM DATA_TYPE (WHERE OPTIONAL_FILTER) Copy For this type of drop rule, you must pass in a non-empty list of raw attributes names. NRQL restrictions Not all NRQL clauses make sense for generating drop rules. You can provide a WHERE clause to select data with specific attributes. Other features such as TIMESERIES, COMPARE WITH, FACET, and other clauses cannot be used. The two action types have these restrictions: DROP_DATA can use only SELECT *. DROP_ATTRIBUTES requires use of SELECT with \"raw\" attributes (attributes with no aggregator function applied). This also means you cannot use SELECT *. Additionally, there are some attributes that are integral to their data type and cannot be dropped (such as timestamp on event data). If you include them, registration will fail. Example drop rules Here are some example drop rules: Drop two event types Let's say you notice you have some event types being sent to New Relic that are not important to you. Also, stopping the source from sending those event types quickly is unrealistic, requiring changes to agents and/or API instrumentation. Using a drop rule is an easier way to accomplish the same goal. Here is an example NerdGraph call that drops two event types: Event1 and Event2. mutation { nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [ { action: DROP_DATA nrql: \"SELECT * FROM Event1, Event2\" description: \"Drops all data for Event1 and Event2.\" } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy Drop events meeting certain criteria Let’s say you have a high volume custom event type that arrives from multiple sources. If you don't find all of that data important, you can use a drop rule. Here is an example of a drop rule that filters out events based on specific criteria. mutation { nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [ { action: DROP_DATA nrql: \"SELECT * FROM MyCustomEvent WHERE appName='LoadGeneratingApp' AND environment='development'\" description: \"Drops all data for MyCustomEvent that comes from the LoadGeneratingApp in the dev environment, because there is too much and we don’t look at it.\" } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy Drop sensitive attributes while maintaining the rest of the data Let's say you noticed an event has attributes that contain Personally Identifiable Information (PII). You are working to update your services to stop sending the data, but until then, you need to cease storing further PII in New Relic. Although you could drop all of the data as it comes in the door with a DROP_DATA rule, the rest of the data still provides value. Therefore, you can register a drop rule to remove only the offending PII from your data: mutation { nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [ { action: DROP_ATTRIBUTES nrql: \"SELECT userEmail, userName FROM MyCustomEvent\" description: \"Removes the user name and email fields from MyCustomEvent\" } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy Verify your drop rule works After you create a drop rule, verify that it is working as expected. The rule should take effect quickly after a successful registration, so try running a TIMESERIES version of the query you registered to see that the data drops off. Drop rule type NRQL DROP_DATA Drop rule NRQL: SELECT * FROM MyEvent WHERE foo = bar Copy Validation NRQL: SELECT count(*) FROM MyEvent WHERE foo = bar TIMESERIES Copy This should drop to 0. To verify that it did not affect any thing else, invert the WHERE clause. DROP_ATTRIBUTES Drop rule NRQL: SELECT dropAttr1, dropAttr2 FROM MyEvent WHERE foo = bar Copy Validation NRQL: SELECT count(dropAttr1), count(dropAttr2) FROM MyEvent WHERE foo = bar TIMESERIES Copy Both lines should drop to 0. To verify that it did not affect events that contained these attributes and still should, invert the WHERE clause. View rules Here is an example NerdGraph call that returns the drop rules set on an account: { actor { account(id: YOUR_ACCOUNT_ID) { nrqlDropRules { list { rules { id nrql accountId action createdBy createdAt description } error { reason description } } } } } } Copy Delete drop rules Here is an example NerdGraph call deleting two specific drop rules: mutation { nrqlDropRulesDelete(accountId: YOUR_ACCOUNT_ID, ruleIds: [\"48\", \"98\"]) { successes { id nrql accountId action description } failures { error { reason description } submitted { ruleId accountId } } } } Copy Audit drop rule history To see who created and deleted drop rules, query your account audit logs. The list endpoint also includes the user ID of the person who created the rule. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic does not review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Rules you create, including all information in those rules, can be viewed and edited by any user with the relevant role-based access control permissions. Only new data will be dropped. Existing data cannot be edited or deleted. Drop attributes on dimensional metric rollups Beta Feature This feature is currently in beta. Sign up here to request access! Dimensional metrics aggregate metrics into rollups for long term storage and as a way to optimize longer term queries. Metric cardinality limits are applied to this data. You can use this feature to decide which attributes you don't need for long term storage and query, but would like to maintain for real time queries. For example, adding containerId as an attribute can be useful for live troubleshooting or recent analysis, but may not be needed when querying over longer periods of time for larger trends. Due to how unique something like containerId can be, it can quickly drive you towards your metric cardinality limits which when hit stops the synthesis of rollups for the remainder of that UTC day. This feature also allows you to keep the high cardinality attributes on the raw data and drop it from rollups which gives you more control over how quickly you approach your cardinaliity limits. Usage Drop attributes from dimensional metrics rollups (with optional filter). This uses DROP_ATTRIBUTES_FROM_METRIC_AGGREGATES action type and uses NRQL of the form: SELECT dropAttr1, dropAttr2 FROM Metric (WHERE OPTIONAL_FILTER) Copy Here is an example NerdGraph request: mutation { nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [ { action: DROP_ATTRIBUTES_FROM_METRIC_AGGREGATES nrql: \"SELECT containerId FROM Metric WHERE metricName = 'some.metric'\" description: \"Removes the containerId from long term querys.\" } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy To verify it's working, wait 3 to 5 minutes for the rule to be picked up and for aggregate data to be generated. Then assuming the example NRQL above is your drop rule, run the following queries: SELECT count(containerId) FROM Metric WHERE metricName = 'some.metric' TIMESERIES SINCE 2 hours ago SELECT count(containerId) FROM Metric WHERE metricName = 'some.metric' TIMESERIES SINCE 2 hours ago RAW Copy The first query should drop to 0 while the second query should continue to hold steady. For more information on how to see the impact this will have on your cardiinality, check out Understand and query high cardinality metrics. Restrictions All restrictions that apply to DROP_ATTRIBUTES apply to DROP_ATTRIBUTES_FROM_METRIC_AGGREGATES with the additional restriction that you can only target the Metric data type. They also do not work on Metric queries targeting data created by an events to metrics rule or on Metric queries targeting timeslice data. Learn more Recommendations for learning more: NerdGraph basics and terminology NRQL basics Browse the Explorers Hub for community discussions about NRQL drop rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.41756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Verify</em> <em>your</em> drop rule works",
        "body": " MyCustomEvent&quot; } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy <em>Verify</em> <em>your</em> drop rule works <em>After</em> you create a drop rule, <em>verify</em> that it is working as expected. The rule should take effect quickly <em>after</em> a successful registration, so try running a TIMESERIES"
      },
      "id": "617446f828ccbcdc29c6ae13"
    },
    {
      "sections": [
        "MySQL monitoring integration",
        "Compatibility and requirements",
        "MySQL versions",
        "Important",
        "System requirements",
        "Enabling your MySQL Server",
        "Configure the integration",
        "Install and activate the integration",
        "Linux installation",
        "Other environments",
        "Windows installation",
        "Amazon ECS installation",
        "Kubernetes installation",
        "mysql-config.yml sample files",
        "Basic configuration",
        "Basic configuration with different metric/inventory intervals",
        "Metrics-only with TLS connection",
        "Metrics-only connecting over socket",
        "Metrics-only with all extended metrics",
        "Multi-instance monitoring",
        "Find and use data"
      ],
      "title": "MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "f4f0e6576ef61f8a8169e4c47b330fa49013f98f",
      "image": "https://docs.newrelic.com/static/6a347940f064146525be36b805414901/01e7c/kubernetes-k8.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration/",
      "published_at": "2021-12-30T21:51:11Z",
      "updated_at": "2021-12-05T05:59:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our MySQL integration collects and sends inventory and metrics from your MySQL database to our platform, where you can see the health of your database server and analyze metric data so that you can easily find the source of any problems. To install the MySQL monitoring integration, you must run through the following steps: Enabling your MySQL Server. Configure the integration. Install and activate the integration. Find and use data. Optionally, see the advanced configuration settings. Compatibility and requirements MySQL versions Our integration is compatible with MySQL version 5.6 or higher. Important For MySQL v8.0 and higher we do not support the following metrics: cluster.slaveRunning, db.qCacheFreeMemoryBytes, db.qCacheHitRatio, and db.qCacheNotCachedPerSecond. System requirements A New Relic account. Don't have one? Sign up for free! No credit card required. If MySQL is not running on Kubernetes or Amazon ECS, you can install the infrastructure agent on a Linux or Windows OS host or on a host capable of remotely accessing where MySQL is installed. Otherwise: If running on Kubernetes, see these requirements. If running on Amazon ECS, see these requirements. Enabling your MySQL Server To capture data from the MySQL integration, you must first create a MySQL user with replication and select permissions to allow the integration to fetch metrics. From the command line, create a user newrelic@localhost with a specific password by running: bash Copy $ sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY $YOUR_PASSWORD WITH MAX_USER_CONNECTIONS 5;\" Grant replication privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Grant privileges to newrelic@localhost, with a maximum of 5 connections, by running: bash Copy $ sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Configure the integration There are several ways to configure the integration, depending on how it was installed: If enabled via Kubernetes, see Monitor services running on Kubernetes. If enabled via Amazon ECS, see Monitor services running on ECS. If installed on-host: edit the config in the integration's YAML config file, mysql-config.yml. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations like interval, timeout, inventory_source. To read all about these common settings refer to our Configuration Format document. Important If you are still using our Legacy configuration and definition files, refer to this document for help. Install and activate the integration To install the MySQL integration, follow the instructions for your environment: Linux installation Follow the instructions for installing an integration, and use nri-mysql as filename. Change the directory to the integrations configuration folder by running: bash Copy $ cd /etc/newrelic-infra/integrations.d Copy the sample configuration file by running: bash Copy $ sudo cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml configuration file with your favorite editor. Check out some great configuration file examples.. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Other environments Windows installation Download the .MSI installer image for New Relic's MySQL integration. Install New Relic's MySQL integration by openning command prompt and running: bash Copy $ msiexec.exe /qn /i $PATH_TO\\nri-mysql-amd64.msi In the Integrations directory, C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d\\, create a copy of the sample configuration file by running: bash Copy $ cp mysql-config.yml.sample mysql-config.yml Edit the mysql-config.yml file by using one of the mysql-config.yml sample files. Restart the infrastructure agent. See how to restart the infrastructure agent in different Linux environments. Amazon ECS installation See Monitor service running on ECS. Kubernetes installation See Monitor service running on Kubernetes. Additional notes: Advanced: Integrations are also available in tarball format to allow for install outside of a package manager. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. mysql-config.yml sample files Basic configuration This is the basic configuration used to collect metrics and inventory from your localhost: integrations: - name: nri-mysql env: HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production inventory_source: config/mysql Copy Basic configuration with different metric/inventory intervals This configuration collects metrics every 30 seconds and inventory every 60 seconds: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: INVENTORY: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password REMOTE_MONITORING: true interval: 60s labels: environment: production inventory_source: config/mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_VERIFY : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password USE_TLS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only connecting over socket Use to connect to MySQL using a socket file. This is an alternative to a TCP Hostname/Port connection: integrations: - name: nri-mysql env: METRICS: true USERNAME: mysql_user PASSWORD: mysql_password SOCKET: /var/run/mysql/mysql.sock REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Metrics-only with all extended metrics Use this to collect your metrics including extended, slave, innodb and my-isam metrics: integrations: - name: nri-mysql env: METRICS: true HOSTNAME: localhost PORT: 3306 USERNAME: mysql_user PASSWORD: mysql_password EXTENDED_METRICS: true EXTENDED_INNODB_METRICS: true EXTENDED_MY_ISAM_METRICS: true REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Multi-instance monitoring Use this if you need to collect metrics from two different MySQL servers using the the same integration. integrations: - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host1 PORT: 3306 USERNAME: mysql1_user PASSWORD: mysql1_password REMOTE_MONITORING: true interval: 30s labels: environment: production - name: nri-mysql env: METRICS: true HOSTNAME: mysql_host2 PORT: 3306 USERNAME: mysql2_user PASSWORD: mysql2_password REMOTE_MONITORING: true interval: 30s labels: environment: production Copy Find and use data After you've configured and installed the integration, you can start monitoring: Data from this service, which is reported to an integration dashboard. Metrics are attached to the MysqlSample event type. You can query this data for troubleshooting purposes or to create custom charts and dashboards. For more on how to find and use your data, see: MySQL's advanced configuration Understand integration data",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.11284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "MySQL <em>monitoring</em> integration",
        "sections": "MySQL <em>monitoring</em> integration",
        "body": " <em>REMOTE_MONITORING</em>: true interval: 60s labels: environment: production inventory_source: config&#x2F;mysql Copy Metrics-only with TLS connection Use to connect to MySQL with TLS. You can add TLS_INSECURE_SKIP_<em>VERIFY</em> : true to disable the server name verification: integrations: - name: nri-mysql env: METRICS: true"
      },
      "id": "61ac554e28ccbc3ccdc24744"
    }
  ],
  "/docs/infrastructure/infrastructure-integrations/cloud-integrations/cloud-integrations-account-status-dashboard": [
    {
      "sections": [
        "Configure polling frequency and data collection for cloud integrations",
        "Overview of settings",
        "Caution",
        "Change polling frequency",
        "Specify data to be fetched",
        "Data collection",
        "Filters",
        "Potential impact on alerts and charts"
      ],
      "title": "Configure polling frequency and data collection for cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "a04234cf9a4b0d18c1ae9e874eee467d0a29278a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/",
      "published_at": "2021-12-30T10:38:16Z",
      "updated_at": "2021-10-24T01:29:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our cloud integrations get data from cloud provider APIs. In New Relic, you can change some of the data collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Overview of settings New Relic cloud integrations get data from cloud providers' APIs. Data is generally collected from monitoring APIs such as AWS CloudWatch, Azure Monitor, and GCP Stackdriver, and inventory metadata is collected from the specific services' APIs. You can use the account status dashboard to see how your cloud integrations are handling data from a cloud service provider. If you want to report more or less data from your cloud integrations, or if you need to control the use of the cloud providers' APIs to prevent reaching rate and throttling limits in your cloud account, you can change the configuration settings to modify the amount of data they report. The two main controls are: Change polling frequency Change what data is reported Examples of business reasons for wanting to change your polling frequency include: Billing: If you need to manage your AWS CloudWatch bill, you may want to decrease the polling frequency. Before you do this, make sure that any alert conditions set for your cloud integrations are not affected by this reduction. New services: If you are deploying a new service or configuration and you want to collect data more often, you may want to increase the polling frequency temporarily. Caution Changing the configuration settings for your integrations may impact alert conditions and chart trends. Change polling frequency The polling frequency configuration determines how often New Relic reports data from your cloud provider for each service. By default, the polling frequency is set to the maximum frequency that is available for each service. To change the polling frequency for a cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Use the dropdowns next to Data polling interval every to select how frequently you want New Relic to capture your cloud integration data. Specify data to be fetched You can specify which information you want captured for your cloud integration by enabling the collection of additional data and by applying multiple filters to each integration. To change this settings for your cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Under Data collections and filters, turn the toggles you want On. For filters, select or enter the values that you want included in your reported data. Data collection For some cloud integrations, an additional number of calls to the cloud provider APIs are needed in order to collect data. For example, to fetch tags for AWS Elastic Map Reduce clusters, an additional call to the service API is required. To better control the amount of API calls that are sent to your cloud account for these integrations, you can specify when you need these types of data to be collected. Different data collection toggles are available, depending on the integration. Toggle Description Collect tags Some integrations require additional API calls to the cloud provider to report tags. Tag collection is enabled by default. Switch this to Off if you don't want the integration to collect your cloud resource tags and thus reduce the volume of API calls. Collect extended inventory Some integrations can collect extended inventory metadata about your cloud resources by making additional API calls to the cloud provider. The metadata included within the extended inventory for each cloud integration is described in the integration documentation. Extended inventory collection is disabled by default. Switch this to On if you want to monitor extended inventory. This will increase the volume of API calls. Collect shards data Available for AWS Kinesis Streams integration. By default, we don't report shard metrics. Switch this to On if you want to monitor shard metrics in addition to data stream metrics. Collect Lambda@Edge data Available for AWS CloudFront integration. By default, we don't report Lambda@Edge data. Switch this to On if you're using Lambda@Edge in AWS CloudFront and want to get Lambda execution location metadata. Collect node data Available for AWS Elasticsearch integration. By default, we don't report Elasticsearch node metrics. Switch this to On if you want to monitor node metrics in addition to cluster metrics. Collect NAT Gateway data and Collect VPN data Available for AWS VPC integration. By default, we don't report NAT Gateway nor VPN metrics. Switch these to On if you want to monitor NAT Gateway and VPN metrics and inventory, in addition to other VPC related entities inventory. Collect IP addresses Available for AWS EC2 integration. By default, we collect EC2 instance metadata that includes public and private IP addresses, and network interface details. Switch this to Off if you don't want New Relic to store and display these IP data. Filters When a filter is On, you specify the data that you want to be collected; for example, if the Limit to AWS region is On, the regions that you select will be the ones that data will be collected for. There are different filters available, depending on the integration: Filter Description Region Select the regions that include the resources that you want to monitor. Queue prefixes Available for AWS SQS integration. Enter each name or prefix for the queues that you want to monitor. Filter values are case-sensitive. Load balancer prefixes Available for AWS ALB integration. Enter each name or prefix for the application load balancers that you want to monitor. Filter values are case-sensitive. Stage name prefixes Available for AWS API Gateway integration. Enter each name or prefix for the stages that you want to monitor. Filter values are case-sensitive. Tag key Enter one tag key that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag value filter. Tag value Enter one tag value that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag key. Resource group Select the resource groups that are associated with the resources that you want to monitor. Potential impact on alerts and charts If you change an integration's configuration, it can impact alert conditions and charts. Here are some things to consider: If you change this setting... It may have this impact... Any configuration setting When you change the configuration settings, the data that New Relic displays in infrastructure charts, on the inventory page, and in the events feed changes as well. Any filters When you create alert conditions after you set filters, make sure that your alerts are not triggered by resources that you filtered out. Filter for regions If you filter for specific regions, it may lower the amount of data reported to New Relic, which could trigger an alert. If you create an alert condition for a specific region and then filter that region out, the region would no longer report data and would never trigger the alert. Polling frequency When you create an alert, make sure that you define the threshold for a time period that is longer than the polling frequency. Tags and extended inventory If you turn on tags and/or extended inventory, New Relic makes more API calls to the cloud provider, which could increase your cloud provider API usage bill.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.02733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure polling frequency and data collection for <em>cloud</em> <em>integrations</em>",
        "sections": "Configure polling frequency and data collection for <em>cloud</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "Our <em>cloud</em> <em>integrations</em> get data from <em>cloud</em> provider APIs. In New Relic, you can change some of the data collection-related settings for your <em>cloud</em> <em>integrations</em>. Read on to see what changes you can make and the reasons for making them. Overview of settings New Relic <em>cloud</em> <em>integrations</em> get data from"
      },
      "id": "617d6fd428ccbc2d9c7fec6e"
    },
    {
      "sections": [
        "Metric data gaps with cloud integrations",
        "Problem",
        "Solution",
        "Amazon (AWS)",
        "Microsoft Azure",
        "Google Cloud Platform (GCP)",
        "Tip",
        "Cause"
      ],
      "title": "Metric data gaps with cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "ad837e6aacd8bb32f58e2b7529e952f90d1be342",
      "image": "https://docs.newrelic.com/static/dfa79b9e3086b81f216d306ba0afe557/c1b63/screen-metric-gap.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/cloud-integrations/metric-data-gaps-cloud-integrations/",
      "published_at": "2021-12-30T10:38:57Z",
      "updated_at": "2021-10-23T16:43:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS, Azure, or GCP integration and are monitoring your metrics. However, you notice gaps in your metric data charts. This screenshot shows a metric data chart with gaps. Solution Here’s a list of metrics which might show gaps in your metric data. If possible, avoid setting up alerts for these metrics because we know they can generate false positives. Amazon (AWS) Integration Provider Event Type Metric SNS SnsTopic QueueSample provider.subscriptionsConfirmed SnsTopic QueueSample provider.subscriptionsPending SnsTopic QueueSample provider.subscriptionsDeleted EFS EfsFileSystem BlockDeviceSample provider.lastKnownSizeInBytes ECS EcsCluster ComputeSample provider.registeredContainerInstancesCount EcsCluster ComputeSample provider.activeServicesCount EcsCluster ComputeSample provider.pendingTasksCount EcsCluster ComputeSample provider.runningTasksCount EcsService ComputeSample provider.pendingCount EcsService ComputeSample provider.runningCount EcsService ComputeSample provider.desiredCount DynamoDB DynamoDbTable DatastoreSample provider.itemCount DynamoDbTable DatastoreSample provider.tableSizeBytes AutoScaling AutoScalingInstance AutoScalingInstanceSample healthStatus Billing BillingBudget FinanceSample provider.actualAmount Billingbudget FinanceSample provider.forecastedAmount BillingBudget FinanceSample provider.limitAmount Microsoft Azure Integration Provider Event Type Metric SQL AzureSqlDatabase AzureSqlDatabaseSample databaseSizeCurrentBytes AzureSqlDatabase AzureSqlDatabaseSample databaseSizeLimitBytes AzureSqlServer AzureSqlServerSample dtuCurrent AzureSqlServer AzureSqlServerSample dtuLimit Google Cloud Platform (GCP) Tip We're currently reviewing the GCP metrics that can cause data gaps. Tip This list isn't complete. We're currently reviewing the full list of metrics that can cause data gaps. Cause Some metrics aren’t present in the usual cloud provider APIs (CloudWatch, Stackdriver, Azure Monitor) and are fetched from the service APIs instead. Each cloud service provider has a unique service API that processes data and interacts with the service. For example, if a metric isn’t present in AWS CloudWatch, New Relic will fetch the metric from the AWS ECS service API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.95016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data gaps with <em>cloud</em> <em>integrations</em>",
        "sections": "Metric data gaps with <em>cloud</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": " AzureSqlDatabase AzureSqlDatabaseSample databaseSizeLimitBytes AzureSqlServer AzureSqlServerSample dtuCurrent AzureSqlServer AzureSqlServerSample dtuLimit Google <em>Cloud</em> Platform (GCP) Tip We&#x27;re currently reviewing the GCP metrics that can cause data gaps. Tip This list isn&#x27;t complete. We&#x27;re currently"
      },
      "id": "617dad1be7b9d26264c039e6"
    },
    {
      "sections": [
        "Introduction to infrastructure integrations",
        "Cloud integrations",
        "On-host integrations",
        "Features",
        "Types of integration data"
      ],
      "title": "Introduction to infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "f54188c082f76568db1aea02a2ca0134d1b9b502",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations/",
      "published_at": "2021-12-30T10:39:03Z",
      "updated_at": "2021-11-24T15:43:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers many integrations and quickstarts for reporting your data to our platform. One category of integrations is our infrastructure integrations. We have two main categories of infrastructure integrations: cloud integrations and on-host integrations. These are described in more detail below. Cloud integrations Our cloud integrations collect data from cloud platform services and accounts. There's no installation process for cloud integrations and they do not require the use of our infrastructure agent: you simply connect your New Relic account to your cloud provider account. Integrations Description Amazon Web Services (AWS) cloud integrations Connect your Amazon Web Services (AWS) account to monitor and report data to New Relic. See our AWS integrations. Microsoft Azure cloud integrations Connect your Microsoft Azure account to monitor and report data to New Relic. See our Azure integrations. Google Cloud Platform (GCP) cloud integrations Connect your Google Cloud Platform (GCP) account to monitor and report data to New Relic. See our GCP integrations. On-host integrations Our on-host integrations are basically our infrastructure service integrations that aren't cloud platform integrations. With the exception of Kubernetes, which can be enabled in a few ways, our on-host integrations work in concert with our infrastructure agent to report data. Integrations Description Kubernetes integration Connect your account to gain visibility of your Kubernetes environment, explore your clusters, and manage alerts. On-host integrations Monitor and report data from many popular services, including NGINX, MySQL, Redis, Apache, RabbitMQ, and many more. Learn how to enable them. Build your own To create your own lightweight infrastructure integration, use our Flex integration. Features After an infrastructure integration is enabled, you can: Filter and analyze your metrics and configuration data in our infrastructure monitoring UI. Query your data and create custom charts and dashboards. Create alert conditions to monitor problems with your services' performance. For cloud integrations, configure data collection settings. Types of integration data For details about the types of data reported, see Infrastructure integration data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.36176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "sections": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "New Relic offers many <em>integrations</em> and quickstarts for reporting your data to our platform. One category of <em>integrations</em> is our <em>infrastructure</em> <em>integrations</em>. We have two main categories of <em>infrastructure</em> <em>integrations</em>: <em>cloud</em> <em>integrations</em> and on-host <em>integrations</em>. These are described in more detail"
      },
      "id": "617d6fd528ccbcffc87fe889"
    }
  ],
  "/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations": [
    {
      "sections": [
        "Cloud integrations: Account status dashboard",
        "Why it matters",
        "Understand dashboard data",
        "Find account status dashboard"
      ],
      "title": "Cloud integrations: Account status dashboard",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "ed264d3c1128779e5e35fb82b6a6a03be433ad50",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/cloud-integrations/cloud-integrations-account-status-dashboard/",
      "published_at": "2021-12-30T10:38:15Z",
      "updated_at": "2021-10-24T01:26:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Each cloud account you link to New Relic infrastructure monitoring (for example, AWS or Azure) has an account status dashboard that shows how our platform is handling data from that cloud service provider. Why it matters Reasons to monitor this dashboard include: Understand API call usage. We use cloud APIs to collect metrics and inventory data. The dashboards show counts and frequencies for those API calls. You may want to monitor these for two reasons: API calls can cost money, and your API usage may be throttled at certain usage levels. To decrease usage, you can configure integration settings to reduce the number of components you monitor or how frequently they're monitored. Troubleshoot missing data or other data issues. The dashboard displays information that affects how integrations report data, including: Errors that affect New Relic collecting data, like permission errors or quota exhaustion errors. Changes to integration configuration, like polling interval changes, or tag-collection being disabled or enabled. Understand dashboard data The specific data displayed on the account status dashboard will differ by cloud service provider. Common charts include: Data updates: Shows updates to metric data or inventory data (updates shown as a 1 value). Account changes: Actions affecting how the integration works. For example: renaming or unlinking a cloud account, changing polling intervals, and other configuration options. Data freshness: Timestamp of the last data point collected for each integration. Fetching errors: These indicate issues with collecting data. (This may be a problem on the cloud-provider side.) Options for better understanding chart data include: Mouse over a chart’s icon to see a chart description (if available). View the chart's underlying NRQL query. Find account status dashboard To find the account status dashboard for a cloud service provider: From one.newrelic.com > Infrastructure, and select a cloud service provider (for example, AWS). Select Account status dashboard for the cloud account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.02693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Cloud</em> <em>integrations</em>: Account status dashboard",
        "sections": "<em>Cloud</em> <em>integrations</em>: Account status dashboard",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "Each <em>cloud</em> account you link to New Relic <em>infrastructure</em> monitoring (for example, AWS or Azure) has an account status dashboard that shows how our platform is handling data from that <em>cloud</em> service provider. Why it matters Reasons to monitor this dashboard include: Understand API call usage. We use"
      },
      "id": "617dad1a28ccbcf5b87ff6c2"
    },
    {
      "sections": [
        "Metric data gaps with cloud integrations",
        "Problem",
        "Solution",
        "Amazon (AWS)",
        "Microsoft Azure",
        "Google Cloud Platform (GCP)",
        "Tip",
        "Cause"
      ],
      "title": "Metric data gaps with cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "ad837e6aacd8bb32f58e2b7529e952f90d1be342",
      "image": "https://docs.newrelic.com/static/dfa79b9e3086b81f216d306ba0afe557/c1b63/screen-metric-gap.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/cloud-integrations/metric-data-gaps-cloud-integrations/",
      "published_at": "2021-12-30T10:38:57Z",
      "updated_at": "2021-10-23T16:43:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS, Azure, or GCP integration and are monitoring your metrics. However, you notice gaps in your metric data charts. This screenshot shows a metric data chart with gaps. Solution Here’s a list of metrics which might show gaps in your metric data. If possible, avoid setting up alerts for these metrics because we know they can generate false positives. Amazon (AWS) Integration Provider Event Type Metric SNS SnsTopic QueueSample provider.subscriptionsConfirmed SnsTopic QueueSample provider.subscriptionsPending SnsTopic QueueSample provider.subscriptionsDeleted EFS EfsFileSystem BlockDeviceSample provider.lastKnownSizeInBytes ECS EcsCluster ComputeSample provider.registeredContainerInstancesCount EcsCluster ComputeSample provider.activeServicesCount EcsCluster ComputeSample provider.pendingTasksCount EcsCluster ComputeSample provider.runningTasksCount EcsService ComputeSample provider.pendingCount EcsService ComputeSample provider.runningCount EcsService ComputeSample provider.desiredCount DynamoDB DynamoDbTable DatastoreSample provider.itemCount DynamoDbTable DatastoreSample provider.tableSizeBytes AutoScaling AutoScalingInstance AutoScalingInstanceSample healthStatus Billing BillingBudget FinanceSample provider.actualAmount Billingbudget FinanceSample provider.forecastedAmount BillingBudget FinanceSample provider.limitAmount Microsoft Azure Integration Provider Event Type Metric SQL AzureSqlDatabase AzureSqlDatabaseSample databaseSizeCurrentBytes AzureSqlDatabase AzureSqlDatabaseSample databaseSizeLimitBytes AzureSqlServer AzureSqlServerSample dtuCurrent AzureSqlServer AzureSqlServerSample dtuLimit Google Cloud Platform (GCP) Tip We're currently reviewing the GCP metrics that can cause data gaps. Tip This list isn't complete. We're currently reviewing the full list of metrics that can cause data gaps. Cause Some metrics aren’t present in the usual cloud provider APIs (CloudWatch, Stackdriver, Azure Monitor) and are fetched from the service APIs instead. Each cloud service provider has a unique service API that processes data and interacts with the service. For example, if a metric isn’t present in AWS CloudWatch, New Relic will fetch the metric from the AWS ECS service API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.95016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data gaps with <em>cloud</em> <em>integrations</em>",
        "sections": "Metric data gaps with <em>cloud</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": " AzureSqlDatabase AzureSqlDatabaseSample databaseSizeLimitBytes AzureSqlServer AzureSqlServerSample dtuCurrent AzureSqlServer AzureSqlServerSample dtuLimit Google <em>Cloud</em> Platform (GCP) Tip We&#x27;re currently reviewing the GCP metrics that can cause data gaps. Tip This list isn&#x27;t complete. We&#x27;re currently"
      },
      "id": "617dad1be7b9d26264c039e6"
    },
    {
      "sections": [
        "Introduction to infrastructure integrations",
        "Cloud integrations",
        "On-host integrations",
        "Features",
        "Types of integration data"
      ],
      "title": "Introduction to infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "f54188c082f76568db1aea02a2ca0134d1b9b502",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations/",
      "published_at": "2021-12-30T10:39:03Z",
      "updated_at": "2021-11-24T15:43:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers many integrations and quickstarts for reporting your data to our platform. One category of integrations is our infrastructure integrations. We have two main categories of infrastructure integrations: cloud integrations and on-host integrations. These are described in more detail below. Cloud integrations Our cloud integrations collect data from cloud platform services and accounts. There's no installation process for cloud integrations and they do not require the use of our infrastructure agent: you simply connect your New Relic account to your cloud provider account. Integrations Description Amazon Web Services (AWS) cloud integrations Connect your Amazon Web Services (AWS) account to monitor and report data to New Relic. See our AWS integrations. Microsoft Azure cloud integrations Connect your Microsoft Azure account to monitor and report data to New Relic. See our Azure integrations. Google Cloud Platform (GCP) cloud integrations Connect your Google Cloud Platform (GCP) account to monitor and report data to New Relic. See our GCP integrations. On-host integrations Our on-host integrations are basically our infrastructure service integrations that aren't cloud platform integrations. With the exception of Kubernetes, which can be enabled in a few ways, our on-host integrations work in concert with our infrastructure agent to report data. Integrations Description Kubernetes integration Connect your account to gain visibility of your Kubernetes environment, explore your clusters, and manage alerts. On-host integrations Monitor and report data from many popular services, including NGINX, MySQL, Redis, Apache, RabbitMQ, and many more. Learn how to enable them. Build your own To create your own lightweight infrastructure integration, use our Flex integration. Features After an infrastructure integration is enabled, you can: Filter and analyze your metrics and configuration data in our infrastructure monitoring UI. Query your data and create custom charts and dashboards. Create alert conditions to monitor problems with your services' performance. For cloud integrations, configure data collection settings. Types of integration data For details about the types of data reported, see Infrastructure integration data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.36176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "sections": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "New Relic offers many <em>integrations</em> and quickstarts for reporting your data to our platform. One category of <em>integrations</em> is our <em>infrastructure</em> <em>integrations</em>. We have two main categories of <em>infrastructure</em> <em>integrations</em>: <em>cloud</em> <em>integrations</em> and on-host <em>integrations</em>. These are described in more detail"
      },
      "id": "617d6fd528ccbcffc87fe889"
    }
  ],
  "/docs/infrastructure/infrastructure-integrations/cloud-integrations/metric-data-gaps-cloud-integrations": [
    {
      "sections": [
        "Configure polling frequency and data collection for cloud integrations",
        "Overview of settings",
        "Caution",
        "Change polling frequency",
        "Specify data to be fetched",
        "Data collection",
        "Filters",
        "Potential impact on alerts and charts"
      ],
      "title": "Configure polling frequency and data collection for cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "a04234cf9a4b0d18c1ae9e874eee467d0a29278a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/",
      "published_at": "2021-12-30T10:38:16Z",
      "updated_at": "2021-10-24T01:29:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our cloud integrations get data from cloud provider APIs. In New Relic, you can change some of the data collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Overview of settings New Relic cloud integrations get data from cloud providers' APIs. Data is generally collected from monitoring APIs such as AWS CloudWatch, Azure Monitor, and GCP Stackdriver, and inventory metadata is collected from the specific services' APIs. You can use the account status dashboard to see how your cloud integrations are handling data from a cloud service provider. If you want to report more or less data from your cloud integrations, or if you need to control the use of the cloud providers' APIs to prevent reaching rate and throttling limits in your cloud account, you can change the configuration settings to modify the amount of data they report. The two main controls are: Change polling frequency Change what data is reported Examples of business reasons for wanting to change your polling frequency include: Billing: If you need to manage your AWS CloudWatch bill, you may want to decrease the polling frequency. Before you do this, make sure that any alert conditions set for your cloud integrations are not affected by this reduction. New services: If you are deploying a new service or configuration and you want to collect data more often, you may want to increase the polling frequency temporarily. Caution Changing the configuration settings for your integrations may impact alert conditions and chart trends. Change polling frequency The polling frequency configuration determines how often New Relic reports data from your cloud provider for each service. By default, the polling frequency is set to the maximum frequency that is available for each service. To change the polling frequency for a cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Use the dropdowns next to Data polling interval every to select how frequently you want New Relic to capture your cloud integration data. Specify data to be fetched You can specify which information you want captured for your cloud integration by enabling the collection of additional data and by applying multiple filters to each integration. To change this settings for your cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Under Data collections and filters, turn the toggles you want On. For filters, select or enter the values that you want included in your reported data. Data collection For some cloud integrations, an additional number of calls to the cloud provider APIs are needed in order to collect data. For example, to fetch tags for AWS Elastic Map Reduce clusters, an additional call to the service API is required. To better control the amount of API calls that are sent to your cloud account for these integrations, you can specify when you need these types of data to be collected. Different data collection toggles are available, depending on the integration. Toggle Description Collect tags Some integrations require additional API calls to the cloud provider to report tags. Tag collection is enabled by default. Switch this to Off if you don't want the integration to collect your cloud resource tags and thus reduce the volume of API calls. Collect extended inventory Some integrations can collect extended inventory metadata about your cloud resources by making additional API calls to the cloud provider. The metadata included within the extended inventory for each cloud integration is described in the integration documentation. Extended inventory collection is disabled by default. Switch this to On if you want to monitor extended inventory. This will increase the volume of API calls. Collect shards data Available for AWS Kinesis Streams integration. By default, we don't report shard metrics. Switch this to On if you want to monitor shard metrics in addition to data stream metrics. Collect Lambda@Edge data Available for AWS CloudFront integration. By default, we don't report Lambda@Edge data. Switch this to On if you're using Lambda@Edge in AWS CloudFront and want to get Lambda execution location metadata. Collect node data Available for AWS Elasticsearch integration. By default, we don't report Elasticsearch node metrics. Switch this to On if you want to monitor node metrics in addition to cluster metrics. Collect NAT Gateway data and Collect VPN data Available for AWS VPC integration. By default, we don't report NAT Gateway nor VPN metrics. Switch these to On if you want to monitor NAT Gateway and VPN metrics and inventory, in addition to other VPC related entities inventory. Collect IP addresses Available for AWS EC2 integration. By default, we collect EC2 instance metadata that includes public and private IP addresses, and network interface details. Switch this to Off if you don't want New Relic to store and display these IP data. Filters When a filter is On, you specify the data that you want to be collected; for example, if the Limit to AWS region is On, the regions that you select will be the ones that data will be collected for. There are different filters available, depending on the integration: Filter Description Region Select the regions that include the resources that you want to monitor. Queue prefixes Available for AWS SQS integration. Enter each name or prefix for the queues that you want to monitor. Filter values are case-sensitive. Load balancer prefixes Available for AWS ALB integration. Enter each name or prefix for the application load balancers that you want to monitor. Filter values are case-sensitive. Stage name prefixes Available for AWS API Gateway integration. Enter each name or prefix for the stages that you want to monitor. Filter values are case-sensitive. Tag key Enter one tag key that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag value filter. Tag value Enter one tag value that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag key. Resource group Select the resource groups that are associated with the resources that you want to monitor. Potential impact on alerts and charts If you change an integration's configuration, it can impact alert conditions and charts. Here are some things to consider: If you change this setting... It may have this impact... Any configuration setting When you change the configuration settings, the data that New Relic displays in infrastructure charts, on the inventory page, and in the events feed changes as well. Any filters When you create alert conditions after you set filters, make sure that your alerts are not triggered by resources that you filtered out. Filter for regions If you filter for specific regions, it may lower the amount of data reported to New Relic, which could trigger an alert. If you create an alert condition for a specific region and then filter that region out, the region would no longer report data and would never trigger the alert. Polling frequency When you create an alert, make sure that you define the threshold for a time period that is longer than the polling frequency. Tags and extended inventory If you turn on tags and/or extended inventory, New Relic makes more API calls to the cloud provider, which could increase your cloud provider API usage bill.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.02733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure polling frequency and data collection for <em>cloud</em> <em>integrations</em>",
        "sections": "Configure polling frequency and data collection for <em>cloud</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "Our <em>cloud</em> <em>integrations</em> get data from <em>cloud</em> provider APIs. In New Relic, you can change some of the data collection-related settings for your <em>cloud</em> <em>integrations</em>. Read on to see what changes you can make and the reasons for making them. Overview of settings New Relic <em>cloud</em> <em>integrations</em> get data from"
      },
      "id": "617d6fd428ccbc2d9c7fec6e"
    },
    {
      "sections": [
        "Cloud integrations: Account status dashboard",
        "Why it matters",
        "Understand dashboard data",
        "Find account status dashboard"
      ],
      "title": "Cloud integrations: Account status dashboard",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "ed264d3c1128779e5e35fb82b6a6a03be433ad50",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/cloud-integrations/cloud-integrations-account-status-dashboard/",
      "published_at": "2021-12-30T10:38:15Z",
      "updated_at": "2021-10-24T01:26:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Each cloud account you link to New Relic infrastructure monitoring (for example, AWS or Azure) has an account status dashboard that shows how our platform is handling data from that cloud service provider. Why it matters Reasons to monitor this dashboard include: Understand API call usage. We use cloud APIs to collect metrics and inventory data. The dashboards show counts and frequencies for those API calls. You may want to monitor these for two reasons: API calls can cost money, and your API usage may be throttled at certain usage levels. To decrease usage, you can configure integration settings to reduce the number of components you monitor or how frequently they're monitored. Troubleshoot missing data or other data issues. The dashboard displays information that affects how integrations report data, including: Errors that affect New Relic collecting data, like permission errors or quota exhaustion errors. Changes to integration configuration, like polling interval changes, or tag-collection being disabled or enabled. Understand dashboard data The specific data displayed on the account status dashboard will differ by cloud service provider. Common charts include: Data updates: Shows updates to metric data or inventory data (updates shown as a 1 value). Account changes: Actions affecting how the integration works. For example: renaming or unlinking a cloud account, changing polling intervals, and other configuration options. Data freshness: Timestamp of the last data point collected for each integration. Fetching errors: These indicate issues with collecting data. (This may be a problem on the cloud-provider side.) Options for better understanding chart data include: Mouse over a chart’s icon to see a chart description (if available). View the chart's underlying NRQL query. Find account status dashboard To find the account status dashboard for a cloud service provider: From one.newrelic.com > Infrastructure, and select a cloud service provider (for example, AWS). Select Account status dashboard for the cloud account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.02693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Cloud</em> <em>integrations</em>: Account status dashboard",
        "sections": "<em>Cloud</em> <em>integrations</em>: Account status dashboard",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "Each <em>cloud</em> account you link to New Relic <em>infrastructure</em> monitoring (for example, AWS or Azure) has an account status dashboard that shows how our platform is handling data from that <em>cloud</em> service provider. Why it matters Reasons to monitor this dashboard include: Understand API call usage. We use"
      },
      "id": "617dad1a28ccbcf5b87ff6c2"
    },
    {
      "sections": [
        "Introduction to infrastructure integrations",
        "Cloud integrations",
        "On-host integrations",
        "Features",
        "Types of integration data"
      ],
      "title": "Introduction to infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "f54188c082f76568db1aea02a2ca0134d1b9b502",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations/",
      "published_at": "2021-12-30T10:39:03Z",
      "updated_at": "2021-11-24T15:43:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers many integrations and quickstarts for reporting your data to our platform. One category of integrations is our infrastructure integrations. We have two main categories of infrastructure integrations: cloud integrations and on-host integrations. These are described in more detail below. Cloud integrations Our cloud integrations collect data from cloud platform services and accounts. There's no installation process for cloud integrations and they do not require the use of our infrastructure agent: you simply connect your New Relic account to your cloud provider account. Integrations Description Amazon Web Services (AWS) cloud integrations Connect your Amazon Web Services (AWS) account to monitor and report data to New Relic. See our AWS integrations. Microsoft Azure cloud integrations Connect your Microsoft Azure account to monitor and report data to New Relic. See our Azure integrations. Google Cloud Platform (GCP) cloud integrations Connect your Google Cloud Platform (GCP) account to monitor and report data to New Relic. See our GCP integrations. On-host integrations Our on-host integrations are basically our infrastructure service integrations that aren't cloud platform integrations. With the exception of Kubernetes, which can be enabled in a few ways, our on-host integrations work in concert with our infrastructure agent to report data. Integrations Description Kubernetes integration Connect your account to gain visibility of your Kubernetes environment, explore your clusters, and manage alerts. On-host integrations Monitor and report data from many popular services, including NGINX, MySQL, Redis, Apache, RabbitMQ, and many more. Learn how to enable them. Build your own To create your own lightweight infrastructure integration, use our Flex integration. Features After an infrastructure integration is enabled, you can: Filter and analyze your metrics and configuration data in our infrastructure monitoring UI. Query your data and create custom charts and dashboards. Create alert conditions to monitor problems with your services' performance. For cloud integrations, configure data collection settings. Types of integration data For details about the types of data reported, see Infrastructure integration data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.36176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "sections": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "New Relic offers many <em>integrations</em> and quickstarts for reporting your data to our platform. One category of <em>integrations</em> is our <em>infrastructure</em> <em>integrations</em>. We have two main categories of <em>infrastructure</em> <em>integrations</em>: <em>cloud</em> <em>integrations</em> and on-host <em>integrations</em>. These are described in more detail"
      },
      "id": "617d6fd528ccbcffc87fe889"
    }
  ],
  "/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations": [
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2021-12-31T01:18:16Z",
      "updated_at": "2021-12-31T01:18:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. As a full platform user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.74257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Understand and use data from infrastructure integrations",
        "Explore your infrastructure integration's data",
        "Types of integration data",
        "Create alert conditions"
      ],
      "title": "Understand and use data from infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "74fbfa8de2ee02bdf8dd4aad22fab7f654e96904",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations/",
      "published_at": "2021-12-30T10:39:38Z",
      "updated_at": "2021-11-24T18:17:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic infrastructure integrations, you can monitor the performance of popular services, including AWS, Azure, Google Cloud Platform, Kubernetes, Redis, MySQL, and more. Here are some tips on how to find, understand, and use data reported from infrastructure integrations. Explore your infrastructure integration's data The best way to understand infrastructure integrations's data and see what you can do with it is to enable an integration and explore the data in the New Relic UI. Some recommendations for exploring: View dashboards: You can find your dashboards in New Relic One. For details, see Integration dashboards. Query data: You can run custom queries and charts of your integration data. For more information, see Query New Relic data. Create alert conditions: See Alert conditions. Learn more about what metrics and inventory data an integration reports: See an integration's documentation: cloud integrations and on-host integrations. Types of integration data New Relic infrastructure integrations are separated into two main categories: Cloud integrations: Integrations for cloud platform services, including AWS, Azure, and GCP. On-host integrations: \"On-host\" refers to core services integrations that you can install directly on a host. Examples: MySQL, NGINX, Kubernetes, Redis. An infrastructure integration can generate four types of data: Metrics: Numeric measurement data. Examples: message counts, error counts, and CPU used percentage. Metric data appears in an integration's charts. For details about what metrics are reported and how to query them, see the documentation for a specific integration. For details about data structure, see Data types. Inventory: Information about the state and configuration of a service or host. Examples of inventory data: configuration settings, the name of the host the service is on, the AWS region, the port being used. Inventory data appears in the Inventory UI page. Inventory data also appears in integration dashboards. Changes to inventory data generates event data. Events: Events represent important activity on a system. Examples of event data: an admin logging in; a package install or uninstall; a service starting; a table being created. Most events represent changes to inventory data. Attributes: Some integrations will generate other non-metric attributes (key-value pairs) that can be queried in New Relic. Create alert conditions To create an alert condition for integration data in infrastructure, Go to one.newrelic.com > Infrastructure, choose an integration, and then select an available alert option. For more information, see Infrastructure and alerts. You can also create alert conditions using NRQL queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.19846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and use data from <em>infrastructure</em> <em>integrations</em>",
        "sections": "Understand and use data from <em>infrastructure</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "With New Relic <em>infrastructure</em> <em>integrations</em>, you can monitor the performance of popular services, including AWS, Azure, Google Cloud Platform, Kubernetes, Redis, MySQL, and more. Here are some tips on how to find, understand, and use data reported from <em>infrastructure</em> <em>integrations</em>. Explore your"
      },
      "id": "617dc61d28ccbcceb080096e"
    },
    {
      "sections": [
        "Use integration data in New Relic dashboards",
        "Get started with integration data",
        "Example NRQL queries",
        "AWS EBS query example",
        "Azure Service Bus query example",
        "Azure Functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Inventory change query example",
        "Tip",
        "Tips for using different data types",
        "Metric data tips",
        "Event data tips",
        "Inventory data tips"
      ],
      "title": "Use integration data in New Relic dashboards",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "559fccfaae3aa29579bb7e1aaea25b37ae011c73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/use-integration-data-new-relic-dashboards/",
      "published_at": "2021-12-30T10:39:50Z",
      "updated_at": "2021-10-24T01:28:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Most data generated by integrations is available in New Relic One dashboards, where you can query your data using NRQL and build custom dashboards. The following tips and sample queries were created for New Relic-built integrations, but most will also apply to integrations built with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. Get started with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com > Infrastructure > Third-party services page, select an integration dashboard. There, you can view the NRQL queries that generated a chart. For examples of NRQL queries for integration data, see the example queries. Use the data explorer or the dashboards to explore and understand the available data. Read the documentation for a specific integration to learn about the reported data. When you create a useful query you'd like to add to your dashboard, select Add to dashboard. Example NRQL queries Here are some examples of NRQL queries that use integration data: AWS EBS query example Here's a NRQL query for the AWS EBS service, showing the total write time metric, faceted by entityName: SELECT sum('provider.volumeTotalWriteTime.Sum') FROM BlockDeviceSample WHERE provider = 'EbsVolume' FACET entityName Copy Azure Service Bus query example Here's a NRQL query for the maximum number of messages in an Azure Service Bus topic queue, faceted by resource group: SELECT max(activeMessages.Maximum) FROM AzureServiceBusTopicSample FACET resourceGroupName Copy Azure Functions query example Here's a NRQL query for Azure Functions, showing the count of executed functions over the past six hours by region over time: SELECT sum(functionExecutionCount.Total) FROM AzureFunctionsAppSample FACET regionName TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Here's a NRQL query for Azure VMs that compares the count of VM events over the past thirty minutes with the same time a week ago: SELECT uniqueCount(vMName) FROM AzureVirtualMachineScaleSetSample FACET name SINCE 30 minutes ago COMPARE WITH 1 week ago Copy NGINX query example Here's an example of a query that you might run on your NGINX integration data and place in a dashboard. This query creates a chart showing the average value of NGINX requests per second over time: SELECT average(net.requestsPerSecond) FROM NginxSample TIMESERIES Copy For more on how to create queries, see NRQL syntax. MySQL query example Here's an example of a query that you might run on your MySQL integration data. This query generates a chart showing the maximum number of used MySQL connections: SELECT max(net.maxUsedConnections) FROM MysqlSample Copy For more on how to create queries, see NRQL syntax. Inventory change query example Here's an example of a query that groups inventory change events from the last day by the type of change: SELECT count(*) FROM InfrastructureEvent WHERE format='inventoryChange' FACET changeType SINCE 1 DAY AGO Copy Tip You can also perform these queries using dimensional metrics. Tips for using different data types Integrations can generate metric, event, and inventory data, all of which are available for querying. Here are some tips for using the different types of integration data: Metric data tips Tips for finding and using integration metric data: All integration data is attached to a data type known as an event (not to be confused with events reported by integrations, which represent important activity in your host/service). This means that all integration data can be found via the data explorer. For more about these two basic New Relic data types, see New Relic data collection. Metric values are treated as attributes: key-value pairs attached to an event. For example, the MySQL integration has an 'active connections' metric; this would be found by querying the connectionsActive attribute of the MysqlSample event. For general information about metrics, see Integration metric data. Event data tips Here are some tips for finding and using integration event data when querying: Most integration events are inventory change events. When inventory is changed, it generates an InfrastructureEvent with a format value of inventoryChange. Integration data can be found via the data explorer. For general information about events, see Event data. Inventory data tips Here are some tips for finding and using integration inventory data: For general information about inventory data, see Integration inventory data. Some inventory data is added as attributes (key-value pairs) to this data. For example, the AWS EC2 integration collects awsRegion as inventory data; this would be found by querying the awsRegion attribute of the ComputeSample event type and provider Ec2Instance. When inventory data changes, an InfrastructureEvent event type is generated with a format value of inventoryChange. See the query examples for an example of querying this data. For more on using NRQL queries, see Intro to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.41838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>integration</em> data in New Relic dashboards",
        "sections": "<em>Get</em> <em>started</em> with <em>integration</em> data",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": " with the <em>Integrations</em> SDK. For a general look at how to find and use integration data, see New Relic data types. <em>Get</em> <em>started</em> with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com &gt; <em>Infrastructure</em> &gt; Third-party services page, select"
      },
      "id": "617dad54196a6740e2f7df3f"
    }
  ],
  "/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations": [
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2021-12-31T01:18:16Z",
      "updated_at": "2021-12-31T01:18:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. As a full platform user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.74257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to infrastructure integrations",
        "Cloud integrations",
        "On-host integrations",
        "Features",
        "Types of integration data"
      ],
      "title": "Introduction to infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "f54188c082f76568db1aea02a2ca0134d1b9b502",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations/",
      "published_at": "2021-12-30T10:39:03Z",
      "updated_at": "2021-11-24T15:43:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers many integrations and quickstarts for reporting your data to our platform. One category of integrations is our infrastructure integrations. We have two main categories of infrastructure integrations: cloud integrations and on-host integrations. These are described in more detail below. Cloud integrations Our cloud integrations collect data from cloud platform services and accounts. There's no installation process for cloud integrations and they do not require the use of our infrastructure agent: you simply connect your New Relic account to your cloud provider account. Integrations Description Amazon Web Services (AWS) cloud integrations Connect your Amazon Web Services (AWS) account to monitor and report data to New Relic. See our AWS integrations. Microsoft Azure cloud integrations Connect your Microsoft Azure account to monitor and report data to New Relic. See our Azure integrations. Google Cloud Platform (GCP) cloud integrations Connect your Google Cloud Platform (GCP) account to monitor and report data to New Relic. See our GCP integrations. On-host integrations Our on-host integrations are basically our infrastructure service integrations that aren't cloud platform integrations. With the exception of Kubernetes, which can be enabled in a few ways, our on-host integrations work in concert with our infrastructure agent to report data. Integrations Description Kubernetes integration Connect your account to gain visibility of your Kubernetes environment, explore your clusters, and manage alerts. On-host integrations Monitor and report data from many popular services, including NGINX, MySQL, Redis, Apache, RabbitMQ, and many more. Learn how to enable them. Build your own To create your own lightweight infrastructure integration, use our Flex integration. Features After an infrastructure integration is enabled, you can: Filter and analyze your metrics and configuration data in our infrastructure monitoring UI. Query your data and create custom charts and dashboards. Create alert conditions to monitor problems with your services' performance. For cloud integrations, configure data collection settings. Types of integration data For details about the types of data reported, see Infrastructure integration data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.41971,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "sections": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "New Relic offers many <em>integrations</em> and quickstarts for reporting your data to our platform. One category of <em>integrations</em> is our <em>infrastructure</em> <em>integrations</em>. We have two main categories of <em>infrastructure</em> <em>integrations</em>: cloud <em>integrations</em> and on-host <em>integrations</em>. These are described in more detail"
      },
      "id": "617d6fd528ccbcffc87fe889"
    },
    {
      "sections": [
        "Use integration data in New Relic dashboards",
        "Get started with integration data",
        "Example NRQL queries",
        "AWS EBS query example",
        "Azure Service Bus query example",
        "Azure Functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Inventory change query example",
        "Tip",
        "Tips for using different data types",
        "Metric data tips",
        "Event data tips",
        "Inventory data tips"
      ],
      "title": "Use integration data in New Relic dashboards",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "559fccfaae3aa29579bb7e1aaea25b37ae011c73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/use-integration-data-new-relic-dashboards/",
      "published_at": "2021-12-30T10:39:50Z",
      "updated_at": "2021-10-24T01:28:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Most data generated by integrations is available in New Relic One dashboards, where you can query your data using NRQL and build custom dashboards. The following tips and sample queries were created for New Relic-built integrations, but most will also apply to integrations built with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. Get started with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com > Infrastructure > Third-party services page, select an integration dashboard. There, you can view the NRQL queries that generated a chart. For examples of NRQL queries for integration data, see the example queries. Use the data explorer or the dashboards to explore and understand the available data. Read the documentation for a specific integration to learn about the reported data. When you create a useful query you'd like to add to your dashboard, select Add to dashboard. Example NRQL queries Here are some examples of NRQL queries that use integration data: AWS EBS query example Here's a NRQL query for the AWS EBS service, showing the total write time metric, faceted by entityName: SELECT sum('provider.volumeTotalWriteTime.Sum') FROM BlockDeviceSample WHERE provider = 'EbsVolume' FACET entityName Copy Azure Service Bus query example Here's a NRQL query for the maximum number of messages in an Azure Service Bus topic queue, faceted by resource group: SELECT max(activeMessages.Maximum) FROM AzureServiceBusTopicSample FACET resourceGroupName Copy Azure Functions query example Here's a NRQL query for Azure Functions, showing the count of executed functions over the past six hours by region over time: SELECT sum(functionExecutionCount.Total) FROM AzureFunctionsAppSample FACET regionName TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Here's a NRQL query for Azure VMs that compares the count of VM events over the past thirty minutes with the same time a week ago: SELECT uniqueCount(vMName) FROM AzureVirtualMachineScaleSetSample FACET name SINCE 30 minutes ago COMPARE WITH 1 week ago Copy NGINX query example Here's an example of a query that you might run on your NGINX integration data and place in a dashboard. This query creates a chart showing the average value of NGINX requests per second over time: SELECT average(net.requestsPerSecond) FROM NginxSample TIMESERIES Copy For more on how to create queries, see NRQL syntax. MySQL query example Here's an example of a query that you might run on your MySQL integration data. This query generates a chart showing the maximum number of used MySQL connections: SELECT max(net.maxUsedConnections) FROM MysqlSample Copy For more on how to create queries, see NRQL syntax. Inventory change query example Here's an example of a query that groups inventory change events from the last day by the type of change: SELECT count(*) FROM InfrastructureEvent WHERE format='inventoryChange' FACET changeType SINCE 1 DAY AGO Copy Tip You can also perform these queries using dimensional metrics. Tips for using different data types Integrations can generate metric, event, and inventory data, all of which are available for querying. Here are some tips for using the different types of integration data: Metric data tips Tips for finding and using integration metric data: All integration data is attached to a data type known as an event (not to be confused with events reported by integrations, which represent important activity in your host/service). This means that all integration data can be found via the data explorer. For more about these two basic New Relic data types, see New Relic data collection. Metric values are treated as attributes: key-value pairs attached to an event. For example, the MySQL integration has an 'active connections' metric; this would be found by querying the connectionsActive attribute of the MysqlSample event. For general information about metrics, see Integration metric data. Event data tips Here are some tips for finding and using integration event data when querying: Most integration events are inventory change events. When inventory is changed, it generates an InfrastructureEvent with a format value of inventoryChange. Integration data can be found via the data explorer. For general information about events, see Event data. Inventory data tips Here are some tips for finding and using integration inventory data: For general information about inventory data, see Integration inventory data. Some inventory data is added as attributes (key-value pairs) to this data. For example, the AWS EC2 integration collects awsRegion as inventory data; this would be found by querying the awsRegion attribute of the ComputeSample event type and provider Ec2Instance. When inventory data changes, an InfrastructureEvent event type is generated with a format value of inventoryChange. See the query examples for an example of querying this data. For more on using NRQL queries, see Intro to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.41838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>integration</em> data in New Relic dashboards",
        "sections": "<em>Get</em> <em>started</em> with <em>integration</em> data",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": " with the <em>Integrations</em> SDK. For a general look at how to find and use integration data, see New Relic data types. <em>Get</em> <em>started</em> with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com &gt; <em>Infrastructure</em> &gt; Third-party services page, select"
      },
      "id": "617dad54196a6740e2f7df3f"
    }
  ],
  "/docs/infrastructure/infrastructure-integrations/get-started/use-integration-data-new-relic-dashboards": [
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2021-12-31T01:18:16Z",
      "updated_at": "2021-12-31T01:18:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. As a full platform user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.7425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to infrastructure integrations",
        "Cloud integrations",
        "On-host integrations",
        "Features",
        "Types of integration data"
      ],
      "title": "Introduction to infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "f54188c082f76568db1aea02a2ca0134d1b9b502",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations/",
      "published_at": "2021-12-30T10:39:03Z",
      "updated_at": "2021-11-24T15:43:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers many integrations and quickstarts for reporting your data to our platform. One category of integrations is our infrastructure integrations. We have two main categories of infrastructure integrations: cloud integrations and on-host integrations. These are described in more detail below. Cloud integrations Our cloud integrations collect data from cloud platform services and accounts. There's no installation process for cloud integrations and they do not require the use of our infrastructure agent: you simply connect your New Relic account to your cloud provider account. Integrations Description Amazon Web Services (AWS) cloud integrations Connect your Amazon Web Services (AWS) account to monitor and report data to New Relic. See our AWS integrations. Microsoft Azure cloud integrations Connect your Microsoft Azure account to monitor and report data to New Relic. See our Azure integrations. Google Cloud Platform (GCP) cloud integrations Connect your Google Cloud Platform (GCP) account to monitor and report data to New Relic. See our GCP integrations. On-host integrations Our on-host integrations are basically our infrastructure service integrations that aren't cloud platform integrations. With the exception of Kubernetes, which can be enabled in a few ways, our on-host integrations work in concert with our infrastructure agent to report data. Integrations Description Kubernetes integration Connect your account to gain visibility of your Kubernetes environment, explore your clusters, and manage alerts. On-host integrations Monitor and report data from many popular services, including NGINX, MySQL, Redis, Apache, RabbitMQ, and many more. Learn how to enable them. Build your own To create your own lightweight infrastructure integration, use our Flex integration. Features After an infrastructure integration is enabled, you can: Filter and analyze your metrics and configuration data in our infrastructure monitoring UI. Query your data and create custom charts and dashboards. Create alert conditions to monitor problems with your services' performance. For cloud integrations, configure data collection settings. Types of integration data For details about the types of data reported, see Infrastructure integration data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.41971,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "sections": "Introduction to <em>infrastructure</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "New Relic offers many <em>integrations</em> and quickstarts for reporting your data to our platform. One category of <em>integrations</em> is our <em>infrastructure</em> <em>integrations</em>. We have two main categories of <em>infrastructure</em> <em>integrations</em>: cloud <em>integrations</em> and on-host <em>integrations</em>. These are described in more detail"
      },
      "id": "617d6fd528ccbcffc87fe889"
    },
    {
      "sections": [
        "Understand and use data from infrastructure integrations",
        "Explore your infrastructure integration's data",
        "Types of integration data",
        "Create alert conditions"
      ],
      "title": "Understand and use data from infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "74fbfa8de2ee02bdf8dd4aad22fab7f654e96904",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations/",
      "published_at": "2021-12-30T10:39:38Z",
      "updated_at": "2021-11-24T18:17:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic infrastructure integrations, you can monitor the performance of popular services, including AWS, Azure, Google Cloud Platform, Kubernetes, Redis, MySQL, and more. Here are some tips on how to find, understand, and use data reported from infrastructure integrations. Explore your infrastructure integration's data The best way to understand infrastructure integrations's data and see what you can do with it is to enable an integration and explore the data in the New Relic UI. Some recommendations for exploring: View dashboards: You can find your dashboards in New Relic One. For details, see Integration dashboards. Query data: You can run custom queries and charts of your integration data. For more information, see Query New Relic data. Create alert conditions: See Alert conditions. Learn more about what metrics and inventory data an integration reports: See an integration's documentation: cloud integrations and on-host integrations. Types of integration data New Relic infrastructure integrations are separated into two main categories: Cloud integrations: Integrations for cloud platform services, including AWS, Azure, and GCP. On-host integrations: \"On-host\" refers to core services integrations that you can install directly on a host. Examples: MySQL, NGINX, Kubernetes, Redis. An infrastructure integration can generate four types of data: Metrics: Numeric measurement data. Examples: message counts, error counts, and CPU used percentage. Metric data appears in an integration's charts. For details about what metrics are reported and how to query them, see the documentation for a specific integration. For details about data structure, see Data types. Inventory: Information about the state and configuration of a service or host. Examples of inventory data: configuration settings, the name of the host the service is on, the AWS region, the port being used. Inventory data appears in the Inventory UI page. Inventory data also appears in integration dashboards. Changes to inventory data generates event data. Events: Events represent important activity on a system. Examples of event data: an admin logging in; a package install or uninstall; a service starting; a table being created. Most events represent changes to inventory data. Attributes: Some integrations will generate other non-metric attributes (key-value pairs) that can be queried in New Relic. Create alert conditions To create an alert condition for integration data in infrastructure, Go to one.newrelic.com > Infrastructure, choose an integration, and then select an available alert option. For more information, see Infrastructure and alerts. You can also create alert conditions using NRQL queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.19844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and use data from <em>infrastructure</em> <em>integrations</em>",
        "sections": "Understand and use data from <em>infrastructure</em> <em>integrations</em>",
        "tags": "<em>Infrastructure</em> <em>integrations</em>",
        "body": "With New Relic <em>infrastructure</em> <em>integrations</em>, you can monitor the performance of popular services, including AWS, Azure, Google Cloud Platform, Kubernetes, Redis, MySQL, and more. Here are some tips on how to find, understand, and use data reported from <em>infrastructure</em> <em>integrations</em>. Explore your"
      },
      "id": "617dc61d28ccbcceb080096e"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring": [
    {
      "sections": [
        "Incorrect data reported",
        "Problem",
        "Troubleshooting",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows"
      ],
      "title": "Incorrect data reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "84b37d403b5c2b8c8c9d8d9220254d77852c49ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-data-reported/",
      "published_at": "2021-12-31T01:42:57Z",
      "updated_at": "2021-12-30T06:51:15Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows unexpected data for some of the events, metrics or attributes collected from the infrastructure agent. Troubleshooting Infrastructure supports trace-level logging that can be enabled on-demand to help troubleshooting complex scenarios. The following trace flags can be configured in order to print all events and metrics send to Telemetry Data Platform. This setting generates a lot of data very quickly, we recommend only enabling it for troubleshooting purposes. Edit the newrelic-infra.yml configuration file and add required flags. For example: verbose: 1 log_file: /path/myfile.log trace: # v3.submission enables detailed logging for events, examples: SystemSample, NetworkSample, etc. - v3.submission # dm.submission - dm.submission Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10, or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Identify the new trace log lines to confirm the data being sent to the Telemetry Data Platform. Log example when v3.submission is enabled: time=\"2021-12-28T09:27:28Z\" level=debug msg=\"Sending events to metrics-ingest.\" component=MetricsIngestSender key=... numEvents=3 postCount=1 timestamps=\"[2021-01-01 09:27:28 +0000 UTC]\" time=\"2021-12-28T09:27:28Z\" level=debug msg=\"Preparing metrics post.\" component=MetricsIngestSender postCount=1 time=\"2021-12-28T09:27:28Z\" level=trace msg=\"[{\\\"EntityID\\\":111,\\\"IsAgent\\\":true,\\\"Events\\\":[{\\\"eventType\\\":\\\"SystemSample\\\",\\\"timestamp\\\":1640683648,\\\"entityKey\\\":\\\"...\\\",\\\"cpuPercent\\\":0.2004008016032026, ...}]\" feature=v3.submission time=\"2021-12-28T09:27:29Z\" level=debug msg=\"Metrics post succeeded.\" component=MetricsIngestSender postCount=1 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.09435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> troubleshooting",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows unexpected data for some of the events, metrics or attributes collected from the <em>infrastructure</em> agent. Troubleshooting <em>Infrastructure</em> supports trace-level logging that can be enabled on-demand to help troubleshooting complex"
      },
      "id": "61cd56e3e7b9d25b3e7f54c3"
    },
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2021-12-31T01:40:19Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.75107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Install <em>infrastructure</em> <em>monitoring</em>",
        "body": "After you sign up for a New Relic account (it&#x27;s free, forever!) and install any of our <em>monitoring</em> services, you can <em>start</em> working with your data. <em>Get</em> <em>started</em> quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    },
    {
      "sections": [
        "Install the infrastructure agent",
        "Quick start: Use our guided install",
        "Important",
        "Install the infrastructure monitoring agent",
        "Linux",
        "Windows Server and 10",
        "Other installation scenarios",
        "One agent, many capabilities",
        "Check the source code",
        "What's next"
      ],
      "title": "Install the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "ccb11bfd79824202d189a3e743771cfc81e77710",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent/",
      "published_at": "2021-12-30T05:58:07Z",
      "updated_at": "2021-11-24T19:41:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure monitoring agent is a lightweight executable file that collects data about your hosts. It also forwards data from our on-host integrations to New Relic, as well as log data for log analytics. The infrastructure monitoring agent can currently run on many Linux distributions, Windows, and macOS. There are multiple ways to install and deploy the agent, depending on your setup and needs. This document describes how the infrastructure monitoring agent works and how to install it. Quick start: Use our guided install The quickest way to get started with our infrastructure monitoring agent is through our guided install. Our guided install not only installs the infrastructure agent, but also discovers the applications and log sources running in your environment. It recommends which ones you should instrument. Ready to get started? You'll need a New Relic account before you can install. Click one of these button to try it out. Get an account Guided install EU guided install The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your infrastructure. For more information on where you can run the agent, check the compatibility and requirements page. Important If you install the agent using the New Relic One UI, the Infrastructure status API is enabled by default. Install the infrastructure monitoring agent Linux If you don't have a New Relic account yet, the guided install won't work. If you want to follow the procedure manually, see our tutorial. Windows Server and 10 If you don't have a New Relic account yet, the guided install won't work. If you want to follow the procedure manually using our MSI installer, see our tutorial. Other installation scenarios The infrastructure monitoring agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Infrastructre can also be deployed in macOS. One agent, many capabilities Our infrastructure monitoring agent collects performance and health data about the system resources and processes of the host where it's enabled (on-premises or virtualized). At the same time, it acts as a forwarder for two types of data: core services metrics, which are collected by on-host integrations, and logs. If you want to collect data about core services running on your host, you need to install the infrastructure monitoring agent first, and then install or enable on-host integrations. Our infrastructure monitoring agent and its integrations collect data from the system and core services. It can also forward logs to New Relic. Backend application metrics (APM) are collected by separate language agents. Notice how each integration and forwarder feed different data types in the New Relic database (NRDB). Check the source code The infrastructure monitoring agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README. What's next After you've installed the infrastructure monitoring agent: Learn how to configure the agent or edit the config template. Install on-host integrations (for example, Apache or MySQL). Enable log forwarding using the infrastructure agent. Learn how to manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.892815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>infrastructure</em> agent",
        "sections": "Install the <em>infrastructure</em> <em>monitoring</em> agent",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " distributions, Windows, and macOS. There are multiple ways to install and deploy the agent, depending on your setup and needs. This document describes how the <em>infrastructure</em> <em>monitoring</em> agent works and how to install it. Quick <em>start</em>: Use our guided install The quickest way to <em>get</em> <em>started</em> with our <em>infrastructure</em>"
      },
      "id": "603e79bd64441f99814e8888"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/infrastructure-security/infrastructure-security": [
    {
      "sections": [
        "Incorrect data reported",
        "Problem",
        "Troubleshooting",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows"
      ],
      "title": "Incorrect data reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "84b37d403b5c2b8c8c9d8d9220254d77852c49ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-data-reported/",
      "published_at": "2021-12-31T01:42:57Z",
      "updated_at": "2021-12-30T06:51:15Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows unexpected data for some of the events, metrics or attributes collected from the infrastructure agent. Troubleshooting Infrastructure supports trace-level logging that can be enabled on-demand to help troubleshooting complex scenarios. The following trace flags can be configured in order to print all events and metrics send to Telemetry Data Platform. This setting generates a lot of data very quickly, we recommend only enabling it for troubleshooting purposes. Edit the newrelic-infra.yml configuration file and add required flags. For example: verbose: 1 log_file: /path/myfile.log trace: # v3.submission enables detailed logging for events, examples: SystemSample, NetworkSample, etc. - v3.submission # dm.submission - dm.submission Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10, or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Identify the new trace log lines to confirm the data being sent to the Telemetry Data Platform. Log example when v3.submission is enabled: time=\"2021-12-28T09:27:28Z\" level=debug msg=\"Sending events to metrics-ingest.\" component=MetricsIngestSender key=... numEvents=3 postCount=1 timestamps=\"[2021-01-01 09:27:28 +0000 UTC]\" time=\"2021-12-28T09:27:28Z\" level=debug msg=\"Preparing metrics post.\" component=MetricsIngestSender postCount=1 time=\"2021-12-28T09:27:28Z\" level=trace msg=\"[{\\\"EntityID\\\":111,\\\"IsAgent\\\":true,\\\"Events\\\":[{\\\"eventType\\\":\\\"SystemSample\\\",\\\"timestamp\\\":1640683648,\\\"entityKey\\\":\\\"...\\\",\\\"cpuPercent\\\":0.2004008016032026, ...}]\" feature=v3.submission time=\"2021-12-28T09:27:29Z\" level=debug msg=\"Metrics post succeeded.\" component=MetricsIngestSender postCount=1 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.96817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> troubleshooting",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows unexpected data for some of the events, metrics or attributes collected from the <em>infrastructure</em> agent. Troubleshooting <em>Infrastructure</em> supports trace-level logging that can be enabled on-demand to help troubleshooting complex"
      },
      "id": "61cd56e3e7b9d25b3e7f54c3"
    },
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2021-12-31T01:40:19Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.93709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Install <em>infrastructure</em> <em>monitoring</em>",
        "tags": "Install <em>and</em> configure",
        "body": " to install New Relic <em>monitoring</em> services: APM Browser <em>Infrastructure</em> Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    },
    {
      "sections": [
        "New infrastructure hosts UI",
        "Tip",
        "Access the new infrastructure UI",
        "Entities are displayed based on golden metrics",
        "Views with improved sorting and filtering",
        "A new nerdlet provides deep infrastructure analysis"
      ],
      "title": "New infrastructure hosts UI",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "ac89449b22873fc0fe525fc4bb41f825ecf518b6",
      "image": "https://docs.newrelic.com/static/77935c07d80f4149e12e7dd6c88cbb66/c1b63/pegasus-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui-entities/",
      "published_at": "2021-12-30T09:38:28Z",
      "updated_at": "2021-12-09T02:31:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our November 2021 relaunch of the infrastructure monitoring tools adds consistency to the way our users interact with the New Relic One platform. Previously, when clicking on the infrastructure item in the top navigation bar, you were redirected outside the Explorer, missing capabilities like the Navigator and Lookout. Now, by clicking on infrastructure or hosts, you are directed to the list of all of our host entities in the list view of Explorer, and infrastructure events are displayed in the activity stream. Our inventory experience has not changed as part of this release. Tip Use the toggle in the UI to access the legacy interface. While we have worked to update the flow and visualizations around your key infrastructure data, we have not removed any of the previous functionality in order to give you time to adjust to the new tools. You can still access the hosts legacy view from the top infrastructure nav drop down. Ready to get started? Make sure you have a New Relic account. It's free, forever! Access the new infrastructure UI Check out the new infrastructure monitoring: Go to one.newrelic.com, click on Infrastructure on the top nav bar, then select Hosts (New). Or go to the Explorer and select Hosts. The infrastructure Explorer list view is organized in these panels: Your system's entities on the left. Estate View panel in the middle. It provides the ability to select up to 25 entities at a time to analyze together: Select the hosts you want to observe, and hit the View Selected button to navigate to the new analysis nerdlet. From the list view you can still jump directly to an individual entity summary by clicking on the entity name in the list. Activity stream on the right. Entities are displayed based on golden metrics The new entity list is powered by golden metrics, which you are starting to see throughout New Relic. You will see the same set of metrics if you select to view Lookout for these infrastructure entity types. These new metrics replace the previous summary metrics in the old UI. Views with improved sorting and filtering We have removed the limitation of fewer than 2,000 entities to sort column values. Note that performance may be slightly impacted if there are more than 10,000 entities. On top of sorting, you can also filter the entities' metric values to hone in on exactly the entities that need your attention. For example, you can now filter only to entities that have a CPU over 80% so you can quickly identify if there are problems in their estate. Filtering is limited to one column for the moment, but it will be extended to multiple columns in future releases. A new nerdlet provides deep infrastructure analysis Once you've selected the desired entities in the entity list view, upon clicking View Selected, a slide out analysis panel appears regarding that set of entities. There are three panels of data: Left panel: Selected entities list Toggle between these entities' key metrics on the top drop down. Hover over any entity row to view more details on the entity. Click View Logs to open a new tab with their logs in context information. For hosts only, use the map icon to launch the auto-map feature for a particular host entity. This view gives you a visual representation of your host’s relationships to other entities in the stack. Select the magnifying glass icon labeled View summary to be redirected to the summary page for that individual entity. If you select an entity in the left panel, the line for that entity will also be highlighted on each chart. Hide the entity from the list clicking on the eye icon. If you chose to hide entities in the left panel, those will be removed from the charts in the middle panel. Middle panel: Golden metrics comparison charts The golden metrics comparison charts represent the golden metrics signals for the selected entities. If you chose to hide entities in the left panel, they will be removed from the charts. If an entity is highlighted in the left panel, the line for that entity will also be highlighted on each chart. Or, if you highlight a line, the entity is also highlighted on the left. Data points on each chart have a tooltip with details. Right panel: Related entities Understanding relationships in New Relic can be complicated, but very powerful when trying to solve problems. Imagine a host is misbehaving and you’d like to know, without a lot of clicking, what else it might be affecting. The related entities panel seeks to show you those entities that are related to your selection on the left panel so you can see common golden signals on those entities. See at a glance if your connected APM service is experiencing a slow response time, decreased throughput or an elevated error rate! When you first enter the new view, you will see the related entities panel sorted by the alert status of those entities. If there's a service with a critical violation, it will be right at the top! If you hover on an entity in the left panel, the related entities associated with the item will be highlighted on the right. Additionally, if you click on the item in the left side, the right panel will re-sort to bump the associated related entities to the top of the column on the right.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.09505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New <em>infrastructure</em> hosts UI",
        "sections": "New <em>infrastructure</em> hosts UI",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> UI",
        "body": "Our November 2021 relaunch of the <em>infrastructure</em> <em>monitoring</em> tools adds consistency to the way our users interact with the New Relic One platform. Previously, when clicking on the <em>infrastructure</em> item in the top navigation bar, you were redirected outside the Explorer, missing capabilities like"
      },
      "id": "61abe359196a67b826d0f09e"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure": [
    {
      "sections": [
        "Incorrect data reported",
        "Problem",
        "Troubleshooting",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows"
      ],
      "title": "Incorrect data reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "84b37d403b5c2b8c8c9d8d9220254d77852c49ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-data-reported/",
      "published_at": "2021-12-31T01:42:57Z",
      "updated_at": "2021-12-30T06:51:15Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows unexpected data for some of the events, metrics or attributes collected from the infrastructure agent. Troubleshooting Infrastructure supports trace-level logging that can be enabled on-demand to help troubleshooting complex scenarios. The following trace flags can be configured in order to print all events and metrics send to Telemetry Data Platform. This setting generates a lot of data very quickly, we recommend only enabling it for troubleshooting purposes. Edit the newrelic-infra.yml configuration file and add required flags. For example: verbose: 1 log_file: /path/myfile.log trace: # v3.submission enables detailed logging for events, examples: SystemSample, NetworkSample, etc. - v3.submission # dm.submission - dm.submission Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10, or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Identify the new trace log lines to confirm the data being sent to the Telemetry Data Platform. Log example when v3.submission is enabled: time=\"2021-12-28T09:27:28Z\" level=debug msg=\"Sending events to metrics-ingest.\" component=MetricsIngestSender key=... numEvents=3 postCount=1 timestamps=\"[2021-01-01 09:27:28 +0000 UTC]\" time=\"2021-12-28T09:27:28Z\" level=debug msg=\"Preparing metrics post.\" component=MetricsIngestSender postCount=1 time=\"2021-12-28T09:27:28Z\" level=trace msg=\"[{\\\"EntityID\\\":111,\\\"IsAgent\\\":true,\\\"Events\\\":[{\\\"eventType\\\":\\\"SystemSample\\\",\\\"timestamp\\\":1640683648,\\\"entityKey\\\":\\\"...\\\",\\\"cpuPercent\\\":0.2004008016032026, ...}]\" feature=v3.submission time=\"2021-12-28T09:27:29Z\" level=debug msg=\"Metrics post succeeded.\" component=MetricsIngestSender postCount=1 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 311.25372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows unexpected data for some of the events, metrics or attributes collected from the <em>infrastructure</em> agent. <em>Troubleshooting</em> <em>Infrastructure</em> supports trace-level logging that can be enabled on-demand to help <em>troubleshooting</em> complex"
      },
      "id": "61cd56e3e7b9d25b3e7f54c3"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-12-30T09:05:23Z",
      "updated_at": "2021-11-13T18:53:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause In Linux and macOS, the New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent. In Windows, it resolves the domain name using internal tools.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.83537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-12-30T09:04:34Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.56735,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ]
}