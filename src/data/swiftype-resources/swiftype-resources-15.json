{
  "/docs/network-performance-monitoring/setup-performance-monitoring/advanced-config": [
    {
      "sections": [
        "Set up network flow data monitoring",
        "Prerequisites",
        "New Relic One account prerequisites",
        "Linux host prerequisites",
        "Network flow data devices prerequisites",
        "Network security prerequisites",
        "Supported types of network flow data",
        "Important",
        "Scaling network flow collection",
        "Set up network flow data monitoring in New Relic One",
        "Manual setup",
        "Tip"
      ],
      "title": "Set up network flow data monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Installation",
        "Setup",
        "NPM"
      ],
      "external_id": "626c9bebce36e550d5793d8ef932e6d654c23e47",
      "image": "https://docs.newrelic.com/static/3d1561743f3311471975006fa41f628a/c1b63/network-flows-guided-install.png",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/setup-performance-monitoring/network-flow-monitoring/",
      "published_at": "2021-10-13T03:31:21Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Set up your network devices so they send network data to New Relic One. Prerequisites New Relic One account prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. A New Relic account ID. Read how to find your account ID. A New Relic license key. Read how to generate a new License key. Linux host prerequisites Docker installed in a Linux host. SSH access to the Docker host, with the ability to launch new containers. Network flow data devices prerequisites Configured network devices to send flow data to the host running the ktranslate docker container. Here's how to configure network flow data collection in some devices: NetFlow data Palo Alto - PAN-OS Fortinet Fortigate Cisco - NX-OS Cisco - IOS Cisco - Meraki sFlow data F5 - BIG-IP jFlow data Juniper - Junos Network security prerequisites Direction Source Destination Ports Protocol Outbound Docker host ktranslate image on Docker Hub 443 TCP Outbound Docker host New Relic Event API US Endpoint: https://insights-collector.newrelic.com EU Endpoint: https://insights-collector.eu01.nr-data.net 443 TCP Outbound Docker host New Relic Log API US Endpoint: https://log-api.newrelic.com EU Endpoint: https://log-api.eu.newrelic.com 443 TCP Inbound Source devices for network flow data Docker host 9995 (default) UDP Supported types of network flow data NPM flow monitoring supports the four primary types of network flow data and their derivatives. When running the ktranslate container, you will specify which major type you want to monitor using the -nf.source option. Important The ktranslate container only supports monitoring one type of network flow data type at a time. If you want to monitor several types, each will require a container. IPFIX and NetFlow v9 can be sent to the same container, but we recommend running a separate container as a best practice. Network flow data type -nf.source value IPFIX ipfix NetFlow v5 netflow5 NetFlow v9 netflow9 sFlow sflow AppFlow netflow5 Argus netflow5 cflowd netflow5 J-Flow netflow5 NetStream netflow5 RFlow netflow5 Cisco NSEL netflow9 Scaling network flow collection When planning your strategy for collecting network flows at scale, New Relic recommends 1 CPU per 2000 flows-per-second (120,000 flows-per-minute). Deciding whether to run more small containers to distribute load or fewer large containers to consolidate management is a matter of personal preference. Set up network flow data monitoring in New Relic One Go to one.newrelic.com and click Add more data. Scroll down until you see Network performance monitoring and click Network Flows. Follow the steps in New Relic One. one.newrelic.com > Add more data > Network performance monitoring > Network Flows to set up network flow data monitoring. To get better visibility into your network device performance, set up SNMP data monitoring. Visualize your network performance data in New Relic. Manual setup If you prefer to do the setup manually, proceed with the following steps. In your local machine, from a Linux host with Docker installed, download the ktranslate image from dockerhub by running bash Copy $ docker pull kentik/ktranslate:v2 Copy the snmp-base.yaml file to the local $HOME directory of your Docker user, and discard the container by running bash Copy $ cd . $ id=$(docker create kentik/ktranslate:v2) $ docker cp $id:/etc/ktranslate/snmp-base.yaml . $ docker rm -v $id In the snmp-base.yaml file, add your network flow devices inside the devices key with the following structure: devices: flowDevice: device_name: edge-router device_ip: 10.10.1.254 flow_only: true # Optional user tags user_tags: owning_team: net_eng environment: production Copy Tip If you're already monitoring SNMP data devices that send network flow data, you don't need to add them in your snmp-base.yaml file a second time. Run ktranslate to listen for network flows by running: Tip Add your New Relic license key and your account ID in the $NR_LICENSE_KEY and $NR_ACCOUNT_ID variables respectively. bash Copy $ docker run -d --name ktranslate-sflow --restart unless-stopped --net=host \\ > -v `pwd`/snmp-base.yaml:/snmp-base.yaml \\ > -e NEW_RELIC_API_KEY=$NR_LICENSE_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -flow_only=true \\ > -nf.source=sflow \\ > nr1.flow $ ## If your account is located in Europe, you need to add the following option before the nr1.flow line $ ## -nr_region=EU \\ Tip This command assumes collection of sflow data. If you are collecting other flow types, you should change the suffix in the --name flag for the container and update the -nf.source argument as necessary To get better visibility into your network device performance, set up SNMP data monitoring. Visualize your network performance data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.97293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up <em>network</em> flow data <em>monitoring</em>",
        "sections": "Set up <em>network</em> flow data <em>monitoring</em>",
        "tags": "<em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "body": " will specify which major type you want to <em>monitor</em> using the -nf.source option. Important The ktranslate container only supports <em>monitoring</em> one type of <em>network</em> flow data type at a time. If you want to <em>monitor</em> several types, each will require a container. IPFIX and NetFlow v9 can be sent to the same container"
      },
      "id": "612724e128ccbc4ac9f2612a"
    },
    {
      "sections": [
        "Visualize your network performance data in New Relic One",
        "Prerequisites",
        "Add the Network dashboards to your account",
        "Tip",
        "Start exploring your network performance data"
      ],
      "title": "Visualize your network performance data in New Relic One",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Monitoring"
      ],
      "external_id": "a9e82cf586cd71595b0fd3bdcc831768578417cf",
      "image": "https://docs.newrelic.com/static/f6a643a55e2f9a2b070d85ab9174ba48/c1b63/flow_data_dashboard.png",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/monitoring-network-data/visualize-network-data/",
      "published_at": "2021-10-13T03:30:23Z",
      "updated_at": "2021-09-14T18:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you've set up your network data for performance monitoring, you can go to New Relic One to install several custom curated visualizations designed specifically for network performance monitoring. Once you've set up these visualizations, you'll be able to start exploring the network data your devices are reporting to New Relic One. Prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. Having set up your Network Performance Monitoring devices. Read how to: Set up SNMP data monitoring. Set up network flow data monitoring. Add the custom visualizations app to your account: Go to one.newrelic.com > Apps, and search for Network Agent Visualizations. Click the app, and then click Open visualization. one.newrelic.com > Apps, and search for Network Agent Visualizations. From the Account ID dropdown, select the account you want to add the visualizations to, and click Enable. Add the Network dashboards to your account You can go to New Relic One and import several dashboards to see curated views of your network telemetry, including the GeoMap and Sankey custom visualizations from the prerequisites. Go to one.newrelic.com > Apps, and search for Quickstarts. Click Quickstarts, and in the search bar, search for Network and click one of the dashboards: The Network - Data Ingest and Cardinality dashboard to analyze usage trends. The Network - Routers and Switches dashboard for SNMP data from Router and Switch entities. The Network - Flow Devices dashboard for network flow data. one.newrelic.com > Apps, and search for Network. Click Import, and Select the account you want to add the dashboard to. Edit the dashboard name, if you want to. Click Import dashboard. Tip If you want to read more about custom visualizations in New Relic One, see the introduction to custom visualizations. Start exploring your network performance data Once you've finished setting up these dashboards, you can start seeing your network data by going to: one.newrelic.com > Dashboards: For usage trend analysis, you'll see the following dashboard: Dashboard for analyzing network telemetry usage trends in New Relic One. For SNMP data, you'll see the following dashboard: Dashboard for SNMP data from Router and Switch entities in New Relic One. For Network flow data, you'll see the following dashboard: Dashboard for Network flow data monitoring in New Relic One. one.newrelic.com > Explorer: Entities are listed under the Network category in the left-hand side menu. Open a specific device to see the details and trend of its performance. On the top right-hand side, click Lookout to see anomalies. Lookout view for Network Performance Monitoring in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.70654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Visualize your <em>network</em> <em>performance</em> data in New Relic One",
        "sections": "Visualize your <em>network</em> <em>performance</em> data in New Relic One",
        "tags": "<em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "body": "After you&#x27;ve set up your <em>network</em> data for <em>performance</em> <em>monitoring</em>, you can go to New Relic One to install several custom curated visualizations designed specifically for <em>network</em> <em>performance</em> <em>monitoring</em>. Once you&#x27;ve set up these visualizations, you&#x27;ll be able to start exploring the <em>network</em> data your"
      },
      "id": "6127249b64441f621ea47c42"
    },
    {
      "sections": [
        "Get started with Network Performance Monitoring",
        "Types of network performance data",
        "Important",
        "High level architecture overview"
      ],
      "title": "Get started with Network Performance Monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Get started"
      ],
      "external_id": "96d12e2c5551a6e5eab76238cd2b787e5c188c01",
      "image": "https://docs.newrelic.com/static/eb0db7c88b717f386c4900a04e12a8ed/e5166/overview_navigator.jpg",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/get-started/npm-introduction/",
      "published_at": "2021-10-12T04:14:59Z",
      "updated_at": "2021-09-14T01:43:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When system performance suffers, you need to know if it’s due to your code, your infrastructure, or the underlying network. And you need to know fast, so you can focus your efforts. With Network Performance Monitoring you can correlate and analyze application, infrastructure, digital experience, and network data all in one place, and understand how network performance and overall system performance impact each other. Using Navigator with Network Performance Monitoring. Network Performance Monitoring adds the context of network data to the application and infrastructure data you already collect in New Relic One. By monitoring your network data, you can: Analyze and understand the performance of your entire stack (application and infrastructure) for a holistic understanding of your system performance. Have all the data in a single platform to eliminate blind spots. See at first glance whether a network is implicated in an issue. Sign up for free! No credit card required. Already have an account? Login. Types of network performance data You can monitor the following types of network performance data: SNMP data: Simple Network Management Protocol (SNMP) is an application–layer protocol for exchanging management information between network devices. To send SNMP data to New Relic One, see Set up SNMP data monitoring. Network flow data: It captures information about the IP traffic going to and from network interfaces in your on-premises network. To send network flow data to New Relic One, see Set up network flow data monitoring. Important We recommend configuring both SNMP and network flow data for better visibility into your network. This will provide both performance metrics and traffic patterns to troubleshoot and optimize your network. High level architecture overview Our solution is based on the ktranslate docker container developed by our partner, Kentik. This single container image is hosted in your environment to collect and process your data to be exported to the Event, Metric, and Log APIs in New Relic One’s Telemetry Data Platform (TDP). Overview of Network Performance Monitoring architecture.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.23651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "sections": "Get started with <em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "tags": "<em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "body": "When system <em>performance</em> suffers, you need to know if it’s due to your code, your infrastructure, or the underlying <em>network</em>. And you need to know fast, so you can focus your efforts. With <em>Network</em> <em>Performance</em> <em>Monitoring</em> you can correlate and analyze application, infrastructure, digital experience"
      },
      "id": "6126f39b28ccbc8c49f26162"
    }
  ],
  "/docs/network-performance-monitoring/setup-performance-monitoring/network-flow-monitoring": [
    {
      "sections": [
        "Set up SNMP data monitoring",
        "Prerequisites",
        "New Relic One account prerequisites",
        "Linux host prerequisites",
        "SNMP devices prerequisites",
        "Supported SNMP versions",
        "Tip",
        "Set up SNMP data monitoring in New Relic One",
        "Manual setup"
      ],
      "title": "Set up SNMP data monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network performance monitoring",
        "Installation",
        "Setup"
      ],
      "external_id": "ab50c7659f03d76e429769be42ddec21d4744a0d",
      "image": "https://docs.newrelic.com/static/59f9f8d2d86daf23058506e7cf1c9fcc/c1b63/snmp-guided-install.png",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/setup-performance-monitoring/snmp-performance-monitoring/",
      "published_at": "2021-10-13T03:30:23Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Set up your network devices so they send network data to New Relic One. Prerequisites New Relic One account prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. A New Relic account ID. Read how to find your account ID. A New Relic license key. Read how to generate a new License key. Linux host prerequisites Docker installed in a Linux host. SSH access to the Docker host, with the ability to launch new containers. SNMP devices prerequisites Configured network devices for SNMP polling from the ktranslate docker container. Some samples of basic SNMP configurations can be found here: Cisco IOS Meraki NX-OS Juniper Junos OS Palo Alto PAN-OS Supported SNMP versions Our NPM container supports all major versions of SNMP (v1, v2c, and v3). Additionally, SNMP v3 has support for the following authentication and privacy settings: Setting Protocol Authentication NoAuth Authentication MD5 Authentication SHA Authentication SHA224 Authentication SHA256 Authentication SHA384 Authentication SHA512 Privacy NoPriv Privacy DES Privacy AES Privacy AES192 Privacy AES256 Privacy AES192C Privacy AES256C Tip We recommend using read-only community strings/authentication with SNMP Set up SNMP data monitoring in New Relic One Go to one.newrelic.com and click Add more data. Scroll down until you see Network performance monitoring and click SNMP. Follow the steps in New Relic One. one.newrelic.com > Add more data > Network performance monitoring > SNMP to set up SNMP data monitoring. To get better visibility into how your network is being used, set up network flow data monitoring. Visualize your network performance data in New Relic. Manual setup If you prefer to do the setup manually, proceed with the following steps. On a Linux host with Docker installed, download the ktranslate image from dockerhub by running bash Copy $ docker pull kentik/ktranslate:v2 Copy the snmp-base.yaml file to the local $HOME directory of your Docker user, and discard the container by running bash Copy $ cd . $ id=$(docker create kentik/ktranslate:v2) $ docker cp $id:/etc/ktranslate/snmp-base.yaml . $ docker rm -v $id Edit the snmp-base.yaml file and define the discovery.cidrs and discovery.default_communities attributes to appropriate values for your network. Tip It's recommended to set discovery.add_mibs: true to automate the addition of all discovered MIBs into the global.mibs_enabled attribute Launch a short-lived container to execute discovery by running bash Copy $ docker run -ti --name ktranslate-discovery --rm --net=host \\ > --user `id -u`:`id -g` \\ > -v `pwd`/snmp-base.yaml:/snmp-base.yaml \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -log_level info \\ > -snmp_discovery=true After the discovery run finishes, you should see an output similar to the following: bash Copy $ >[Info] KTranslate Adding 3 new snmp devices to the config, 0 replaced from 3 $ # In this example, the discovery run found 3 new SNMP devices. The discovered devices are listed in the snmp-base.yaml file's devices.{} section. By default, only the IF-MIB mib is polled. You can manually add other mibs to the global.mibs_enabled attribute if you did not set discovery.add_mibs: true before running the discovery. Run ktranslate to poll target devices by running: Tip Add your New Relic License key and your account ID in the $NR_LICENSE_KEY and $NR_ACCOUNT_ID variables respectively. bash Copy $ docker run -d --name ktranslate-snmp --restart unless-stopped --net=host \\ > -v `pwd`/snmp-base.yaml:/snmp-base.yaml \\ > -e NEW_RELIC_API_KEY=$NR_LICENSE_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -log_level=info \\ > -metrics=jchf \\ > -tee_logs=true \\ > ## If your account is located in Europe, you need to add the following option: $ ## -nr_region=EU $ nr1.snmp To get better visibility into how your network is being used, set up network flow data monitoring. Visualize your network performance data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 253.06836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up SNMP data <em>monitoring</em>",
        "sections": "Set up SNMP data <em>monitoring</em>",
        "tags": "<em>Network</em> <em>performance</em> <em>monitoring</em>",
        "body": " SNMP data <em>monitoring</em>. To get better visibility into how your <em>network</em> is being used, set up <em>network</em> flow data <em>monitoring</em>. Visualize your <em>network</em> <em>performance</em> data in New Relic. Manual <em>setup</em> If you prefer to do the <em>setup</em> manually, proceed with the following steps. On a Linux host with Docker installed"
      },
      "id": "6127249b28ccbc09a4f26187"
    },
    {
      "sections": [
        "Advanced configuration for Network Performance Monitoring",
        "SNMP-base YAML sample file",
        "Devices section",
        "Trap section",
        "Discovery section",
        "Global section",
        "SNMPv3 optional configuration",
        "The flow_only attribute",
        "Advanced options for running the ktranslate docker image",
        "Logs sent with Network performance monitoring",
        "Tip",
        "Metrics sent with Network performance monitoring"
      ],
      "title": "Advanced configuration for Network Performance Monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network performance monitoring",
        "Advanced configuration"
      ],
      "external_id": "8262ac964abbda46760776a63b051e05ecfecc4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/setup-performance-monitoring/advanced-config/",
      "published_at": "2021-10-13T02:04:26Z",
      "updated_at": "2021-10-13T02:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to explore all the options you can use when configuring the monitoring of your network performance, see the following sections. SNMP-base YAML sample file Here's an example of the various configuration options available in the snmp-base.yaml file used by the ktranslate docker image to poll for SNMP and flow data devices. devices: deviceOne: device_name: router123 device_ip: 10.10.0.201 oid: .1.3.6.1.4.1.2636.1.1.1.2.21.0 snmp_comm: public poll_time_sec: 300 user_tags: owning_team: net_eng environment: production trap: listen: 127.0.0.1:162 community: public version: \"\" transport: \"\" discovery: cidrs: - 10.10.0.0/24 - 10.20.0.0/24 - 192.168.0.21/32 debug: false ports: - 161 - 1161 default_communities: - public default_v3: null add_devices: true threads: 4 use_snmp_v1: false replace_devices: true global: poll_time_sec: 60 timeout_ms: 5000 retries: 0 mibs_enabled: - IF-MIB drop_if_outside_poll: false mib_profile_dir: profiles Copy Devices section Option name Required Description device_name ✓ Name of the device reporting to New Relic One device_ip ✓ IP to send SNMP queries to port Port to send SNMP queries to. By default, it's set to port 161 provider Value used during entity synthesis for New Relic One mib_profile SNMP Profile file that was associated with this device during the discovery run based on its sysOID snmp_comm ✓ SNMPv1/2c community string to use. For SNMPv3, set it to snmp_v3 use_snmp_v1 Indicates whether to use SNMPv1. By default, it's set to false snmp_v3 SNMPv3 authentication configuration poll_time_sec Indicates the polling frequency in seconds. This setting is used to override the global.poll_time_sec attribute. timeout_ms Indicates the polling timeout in milliseconds. By default, it's set to 5000 retries Indicates the number of attempts to retry to get the device information. By default, it's set to 0 last_checked Timestamp when this device was last discovered by the ktranslate docker image oid ✓ sysOID for the device description Description of the device discovered_mibs List of MIBs from our known SNMP profiles this device can respond to, found during discovery by the ktranslate docker image debug Indicates whether to run SNMP polling in debug mode. By default, it's set to false user_tags Additional key:value pair attributes to give more context to the device. For example, environment: production match_attributes Additional attribute:regex pairs to whitelist metrics. Only matching attributes are sent. For example, if_Description: \"^igb|^eth\" monitor_admin_shut Indicates whether the monitor shuts interfaces also. By default, it's set to false Trap section Option name Required Description listen ✓ Listening IP port for receiving SNMP traps community SNMP community string for receiving SNMP traps version SNMP version to use. Options are v1, v2c, and v3. (Default: v2c) transport SNMP transport protocol to use. The possible values are TCP and UDP. By default, it's set to UDP v3_config SNMP v3 config to use. Only used if version is v3. Discovery section Option name Required Description cidrs ✓ Array of target IP ranges in CIDR notation. You can add /32 at the end of the IP to poll for SNMP devices without testing with ICMP echo. Optionally, you can point to a cidrs.yaml file in the snmp-base.yaml file: discovery: cidrs: \"@cidrs.yaml\" Copy The cidrs.yaml file should be similar to the following - 10.10.0.0/24 - 10.20.0.0/24 - 192.168.0.21/32 Copy ports ✓ Array of target ports to scan during SNMP polling default_communities ✓ Array of SNMPv1/v2c community strings to scan during SNMP polling. This array is evaluated in order and discovery accepts the first passing community. For SNMPv3, set it to default_v3 default_v3 SNMPv3 configuration to scan during SNMP polling use_snmp_v1 Indicates whether to use SNMPv1 during discovery. By default, it's set to false add_devices ✓ Indicates whether to add discovered devices to the devices section of the snmp-base.yaml file. By default, it's set to true add_mibs ✓ Indicates whether to add discovered MIBs to the global.mibs_enabled section of the snmp-base.yaml file. By default, it's set to true replace_devices ✓ Indicates whether to replace discovered devices if they already exist in the devices section of the snmp-base.yaml file. By default, it's set to true debug Indicates whether to enable debug level logging during discovery. By default, it's set to false threads ✓ Integer limit of threads to use during discovery. It must be less than the number of cores available to the container Global section Option name Required Description poll_time_sec ✓ Time in seconds to poll devices. By default, it's set to 60 timeout_ms ✓ Time in milliseconds queries timeout. By default, it's set to 5000 retries ✓ Number of attempts to retry failed polls. By default, it's set to 0 mibs_enabled ✓ Array of all active MIBs the ktranslate docker image will poll. Polling only occurs if the MIB is valid for a given device drop_if_outside_poll Indicates whether to drop all values from this cycle if polling takes longer than the value set in poll_time_sec. By default, it's set to false mib_profile_dir Directory to find curated MIB profiles SNMPv3 optional configuration Here's an example of SNMPv3 configuration section for the snmp-base.yaml file: yaml default_v3: user_name: userNamev3 authentication_protocol: MD5 authentication_passphrase: authPassPrivacy privacy_protocol: AES256 privacy_passphrase: passPrivacy Copy Option name Required Description user_name ✓ User name for SNMPv3 authentication authentication_protocol ✓ SNMPv3 authentication protocol. The possible values are NoAuth, MD5, or SHA authentication_passphrase SNMPv3 authentication passphrase privacy_protocol ✓ SNMPv3 privacy protocol. The possible values are AuthNoPriv, DES, AES, AES192, AES256, AES192C, or AES256C privacy_passphrase SNMPv3 privacy passphrase context_engine_id SNMPv3 context engine ID context_name SNMPv3 context name The flow_only attribute There are several supported configurations available for running ktranslate against devices for both SNMP and network flow data collection. The flow_only attribute on both a ktranslate docker container level and in the devices section of the snmp-base.yaml file allows you to get different results: If you have multiple containers collecting both SNMP and network flow data with the ktranslate docker image, define your devices in the snmp-base.yaml file, following the standards for SNMP data polling. They will be automatically matched to their respective flows based on their device_ip matching the sampling IP for the flow device. For network flow data devices, run the ktranslate docker image with the -flow_only=true option. snmp-base.yaml file - No setting changes needed If you have multiple containers collecting both SNMP and network flow data with the ktranslate docker image, and you have specific devices where you only want network flow or SNMP data collection and no SNMP or network flow data polling respectively, you can set them up in their respective device configuration section in the snmp-base.yaml file. For network flow data devices, run the ktranslate docker image with the -flow_only=true option. snmp-base.yaml file - Change the flow_only to true: flow_only: true Copy Advanced options for running the ktranslate docker image In this table you can find additional options you can use with the ktranslate docker image. Option name Description -max_threads Lets you process higher volumes of flow. We recommend one CPU core available for every 2,000 flows per second (fps) of network flow data sent. -sample_rate=100 Changes the default sample rate value at which flows are passed to New Relic One Events. It also sets the sample rate value for flow types that don't have a default sample rate value. -nf.workers=1 Overrides the number of workers used in processing udp packets. Use one worker for every 4,000 of flows per second (fps) of network flow data sent. -nf.port Overrides the default 9995 listening port for incoming flow packets. -listen Overrides the default 8082 port used by ktranslate to expose health metrics. You must use this option when running multiple ktranslate containers on a single host. -metalisten Overrides the default 8083 port used by ktranslate to expose metadata. You must use this option when running multiple ktranslate containers on a single host. -metrics=jchf Forwards health metrics from ktranslate into New Relic One. -log_level Overrides the default info log level for ktranslate. The available options are debug, info, warn, or error. -tee_logs Forwards logs from ktranslate into New Relic One Logs. HTTPS_PROXY Environment variable that can be used during Docker runtime to setup ktranslate to ship data to New Relic via proxy. Ex: -e HTTPS_PROXY=https://user:password@hostname:port You can also run several ktranslate images to monitor different network flow types simultaneously. See the follwing example: bash Copy $ docker run -d --name ktranslate-sflow --net=host \\ > -e NEW_RELIC_API_KEY=$INSERT_API_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -nf.source=sflow \\ > -nf.port=9996 \\ > -max_threads=1 \\ > -listen 0.0.0.0:8084 \\ > -metalisten 0.0.0.0:8085 \\ > nr1.flow $ $ $ docker run -d --name ktranslate-netflow9 --net=host \\ > -e NEW_RELIC_API_KEY=$INSERT_API_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -nf.source=netflow9 \\ > -nf.port=2055 \\ > -max_threads=2 \\ > -listen 0.0.0.0:8086 \\ > -metalisten 0.0.0.0:8087 \\ > nr1.flow Logs sent with Network performance monitoring If you want to check the logs locally, run docker logs ktranslate-snmp. The -tee_logs=true option sends logs to New Relic One when polling devices. To see them, do the following: Go to one.newrelic.com > Logs. In Find logs where enter collector.name:\"ktranslate\" and click Query logs. Tip If you want to filter out all the information messages, enter collector.name:\"ktranslate\" message:-*\\[Info\\]*. Metrics sent with Network performance monitoring The -metrics option captures one of the following performance metrics when polling devices: Metric Description baseserver_healthcheck_execution_total Rate of internal health checks. Shows mostly that things are not deadlocked. delivery_metrics_nr Rate of metrics sent to New Relic One. delivery_logs_nr Rate of logs sent to New Relic One. delivery_wins_nr Rate of 200 HTTP codes received from sending metrics and events to New Relic One. device_metrics Rate of SNMP polling of device level metrics. inputq Messages per second (msg/sec) recieved over the last 60 seconds from SNMP or network flow devices. interface_metrics Rate of SNMP polling of interface level metrics. jchfq Gauge rate with number of available pre-allocated buffers. It should be 8,000 aproximately. To see these metrics in New Relic One: Go to one.newrelic.com and click Query your data. Enter the following NRQL query: FROM Metric SELECT latest(kentik.ktranslate.chf.kkc.baseserver_healthcheck_execution_total) AS 'baseserver_healthcheck_execution_total', latest(kentik.ktranslate.chf.kkc.delivery_metrics_nr) AS 'delivery_metrics_nr', latest(kentik.ktranslate.chf.kkc.delivery_logs_nr) AS 'delivery_logs_nr', latest(kentik.ktranslate.chf.kkc.delivery_wins_nr) AS 'delivery_wins_nr', latest(kentik.ktranslate.chf.kkc.device_metrics) AS 'device_metrics', latest(kentik.ktranslate.chf.kkc.inputq) AS 'inputq', latest(kentik.ktranslate.chf.kkc.interface_metrics) AS 'interface_metrics', latest(kentik.ktranslate.chf.kkc.jchfq) AS 'jchfq' WHERE provider = 'kentik-agent' AND instrumentation.name = 'heartbeat' LIMIT MAX Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.9925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Advanced configuration for <em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "sections": "Advanced configuration for <em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "tags": "<em>Network</em> <em>performance</em> <em>monitoring</em>",
        "body": "If you want to explore all the options you can use when configuring the <em>monitoring</em> of your <em>network</em> <em>performance</em>, see the following sections. SNMP-base YAML sample file Here&#x27;s an example of the various configuration options available in the snmp-base.yaml file used by the ktranslate docker image"
      },
      "id": "6127249be7b9d29922f565b0"
    },
    {
      "sections": [
        "Visualize your network performance data in New Relic One",
        "Prerequisites",
        "Add the Network dashboards to your account",
        "Tip",
        "Start exploring your network performance data"
      ],
      "title": "Visualize your network performance data in New Relic One",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Monitoring"
      ],
      "external_id": "a9e82cf586cd71595b0fd3bdcc831768578417cf",
      "image": "https://docs.newrelic.com/static/f6a643a55e2f9a2b070d85ab9174ba48/c1b63/flow_data_dashboard.png",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/monitoring-network-data/visualize-network-data/",
      "published_at": "2021-10-13T03:30:23Z",
      "updated_at": "2021-09-14T18:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you've set up your network data for performance monitoring, you can go to New Relic One to install several custom curated visualizations designed specifically for network performance monitoring. Once you've set up these visualizations, you'll be able to start exploring the network data your devices are reporting to New Relic One. Prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. Having set up your Network Performance Monitoring devices. Read how to: Set up SNMP data monitoring. Set up network flow data monitoring. Add the custom visualizations app to your account: Go to one.newrelic.com > Apps, and search for Network Agent Visualizations. Click the app, and then click Open visualization. one.newrelic.com > Apps, and search for Network Agent Visualizations. From the Account ID dropdown, select the account you want to add the visualizations to, and click Enable. Add the Network dashboards to your account You can go to New Relic One and import several dashboards to see curated views of your network telemetry, including the GeoMap and Sankey custom visualizations from the prerequisites. Go to one.newrelic.com > Apps, and search for Quickstarts. Click Quickstarts, and in the search bar, search for Network and click one of the dashboards: The Network - Data Ingest and Cardinality dashboard to analyze usage trends. The Network - Routers and Switches dashboard for SNMP data from Router and Switch entities. The Network - Flow Devices dashboard for network flow data. one.newrelic.com > Apps, and search for Network. Click Import, and Select the account you want to add the dashboard to. Edit the dashboard name, if you want to. Click Import dashboard. Tip If you want to read more about custom visualizations in New Relic One, see the introduction to custom visualizations. Start exploring your network performance data Once you've finished setting up these dashboards, you can start seeing your network data by going to: one.newrelic.com > Dashboards: For usage trend analysis, you'll see the following dashboard: Dashboard for analyzing network telemetry usage trends in New Relic One. For SNMP data, you'll see the following dashboard: Dashboard for SNMP data from Router and Switch entities in New Relic One. For Network flow data, you'll see the following dashboard: Dashboard for Network flow data monitoring in New Relic One. one.newrelic.com > Explorer: Entities are listed under the Network category in the left-hand side menu. Open a specific device to see the details and trend of its performance. On the top right-hand side, click Lookout to see anomalies. Lookout view for Network Performance Monitoring in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.33138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Visualize your <em>network</em> <em>performance</em> data in New Relic One",
        "sections": "Visualize your <em>network</em> <em>performance</em> data in New Relic One",
        "tags": "<em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "body": "After you&#x27;ve set up your <em>network</em> data for <em>performance</em> <em>monitoring</em>, you can go to New Relic One to install several custom curated visualizations designed specifically for <em>network</em> <em>performance</em> <em>monitoring</em>. Once you&#x27;ve set up these visualizations, you&#x27;ll be able to start exploring the <em>network</em> data your"
      },
      "id": "6127249b64441f621ea47c42"
    }
  ],
  "/docs/network-performance-monitoring/setup-performance-monitoring/snmp-performance-monitoring": [
    {
      "sections": [
        "Set up network flow data monitoring",
        "Prerequisites",
        "New Relic One account prerequisites",
        "Linux host prerequisites",
        "Network flow data devices prerequisites",
        "Network security prerequisites",
        "Supported types of network flow data",
        "Important",
        "Scaling network flow collection",
        "Set up network flow data monitoring in New Relic One",
        "Manual setup",
        "Tip"
      ],
      "title": "Set up network flow data monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Installation",
        "Setup",
        "NPM"
      ],
      "external_id": "626c9bebce36e550d5793d8ef932e6d654c23e47",
      "image": "https://docs.newrelic.com/static/3d1561743f3311471975006fa41f628a/c1b63/network-flows-guided-install.png",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/setup-performance-monitoring/network-flow-monitoring/",
      "published_at": "2021-10-13T03:31:21Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Set up your network devices so they send network data to New Relic One. Prerequisites New Relic One account prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. A New Relic account ID. Read how to find your account ID. A New Relic license key. Read how to generate a new License key. Linux host prerequisites Docker installed in a Linux host. SSH access to the Docker host, with the ability to launch new containers. Network flow data devices prerequisites Configured network devices to send flow data to the host running the ktranslate docker container. Here's how to configure network flow data collection in some devices: NetFlow data Palo Alto - PAN-OS Fortinet Fortigate Cisco - NX-OS Cisco - IOS Cisco - Meraki sFlow data F5 - BIG-IP jFlow data Juniper - Junos Network security prerequisites Direction Source Destination Ports Protocol Outbound Docker host ktranslate image on Docker Hub 443 TCP Outbound Docker host New Relic Event API US Endpoint: https://insights-collector.newrelic.com EU Endpoint: https://insights-collector.eu01.nr-data.net 443 TCP Outbound Docker host New Relic Log API US Endpoint: https://log-api.newrelic.com EU Endpoint: https://log-api.eu.newrelic.com 443 TCP Inbound Source devices for network flow data Docker host 9995 (default) UDP Supported types of network flow data NPM flow monitoring supports the four primary types of network flow data and their derivatives. When running the ktranslate container, you will specify which major type you want to monitor using the -nf.source option. Important The ktranslate container only supports monitoring one type of network flow data type at a time. If you want to monitor several types, each will require a container. IPFIX and NetFlow v9 can be sent to the same container, but we recommend running a separate container as a best practice. Network flow data type -nf.source value IPFIX ipfix NetFlow v5 netflow5 NetFlow v9 netflow9 sFlow sflow AppFlow netflow5 Argus netflow5 cflowd netflow5 J-Flow netflow5 NetStream netflow5 RFlow netflow5 Cisco NSEL netflow9 Scaling network flow collection When planning your strategy for collecting network flows at scale, New Relic recommends 1 CPU per 2000 flows-per-second (120,000 flows-per-minute). Deciding whether to run more small containers to distribute load or fewer large containers to consolidate management is a matter of personal preference. Set up network flow data monitoring in New Relic One Go to one.newrelic.com and click Add more data. Scroll down until you see Network performance monitoring and click Network Flows. Follow the steps in New Relic One. one.newrelic.com > Add more data > Network performance monitoring > Network Flows to set up network flow data monitoring. To get better visibility into your network device performance, set up SNMP data monitoring. Visualize your network performance data in New Relic. Manual setup If you prefer to do the setup manually, proceed with the following steps. In your local machine, from a Linux host with Docker installed, download the ktranslate image from dockerhub by running bash Copy $ docker pull kentik/ktranslate:v2 Copy the snmp-base.yaml file to the local $HOME directory of your Docker user, and discard the container by running bash Copy $ cd . $ id=$(docker create kentik/ktranslate:v2) $ docker cp $id:/etc/ktranslate/snmp-base.yaml . $ docker rm -v $id In the snmp-base.yaml file, add your network flow devices inside the devices key with the following structure: devices: flowDevice: device_name: edge-router device_ip: 10.10.1.254 flow_only: true # Optional user tags user_tags: owning_team: net_eng environment: production Copy Tip If you're already monitoring SNMP data devices that send network flow data, you don't need to add them in your snmp-base.yaml file a second time. Run ktranslate to listen for network flows by running: Tip Add your New Relic license key and your account ID in the $NR_LICENSE_KEY and $NR_ACCOUNT_ID variables respectively. bash Copy $ docker run -d --name ktranslate-sflow --restart unless-stopped --net=host \\ > -v `pwd`/snmp-base.yaml:/snmp-base.yaml \\ > -e NEW_RELIC_API_KEY=$NR_LICENSE_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -flow_only=true \\ > -nf.source=sflow \\ > nr1.flow $ ## If your account is located in Europe, you need to add the following option before the nr1.flow line $ ## -nr_region=EU \\ Tip This command assumes collection of sflow data. If you are collecting other flow types, you should change the suffix in the --name flag for the container and update the -nf.source argument as necessary To get better visibility into your network device performance, set up SNMP data monitoring. Visualize your network performance data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.57053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up <em>network</em> flow data <em>monitoring</em>",
        "sections": "Set up <em>network</em> flow data <em>monitoring</em>",
        "tags": "<em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "body": " <em>monitoring</em> &gt; <em>Network</em> Flows to set up <em>network</em> flow data <em>monitoring</em>. To get better visibility into your <em>network</em> device <em>performance</em>, set up SNMP data <em>monitoring</em>. Visualize your <em>network</em> <em>performance</em> data in New Relic. Manual <em>setup</em> If you prefer to do the <em>setup</em> manually, proceed with the following steps. In your"
      },
      "id": "612724e128ccbc4ac9f2612a"
    },
    {
      "sections": [
        "Advanced configuration for Network Performance Monitoring",
        "SNMP-base YAML sample file",
        "Devices section",
        "Trap section",
        "Discovery section",
        "Global section",
        "SNMPv3 optional configuration",
        "The flow_only attribute",
        "Advanced options for running the ktranslate docker image",
        "Logs sent with Network performance monitoring",
        "Tip",
        "Metrics sent with Network performance monitoring"
      ],
      "title": "Advanced configuration for Network Performance Monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network performance monitoring",
        "Advanced configuration"
      ],
      "external_id": "8262ac964abbda46760776a63b051e05ecfecc4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/setup-performance-monitoring/advanced-config/",
      "published_at": "2021-10-13T02:04:26Z",
      "updated_at": "2021-10-13T02:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to explore all the options you can use when configuring the monitoring of your network performance, see the following sections. SNMP-base YAML sample file Here's an example of the various configuration options available in the snmp-base.yaml file used by the ktranslate docker image to poll for SNMP and flow data devices. devices: deviceOne: device_name: router123 device_ip: 10.10.0.201 oid: .1.3.6.1.4.1.2636.1.1.1.2.21.0 snmp_comm: public poll_time_sec: 300 user_tags: owning_team: net_eng environment: production trap: listen: 127.0.0.1:162 community: public version: \"\" transport: \"\" discovery: cidrs: - 10.10.0.0/24 - 10.20.0.0/24 - 192.168.0.21/32 debug: false ports: - 161 - 1161 default_communities: - public default_v3: null add_devices: true threads: 4 use_snmp_v1: false replace_devices: true global: poll_time_sec: 60 timeout_ms: 5000 retries: 0 mibs_enabled: - IF-MIB drop_if_outside_poll: false mib_profile_dir: profiles Copy Devices section Option name Required Description device_name ✓ Name of the device reporting to New Relic One device_ip ✓ IP to send SNMP queries to port Port to send SNMP queries to. By default, it's set to port 161 provider Value used during entity synthesis for New Relic One mib_profile SNMP Profile file that was associated with this device during the discovery run based on its sysOID snmp_comm ✓ SNMPv1/2c community string to use. For SNMPv3, set it to snmp_v3 use_snmp_v1 Indicates whether to use SNMPv1. By default, it's set to false snmp_v3 SNMPv3 authentication configuration poll_time_sec Indicates the polling frequency in seconds. This setting is used to override the global.poll_time_sec attribute. timeout_ms Indicates the polling timeout in milliseconds. By default, it's set to 5000 retries Indicates the number of attempts to retry to get the device information. By default, it's set to 0 last_checked Timestamp when this device was last discovered by the ktranslate docker image oid ✓ sysOID for the device description Description of the device discovered_mibs List of MIBs from our known SNMP profiles this device can respond to, found during discovery by the ktranslate docker image debug Indicates whether to run SNMP polling in debug mode. By default, it's set to false user_tags Additional key:value pair attributes to give more context to the device. For example, environment: production match_attributes Additional attribute:regex pairs to whitelist metrics. Only matching attributes are sent. For example, if_Description: \"^igb|^eth\" monitor_admin_shut Indicates whether the monitor shuts interfaces also. By default, it's set to false Trap section Option name Required Description listen ✓ Listening IP port for receiving SNMP traps community SNMP community string for receiving SNMP traps version SNMP version to use. Options are v1, v2c, and v3. (Default: v2c) transport SNMP transport protocol to use. The possible values are TCP and UDP. By default, it's set to UDP v3_config SNMP v3 config to use. Only used if version is v3. Discovery section Option name Required Description cidrs ✓ Array of target IP ranges in CIDR notation. You can add /32 at the end of the IP to poll for SNMP devices without testing with ICMP echo. Optionally, you can point to a cidrs.yaml file in the snmp-base.yaml file: discovery: cidrs: \"@cidrs.yaml\" Copy The cidrs.yaml file should be similar to the following - 10.10.0.0/24 - 10.20.0.0/24 - 192.168.0.21/32 Copy ports ✓ Array of target ports to scan during SNMP polling default_communities ✓ Array of SNMPv1/v2c community strings to scan during SNMP polling. This array is evaluated in order and discovery accepts the first passing community. For SNMPv3, set it to default_v3 default_v3 SNMPv3 configuration to scan during SNMP polling use_snmp_v1 Indicates whether to use SNMPv1 during discovery. By default, it's set to false add_devices ✓ Indicates whether to add discovered devices to the devices section of the snmp-base.yaml file. By default, it's set to true add_mibs ✓ Indicates whether to add discovered MIBs to the global.mibs_enabled section of the snmp-base.yaml file. By default, it's set to true replace_devices ✓ Indicates whether to replace discovered devices if they already exist in the devices section of the snmp-base.yaml file. By default, it's set to true debug Indicates whether to enable debug level logging during discovery. By default, it's set to false threads ✓ Integer limit of threads to use during discovery. It must be less than the number of cores available to the container Global section Option name Required Description poll_time_sec ✓ Time in seconds to poll devices. By default, it's set to 60 timeout_ms ✓ Time in milliseconds queries timeout. By default, it's set to 5000 retries ✓ Number of attempts to retry failed polls. By default, it's set to 0 mibs_enabled ✓ Array of all active MIBs the ktranslate docker image will poll. Polling only occurs if the MIB is valid for a given device drop_if_outside_poll Indicates whether to drop all values from this cycle if polling takes longer than the value set in poll_time_sec. By default, it's set to false mib_profile_dir Directory to find curated MIB profiles SNMPv3 optional configuration Here's an example of SNMPv3 configuration section for the snmp-base.yaml file: yaml default_v3: user_name: userNamev3 authentication_protocol: MD5 authentication_passphrase: authPassPrivacy privacy_protocol: AES256 privacy_passphrase: passPrivacy Copy Option name Required Description user_name ✓ User name for SNMPv3 authentication authentication_protocol ✓ SNMPv3 authentication protocol. The possible values are NoAuth, MD5, or SHA authentication_passphrase SNMPv3 authentication passphrase privacy_protocol ✓ SNMPv3 privacy protocol. The possible values are AuthNoPriv, DES, AES, AES192, AES256, AES192C, or AES256C privacy_passphrase SNMPv3 privacy passphrase context_engine_id SNMPv3 context engine ID context_name SNMPv3 context name The flow_only attribute There are several supported configurations available for running ktranslate against devices for both SNMP and network flow data collection. The flow_only attribute on both a ktranslate docker container level and in the devices section of the snmp-base.yaml file allows you to get different results: If you have multiple containers collecting both SNMP and network flow data with the ktranslate docker image, define your devices in the snmp-base.yaml file, following the standards for SNMP data polling. They will be automatically matched to their respective flows based on their device_ip matching the sampling IP for the flow device. For network flow data devices, run the ktranslate docker image with the -flow_only=true option. snmp-base.yaml file - No setting changes needed If you have multiple containers collecting both SNMP and network flow data with the ktranslate docker image, and you have specific devices where you only want network flow or SNMP data collection and no SNMP or network flow data polling respectively, you can set them up in their respective device configuration section in the snmp-base.yaml file. For network flow data devices, run the ktranslate docker image with the -flow_only=true option. snmp-base.yaml file - Change the flow_only to true: flow_only: true Copy Advanced options for running the ktranslate docker image In this table you can find additional options you can use with the ktranslate docker image. Option name Description -max_threads Lets you process higher volumes of flow. We recommend one CPU core available for every 2,000 flows per second (fps) of network flow data sent. -sample_rate=100 Changes the default sample rate value at which flows are passed to New Relic One Events. It also sets the sample rate value for flow types that don't have a default sample rate value. -nf.workers=1 Overrides the number of workers used in processing udp packets. Use one worker for every 4,000 of flows per second (fps) of network flow data sent. -nf.port Overrides the default 9995 listening port for incoming flow packets. -listen Overrides the default 8082 port used by ktranslate to expose health metrics. You must use this option when running multiple ktranslate containers on a single host. -metalisten Overrides the default 8083 port used by ktranslate to expose metadata. You must use this option when running multiple ktranslate containers on a single host. -metrics=jchf Forwards health metrics from ktranslate into New Relic One. -log_level Overrides the default info log level for ktranslate. The available options are debug, info, warn, or error. -tee_logs Forwards logs from ktranslate into New Relic One Logs. HTTPS_PROXY Environment variable that can be used during Docker runtime to setup ktranslate to ship data to New Relic via proxy. Ex: -e HTTPS_PROXY=https://user:password@hostname:port You can also run several ktranslate images to monitor different network flow types simultaneously. See the follwing example: bash Copy $ docker run -d --name ktranslate-sflow --net=host \\ > -e NEW_RELIC_API_KEY=$INSERT_API_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -nf.source=sflow \\ > -nf.port=9996 \\ > -max_threads=1 \\ > -listen 0.0.0.0:8084 \\ > -metalisten 0.0.0.0:8085 \\ > nr1.flow $ $ $ docker run -d --name ktranslate-netflow9 --net=host \\ > -e NEW_RELIC_API_KEY=$INSERT_API_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -nf.source=netflow9 \\ > -nf.port=2055 \\ > -max_threads=2 \\ > -listen 0.0.0.0:8086 \\ > -metalisten 0.0.0.0:8087 \\ > nr1.flow Logs sent with Network performance monitoring If you want to check the logs locally, run docker logs ktranslate-snmp. The -tee_logs=true option sends logs to New Relic One when polling devices. To see them, do the following: Go to one.newrelic.com > Logs. In Find logs where enter collector.name:\"ktranslate\" and click Query logs. Tip If you want to filter out all the information messages, enter collector.name:\"ktranslate\" message:-*\\[Info\\]*. Metrics sent with Network performance monitoring The -metrics option captures one of the following performance metrics when polling devices: Metric Description baseserver_healthcheck_execution_total Rate of internal health checks. Shows mostly that things are not deadlocked. delivery_metrics_nr Rate of metrics sent to New Relic One. delivery_logs_nr Rate of logs sent to New Relic One. delivery_wins_nr Rate of 200 HTTP codes received from sending metrics and events to New Relic One. device_metrics Rate of SNMP polling of device level metrics. inputq Messages per second (msg/sec) recieved over the last 60 seconds from SNMP or network flow devices. interface_metrics Rate of SNMP polling of interface level metrics. jchfq Gauge rate with number of available pre-allocated buffers. It should be 8,000 aproximately. To see these metrics in New Relic One: Go to one.newrelic.com and click Query your data. Enter the following NRQL query: FROM Metric SELECT latest(kentik.ktranslate.chf.kkc.baseserver_healthcheck_execution_total) AS 'baseserver_healthcheck_execution_total', latest(kentik.ktranslate.chf.kkc.delivery_metrics_nr) AS 'delivery_metrics_nr', latest(kentik.ktranslate.chf.kkc.delivery_logs_nr) AS 'delivery_logs_nr', latest(kentik.ktranslate.chf.kkc.delivery_wins_nr) AS 'delivery_wins_nr', latest(kentik.ktranslate.chf.kkc.device_metrics) AS 'device_metrics', latest(kentik.ktranslate.chf.kkc.inputq) AS 'inputq', latest(kentik.ktranslate.chf.kkc.interface_metrics) AS 'interface_metrics', latest(kentik.ktranslate.chf.kkc.jchfq) AS 'jchfq' WHERE provider = 'kentik-agent' AND instrumentation.name = 'heartbeat' LIMIT MAX Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.71823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Advanced configuration for <em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "sections": "Advanced configuration for <em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "tags": "<em>Network</em> <em>performance</em> <em>monitoring</em>",
        "body": "If you want to explore all the options you can use when configuring the <em>monitoring</em> of your <em>network</em> <em>performance</em>, see the following sections. SNMP-base YAML sample file Here&#x27;s an example of the various configuration options available in the snmp-base.yaml file used by the ktranslate docker image"
      },
      "id": "6127249be7b9d29922f565b0"
    },
    {
      "sections": [
        "Visualize your network performance data in New Relic One",
        "Prerequisites",
        "Add the Network dashboards to your account",
        "Tip",
        "Start exploring your network performance data"
      ],
      "title": "Visualize your network performance data in New Relic One",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Monitoring"
      ],
      "external_id": "a9e82cf586cd71595b0fd3bdcc831768578417cf",
      "image": "https://docs.newrelic.com/static/f6a643a55e2f9a2b070d85ab9174ba48/c1b63/flow_data_dashboard.png",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/monitoring-network-data/visualize-network-data/",
      "published_at": "2021-10-13T03:30:23Z",
      "updated_at": "2021-09-14T18:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you've set up your network data for performance monitoring, you can go to New Relic One to install several custom curated visualizations designed specifically for network performance monitoring. Once you've set up these visualizations, you'll be able to start exploring the network data your devices are reporting to New Relic One. Prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. Having set up your Network Performance Monitoring devices. Read how to: Set up SNMP data monitoring. Set up network flow data monitoring. Add the custom visualizations app to your account: Go to one.newrelic.com > Apps, and search for Network Agent Visualizations. Click the app, and then click Open visualization. one.newrelic.com > Apps, and search for Network Agent Visualizations. From the Account ID dropdown, select the account you want to add the visualizations to, and click Enable. Add the Network dashboards to your account You can go to New Relic One and import several dashboards to see curated views of your network telemetry, including the GeoMap and Sankey custom visualizations from the prerequisites. Go to one.newrelic.com > Apps, and search for Quickstarts. Click Quickstarts, and in the search bar, search for Network and click one of the dashboards: The Network - Data Ingest and Cardinality dashboard to analyze usage trends. The Network - Routers and Switches dashboard for SNMP data from Router and Switch entities. The Network - Flow Devices dashboard for network flow data. one.newrelic.com > Apps, and search for Network. Click Import, and Select the account you want to add the dashboard to. Edit the dashboard name, if you want to. Click Import dashboard. Tip If you want to read more about custom visualizations in New Relic One, see the introduction to custom visualizations. Start exploring your network performance data Once you've finished setting up these dashboards, you can start seeing your network data by going to: one.newrelic.com > Dashboards: For usage trend analysis, you'll see the following dashboard: Dashboard for analyzing network telemetry usage trends in New Relic One. For SNMP data, you'll see the following dashboard: Dashboard for SNMP data from Router and Switch entities in New Relic One. For Network flow data, you'll see the following dashboard: Dashboard for Network flow data monitoring in New Relic One. one.newrelic.com > Explorer: Entities are listed under the Network category in the left-hand side menu. Open a specific device to see the details and trend of its performance. On the top right-hand side, click Lookout to see anomalies. Lookout view for Network Performance Monitoring in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.70654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Visualize your <em>network</em> <em>performance</em> data in New Relic One",
        "sections": "Visualize your <em>network</em> <em>performance</em> data in New Relic One",
        "tags": "<em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "body": "After you&#x27;ve set up your <em>network</em> data for <em>performance</em> <em>monitoring</em>, you can go to New Relic One to install several custom curated visualizations designed specifically for <em>network</em> <em>performance</em> <em>monitoring</em>. Once you&#x27;ve set up these visualizations, you&#x27;ll be able to start exploring the <em>network</em> data your"
      },
      "id": "6127249b64441f621ea47c42"
    }
  ],
  "/docs/network-performance-monitoring/troubleshooting/snmp-troubleshooting-no-devices": [
    {
      "sections": [
        "Advanced configuration for Network Performance Monitoring",
        "SNMP-base YAML sample file",
        "Devices section",
        "Trap section",
        "Discovery section",
        "Global section",
        "SNMPv3 optional configuration",
        "The flow_only attribute",
        "Advanced options for running the ktranslate docker image",
        "Logs sent with Network performance monitoring",
        "Tip",
        "Metrics sent with Network performance monitoring"
      ],
      "title": "Advanced configuration for Network Performance Monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network performance monitoring",
        "Advanced configuration"
      ],
      "external_id": "8262ac964abbda46760776a63b051e05ecfecc4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/setup-performance-monitoring/advanced-config/",
      "published_at": "2021-10-13T02:04:26Z",
      "updated_at": "2021-10-13T02:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to explore all the options you can use when configuring the monitoring of your network performance, see the following sections. SNMP-base YAML sample file Here's an example of the various configuration options available in the snmp-base.yaml file used by the ktranslate docker image to poll for SNMP and flow data devices. devices: deviceOne: device_name: router123 device_ip: 10.10.0.201 oid: .1.3.6.1.4.1.2636.1.1.1.2.21.0 snmp_comm: public poll_time_sec: 300 user_tags: owning_team: net_eng environment: production trap: listen: 127.0.0.1:162 community: public version: \"\" transport: \"\" discovery: cidrs: - 10.10.0.0/24 - 10.20.0.0/24 - 192.168.0.21/32 debug: false ports: - 161 - 1161 default_communities: - public default_v3: null add_devices: true threads: 4 use_snmp_v1: false replace_devices: true global: poll_time_sec: 60 timeout_ms: 5000 retries: 0 mibs_enabled: - IF-MIB drop_if_outside_poll: false mib_profile_dir: profiles Copy Devices section Option name Required Description device_name ✓ Name of the device reporting to New Relic One device_ip ✓ IP to send SNMP queries to port Port to send SNMP queries to. By default, it's set to port 161 provider Value used during entity synthesis for New Relic One mib_profile SNMP Profile file that was associated with this device during the discovery run based on its sysOID snmp_comm ✓ SNMPv1/2c community string to use. For SNMPv3, set it to snmp_v3 use_snmp_v1 Indicates whether to use SNMPv1. By default, it's set to false snmp_v3 SNMPv3 authentication configuration poll_time_sec Indicates the polling frequency in seconds. This setting is used to override the global.poll_time_sec attribute. timeout_ms Indicates the polling timeout in milliseconds. By default, it's set to 5000 retries Indicates the number of attempts to retry to get the device information. By default, it's set to 0 last_checked Timestamp when this device was last discovered by the ktranslate docker image oid ✓ sysOID for the device description Description of the device discovered_mibs List of MIBs from our known SNMP profiles this device can respond to, found during discovery by the ktranslate docker image debug Indicates whether to run SNMP polling in debug mode. By default, it's set to false user_tags Additional key:value pair attributes to give more context to the device. For example, environment: production match_attributes Additional attribute:regex pairs to whitelist metrics. Only matching attributes are sent. For example, if_Description: \"^igb|^eth\" monitor_admin_shut Indicates whether the monitor shuts interfaces also. By default, it's set to false Trap section Option name Required Description listen ✓ Listening IP port for receiving SNMP traps community SNMP community string for receiving SNMP traps version SNMP version to use. Options are v1, v2c, and v3. (Default: v2c) transport SNMP transport protocol to use. The possible values are TCP and UDP. By default, it's set to UDP v3_config SNMP v3 config to use. Only used if version is v3. Discovery section Option name Required Description cidrs ✓ Array of target IP ranges in CIDR notation. You can add /32 at the end of the IP to poll for SNMP devices without testing with ICMP echo. Optionally, you can point to a cidrs.yaml file in the snmp-base.yaml file: discovery: cidrs: \"@cidrs.yaml\" Copy The cidrs.yaml file should be similar to the following - 10.10.0.0/24 - 10.20.0.0/24 - 192.168.0.21/32 Copy ports ✓ Array of target ports to scan during SNMP polling default_communities ✓ Array of SNMPv1/v2c community strings to scan during SNMP polling. This array is evaluated in order and discovery accepts the first passing community. For SNMPv3, set it to default_v3 default_v3 SNMPv3 configuration to scan during SNMP polling use_snmp_v1 Indicates whether to use SNMPv1 during discovery. By default, it's set to false add_devices ✓ Indicates whether to add discovered devices to the devices section of the snmp-base.yaml file. By default, it's set to true add_mibs ✓ Indicates whether to add discovered MIBs to the global.mibs_enabled section of the snmp-base.yaml file. By default, it's set to true replace_devices ✓ Indicates whether to replace discovered devices if they already exist in the devices section of the snmp-base.yaml file. By default, it's set to true debug Indicates whether to enable debug level logging during discovery. By default, it's set to false threads ✓ Integer limit of threads to use during discovery. It must be less than the number of cores available to the container Global section Option name Required Description poll_time_sec ✓ Time in seconds to poll devices. By default, it's set to 60 timeout_ms ✓ Time in milliseconds queries timeout. By default, it's set to 5000 retries ✓ Number of attempts to retry failed polls. By default, it's set to 0 mibs_enabled ✓ Array of all active MIBs the ktranslate docker image will poll. Polling only occurs if the MIB is valid for a given device drop_if_outside_poll Indicates whether to drop all values from this cycle if polling takes longer than the value set in poll_time_sec. By default, it's set to false mib_profile_dir Directory to find curated MIB profiles SNMPv3 optional configuration Here's an example of SNMPv3 configuration section for the snmp-base.yaml file: yaml default_v3: user_name: userNamev3 authentication_protocol: MD5 authentication_passphrase: authPassPrivacy privacy_protocol: AES256 privacy_passphrase: passPrivacy Copy Option name Required Description user_name ✓ User name for SNMPv3 authentication authentication_protocol ✓ SNMPv3 authentication protocol. The possible values are NoAuth, MD5, or SHA authentication_passphrase SNMPv3 authentication passphrase privacy_protocol ✓ SNMPv3 privacy protocol. The possible values are AuthNoPriv, DES, AES, AES192, AES256, AES192C, or AES256C privacy_passphrase SNMPv3 privacy passphrase context_engine_id SNMPv3 context engine ID context_name SNMPv3 context name The flow_only attribute There are several supported configurations available for running ktranslate against devices for both SNMP and network flow data collection. The flow_only attribute on both a ktranslate docker container level and in the devices section of the snmp-base.yaml file allows you to get different results: If you have multiple containers collecting both SNMP and network flow data with the ktranslate docker image, define your devices in the snmp-base.yaml file, following the standards for SNMP data polling. They will be automatically matched to their respective flows based on their device_ip matching the sampling IP for the flow device. For network flow data devices, run the ktranslate docker image with the -flow_only=true option. snmp-base.yaml file - No setting changes needed If you have multiple containers collecting both SNMP and network flow data with the ktranslate docker image, and you have specific devices where you only want network flow or SNMP data collection and no SNMP or network flow data polling respectively, you can set them up in their respective device configuration section in the snmp-base.yaml file. For network flow data devices, run the ktranslate docker image with the -flow_only=true option. snmp-base.yaml file - Change the flow_only to true: flow_only: true Copy Advanced options for running the ktranslate docker image In this table you can find additional options you can use with the ktranslate docker image. Option name Description -max_threads Lets you process higher volumes of flow. We recommend one CPU core available for every 2,000 flows per second (fps) of network flow data sent. -sample_rate=100 Changes the default sample rate value at which flows are passed to New Relic One Events. It also sets the sample rate value for flow types that don't have a default sample rate value. -nf.workers=1 Overrides the number of workers used in processing udp packets. Use one worker for every 4,000 of flows per second (fps) of network flow data sent. -nf.port Overrides the default 9995 listening port for incoming flow packets. -listen Overrides the default 8082 port used by ktranslate to expose health metrics. You must use this option when running multiple ktranslate containers on a single host. -metalisten Overrides the default 8083 port used by ktranslate to expose metadata. You must use this option when running multiple ktranslate containers on a single host. -metrics=jchf Forwards health metrics from ktranslate into New Relic One. -log_level Overrides the default info log level for ktranslate. The available options are debug, info, warn, or error. -tee_logs Forwards logs from ktranslate into New Relic One Logs. HTTPS_PROXY Environment variable that can be used during Docker runtime to setup ktranslate to ship data to New Relic via proxy. Ex: -e HTTPS_PROXY=https://user:password@hostname:port You can also run several ktranslate images to monitor different network flow types simultaneously. See the follwing example: bash Copy $ docker run -d --name ktranslate-sflow --net=host \\ > -e NEW_RELIC_API_KEY=$INSERT_API_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -nf.source=sflow \\ > -nf.port=9996 \\ > -max_threads=1 \\ > -listen 0.0.0.0:8084 \\ > -metalisten 0.0.0.0:8085 \\ > nr1.flow $ $ $ docker run -d --name ktranslate-netflow9 --net=host \\ > -e NEW_RELIC_API_KEY=$INSERT_API_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -nf.source=netflow9 \\ > -nf.port=2055 \\ > -max_threads=2 \\ > -listen 0.0.0.0:8086 \\ > -metalisten 0.0.0.0:8087 \\ > nr1.flow Logs sent with Network performance monitoring If you want to check the logs locally, run docker logs ktranslate-snmp. The -tee_logs=true option sends logs to New Relic One when polling devices. To see them, do the following: Go to one.newrelic.com > Logs. In Find logs where enter collector.name:\"ktranslate\" and click Query logs. Tip If you want to filter out all the information messages, enter collector.name:\"ktranslate\" message:-*\\[Info\\]*. Metrics sent with Network performance monitoring The -metrics option captures one of the following performance metrics when polling devices: Metric Description baseserver_healthcheck_execution_total Rate of internal health checks. Shows mostly that things are not deadlocked. delivery_metrics_nr Rate of metrics sent to New Relic One. delivery_logs_nr Rate of logs sent to New Relic One. delivery_wins_nr Rate of 200 HTTP codes received from sending metrics and events to New Relic One. device_metrics Rate of SNMP polling of device level metrics. inputq Messages per second (msg/sec) recieved over the last 60 seconds from SNMP or network flow devices. interface_metrics Rate of SNMP polling of interface level metrics. jchfq Gauge rate with number of available pre-allocated buffers. It should be 8,000 aproximately. To see these metrics in New Relic One: Go to one.newrelic.com and click Query your data. Enter the following NRQL query: FROM Metric SELECT latest(kentik.ktranslate.chf.kkc.baseserver_healthcheck_execution_total) AS 'baseserver_healthcheck_execution_total', latest(kentik.ktranslate.chf.kkc.delivery_metrics_nr) AS 'delivery_metrics_nr', latest(kentik.ktranslate.chf.kkc.delivery_logs_nr) AS 'delivery_logs_nr', latest(kentik.ktranslate.chf.kkc.delivery_wins_nr) AS 'delivery_wins_nr', latest(kentik.ktranslate.chf.kkc.device_metrics) AS 'device_metrics', latest(kentik.ktranslate.chf.kkc.inputq) AS 'inputq', latest(kentik.ktranslate.chf.kkc.interface_metrics) AS 'interface_metrics', latest(kentik.ktranslate.chf.kkc.jchfq) AS 'jchfq' WHERE provider = 'kentik-agent' AND instrumentation.name = 'heartbeat' LIMIT MAX Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Advanced configuration for <em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "sections": "Advanced configuration for <em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "tags": "<em>Network</em> <em>performance</em> <em>monitoring</em>",
        "body": "If you want to explore all the options you can use when configuring the <em>monitoring</em> of your <em>network</em> <em>performance</em>, see the following sections. SNMP-base YAML sample file Here&#x27;s an example of the various configuration options available in the snmp-base.yaml file used by the ktranslate docker image"
      },
      "id": "6127249be7b9d29922f565b0"
    },
    {
      "sections": [
        "Set up network flow data monitoring",
        "Prerequisites",
        "New Relic One account prerequisites",
        "Linux host prerequisites",
        "Network flow data devices prerequisites",
        "Network security prerequisites",
        "Supported types of network flow data",
        "Important",
        "Scaling network flow collection",
        "Set up network flow data monitoring in New Relic One",
        "Manual setup",
        "Tip"
      ],
      "title": "Set up network flow data monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Installation",
        "Setup",
        "NPM"
      ],
      "external_id": "626c9bebce36e550d5793d8ef932e6d654c23e47",
      "image": "https://docs.newrelic.com/static/3d1561743f3311471975006fa41f628a/c1b63/network-flows-guided-install.png",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/setup-performance-monitoring/network-flow-monitoring/",
      "published_at": "2021-10-13T03:31:21Z",
      "updated_at": "2021-10-13T03:31:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Set up your network devices so they send network data to New Relic One. Prerequisites New Relic One account prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. A New Relic account ID. Read how to find your account ID. A New Relic license key. Read how to generate a new License key. Linux host prerequisites Docker installed in a Linux host. SSH access to the Docker host, with the ability to launch new containers. Network flow data devices prerequisites Configured network devices to send flow data to the host running the ktranslate docker container. Here's how to configure network flow data collection in some devices: NetFlow data Palo Alto - PAN-OS Fortinet Fortigate Cisco - NX-OS Cisco - IOS Cisco - Meraki sFlow data F5 - BIG-IP jFlow data Juniper - Junos Network security prerequisites Direction Source Destination Ports Protocol Outbound Docker host ktranslate image on Docker Hub 443 TCP Outbound Docker host New Relic Event API US Endpoint: https://insights-collector.newrelic.com EU Endpoint: https://insights-collector.eu01.nr-data.net 443 TCP Outbound Docker host New Relic Log API US Endpoint: https://log-api.newrelic.com EU Endpoint: https://log-api.eu.newrelic.com 443 TCP Inbound Source devices for network flow data Docker host 9995 (default) UDP Supported types of network flow data NPM flow monitoring supports the four primary types of network flow data and their derivatives. When running the ktranslate container, you will specify which major type you want to monitor using the -nf.source option. Important The ktranslate container only supports monitoring one type of network flow data type at a time. If you want to monitor several types, each will require a container. IPFIX and NetFlow v9 can be sent to the same container, but we recommend running a separate container as a best practice. Network flow data type -nf.source value IPFIX ipfix NetFlow v5 netflow5 NetFlow v9 netflow9 sFlow sflow AppFlow netflow5 Argus netflow5 cflowd netflow5 J-Flow netflow5 NetStream netflow5 RFlow netflow5 Cisco NSEL netflow9 Scaling network flow collection When planning your strategy for collecting network flows at scale, New Relic recommends 1 CPU per 2000 flows-per-second (120,000 flows-per-minute). Deciding whether to run more small containers to distribute load or fewer large containers to consolidate management is a matter of personal preference. Set up network flow data monitoring in New Relic One Go to one.newrelic.com and click Add more data. Scroll down until you see Network performance monitoring and click Network Flows. Follow the steps in New Relic One. one.newrelic.com > Add more data > Network performance monitoring > Network Flows to set up network flow data monitoring. To get better visibility into your network device performance, set up SNMP data monitoring. Visualize your network performance data in New Relic. Manual setup If you prefer to do the setup manually, proceed with the following steps. In your local machine, from a Linux host with Docker installed, download the ktranslate image from dockerhub by running bash Copy $ docker pull kentik/ktranslate:v2 Copy the snmp-base.yaml file to the local $HOME directory of your Docker user, and discard the container by running bash Copy $ cd . $ id=$(docker create kentik/ktranslate:v2) $ docker cp $id:/etc/ktranslate/snmp-base.yaml . $ docker rm -v $id In the snmp-base.yaml file, add your network flow devices inside the devices key with the following structure: devices: flowDevice: device_name: edge-router device_ip: 10.10.1.254 flow_only: true # Optional user tags user_tags: owning_team: net_eng environment: production Copy Tip If you're already monitoring SNMP data devices that send network flow data, you don't need to add them in your snmp-base.yaml file a second time. Run ktranslate to listen for network flows by running: Tip Add your New Relic license key and your account ID in the $NR_LICENSE_KEY and $NR_ACCOUNT_ID variables respectively. bash Copy $ docker run -d --name ktranslate-sflow --restart unless-stopped --net=host \\ > -v `pwd`/snmp-base.yaml:/snmp-base.yaml \\ > -e NEW_RELIC_API_KEY=$NR_LICENSE_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$NR_ACCOUNT_ID \\ > -metrics=jchf \\ > -log_level=info \\ > -tee_logs=true \\ > -flow_only=true \\ > -nf.source=sflow \\ > nr1.flow $ ## If your account is located in Europe, you need to add the following option before the nr1.flow line $ ## -nr_region=EU \\ Tip This command assumes collection of sflow data. If you are collecting other flow types, you should change the suffix in the --name flag for the container and update the -nf.source argument as necessary To get better visibility into your network device performance, set up SNMP data monitoring. Visualize your network performance data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.97287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up <em>network</em> flow data <em>monitoring</em>",
        "sections": "Set up <em>network</em> flow data <em>monitoring</em>",
        "tags": "<em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "body": " will specify which major type you want to <em>monitor</em> using the -nf.source option. Important The ktranslate container only supports <em>monitoring</em> one type of <em>network</em> flow data type at a time. If you want to <em>monitor</em> several types, each will require a container. IPFIX and NetFlow v9 can be sent to the same container"
      },
      "id": "612724e128ccbc4ac9f2612a"
    },
    {
      "sections": [
        "Visualize your network performance data in New Relic One",
        "Prerequisites",
        "Add the Network dashboards to your account",
        "Tip",
        "Start exploring your network performance data"
      ],
      "title": "Visualize your network performance data in New Relic One",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Monitoring"
      ],
      "external_id": "a9e82cf586cd71595b0fd3bdcc831768578417cf",
      "image": "https://docs.newrelic.com/static/f6a643a55e2f9a2b070d85ab9174ba48/c1b63/flow_data_dashboard.png",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/monitoring-network-data/visualize-network-data/",
      "published_at": "2021-10-13T03:30:23Z",
      "updated_at": "2021-09-14T18:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you've set up your network data for performance monitoring, you can go to New Relic One to install several custom curated visualizations designed specifically for network performance monitoring. Once you've set up these visualizations, you'll be able to start exploring the network data your devices are reporting to New Relic One. Prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. Having set up your Network Performance Monitoring devices. Read how to: Set up SNMP data monitoring. Set up network flow data monitoring. Add the custom visualizations app to your account: Go to one.newrelic.com > Apps, and search for Network Agent Visualizations. Click the app, and then click Open visualization. one.newrelic.com > Apps, and search for Network Agent Visualizations. From the Account ID dropdown, select the account you want to add the visualizations to, and click Enable. Add the Network dashboards to your account You can go to New Relic One and import several dashboards to see curated views of your network telemetry, including the GeoMap and Sankey custom visualizations from the prerequisites. Go to one.newrelic.com > Apps, and search for Quickstarts. Click Quickstarts, and in the search bar, search for Network and click one of the dashboards: The Network - Data Ingest and Cardinality dashboard to analyze usage trends. The Network - Routers and Switches dashboard for SNMP data from Router and Switch entities. The Network - Flow Devices dashboard for network flow data. one.newrelic.com > Apps, and search for Network. Click Import, and Select the account you want to add the dashboard to. Edit the dashboard name, if you want to. Click Import dashboard. Tip If you want to read more about custom visualizations in New Relic One, see the introduction to custom visualizations. Start exploring your network performance data Once you've finished setting up these dashboards, you can start seeing your network data by going to: one.newrelic.com > Dashboards: For usage trend analysis, you'll see the following dashboard: Dashboard for analyzing network telemetry usage trends in New Relic One. For SNMP data, you'll see the following dashboard: Dashboard for SNMP data from Router and Switch entities in New Relic One. For Network flow data, you'll see the following dashboard: Dashboard for Network flow data monitoring in New Relic One. one.newrelic.com > Explorer: Entities are listed under the Network category in the left-hand side menu. Open a specific device to see the details and trend of its performance. On the top right-hand side, click Lookout to see anomalies. Lookout view for Network Performance Monitoring in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.70654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Visualize your <em>network</em> <em>performance</em> data in New Relic One",
        "sections": "Visualize your <em>network</em> <em>performance</em> data in New Relic One",
        "tags": "<em>Network</em> <em>Performance</em> <em>Monitoring</em>",
        "body": "After you&#x27;ve set up your <em>network</em> data for <em>performance</em> <em>monitoring</em>, you can go to New Relic One to install several custom curated visualizations designed specifically for <em>network</em> <em>performance</em> <em>monitoring</em>. Once you&#x27;ve set up these visualizations, you&#x27;ll be able to start exploring the <em>network</em> data your"
      },
      "id": "6127249b64441f621ea47c42"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/build-new-relic-one/build-custom-new-relic-one-application": [
    {
      "sections": [
        "What is an entity in New Relic?",
        "What's an entity?",
        "Find and explore entities and entity data",
        "Tip",
        "Group and organize entities",
        "Customize entity data with entity synthesis",
        "Reserved attributes for synthesized entities",
        "Entity relationships",
        "Important",
        "Which relationships are created?",
        "Source: New Relic agent",
        "Source: Infrastructure",
        "Source: Synthetics monitor",
        "Source: Kubernetes",
        "External services"
      ],
      "title": "What is an entity in New Relic?",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "52a3e08bc9103c717d27b153e4fd4f547d6ecc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/",
      "published_at": "2021-10-12T15:06:27Z",
      "updated_at": "2021-09-01T17:25:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic monitoring is built around the concept of entities. In this doc, you'll learn how we define entities, what you can do with them, and how you can create your own entities or groupings of entities. What's an entity? From a New Relic perspective, entity is purposefully a broad concept. An entity is anything that a) reports data to New Relic or that contains data that we have access to, and b) is something we've identified with a unique entity ID. For most entities, the ID is indicated by the attribute entityGuid. An entity can be any fundamental data-reporting component, like an application, a host, or a database service, but it can also refer to larger groupings of those components. For example, to monitor a data center, you could aggregate those hosts in New Relic to be a workload (a custom grouping of entities). That workload is, itself, also an entity. Also very important is the relationships between entities. Our behind-the-scenes relationship-mapping helps us understand how entities are connected, how they affect each other. And this allows us to give you the power to configure how any data you're bringing in is related to existing entities, or how it's related to other entities. Our focus on entities and their relationships is important because our goal is to give you practical information about your business-important entities, and not give you an unhelpfully huge stream of data from a huge list of monitored things. With more insight at the entity level, you can better monitor and troubleshoot complex, modern systems. Find and explore entities and entity data Tip You can create new entity types for monitoring any data source. Learn more about entity synthesis. Some tips for finding and understanding entity data: To find an entity's entityGuid and entityName and other metadata: from any list of monitored entities in the New Relic Explorer, click an entity's icon, and click See metadata and tags. For most entities, its GUID is reported as the attribute entityGuid. For workloads, it's workloadGuid. You can run NRQL queries to find entities by their GUID. To see connections between entities, you have several options: When viewing an entity in the UI, use the Related entities UI. Service maps. Distributed tracing. Our NerdGraph API. To group entities together, see Group entities. Customize entity definitions and relationships. To learn technical details about entity types, see our GitHub repo. In an entity type's definition file, you'll see information like: The domain: for example, APM, or Infra. Its type: for example, Application or AWSECSCONTAINERINSTANCE. Default tags. The entityExpirationTime: how long data from that entity lasts in the UI, which is different from database data retention. Group and organize entities You can place entities into groups that reflect business-important relationships in your organization. For example, you might group all entities related to a specific team or department, or related to a specific service. Or you might group multiple hosts together to reflect their grouping in a data center. To group your entities, see: Tag entities. Create workloads, which allow you to group business-important sets of entities. Create entities and customize entity data Customize entity data with entity synthesis If you have telemetry from any source that's not supported by New Relic out of the box, you can propose a mapping for it. Once approved, any telemetry received by New Relic that matches your definition file will be synthesized into an entity. To learn more: For reserved attributes and how entity relationships are defined, keep reading this doc. For how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Reserved attributes for synthesized entities These attributes are meant to be synthesized from the telemetry we receive. Do not set them unless you're aware of the implications and consequences. Attribute Description entity.guid Generally, you should not set this attribute field on your telemetry data. New Relic may add this field to ingested data to store a unique identifier for the entity associated with the data point. If telemetry arrives with the entity.guid attribute already present, then New Relic will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. One use case for passing this attribute is to associate ingested telemetry with an entity already created by New Relic. When the entity.guid attribute is sent, the value will override New Relic’s entity identification system (such as entity synthesis definitions) and instead will use the attribute as the data. entity.name This attribute shouldn't be put on ingested telemetry data unless you're trying to override the entity name that would have been selected by New Relic’s entity identification system. While New Relic won't change the value if it's already present on the data, New Relic may add the attribute to your data. Therefore invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. If this field is present on ingested telemetry, its value will be used to name the entity associated with the data point. This name will be used instead of the name selected by New Relic’s entity identification system (for example, entity synthesis definitions). Note that many entities use the name as part of their identification, so changing this field may result in the generation of a new entity. entity.type This attribute shouldn't be put on ingested telemetry data except for certain legacy cases where it's required to distinguish entity types. Passing this field may interfere with entity detection, particularly if unrecognized values are sent in this field. While New Relic won't change the value if already present on the data, the field is not guaranteed to provide unambiguous filtering of telemetry at query-time. Existing entity definitions already have overlapping values, and we recommend avoiding entity.type in favor of other fields for filtering telemetry queries. This field is used by New Relic, meaning that invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. To learn how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Entity relationships Connections between entities are automatically created by New Relic based on what we can infer from your telemetry. For example, when two services that communicate using HTTP are instrumented with New Relic, we infer a \"calls/called-by\" relationship between them. When viewing a specific entity in either the New Relic Explorer, Navigator, or Lookout, you can see its Related entities in the entity's mini overview. This gives a visualization of the various entities connected directly to the current entity. You can quickly view important metrics for these related entities and navigate from one entity to another, through all the connected parts of your stack. Tip Learn more about how entities are related with our NerdGraph API. When relationships are not automatically detected, you can manually create them using the \"Add/edit related entities\" link in Related entities. Important Currently, you can only manually create calls/called-by relationships between service entities. Tip To manage manual relationships, you need to have modify and delete capabilities on entity relationships. If you don’t see the edit relationships button, contact your account admin. Which relationships are created? These are the relationships created between entities: Source: New Relic agent Relationship source Relationship type Relationship target Why is the relationship created? Application instrumented with a New Relic agent CALLS Application instrumented with a New Relic agent Relationships between applications monitored by New Relic agents are reported using the DurationByCaller metric. The callee reports the metric. For example, the metric DurationByCaller/Mobile/100/1234/HTTP/all indicates that the caller is APPLICATION 1234 for account 100. Application instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent An application (caller) that calls a service (callee) monitored by New Relic creates a relationship that's reported by the caller using the ExternalApp metric. For example, the metric ExternalApp/dirac.vips.net/100#1234/all indicates that the callee is APPLICATION 1234 for account 100. The metric is reported if the callee successfully responds to the caller. Service instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent When a New Relic agent detects that a service (caller) calls another service (callee) instrumented by New Relic, the callee reports the metric ClientApplication. For example, the metric ClientApplication/100#1234/all indicates that the caller is APPLICATION 1234 for account 100. Service instrumented with a New Relic agent CALLS A datastore instance When an application calls a datastore instance it creates a relationship reported with the DatastoreInstance metric. For example, the metric Datastore/instance/MySQL/172.16.16.3/3306 indicates the datastore instance is vendor: MySQL, host: 172.16.16.3, port: 3306. This metric also supports the legacy datastore instance format Datastore/instance/MySQL/172.16.16.3:3306. Currently we cannot determine whether the datastore instance is instrumented by New Relic and has an entity associated to it. APM agent SERVES Browser agent This relationship is created when an APM agent injects the browser agent into a page. Workload entity CONTAINS Any entity When a workload is created or updated, relationships for each of the entities that belong to the workload are created. Because some workloads are “dynamic” (defined by tags), relationships are re-created every 5 minutes. This way entities can join or leave the workload. Source: Infrastructure Relationship source Relationship type Relationship target Why is the relationship created? Infrastructure host HOSTS Application This relationship is created when an application is running in one or more hosts, and the infra agent is running in those hosts. Infrastructure host HOSTS Container This relationship is created when containers are running in one or more hosts, and the host is instrumented with the infra agent. Source: Synthetics monitor Relationship source Relationship type Relationship target Why is the relationship created? Synthetics Monitor CALLS Browser agent This relationship is created when a synthetics monitor checks a page instrumented with the browser agent. Synthetics Monitor CALLS APM application Agent events that contain the attribute nr.syntheticsMonitorId have been described as synthetics monitors (the source) interacting with an APM application (the target). If the header exists and the APM application Id exists, a relationship is created between the monitor and the app. Source: Kubernetes Relationship source Relationship type Relationship target Why is the relationship created? Cluster CONTAINS Pod This relationship is created when a pod is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Deployment This relationship is created when a deployment is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS DaemonSet This relationship is created when a DaemonSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS StatefulSet This relationship is created when a StatefulSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Host This relationship is created when a host that's part of a cluster is instrumented with the New Relic Kubernetes integration. Deployment CONTAINS Pod This relationship is created when a deployment creates a pod in a cluster instrumented with the New Relic Kubernetes integration. DaemonSet CONTAINS Pod This relationship is created when a DaemonSet is created a pod in a cluster instrumented with the New Relic Kubernetes integration. StatefulSet CONTAINS Pod This relationship is created when a StatefulSet creates a pod in a cluster instrumented with the New Relic Kubernetes integration. Pod CONTAINS Container This relationship is created when a pod creates a container in a cluster instrumented with the New Relic Kubernetes integration. Host HOSTS Pod This relationship is created when a pod is running in a host that's part of a cluster instrumented with the New Relic Kubernetes integration. Container HOSTS Application This relationship is created when an application is running in docker, and the hosts where docker is running are instrumented by the the infra agent. External services Relationship source Relationship type Relationship target Why is the relationship created? External service CALLS External service When the relationship is created, the external service reports a span with its name on the service.name attribute and the name of the service that initiates the call in the parent.service.name attribute. Application IS External service A relationship between an application and an external service is created so that users can navigate between them using the related entities component. Browser application instrumented with a New Relic agent CALLS External service A browser application reports an Ajax/HostTransaction metric when calling an external service (URL). Example metric: Ajax/HostTransaction/api.segment.io:443/CallbackTime' Cluster CONTAINS External service When the relationship is created, the external service reports a span with the attribute k8s.cluster.name, the name of the cluster. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span. Pod HOSTS External service When the relationship is created, the external service reports a span with the following attributes: service.name: The name of the service. k8s.cluster.name: The name of the cluster. k8s.pod.name: The name of the pod that’s running the service. k8s.namespace.name: The namespace where the pod was created. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.94127,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "What is an entity in <em>New</em> <em>Relic</em>?",
        "sections": "What is an entity in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ". If telemetry arrives with the entity.guid attribute already present, then <em>New</em> <em>Relic</em> will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. <em>One</em> <em>use</em> case for passing this attribute is to associate"
      },
      "id": "603ec160e7b9d295f72a07fc"
    },
    {
      "sections": [
        "Basic platform UI: search, share, chart UI, customize navigation, and more",
        "Observe your platform",
        "Customize the navigation bar and shortcuts",
        "Light and dark mode",
        "Search accounts and entities",
        "Chart and query features",
        "Share New Relic views with others",
        "Account and user settings",
        "Other UI experiences"
      ],
      "title": "Basic platform UI: search, share, chart UI, customize navigation, and more",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "b3cdcfc60a2821dfa5bee9766aba483cc3389398",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/basic-ui-features/",
      "published_at": "2021-10-13T08:56:03Z",
      "updated_at": "2021-08-21T09:29:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One has some basic UI functions that are widely available across the platform. Understanding these features will help you find and analyze your data more easily. Observe your platform New Relic One gives you full access to the data from all the entities in your stack. Go to the New Relic Explorer at one.newrelic.com to see a full list of entities, identify overall behaviors, filter them to locate sources of performance issues, or plan improvements for your system. Customize the navigation bar and shortcuts Select the edit icon at the right end of the navigation bar to customize your view. Home, Explorer, Browse data, Dashboards, and Alerts & AI are fixed, but you can favorite up to six more elements to display on the bar as well. The rest will go on the More group. Navigation shortcuts are a faster way to find entities and apps that are relevant to you. Mouse over any menu item for quick access to your favorite entities, those you recently visited, or just to search without having to navigate to a specific section. If you click on an entity, you can choose to open it in the same browser tab or in a new one. Light and dark mode See Light and dark mode. Search accounts and entities Access Quick find clicking the button, near the top right of the New Relic One UI. Some details about your search: You can search across all accounts that you have been granted access to in your organization. For more about account access, see Factors affecting access. Entities that cease to exist are available in search for eight days. If your organization has multiple accounts, use the account picker at the top left corner to select accounts. Chart and query features You can add most charts to a new or existing dashboard. Here are some query and chart features available across all or most of the platform: If you want to... Do this... Start querying your data Mouse over Browse data and select metrics, events, logs, or traces for a direct access to any of those types of data. Also, at the top of any UI page, select Query your data to access the data explorer and query builder. View a chart's query For some charts, you can view the NRQL query used to generate that chart. This can help you understand a chart better or use it as the basis for a new query. Choose time range Drag across a section of a chart to zoom in on that time range. Or, use the time picker in the top right corner of the UI to select pre-set time ranges or set a custom one. View chart details Mouse over a chart to see a pop-up with more detail. For some charts, selecting a point on the chart will take you to a UI page with more information about that metric. Hide or return chart elements To hide or unhide a displayed chart element, select that element's name below the chart. The chart display will adjust to reflect the absence or presence of that element. Share New Relic views with others Here are some options for sharing New Relic UI pages and visualizations. If you want to... Do this... Share UI pages and dashboards To share an entire New Relic UI page, click Share near the top of the UI to copy the URL. Share charts If New Relic charts are built with NRQL queries, they have a menu that exposes various options, including sharing options like Get as image and Get chart link. Some notes about sharing: The person you share with may not have access to view the data from that account. To solve that, someone on your team with New Relic user management abilities must add that person to the account. If someone can't access a custom dashboard, it may be that it is set to private. Read more about dashboard permissions. Some sharing options have associated time ranges, which may impact later viewings of it. For example, if you use a chart's Get chart link option and that chart is set to 'Last 30 minutes', when viewed it will show the last 30 minutes, not the time range displayed when it was shared. To share a specific time range, you must select that time range in the UI. Account and user settings To find account settings and user preferences, use the account dropdown, located at the top right of the UI, beside your user name. Other UI experiences This has been a look at a few basic platform UI experiences. For more about the UI, search for docs related to the specific New Relic solution you're using.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.63931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Share <em>New</em> <em>Relic</em> views with others",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": "<em>New</em> <em>Relic</em> <em>One</em> has some basic UI functions that are widely available across the platform. Understanding these features will help you find and analyze your data more easily. Observe your platform <em>New</em> <em>Relic</em> <em>One</em> gives you full access to the data from all the entities in your stack. Go to the <em>New</em> <em>Relic</em>"
      },
      "id": "603ec1f964441f5b0e4e8860"
    },
    {
      "sections": [
        "Dependencies UI: View an entity's upstream and downstream dependencies",
        "Requirements",
        "View dependencies"
      ],
      "title": "Dependencies UI: View an entity's upstream and downstream dependencies",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "2b2f328a6281bb155bcde07efec7f42eae943048",
      "image": "https://docs.newrelic.com/static/aabc5f64a91cc01b6e226df53c62458f/c1b63/new-relic-one-dependencies-UI.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/explore-downstream-dependencies-new-relic-one/",
      "published_at": "2021-10-13T08:57:23Z",
      "updated_at": "2021-08-21T09:29:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic Explorer, an entity's Dependencies page shows a filterable list of all the applications, services, databases, and hosts connected to the entity. It shows upstream and downstream dependencies, and provides paths to explore them. Similar to service maps, the dependencies page helps you understand how all of your upstream and downstream services are connected. It also uses the same color coding system used by service maps to show you what's performing well and what isn't. Requirements To view an entity's dependencies, make sure your app uses the minimum required APM agent version: C 1.0.0 or higher Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher View dependencies To view dependencies for applications, services, databases, and hosts connected to an entity: Go to one.newrelic.com, select Explorer, and select an entity. Select Dependencies. To drill down further, filter the apps, services, databases, or hosts. one.newrelic.com > Explorer > (select an entity) > Dependencies: View a filterable list of all the apps, services, databases, and hosts connected to an entity, and their color-coded health status. You can filter the dependencies page to view specific things that report to the entity. Dependencies include: Services: APM-monitored applications and services. Mobile applications: your mobile apps. Browser applications: your front-end browser apps. External services: external services monitored by APM. External services include out-of-process services such as web services, resources in the cloud, and any other network calls. Databases: your application's database and cache data. Databases are agentless. Because of this, alerts cannot be set for the database, as only the service call is reported to New Relic. Hosts: your infrastructure (servers and hosts).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.63931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": "In the <em>New</em> <em>Relic</em> Explorer, an entity&#x27;s Dependencies page shows a filterable list of all the applications, services, databases, and hosts connected to the entity. It shows upstream and downstream dependencies, and provides paths to explore them. Similar to service maps, the dependencies page helps"
      },
      "id": "603eb2e564441f0fe44e889b"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/core-concepts/dashboards-api-migration-insights-api-nerdgraph": [
    {
      "sections": [
        "Dashboards API",
        "Starting out with NerdGraph",
        "Operations",
        "Dashboard CRUD operations",
        "Dashboard page operations",
        "Other operations",
        "Limits",
        "Dashboard limits",
        "Dashboard page limits",
        "Widget limits",
        "Errors as first class citizens",
        "Errors as part of every mutation response"
      ],
      "title": "Dashboards API",
      "type": "docs",
      "tags": [
        "Dashboards",
        "Dashboards API"
      ],
      "external_id": "96f807b5a19101ec83176ceeb95b822eb8165896",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/dashboards-api/",
      "published_at": "2021-10-12T12:16:54Z",
      "updated_at": "2021-08-08T11:47:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Dashboards API allows you to create and manage dashboards. Starting out with NerdGraph If you're new to NerdGraph and GraphQL, you may want to first read our Introduction to NerdGraph. If you’re already familiar with the dashboards API, you can read Create dashboards with NerdGraph. When using NerdGraph, it helps to understand that our dashboards are entities that report data from other entities, such as monitored apps, hosts and services. Find the NerdGraph API explorer at api.newrelic.com/graphiql. Operations We have defined a granular GraphQL API that lets you execute different dashboard operations depending on their goal and scope. Dashboard CRUD operations Operation GraphQL operation type Notes actor > entity() query Get dashboard operation. You can get all dashboard and widget data for a given dashboard entity GUID. dashboardCreate() mutation Create dashboard operation. You can create a dashboard attached to a specific account by specifying all its elements, from metadata to widget configuration. dashboardUpdate() mutation Update dashboard operation. You can update an existing dashboard given a dashboard entity GUID. You need to specify the complete, updated dashboard elements, from metadata to widget configuration. dashboardDelete() mutation Delete dashboard operation. You can delete an existing dashboard given a dashboard entity GUID. This operation executes a logical delete that lets you recover your dashboard. dashboardUndelete() mutation Undelete dashboard operation. You can recover a previously deleted dashboard given a dashboard entity GUID. Dashboard page operations Operation GraphQL operation type Notes dashboardUpdatePage() mutation Update dashboard page operation. You can update one page of an existing dashboard given a dashboard page entity GUID. You need to specify the complete, updated dashboard page elements, from metadata to widget configuration. dashboardUpdateWidgetsInPage() mutation Update widgets operation. You can update a set of existing widgets of a dashboard page given a dashboard page entity GUID. You need to specify the set of widgets to be updated and their complete configuration. dashboardAddWidgetsToPage() mutation Add widgets operation. You can add a set of new widgets to a dashboard page given a dashboard page entity GUID. You need to specify the set of new widgets and their complete configuration. Other operations Operation GraphQL operation type Notes dashboardCreateSnapshotUrl() mutation Create dashboard page snapshot operation. You can create a public URL for a given dashboard page entity GUID. The dashboard page can then be accessed in the form of a static snapshot in the resulting public URL. actor > dashboard > liveUrls() query List all live URLs operation. You can get the complete list of live URLs you have access to. A live URL is a mechanism that allows you to share dashboard pages and widgets publicly with up-to-date or live data. dashboardWidgetRevokeLiveUrl() mutation Revoke widget live URL operation. You can revoke a previously created live URL of a widget. As a result, the live URL will become unavailable to the public. Limits We have limited the values you can set to some of the dashboard properties. This allows us to keep dashboards in good shape while boosting their usability. Dashboard limits Limit Value Maximum number of pages in a dashboard 20 Maximum length of a dashboard name 255 Maximum length of a dashboard description 1024 Dashboard page limits Limit Value Maximum number of widgets in a dashboard page 100 Maximum length of a dashboard page name 255 Maximum length of a dashboard page description 1024 Widget limits Limit Value Maximum length of a widget title 255 Maximum number of entities linked to a widget 1 Maximum number of queries in a widget 20 Maximum layout column of a widget 12 Minimum layout column of a widget 1 Minimum layout row of a widget 1 Maximum layout width of a widget 12 Minimum layout width of a widget 1 Maximum layout height of a widget 32 Minimum layout height of a widget 1 Errors as first class citizens All dashboard mutations offer a way to ask for errors when being executed. This means that you can perform your dashboard mutations and check the response in order to detect expected potential issues. Every error has a type and a description to help you identify what’s the source of the problem. Errors as part of every mutation response mutation { dashboardMutation(guid: \"MY_EXISTING_DASHBOARD_GUID\") { mutationResult { result } errors { description type } } } Copy Keep in mind that these are expected errors that we are aware of in advance. You should also check for unexpected errors that will be returned in the standard GraphQL errors field.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.34952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Dashboards</em> <em>API</em>",
        "sections": "<em>Dashboards</em> <em>API</em>",
        "tags": "<em>Dashboards</em> <em>API</em>",
        "body": "The <em>Dashboards</em> <em>API</em> allows you to create and manage <em>dashboards</em>. Starting out with <em>NerdGraph</em> If you&#x27;re new to <em>NerdGraph</em> and <em>Graph</em>QL, you may want to first read our Introduction to <em>NerdGraph</em>. If you’re already familiar with the <em>dashboards</em> <em>API</em>, you can read Create <em>dashboards</em> with <em>NerdGraph</em>. When using"
      },
      "id": "60dd3c8328ccbc8f1a71b46c"
    },
    {
      "sections": [
        "NerdGraph tutorial: Manage log parsing rules",
        "Data parsing schema",
        "Example query of log parsing rules",
        "Create parsing rules",
        "Update parsing rules",
        "Delete parsing rules"
      ],
      "title": "NerdGraph tutorial: Manage log parsing rules",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples",
        "Logs"
      ],
      "external_id": "e7c9f3ed8aeef68f62b26b583bb633522585ad44",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/examples/nerdgraph-log-parsing-rules-tutorial/",
      "published_at": "2021-10-17T12:46:47Z",
      "updated_at": "2021-10-17T11:35:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NerdGraph at api.newrelic.com/graphiql to create, query, and manage your parsing rules for logs. NerdGraph is our GraphQL-format API explorer. This document includes: The parsing rule schema An example query of parsing rules How to create a parsing rule How to update a parsing rule How to delete a parsing rule Data parsing schema Available parsing rule fields include: Fields Description id Unique data parsing identifier. parsingRules The name of the parsing rule. description A description of what this parsing rule represents. grok The Grok pattern for this parsing rule. For example, you can include the logtype for the Grok pattern you are using with a built-in parsing ruleset, such as logtype = 'alb'. However, you are not limited to using logtype; any attribute can be used as matching criteria. lucene The search value used for your Grok pattern from the New Relic UI; for example, logtype:alb. accountId The New Relic account ID for the user. nrql The NRQL query used for queries, if applicable; for example: \"SELECT * FROM Log WHERE `logtype` = 'testLogs'\" Copy createdBy The user who created the rule. Optional: You can also include email, gravatar, id, and name with this. updatedBy The user who last updated the rule. Optional: You can also include email, gravatar, id, and name with this. enabled Whether or not this parsing rule is enabled. deleted Whether or not this parsing rule has been deleted. Deleting a parsing rule does not delete the already routed logs. Example query of log parsing rules This NerdGraph API request example gets all of the parsing rules for a given account. In this example, all of the available fields are requested. { \"data\": { \"actor\": { \"account\": { \"id\": 12345678, \"logConfigurations\": { \"parsingRules\": [ { \"accountId\": 12345678, \"createdBy\": { \"email\": \"myname@ncompany.com\", \"gravatar\": \"https://secure.gravatar.com/avatar/d0a88888888d666d111111111111111f\", \"id\": 7777777, \"name\": \"My Name\" }, \"deleted\": false, \"description\": \"Integer Test\", \"enabled\": true, \"grok\": \"source=%{NUMBER:test:int}\", \"id\": \"123\", \"lucene\": , \"nrql\": \"SELECT * FROM Log WHERE `logtype` = 'integer'\", \"updatedAt\": \"2021-08-23T17:25:06.553Z[UTC]\", \"updatedBy\": { \"email\": \"myname@ncompany.com\", \"gravatar\": \"https://secure.gravatar.com/avatar/d0a88888888d666d111111111111111f\", \"id\": 7777777, \"name\": \"My Name\" } } ... Copy Create parsing rules This example creates a new log parsing rule. Before creating the rule, be sure to review the documentation about log parsing and built-in parsing rulesets. mutation { logConfigurationsCreateParsingRule(accountId: 12345678, rule: {description: \"example parsing rule\", enabled: false, grok: \"sampleattribute=%{NUMBER:test:int}\", lucene: \"logtype:testLogs\", nrql: \"SELECT * FROM Log WHERE `logtype` = 'testLogs'\"}) { rule { id enabled description grok } errors { message type } } } Copy Update parsing rules This example updates the parsing rule whose id is \"123\". You can update any of the following fields as needed: description, enabled, grok, lucene, and nrql. mutation { logConfigurationsUpdateParsingRule(accountId: 12345678, rule: {description: \"example parsing rule\", enabled: false, grok: \"sampleattribute=%{NUMBER:test:int}\", lucene: \"logtype:testLogs\", nrql: \"SELECT * FROM Log WHERE `logtype` = 'testLogs'\"}, id: \"123\") { errors { message type } rule { id grok description enabled } } } Copy Delete parsing rules Deleting a parsing rule doesn't delete the already persisted data. The data is retained for a given period of time defined by the retentionPolicy field. mutation { logConfigurationsDeleteParsingRule(accountId: 123456789, id: \"123\") { errors { message type } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.93396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Manage log parsing rules",
        "sections": "<em>NerdGraph</em> tutorial: Manage log parsing rules",
        "tags": "<em>NerdGraph</em>",
        "body": "You can use <em>NerdGraph</em> at <em>api</em>.newrelic.com&#x2F;graphiql to create, query, and manage your parsing rules for logs. <em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> explorer. This document includes: The parsing rule schema An example query of parsing rules How to create a parsing rule How to update a parsing rule How"
      },
      "id": "616c0a8828ccbc63870024f2"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-10-17T01:38:28Z",
      "title": "Collect data",
      "updated_at": "2021-10-14T01:38:28Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes   Use custom attributes for deeper analysis Create custom events 5 min Define, visualize, and get alerts on the data you want using custom events Collect data - any source 15 min APIs, agents, OS emitters - get any data Monitor your network devices with New Relic 45 min Monitor your network devices with New Relic Build queries with NerdGraph 25 min Try NerdGraph and build the queries you need Query data with NRQL 10 min Query default data, custom events, and attributes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.25888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " network devices with New Relic Build queries with <em>NerdGraph</em> 25 min Try <em>NerdGraph</em> and build the queries you need Query data with NRQL 10 min Query default data, custom events, and attributes"
      },
      "id": "6091fa38196a67a932d52a29"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-explorer-view-performance-across-apps-services-hosts": [
    {
      "sections": [
        "What is an entity in New Relic?",
        "What's an entity?",
        "Find and explore entities and entity data",
        "Tip",
        "Group and organize entities",
        "Customize entity data with entity synthesis",
        "Reserved attributes for synthesized entities",
        "Entity relationships",
        "Important",
        "Which relationships are created?",
        "Source: New Relic agent",
        "Source: Infrastructure",
        "Source: Synthetics monitor",
        "Source: Kubernetes",
        "External services"
      ],
      "title": "What is an entity in New Relic?",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "52a3e08bc9103c717d27b153e4fd4f547d6ecc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/",
      "published_at": "2021-10-12T15:06:27Z",
      "updated_at": "2021-09-01T17:25:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic monitoring is built around the concept of entities. In this doc, you'll learn how we define entities, what you can do with them, and how you can create your own entities or groupings of entities. What's an entity? From a New Relic perspective, entity is purposefully a broad concept. An entity is anything that a) reports data to New Relic or that contains data that we have access to, and b) is something we've identified with a unique entity ID. For most entities, the ID is indicated by the attribute entityGuid. An entity can be any fundamental data-reporting component, like an application, a host, or a database service, but it can also refer to larger groupings of those components. For example, to monitor a data center, you could aggregate those hosts in New Relic to be a workload (a custom grouping of entities). That workload is, itself, also an entity. Also very important is the relationships between entities. Our behind-the-scenes relationship-mapping helps us understand how entities are connected, how they affect each other. And this allows us to give you the power to configure how any data you're bringing in is related to existing entities, or how it's related to other entities. Our focus on entities and their relationships is important because our goal is to give you practical information about your business-important entities, and not give you an unhelpfully huge stream of data from a huge list of monitored things. With more insight at the entity level, you can better monitor and troubleshoot complex, modern systems. Find and explore entities and entity data Tip You can create new entity types for monitoring any data source. Learn more about entity synthesis. Some tips for finding and understanding entity data: To find an entity's entityGuid and entityName and other metadata: from any list of monitored entities in the New Relic Explorer, click an entity's icon, and click See metadata and tags. For most entities, its GUID is reported as the attribute entityGuid. For workloads, it's workloadGuid. You can run NRQL queries to find entities by their GUID. To see connections between entities, you have several options: When viewing an entity in the UI, use the Related entities UI. Service maps. Distributed tracing. Our NerdGraph API. To group entities together, see Group entities. Customize entity definitions and relationships. To learn technical details about entity types, see our GitHub repo. In an entity type's definition file, you'll see information like: The domain: for example, APM, or Infra. Its type: for example, Application or AWSECSCONTAINERINSTANCE. Default tags. The entityExpirationTime: how long data from that entity lasts in the UI, which is different from database data retention. Group and organize entities You can place entities into groups that reflect business-important relationships in your organization. For example, you might group all entities related to a specific team or department, or related to a specific service. Or you might group multiple hosts together to reflect their grouping in a data center. To group your entities, see: Tag entities. Create workloads, which allow you to group business-important sets of entities. Create entities and customize entity data Customize entity data with entity synthesis If you have telemetry from any source that's not supported by New Relic out of the box, you can propose a mapping for it. Once approved, any telemetry received by New Relic that matches your definition file will be synthesized into an entity. To learn more: For reserved attributes and how entity relationships are defined, keep reading this doc. For how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Reserved attributes for synthesized entities These attributes are meant to be synthesized from the telemetry we receive. Do not set them unless you're aware of the implications and consequences. Attribute Description entity.guid Generally, you should not set this attribute field on your telemetry data. New Relic may add this field to ingested data to store a unique identifier for the entity associated with the data point. If telemetry arrives with the entity.guid attribute already present, then New Relic will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. One use case for passing this attribute is to associate ingested telemetry with an entity already created by New Relic. When the entity.guid attribute is sent, the value will override New Relic’s entity identification system (such as entity synthesis definitions) and instead will use the attribute as the data. entity.name This attribute shouldn't be put on ingested telemetry data unless you're trying to override the entity name that would have been selected by New Relic’s entity identification system. While New Relic won't change the value if it's already present on the data, New Relic may add the attribute to your data. Therefore invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. If this field is present on ingested telemetry, its value will be used to name the entity associated with the data point. This name will be used instead of the name selected by New Relic’s entity identification system (for example, entity synthesis definitions). Note that many entities use the name as part of their identification, so changing this field may result in the generation of a new entity. entity.type This attribute shouldn't be put on ingested telemetry data except for certain legacy cases where it's required to distinguish entity types. Passing this field may interfere with entity detection, particularly if unrecognized values are sent in this field. While New Relic won't change the value if already present on the data, the field is not guaranteed to provide unambiguous filtering of telemetry at query-time. Existing entity definitions already have overlapping values, and we recommend avoiding entity.type in favor of other fields for filtering telemetry queries. This field is used by New Relic, meaning that invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. To learn how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Entity relationships Connections between entities are automatically created by New Relic based on what we can infer from your telemetry. For example, when two services that communicate using HTTP are instrumented with New Relic, we infer a \"calls/called-by\" relationship between them. When viewing a specific entity in either the New Relic Explorer, Navigator, or Lookout, you can see its Related entities in the entity's mini overview. This gives a visualization of the various entities connected directly to the current entity. You can quickly view important metrics for these related entities and navigate from one entity to another, through all the connected parts of your stack. Tip Learn more about how entities are related with our NerdGraph API. When relationships are not automatically detected, you can manually create them using the \"Add/edit related entities\" link in Related entities. Important Currently, you can only manually create calls/called-by relationships between service entities. Tip To manage manual relationships, you need to have modify and delete capabilities on entity relationships. If you don’t see the edit relationships button, contact your account admin. Which relationships are created? These are the relationships created between entities: Source: New Relic agent Relationship source Relationship type Relationship target Why is the relationship created? Application instrumented with a New Relic agent CALLS Application instrumented with a New Relic agent Relationships between applications monitored by New Relic agents are reported using the DurationByCaller metric. The callee reports the metric. For example, the metric DurationByCaller/Mobile/100/1234/HTTP/all indicates that the caller is APPLICATION 1234 for account 100. Application instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent An application (caller) that calls a service (callee) monitored by New Relic creates a relationship that's reported by the caller using the ExternalApp metric. For example, the metric ExternalApp/dirac.vips.net/100#1234/all indicates that the callee is APPLICATION 1234 for account 100. The metric is reported if the callee successfully responds to the caller. Service instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent When a New Relic agent detects that a service (caller) calls another service (callee) instrumented by New Relic, the callee reports the metric ClientApplication. For example, the metric ClientApplication/100#1234/all indicates that the caller is APPLICATION 1234 for account 100. Service instrumented with a New Relic agent CALLS A datastore instance When an application calls a datastore instance it creates a relationship reported with the DatastoreInstance metric. For example, the metric Datastore/instance/MySQL/172.16.16.3/3306 indicates the datastore instance is vendor: MySQL, host: 172.16.16.3, port: 3306. This metric also supports the legacy datastore instance format Datastore/instance/MySQL/172.16.16.3:3306. Currently we cannot determine whether the datastore instance is instrumented by New Relic and has an entity associated to it. APM agent SERVES Browser agent This relationship is created when an APM agent injects the browser agent into a page. Workload entity CONTAINS Any entity When a workload is created or updated, relationships for each of the entities that belong to the workload are created. Because some workloads are “dynamic” (defined by tags), relationships are re-created every 5 minutes. This way entities can join or leave the workload. Source: Infrastructure Relationship source Relationship type Relationship target Why is the relationship created? Infrastructure host HOSTS Application This relationship is created when an application is running in one or more hosts, and the infra agent is running in those hosts. Infrastructure host HOSTS Container This relationship is created when containers are running in one or more hosts, and the host is instrumented with the infra agent. Source: Synthetics monitor Relationship source Relationship type Relationship target Why is the relationship created? Synthetics Monitor CALLS Browser agent This relationship is created when a synthetics monitor checks a page instrumented with the browser agent. Synthetics Monitor CALLS APM application Agent events that contain the attribute nr.syntheticsMonitorId have been described as synthetics monitors (the source) interacting with an APM application (the target). If the header exists and the APM application Id exists, a relationship is created between the monitor and the app. Source: Kubernetes Relationship source Relationship type Relationship target Why is the relationship created? Cluster CONTAINS Pod This relationship is created when a pod is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Deployment This relationship is created when a deployment is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS DaemonSet This relationship is created when a DaemonSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS StatefulSet This relationship is created when a StatefulSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Host This relationship is created when a host that's part of a cluster is instrumented with the New Relic Kubernetes integration. Deployment CONTAINS Pod This relationship is created when a deployment creates a pod in a cluster instrumented with the New Relic Kubernetes integration. DaemonSet CONTAINS Pod This relationship is created when a DaemonSet is created a pod in a cluster instrumented with the New Relic Kubernetes integration. StatefulSet CONTAINS Pod This relationship is created when a StatefulSet creates a pod in a cluster instrumented with the New Relic Kubernetes integration. Pod CONTAINS Container This relationship is created when a pod creates a container in a cluster instrumented with the New Relic Kubernetes integration. Host HOSTS Pod This relationship is created when a pod is running in a host that's part of a cluster instrumented with the New Relic Kubernetes integration. Container HOSTS Application This relationship is created when an application is running in docker, and the hosts where docker is running are instrumented by the the infra agent. External services Relationship source Relationship type Relationship target Why is the relationship created? External service CALLS External service When the relationship is created, the external service reports a span with its name on the service.name attribute and the name of the service that initiates the call in the parent.service.name attribute. Application IS External service A relationship between an application and an external service is created so that users can navigate between them using the related entities component. Browser application instrumented with a New Relic agent CALLS External service A browser application reports an Ajax/HostTransaction metric when calling an external service (URL). Example metric: Ajax/HostTransaction/api.segment.io:443/CallbackTime' Cluster CONTAINS External service When the relationship is created, the external service reports a span with the attribute k8s.cluster.name, the name of the cluster. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span. Pod HOSTS External service When the relationship is created, the external service reports a span with the following attributes: service.name: The name of the service. k8s.cluster.name: The name of the cluster. k8s.pod.name: The name of the pod that’s running the service. k8s.namespace.name: The namespace where the pod was created. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.73877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "What is an entity in <em>New</em> <em>Relic</em>?",
        "sections": "What is an entity in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ". If telemetry arrives with the entity.guid attribute already present, then <em>New</em> <em>Relic</em> will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. <em>One</em> <em>use</em> case for passing this attribute is to associate"
      },
      "id": "603ec160e7b9d295f72a07fc"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-10-12T15:16:12Z",
      "updated_at": "2021-08-21T09:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters When using our API to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.21648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to filter the UI <em>Use</em> the filter field at the top of the <em>New</em> <em>Relic</em> Explorer to filter down to the entities you care about. You can <em>use</em> multiple filter conditions. To filter down to certain entities using tags: From <em>one</em>.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "sections": [
        "New Relic Lookout: Monitor your estate at a glance",
        "Why it matters",
        "Requirements",
        "Get started with New Relic Lookout",
        "Circle visualization and table view",
        "Abnormal golden signals",
        "Instant search",
        "Change view",
        "Drill down into the details",
        "Performance tab",
        "Abnormal History tab",
        "Correlations tab",
        "Profile tab",
        "Traces tab",
        "Create a custom view",
        "Query: Compare the last 15 minutes to the same time 1 day ago",
        "Query: Compare a specific time range to the same range a month ago",
        "Example: Unusual increases in error count"
      ],
      "title": "New Relic Lookout: Monitor your estate at a glance",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "9193dcc8851c185ff5d96f6f93ab412bd1be69e9",
      "image": "https://docs.newrelic.com/static/178b37068bad2a68cff027c8bdcf663a/c1b63/lookout-intro.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-lookout-monitor-your-estate-glance/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-08-21T09:27:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Lookout provides visibility into your entire estate. It doesn't require any configuration — you can query anything in your estate that matters to you right now and understand your system as a whole, or dive deep into causes and effects, so you can quickly get the data you need to take action. Know exactly where to focus your attention with New Relic Lookout. The brighter the color, the more severe the change, and the bigger the size, the bigger the scale. Then dig deeper with correlations and abnormal history to see how it impacts your whole system—no configuration needed. Why it matters New Relic Lookout helps software teams of any size discover potential issues before they have an impact. Fill gaps in monitoring with full coverage out-of-the-box, no configuration or setup required. Immediately see anything deviating from normal across your entire estate. Proactively spot emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in New Relic database (NRDB), including third-party, open, and custom data. Launch into other areas of New Relic One for deeper understanding Requirements New Relic Lookout requires Pro or Enterprise edition. If you are on Standard edition, you can still use the New Relic Lookout view in the New Relic Explorer. If you want to see data spanning 13-months, correlations, profiles, traces, and other details, you must upgrade to a higher edition. Get started with New Relic Lookout To access New Relic Lookout, click the Apps button in New Relic One and locate the New Relic Lookout launcher. You can also access New Relic Lookout directly from the New Relic One header bar, via the More dropdown. Enablement of key service performance indicator data is required for New Relic Lookout to provide value from the data you already have. The default view provides insight into three key Service performance indicators broken down by application: throughput, response time, and errors. These metrics are analyzed to show how the data has behaved during the last five minutes compared to the prior hour. one.newrelic.com > Apps > New Relic Lookout: Anything that significantly deviates from the trend is automatically discovered by New Relic Lookout, which doesn't require any configuration. Circle visualization and table view Each application (or other facet) is represented by a circle. The size of the circles indicate the magnitude of the signal for that application and the color indicates whether the value has significantly decreased or increased in the last five minutes, based on the standard deviation of the prior hour (default evaluation and comparison time windows.) Please note that the type of signal is important when interpreting your results. When you first look at the legend below, you might be tempted to interpret yellow as good and dark purple as bad, but that is not always the case. Here are some examples: In the APM/services golden signals, a dark yellow circle in Throughput might signify that something bad has occurred and led to a drop in traffic. At the same time, a dark purple circle might also be concerning due to unexpected load. Both are significant findings worth exploring. In browser golden signals, a dark purple circle in Page Views might be great, as you are seeing more traffic to your site! With errors golden signals (in all entity types), a large circle, even if gray (not deviating from normal volume), is worth exploring because a high count of errors in your system is important to investigate. The legend allows you to change the colors used to highlight deviating services To change the color palette, click the gear icon by the low-high color legend. This allows you to change the colors used to highlight deviating services. To get a table view of the same data, click the toggle on the right. You can also hover over each color to filter the view by degree lower or higher deviance. Abnormal golden signals On the right, New Relic Lookout displays the most significantly deviating applications (or other facet) in a side panel, weighted by both the magnitude of the performance indicators and the scale of their deviations. Details include the name of the key performance indicator, their magnitude during the recent time window, and the difference between the averages from one time compared to the other. Instant search Click the magnifying glass icon in the side panel to open a search box. Typing into the search box filters the circles, table, and abnormal signals to applications (or other facets) that contain the text. This is a good way to quickly zoom to various subsystems. New Relic Lookout doesn't rerun the analysis when using the instant search. Change view Click the Change View button on the right side panel. The panel that appears shows you all the entity-specific golden signals you can toggle between out of the box. By choosing the Browser Golden Signal or other views, you can change from the default view. Each new view will have the golden signals appropriate for that entity type. Drill down into the details To analyze an application or facet, click a circle, table row, or abnormal golden signal. The details panel shows the degree of deviation of the performance indicator, a link to the affected entity, and recent alert and deployment activity for that entity, when available. There’s also an indication of whether the selected evaluation time period would be abnormal or not in reference to other comparison time windows, such as the same time yesterday or the same time last week. This allows you to quickly see if the abnormal behavior is odd in general, or just based on the comparison time window. Performance tab The default tab shows charts for other key performance indicators for the selected application or facet. The charts compare the two time windows being analyzed. You can click their titles to rerun the analysis, focusing on the selected key performance indicator. When the target is a New Relic One application, we show the top transactions, error classes, external services, and database operations, alongside links to the relevant New Relic One features. Abnormal History tab This section analyzes past performance of the selected signal and calls out any time periods with notable abnormalities. Each card represents an abnormal time window and can be clicked for more details. The charts will display any relevant violations and deployments in New Relic. Correlations tab New Relic Lookout can find other signals that began behaving differently around the same time as the selected signal for that entity type. Clicking the name of the signal reruns the analysis, focusing on that key performance indicator. The chart titles link to New Relic One when there’s an associated entity in your account. Note that correlations currently do not analyze across accounts. The correlated signals displayed are for others in the account of the original application you are viewing. This helps focus the data on correlations that are more likely related to your issue. Profile tab Based on the same technology as New Relic’s error profiles, this tab compares the last five minutes to the prior hour by default (or whatever time windows you’ve selected with query editing) and surfaces any attributes that have significantly different distributions in the events being targeted by the selected signal. For example, if a custom attribute indicated that a recent throughput spike came from one user, that would surface highly in Profiles if most of the traffic usually comes from many users. Traces tab If the entity has distributed traces configured and available in the selected evaluated time window, the Traces section is enabled. Each card shows a summary of a trace and can be clicked for details. The Explore all traces links to the distributed traces application, filtered to the selected entity. Create a custom view To target signals and time windows beyond the default values, click the Change view button and select Custom view. To create your own view: Select the account or subaccount. Select the data type (metrics or events). Different functionality is available depending on the type. In View a chart with, select the metric or event you are interested in. Default is golden signals (throughput, response time, and errors). You can also build custom queries (filters) to target a signal that isn't on the list. In Facet by, select what the circles represent. Default is appName, but you can also choose host or any other facetable attribute available for the signal you’ve selected. If you plan to save/favorite this new view, provide a name in the Name your view box. Keep in mind that you can edit this view at any time using the pencil icon. The default time windows analyzed by New Relic Lookout are the last five minutes compared to the hour before. Use the time controls (View data from and Compare data to) to target other time windows. one.newrelic.com > Apps > New Relic Lookout: All event and metric data in the New Relic database can be queried using the Edit query feature. Click Analyze to begin analyzing the signal you’ve selected. You can also create your own query: Create your query. This query is comparing data from the past thirty minutes to data from the same range a day ago. Change from Basic to Advanced after clicking the Custom view button. Select the data type (metrics or events). Different functionality is available depending on the type. Enter your query using NRQL. Please note that not all NRQL features are available in the Lookout Advanced query feature. By default, the system will run this query using the last five minutes of data compared to the previous hour. Some examples of the syntax for changing the comparison and evaluation time windows are below. Click Analyze to begin analyzing the signal you’ve selected. Query: Compare the last 15 minutes to the same time 1 day ago Please note that the UNTIL NOW portion is required here unlike in standard NRQL. Without the UNTIL NOW added, the system will query a 5 minute slice of data starting 15 minutes ago SINCE 15 minutes AGO UNTIL NOW COMPARE WITH 1 day ago Copy Query: Compare a specific time range to the same range a month ago SINCE '2021-03-07 07:00:00-0500' UNTIL '2021-03-08 07:00:00-0500' COMPARE WITH 1 month ago Copy Or: SINCE 'today at midnight' UNTIL 'now' COMPARE WITH 1 MONTH AGO Copy Example: Unusual increases in error count The default view of New Relic Lookout shows application status across your estate, comparing the last five minutes to the hour before. Under regular operation, most large systems may have a handful of abnormalities, but usually most things will indicate normal behavior. Suddenly, several circles begin to change to red under the Errors section. This indicates that several applications are experiencing unusual increases in error count. It may be that one or two circles for important systems are red, and perhaps much larger than they usually appear. Clicking one of these can provide more information on what is happening. You might see that the error rate is substantially elevated, even thousands of percent higher than normal. To troubleshoot this issue, here's what you might discover in the New Relic Lookout tabs: Performance would show you data about other signals, illuminating the characteristics of the change in system dynamics. Correlations would surface other applications that are affected and how, as well as opportunities to pivot to other applications that may be closer to the underlying causes. Traces, in turn, would show distributed traces, which can provide specific examples of traffic running through those systems. Abnormal history would show other times in the past week with elevated errors, showing whether or not this problem happens regularly, such as every day at the same time or whenever there is a deployment. Profiles might show that all or most of the new errors share common properties, such as all being isolated to just one region/account/user. Combining the information from these sections, not only can you get a sense of what is going on, but also where to focus actions to resolve the problem.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.21616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "sections": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in <em>New</em> <em>Relic</em> database (NRDB), including third-party, open, and custom data. Launch into other areas of <em>New</em> <em>Relic</em> <em>One</em> for deeper"
      },
      "id": "603e821e64441f5a444e8845"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-lookout-monitor-your-estate-glance": [
    {
      "sections": [
        "What is an entity in New Relic?",
        "What's an entity?",
        "Find and explore entities and entity data",
        "Tip",
        "Group and organize entities",
        "Customize entity data with entity synthesis",
        "Reserved attributes for synthesized entities",
        "Entity relationships",
        "Important",
        "Which relationships are created?",
        "Source: New Relic agent",
        "Source: Infrastructure",
        "Source: Synthetics monitor",
        "Source: Kubernetes",
        "External services"
      ],
      "title": "What is an entity in New Relic?",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "52a3e08bc9103c717d27b153e4fd4f547d6ecc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/",
      "published_at": "2021-10-12T15:06:27Z",
      "updated_at": "2021-09-01T17:25:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic monitoring is built around the concept of entities. In this doc, you'll learn how we define entities, what you can do with them, and how you can create your own entities or groupings of entities. What's an entity? From a New Relic perspective, entity is purposefully a broad concept. An entity is anything that a) reports data to New Relic or that contains data that we have access to, and b) is something we've identified with a unique entity ID. For most entities, the ID is indicated by the attribute entityGuid. An entity can be any fundamental data-reporting component, like an application, a host, or a database service, but it can also refer to larger groupings of those components. For example, to monitor a data center, you could aggregate those hosts in New Relic to be a workload (a custom grouping of entities). That workload is, itself, also an entity. Also very important is the relationships between entities. Our behind-the-scenes relationship-mapping helps us understand how entities are connected, how they affect each other. And this allows us to give you the power to configure how any data you're bringing in is related to existing entities, or how it's related to other entities. Our focus on entities and their relationships is important because our goal is to give you practical information about your business-important entities, and not give you an unhelpfully huge stream of data from a huge list of monitored things. With more insight at the entity level, you can better monitor and troubleshoot complex, modern systems. Find and explore entities and entity data Tip You can create new entity types for monitoring any data source. Learn more about entity synthesis. Some tips for finding and understanding entity data: To find an entity's entityGuid and entityName and other metadata: from any list of monitored entities in the New Relic Explorer, click an entity's icon, and click See metadata and tags. For most entities, its GUID is reported as the attribute entityGuid. For workloads, it's workloadGuid. You can run NRQL queries to find entities by their GUID. To see connections between entities, you have several options: When viewing an entity in the UI, use the Related entities UI. Service maps. Distributed tracing. Our NerdGraph API. To group entities together, see Group entities. Customize entity definitions and relationships. To learn technical details about entity types, see our GitHub repo. In an entity type's definition file, you'll see information like: The domain: for example, APM, or Infra. Its type: for example, Application or AWSECSCONTAINERINSTANCE. Default tags. The entityExpirationTime: how long data from that entity lasts in the UI, which is different from database data retention. Group and organize entities You can place entities into groups that reflect business-important relationships in your organization. For example, you might group all entities related to a specific team or department, or related to a specific service. Or you might group multiple hosts together to reflect their grouping in a data center. To group your entities, see: Tag entities. Create workloads, which allow you to group business-important sets of entities. Create entities and customize entity data Customize entity data with entity synthesis If you have telemetry from any source that's not supported by New Relic out of the box, you can propose a mapping for it. Once approved, any telemetry received by New Relic that matches your definition file will be synthesized into an entity. To learn more: For reserved attributes and how entity relationships are defined, keep reading this doc. For how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Reserved attributes for synthesized entities These attributes are meant to be synthesized from the telemetry we receive. Do not set them unless you're aware of the implications and consequences. Attribute Description entity.guid Generally, you should not set this attribute field on your telemetry data. New Relic may add this field to ingested data to store a unique identifier for the entity associated with the data point. If telemetry arrives with the entity.guid attribute already present, then New Relic will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. One use case for passing this attribute is to associate ingested telemetry with an entity already created by New Relic. When the entity.guid attribute is sent, the value will override New Relic’s entity identification system (such as entity synthesis definitions) and instead will use the attribute as the data. entity.name This attribute shouldn't be put on ingested telemetry data unless you're trying to override the entity name that would have been selected by New Relic’s entity identification system. While New Relic won't change the value if it's already present on the data, New Relic may add the attribute to your data. Therefore invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. If this field is present on ingested telemetry, its value will be used to name the entity associated with the data point. This name will be used instead of the name selected by New Relic’s entity identification system (for example, entity synthesis definitions). Note that many entities use the name as part of their identification, so changing this field may result in the generation of a new entity. entity.type This attribute shouldn't be put on ingested telemetry data except for certain legacy cases where it's required to distinguish entity types. Passing this field may interfere with entity detection, particularly if unrecognized values are sent in this field. While New Relic won't change the value if already present on the data, the field is not guaranteed to provide unambiguous filtering of telemetry at query-time. Existing entity definitions already have overlapping values, and we recommend avoiding entity.type in favor of other fields for filtering telemetry queries. This field is used by New Relic, meaning that invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. To learn how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Entity relationships Connections between entities are automatically created by New Relic based on what we can infer from your telemetry. For example, when two services that communicate using HTTP are instrumented with New Relic, we infer a \"calls/called-by\" relationship between them. When viewing a specific entity in either the New Relic Explorer, Navigator, or Lookout, you can see its Related entities in the entity's mini overview. This gives a visualization of the various entities connected directly to the current entity. You can quickly view important metrics for these related entities and navigate from one entity to another, through all the connected parts of your stack. Tip Learn more about how entities are related with our NerdGraph API. When relationships are not automatically detected, you can manually create them using the \"Add/edit related entities\" link in Related entities. Important Currently, you can only manually create calls/called-by relationships between service entities. Tip To manage manual relationships, you need to have modify and delete capabilities on entity relationships. If you don’t see the edit relationships button, contact your account admin. Which relationships are created? These are the relationships created between entities: Source: New Relic agent Relationship source Relationship type Relationship target Why is the relationship created? Application instrumented with a New Relic agent CALLS Application instrumented with a New Relic agent Relationships between applications monitored by New Relic agents are reported using the DurationByCaller metric. The callee reports the metric. For example, the metric DurationByCaller/Mobile/100/1234/HTTP/all indicates that the caller is APPLICATION 1234 for account 100. Application instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent An application (caller) that calls a service (callee) monitored by New Relic creates a relationship that's reported by the caller using the ExternalApp metric. For example, the metric ExternalApp/dirac.vips.net/100#1234/all indicates that the callee is APPLICATION 1234 for account 100. The metric is reported if the callee successfully responds to the caller. Service instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent When a New Relic agent detects that a service (caller) calls another service (callee) instrumented by New Relic, the callee reports the metric ClientApplication. For example, the metric ClientApplication/100#1234/all indicates that the caller is APPLICATION 1234 for account 100. Service instrumented with a New Relic agent CALLS A datastore instance When an application calls a datastore instance it creates a relationship reported with the DatastoreInstance metric. For example, the metric Datastore/instance/MySQL/172.16.16.3/3306 indicates the datastore instance is vendor: MySQL, host: 172.16.16.3, port: 3306. This metric also supports the legacy datastore instance format Datastore/instance/MySQL/172.16.16.3:3306. Currently we cannot determine whether the datastore instance is instrumented by New Relic and has an entity associated to it. APM agent SERVES Browser agent This relationship is created when an APM agent injects the browser agent into a page. Workload entity CONTAINS Any entity When a workload is created or updated, relationships for each of the entities that belong to the workload are created. Because some workloads are “dynamic” (defined by tags), relationships are re-created every 5 minutes. This way entities can join or leave the workload. Source: Infrastructure Relationship source Relationship type Relationship target Why is the relationship created? Infrastructure host HOSTS Application This relationship is created when an application is running in one or more hosts, and the infra agent is running in those hosts. Infrastructure host HOSTS Container This relationship is created when containers are running in one or more hosts, and the host is instrumented with the infra agent. Source: Synthetics monitor Relationship source Relationship type Relationship target Why is the relationship created? Synthetics Monitor CALLS Browser agent This relationship is created when a synthetics monitor checks a page instrumented with the browser agent. Synthetics Monitor CALLS APM application Agent events that contain the attribute nr.syntheticsMonitorId have been described as synthetics monitors (the source) interacting with an APM application (the target). If the header exists and the APM application Id exists, a relationship is created between the monitor and the app. Source: Kubernetes Relationship source Relationship type Relationship target Why is the relationship created? Cluster CONTAINS Pod This relationship is created when a pod is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Deployment This relationship is created when a deployment is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS DaemonSet This relationship is created when a DaemonSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS StatefulSet This relationship is created when a StatefulSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Host This relationship is created when a host that's part of a cluster is instrumented with the New Relic Kubernetes integration. Deployment CONTAINS Pod This relationship is created when a deployment creates a pod in a cluster instrumented with the New Relic Kubernetes integration. DaemonSet CONTAINS Pod This relationship is created when a DaemonSet is created a pod in a cluster instrumented with the New Relic Kubernetes integration. StatefulSet CONTAINS Pod This relationship is created when a StatefulSet creates a pod in a cluster instrumented with the New Relic Kubernetes integration. Pod CONTAINS Container This relationship is created when a pod creates a container in a cluster instrumented with the New Relic Kubernetes integration. Host HOSTS Pod This relationship is created when a pod is running in a host that's part of a cluster instrumented with the New Relic Kubernetes integration. Container HOSTS Application This relationship is created when an application is running in docker, and the hosts where docker is running are instrumented by the the infra agent. External services Relationship source Relationship type Relationship target Why is the relationship created? External service CALLS External service When the relationship is created, the external service reports a span with its name on the service.name attribute and the name of the service that initiates the call in the parent.service.name attribute. Application IS External service A relationship between an application and an external service is created so that users can navigate between them using the related entities component. Browser application instrumented with a New Relic agent CALLS External service A browser application reports an Ajax/HostTransaction metric when calling an external service (URL). Example metric: Ajax/HostTransaction/api.segment.io:443/CallbackTime' Cluster CONTAINS External service When the relationship is created, the external service reports a span with the attribute k8s.cluster.name, the name of the cluster. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span. Pod HOSTS External service When the relationship is created, the external service reports a span with the following attributes: service.name: The name of the service. k8s.cluster.name: The name of the cluster. k8s.pod.name: The name of the pod that’s running the service. k8s.namespace.name: The namespace where the pod was created. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.73877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "What is an entity in <em>New</em> <em>Relic</em>?",
        "sections": "What is an entity in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ". If telemetry arrives with the entity.guid attribute already present, then <em>New</em> <em>Relic</em> will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. <em>One</em> <em>use</em> case for passing this attribute is to associate"
      },
      "id": "603ec160e7b9d295f72a07fc"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-10-12T15:16:12Z",
      "updated_at": "2021-08-21T09:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters When using our API to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.21648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to filter the UI <em>Use</em> the filter field at the top of the <em>New</em> <em>Relic</em> Explorer to filter down to the entities you care about. You can <em>use</em> multiple filter conditions. To filter down to certain entities using tags: From <em>one</em>.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "sections": [
        "New Relic Explorer: View performance across apps, services, hosts",
        "Why it matters",
        "View and connect the performance of your entities",
        "Tip",
        "List view",
        "New Relic Navigator",
        "New Relic Lookout",
        "Understand the state of your system with the health (alert) status",
        "Important",
        "Filter entities using the filterbar",
        "Entity data retention"
      ],
      "title": "New Relic Explorer: View performance across apps, services, hosts",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e1029a5f385863d0feffa2a6ebedcc417bbc9fbf",
      "image": "https://docs.newrelic.com/static/418c556bcaa53ce2b71a5b5fdfee88d8/be86f/new-relic-one-entity-alert-status-red.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-explorer-view-performance-across-apps-services-hosts/",
      "published_at": "2021-10-13T05:59:04Z",
      "updated_at": "2021-07-28T06:53:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In digital business, systems are becoming increasingly large, complex, and interdependent. You have hundreds of applications and services running at the same time, and you need to monitor thousands of elements emitting data (we call those data sources entities). With the New Relic Explorer, we give you a new, efficient front-door experience to easily observe the full stack of your software. We automatically create and maintain visibility from the data you send us. Use the New Relic Explorer to access and give context to the performance data from all your monitored applications, services, hosts, containers, synthetic monitors, etc. You can quickly see the entities related to a problem, exposing possible root causes and what other systems might be affected. Why it matters With the New Relic Explorer, it’s more than just observing the metrics: understand the root of what’s happening, not just the symptoms. Gain extensive visibility of each entity in your solution, its alert status, and how the entities are connected, at a glance. See all your workloads, and create a new one in a click. Get a high level view of how your system’s doing with the New Relic Navigator. Quickly grasp unusual trends and behaviors with New Relic Lookout. Filter and group related entities to quickly drill down to the issues. Troubleshoot issues with tools that are faster, less cumbersome, and more accurate. Identify areas of improvement, and plan your changes. Want to learn more? See the video (it's only 45 seconds!): Short guide to using the New Relic Explorer. View and connect the performance of your entities Access the New Relic Explorer at one.newrelic.com and see together data reported by any entity from across all of your New Relic accounts. Entity categories include: Services: APM-monitored applications and services monitored. Hosts: your monitored infrastructure (your servers and hosts). Mobile applications: your mobile apps. Browser applications: your front-end browser apps. Integration-reported data: data from services monitored by our integrations, including our on-host integrations (like Kubernetes, StatsD, and NGINX), and cloud platform integrations, like Amazon, Microsoft Azure, and Google Cloud Platform (GCP). Workloads, your customized entity groupings. Containers, such as Kubernetes or Docker. Synthetic monitors, for simulations. Tip You can create new entity types to monitor any data source. Learn more about entity synthesis. Toggle between the Explorer's three views and the following features: one.newrelic.com > Explorer: Use the New Relic Explorer to locate and examine the entities you monitor. List. Browse and filter from a list of all the entities in your account. Use this landing interface to navigate, group, and filter your entities. New Relic Navigator. Get a high density overview of all your entities, grouped by entity type or by tags. Use this to detect any issues and health patterns at a glance. New Relic Lookout. Spot entities that have recent performance deviations. Use this to quickly identify unusual behaviors. Saved views. Save your favorite filters as a view and recover them in a click each time you return to the Explorer. Filterbar. Drill down and locate problematic entities easily with our improved search capabilities, and benefit from the AND and OR operators in one place. See everything. All the different entity types you have access to are listed in the collapsible sidebar on the left of the screen. This sidebar is interactive and used for exploratory purposes. It allows you to see only entities of the selected type, as it updates the filter from the filterbar. Create a new workload for meaningful groupings of your monitored entities. Add more data to instrument more elements of your system and achieve full stack observability. List view Your monitored entities are on the left, in a collapsable menu. You may need to scroll your list of entities to see them all. The list view also has a collapsable activity stream on the right side. You can see different useful events related to the first 25 alerting entities which are currently being filtered. Click on any entity for more details on its performance. The entity overview also incorporates the relationship between the selected entity and other entities in your system. New Relic Navigator The New Relic Navigator makes it easy to explore large numbers of entities as it intuitively displays the entire estate of your system in a highly dense honeycomb view with traffic light colors based on alerts. With the New Relic Navigator you can: Quickly explore the health of your environment at a glance. See all the entities that belong to all your accounts, and focus on specific entity types or specific groups of entities grouped by tags. Group and filter across all your entities to quickly zero in on issues. Click on any entity to see a mini-overview of its activity, metrics, and meta-data. New Relic Lookout New Relic Lookout provides an intuitive view of entities that are deviating from normal behavior, using circle visualization with color indicating severity and size conveying the scale of recent changes. You don’t need to configure anything: New Relic Lookout automatically compares performance within the last five minutes against the previous hour. Use New Relic Lookout to: Select the entity type to see golden signals of throughput, response time, and errors across all your accounts. Zoom in with correlations, abnormal history, traces, and the ability to leverage New Relic’s profiles across your estate. Click on an entity of interest to access the mini-overview component. Read more about New Relic Lookout. Tip You can modify the color palette to focus on clusters of interest. Understand the state of your system with the health (alert) status The New Relic Explorer shows a color-coded health status for entities. For example, you may see a red alert status indicating a critical violation in progress. To see what an alert status means, mouse over it. To see details about an entity's alerting status, select the entity. NRQL alert conditions aren't used to determine alert status because they aren't associated with specific entities. Important Starting June 8, 2020, New Relic One will not continue to display any APM application that hasn't reported data for 93 days. To match our published APM data retention guidelines, applications that have not reported data will be available within the New Relic UI for 90 days. After 90 days, those applications will be removed from the UI; however, key metrics will continue to be available via the New Relic REST API based on subscription level. For more information, see New Relic's Explorers Hub post. Filter entities using the filterbar The filterbar lets you select the entities displayed according to the conditions you enter: Type in a string of characters and/or numbers (for example, an environment) to find any entity that has this string in their name or ID. When typing, the UI suggests items that coincide with the string you're entering, so you can select one of those from the dropdown. You can also filter by the name of the entity, the entity type, account ID, environment, or a tag. Tip Selection parameters, once created, have a blue background. If you filter using a string, the filter will have the = operator. If you filter using the dropdown menu, once the first element of the searched item (tag key or attribute) is entered, you need to select an operator (=, !=, LIKE, NOT_LIKE, IN, NOT IN) for your filter. Once the operator is selected, complete the filter by selecting the value to complete the search item. To add more filters, first you have to select an operator, AND or OR. Use AND to indicate you want to restrict the selection removing entities from the list of results. You can also use the AND operator to add conditions that need to be met in the list of results, for example, entityType = Services AND location = APAC. Note that entityType = Services AND entityType = Hosts doesn’t return any results, as entities can only have one type and no entity would match this condition. Use OR to add more entities to the selection. For example, the filter entityType = Services OR entityType = Hosts returns every entity you have access to that is of type Services or Hosts. Entity data retention Availability of data depends on these factors: Scope Data retention New Relic Explorer and search In the UI, data is available for eight days after an entity no longer exists, with one exception: data reported by integrations, such as Amazon AWS, is only available for one day after an entity ceases to exist. Our database (accessible via NRQL query) For querying our database (for example, via the query builder or data explorer), availability is dependent on the data retention for that data type. As a result of these factors, a short-lived entity (like a cloud host) may not be available in the explorer list or via search, but its data may still be available via NRQL query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Explorer: View performance across apps, services, hosts",
        "sections": "<em>New</em> <em>Relic</em> Explorer: View performance across apps, services, hosts",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to monitor any data source. Learn more about entity synthesis. Toggle between the Explorer&#x27;s three views and the following features: <em>one</em>.newrelic.com &gt; Explorer: <em>Use</em> the <em>New</em> <em>Relic</em> Explorer to locate and examine the entities you monitor. List. Browse and filter from a list of all the entities in your"
      },
      "id": "603ec1f928ccbca50ceba7b6"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/core-concepts/transition-new-relic-one-insights": [
    {
      "sections": [
        "What is an entity in New Relic?",
        "What's an entity?",
        "Find and explore entities and entity data",
        "Tip",
        "Group and organize entities",
        "Customize entity data with entity synthesis",
        "Reserved attributes for synthesized entities",
        "Entity relationships",
        "Important",
        "Which relationships are created?",
        "Source: New Relic agent",
        "Source: Infrastructure",
        "Source: Synthetics monitor",
        "Source: Kubernetes",
        "External services"
      ],
      "title": "What is an entity in New Relic?",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "52a3e08bc9103c717d27b153e4fd4f547d6ecc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/",
      "published_at": "2021-10-12T15:06:27Z",
      "updated_at": "2021-09-01T17:25:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic monitoring is built around the concept of entities. In this doc, you'll learn how we define entities, what you can do with them, and how you can create your own entities or groupings of entities. What's an entity? From a New Relic perspective, entity is purposefully a broad concept. An entity is anything that a) reports data to New Relic or that contains data that we have access to, and b) is something we've identified with a unique entity ID. For most entities, the ID is indicated by the attribute entityGuid. An entity can be any fundamental data-reporting component, like an application, a host, or a database service, but it can also refer to larger groupings of those components. For example, to monitor a data center, you could aggregate those hosts in New Relic to be a workload (a custom grouping of entities). That workload is, itself, also an entity. Also very important is the relationships between entities. Our behind-the-scenes relationship-mapping helps us understand how entities are connected, how they affect each other. And this allows us to give you the power to configure how any data you're bringing in is related to existing entities, or how it's related to other entities. Our focus on entities and their relationships is important because our goal is to give you practical information about your business-important entities, and not give you an unhelpfully huge stream of data from a huge list of monitored things. With more insight at the entity level, you can better monitor and troubleshoot complex, modern systems. Find and explore entities and entity data Tip You can create new entity types for monitoring any data source. Learn more about entity synthesis. Some tips for finding and understanding entity data: To find an entity's entityGuid and entityName and other metadata: from any list of monitored entities in the New Relic Explorer, click an entity's icon, and click See metadata and tags. For most entities, its GUID is reported as the attribute entityGuid. For workloads, it's workloadGuid. You can run NRQL queries to find entities by their GUID. To see connections between entities, you have several options: When viewing an entity in the UI, use the Related entities UI. Service maps. Distributed tracing. Our NerdGraph API. To group entities together, see Group entities. Customize entity definitions and relationships. To learn technical details about entity types, see our GitHub repo. In an entity type's definition file, you'll see information like: The domain: for example, APM, or Infra. Its type: for example, Application or AWSECSCONTAINERINSTANCE. Default tags. The entityExpirationTime: how long data from that entity lasts in the UI, which is different from database data retention. Group and organize entities You can place entities into groups that reflect business-important relationships in your organization. For example, you might group all entities related to a specific team or department, or related to a specific service. Or you might group multiple hosts together to reflect their grouping in a data center. To group your entities, see: Tag entities. Create workloads, which allow you to group business-important sets of entities. Create entities and customize entity data Customize entity data with entity synthesis If you have telemetry from any source that's not supported by New Relic out of the box, you can propose a mapping for it. Once approved, any telemetry received by New Relic that matches your definition file will be synthesized into an entity. To learn more: For reserved attributes and how entity relationships are defined, keep reading this doc. For how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Reserved attributes for synthesized entities These attributes are meant to be synthesized from the telemetry we receive. Do not set them unless you're aware of the implications and consequences. Attribute Description entity.guid Generally, you should not set this attribute field on your telemetry data. New Relic may add this field to ingested data to store a unique identifier for the entity associated with the data point. If telemetry arrives with the entity.guid attribute already present, then New Relic will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. One use case for passing this attribute is to associate ingested telemetry with an entity already created by New Relic. When the entity.guid attribute is sent, the value will override New Relic’s entity identification system (such as entity synthesis definitions) and instead will use the attribute as the data. entity.name This attribute shouldn't be put on ingested telemetry data unless you're trying to override the entity name that would have been selected by New Relic’s entity identification system. While New Relic won't change the value if it's already present on the data, New Relic may add the attribute to your data. Therefore invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. If this field is present on ingested telemetry, its value will be used to name the entity associated with the data point. This name will be used instead of the name selected by New Relic’s entity identification system (for example, entity synthesis definitions). Note that many entities use the name as part of their identification, so changing this field may result in the generation of a new entity. entity.type This attribute shouldn't be put on ingested telemetry data except for certain legacy cases where it's required to distinguish entity types. Passing this field may interfere with entity detection, particularly if unrecognized values are sent in this field. While New Relic won't change the value if already present on the data, the field is not guaranteed to provide unambiguous filtering of telemetry at query-time. Existing entity definitions already have overlapping values, and we recommend avoiding entity.type in favor of other fields for filtering telemetry queries. This field is used by New Relic, meaning that invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. To learn how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Entity relationships Connections between entities are automatically created by New Relic based on what we can infer from your telemetry. For example, when two services that communicate using HTTP are instrumented with New Relic, we infer a \"calls/called-by\" relationship between them. When viewing a specific entity in either the New Relic Explorer, Navigator, or Lookout, you can see its Related entities in the entity's mini overview. This gives a visualization of the various entities connected directly to the current entity. You can quickly view important metrics for these related entities and navigate from one entity to another, through all the connected parts of your stack. Tip Learn more about how entities are related with our NerdGraph API. When relationships are not automatically detected, you can manually create them using the \"Add/edit related entities\" link in Related entities. Important Currently, you can only manually create calls/called-by relationships between service entities. Tip To manage manual relationships, you need to have modify and delete capabilities on entity relationships. If you don’t see the edit relationships button, contact your account admin. Which relationships are created? These are the relationships created between entities: Source: New Relic agent Relationship source Relationship type Relationship target Why is the relationship created? Application instrumented with a New Relic agent CALLS Application instrumented with a New Relic agent Relationships between applications monitored by New Relic agents are reported using the DurationByCaller metric. The callee reports the metric. For example, the metric DurationByCaller/Mobile/100/1234/HTTP/all indicates that the caller is APPLICATION 1234 for account 100. Application instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent An application (caller) that calls a service (callee) monitored by New Relic creates a relationship that's reported by the caller using the ExternalApp metric. For example, the metric ExternalApp/dirac.vips.net/100#1234/all indicates that the callee is APPLICATION 1234 for account 100. The metric is reported if the callee successfully responds to the caller. Service instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent When a New Relic agent detects that a service (caller) calls another service (callee) instrumented by New Relic, the callee reports the metric ClientApplication. For example, the metric ClientApplication/100#1234/all indicates that the caller is APPLICATION 1234 for account 100. Service instrumented with a New Relic agent CALLS A datastore instance When an application calls a datastore instance it creates a relationship reported with the DatastoreInstance metric. For example, the metric Datastore/instance/MySQL/172.16.16.3/3306 indicates the datastore instance is vendor: MySQL, host: 172.16.16.3, port: 3306. This metric also supports the legacy datastore instance format Datastore/instance/MySQL/172.16.16.3:3306. Currently we cannot determine whether the datastore instance is instrumented by New Relic and has an entity associated to it. APM agent SERVES Browser agent This relationship is created when an APM agent injects the browser agent into a page. Workload entity CONTAINS Any entity When a workload is created or updated, relationships for each of the entities that belong to the workload are created. Because some workloads are “dynamic” (defined by tags), relationships are re-created every 5 minutes. This way entities can join or leave the workload. Source: Infrastructure Relationship source Relationship type Relationship target Why is the relationship created? Infrastructure host HOSTS Application This relationship is created when an application is running in one or more hosts, and the infra agent is running in those hosts. Infrastructure host HOSTS Container This relationship is created when containers are running in one or more hosts, and the host is instrumented with the infra agent. Source: Synthetics monitor Relationship source Relationship type Relationship target Why is the relationship created? Synthetics Monitor CALLS Browser agent This relationship is created when a synthetics monitor checks a page instrumented with the browser agent. Synthetics Monitor CALLS APM application Agent events that contain the attribute nr.syntheticsMonitorId have been described as synthetics monitors (the source) interacting with an APM application (the target). If the header exists and the APM application Id exists, a relationship is created between the monitor and the app. Source: Kubernetes Relationship source Relationship type Relationship target Why is the relationship created? Cluster CONTAINS Pod This relationship is created when a pod is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Deployment This relationship is created when a deployment is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS DaemonSet This relationship is created when a DaemonSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS StatefulSet This relationship is created when a StatefulSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Host This relationship is created when a host that's part of a cluster is instrumented with the New Relic Kubernetes integration. Deployment CONTAINS Pod This relationship is created when a deployment creates a pod in a cluster instrumented with the New Relic Kubernetes integration. DaemonSet CONTAINS Pod This relationship is created when a DaemonSet is created a pod in a cluster instrumented with the New Relic Kubernetes integration. StatefulSet CONTAINS Pod This relationship is created when a StatefulSet creates a pod in a cluster instrumented with the New Relic Kubernetes integration. Pod CONTAINS Container This relationship is created when a pod creates a container in a cluster instrumented with the New Relic Kubernetes integration. Host HOSTS Pod This relationship is created when a pod is running in a host that's part of a cluster instrumented with the New Relic Kubernetes integration. Container HOSTS Application This relationship is created when an application is running in docker, and the hosts where docker is running are instrumented by the the infra agent. External services Relationship source Relationship type Relationship target Why is the relationship created? External service CALLS External service When the relationship is created, the external service reports a span with its name on the service.name attribute and the name of the service that initiates the call in the parent.service.name attribute. Application IS External service A relationship between an application and an external service is created so that users can navigate between them using the related entities component. Browser application instrumented with a New Relic agent CALLS External service A browser application reports an Ajax/HostTransaction metric when calling an external service (URL). Example metric: Ajax/HostTransaction/api.segment.io:443/CallbackTime' Cluster CONTAINS External service When the relationship is created, the external service reports a span with the attribute k8s.cluster.name, the name of the cluster. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span. Pod HOSTS External service When the relationship is created, the external service reports a span with the following attributes: service.name: The name of the service. k8s.cluster.name: The name of the cluster. k8s.pod.name: The name of the pod that’s running the service. k8s.namespace.name: The namespace where the pod was created. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.73877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "What is an entity in <em>New</em> <em>Relic</em>?",
        "sections": "What is an entity in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ". If telemetry arrives with the entity.guid attribute already present, then <em>New</em> <em>Relic</em> will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. <em>One</em> <em>use</em> case for passing this attribute is to associate"
      },
      "id": "603ec160e7b9d295f72a07fc"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-10-12T15:16:12Z",
      "updated_at": "2021-08-21T09:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters When using our API to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.21648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to filter the UI <em>Use</em> the filter field at the top of the <em>New</em> <em>Relic</em> Explorer to filter down to the entities you care about. You can <em>use</em> multiple filter conditions. To filter down to certain entities using tags: From <em>one</em>.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "sections": [
        "New Relic Lookout: Monitor your estate at a glance",
        "Why it matters",
        "Requirements",
        "Get started with New Relic Lookout",
        "Circle visualization and table view",
        "Abnormal golden signals",
        "Instant search",
        "Change view",
        "Drill down into the details",
        "Performance tab",
        "Abnormal History tab",
        "Correlations tab",
        "Profile tab",
        "Traces tab",
        "Create a custom view",
        "Query: Compare the last 15 minutes to the same time 1 day ago",
        "Query: Compare a specific time range to the same range a month ago",
        "Example: Unusual increases in error count"
      ],
      "title": "New Relic Lookout: Monitor your estate at a glance",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "9193dcc8851c185ff5d96f6f93ab412bd1be69e9",
      "image": "https://docs.newrelic.com/static/178b37068bad2a68cff027c8bdcf663a/c1b63/lookout-intro.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-lookout-monitor-your-estate-glance/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-08-21T09:27:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Lookout provides visibility into your entire estate. It doesn't require any configuration — you can query anything in your estate that matters to you right now and understand your system as a whole, or dive deep into causes and effects, so you can quickly get the data you need to take action. Know exactly where to focus your attention with New Relic Lookout. The brighter the color, the more severe the change, and the bigger the size, the bigger the scale. Then dig deeper with correlations and abnormal history to see how it impacts your whole system—no configuration needed. Why it matters New Relic Lookout helps software teams of any size discover potential issues before they have an impact. Fill gaps in monitoring with full coverage out-of-the-box, no configuration or setup required. Immediately see anything deviating from normal across your entire estate. Proactively spot emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in New Relic database (NRDB), including third-party, open, and custom data. Launch into other areas of New Relic One for deeper understanding Requirements New Relic Lookout requires Pro or Enterprise edition. If you are on Standard edition, you can still use the New Relic Lookout view in the New Relic Explorer. If you want to see data spanning 13-months, correlations, profiles, traces, and other details, you must upgrade to a higher edition. Get started with New Relic Lookout To access New Relic Lookout, click the Apps button in New Relic One and locate the New Relic Lookout launcher. You can also access New Relic Lookout directly from the New Relic One header bar, via the More dropdown. Enablement of key service performance indicator data is required for New Relic Lookout to provide value from the data you already have. The default view provides insight into three key Service performance indicators broken down by application: throughput, response time, and errors. These metrics are analyzed to show how the data has behaved during the last five minutes compared to the prior hour. one.newrelic.com > Apps > New Relic Lookout: Anything that significantly deviates from the trend is automatically discovered by New Relic Lookout, which doesn't require any configuration. Circle visualization and table view Each application (or other facet) is represented by a circle. The size of the circles indicate the magnitude of the signal for that application and the color indicates whether the value has significantly decreased or increased in the last five minutes, based on the standard deviation of the prior hour (default evaluation and comparison time windows.) Please note that the type of signal is important when interpreting your results. When you first look at the legend below, you might be tempted to interpret yellow as good and dark purple as bad, but that is not always the case. Here are some examples: In the APM/services golden signals, a dark yellow circle in Throughput might signify that something bad has occurred and led to a drop in traffic. At the same time, a dark purple circle might also be concerning due to unexpected load. Both are significant findings worth exploring. In browser golden signals, a dark purple circle in Page Views might be great, as you are seeing more traffic to your site! With errors golden signals (in all entity types), a large circle, even if gray (not deviating from normal volume), is worth exploring because a high count of errors in your system is important to investigate. The legend allows you to change the colors used to highlight deviating services To change the color palette, click the gear icon by the low-high color legend. This allows you to change the colors used to highlight deviating services. To get a table view of the same data, click the toggle on the right. You can also hover over each color to filter the view by degree lower or higher deviance. Abnormal golden signals On the right, New Relic Lookout displays the most significantly deviating applications (or other facet) in a side panel, weighted by both the magnitude of the performance indicators and the scale of their deviations. Details include the name of the key performance indicator, their magnitude during the recent time window, and the difference between the averages from one time compared to the other. Instant search Click the magnifying glass icon in the side panel to open a search box. Typing into the search box filters the circles, table, and abnormal signals to applications (or other facets) that contain the text. This is a good way to quickly zoom to various subsystems. New Relic Lookout doesn't rerun the analysis when using the instant search. Change view Click the Change View button on the right side panel. The panel that appears shows you all the entity-specific golden signals you can toggle between out of the box. By choosing the Browser Golden Signal or other views, you can change from the default view. Each new view will have the golden signals appropriate for that entity type. Drill down into the details To analyze an application or facet, click a circle, table row, or abnormal golden signal. The details panel shows the degree of deviation of the performance indicator, a link to the affected entity, and recent alert and deployment activity for that entity, when available. There’s also an indication of whether the selected evaluation time period would be abnormal or not in reference to other comparison time windows, such as the same time yesterday or the same time last week. This allows you to quickly see if the abnormal behavior is odd in general, or just based on the comparison time window. Performance tab The default tab shows charts for other key performance indicators for the selected application or facet. The charts compare the two time windows being analyzed. You can click their titles to rerun the analysis, focusing on the selected key performance indicator. When the target is a New Relic One application, we show the top transactions, error classes, external services, and database operations, alongside links to the relevant New Relic One features. Abnormal History tab This section analyzes past performance of the selected signal and calls out any time periods with notable abnormalities. Each card represents an abnormal time window and can be clicked for more details. The charts will display any relevant violations and deployments in New Relic. Correlations tab New Relic Lookout can find other signals that began behaving differently around the same time as the selected signal for that entity type. Clicking the name of the signal reruns the analysis, focusing on that key performance indicator. The chart titles link to New Relic One when there’s an associated entity in your account. Note that correlations currently do not analyze across accounts. The correlated signals displayed are for others in the account of the original application you are viewing. This helps focus the data on correlations that are more likely related to your issue. Profile tab Based on the same technology as New Relic’s error profiles, this tab compares the last five minutes to the prior hour by default (or whatever time windows you’ve selected with query editing) and surfaces any attributes that have significantly different distributions in the events being targeted by the selected signal. For example, if a custom attribute indicated that a recent throughput spike came from one user, that would surface highly in Profiles if most of the traffic usually comes from many users. Traces tab If the entity has distributed traces configured and available in the selected evaluated time window, the Traces section is enabled. Each card shows a summary of a trace and can be clicked for details. The Explore all traces links to the distributed traces application, filtered to the selected entity. Create a custom view To target signals and time windows beyond the default values, click the Change view button and select Custom view. To create your own view: Select the account or subaccount. Select the data type (metrics or events). Different functionality is available depending on the type. In View a chart with, select the metric or event you are interested in. Default is golden signals (throughput, response time, and errors). You can also build custom queries (filters) to target a signal that isn't on the list. In Facet by, select what the circles represent. Default is appName, but you can also choose host or any other facetable attribute available for the signal you’ve selected. If you plan to save/favorite this new view, provide a name in the Name your view box. Keep in mind that you can edit this view at any time using the pencil icon. The default time windows analyzed by New Relic Lookout are the last five minutes compared to the hour before. Use the time controls (View data from and Compare data to) to target other time windows. one.newrelic.com > Apps > New Relic Lookout: All event and metric data in the New Relic database can be queried using the Edit query feature. Click Analyze to begin analyzing the signal you’ve selected. You can also create your own query: Create your query. This query is comparing data from the past thirty minutes to data from the same range a day ago. Change from Basic to Advanced after clicking the Custom view button. Select the data type (metrics or events). Different functionality is available depending on the type. Enter your query using NRQL. Please note that not all NRQL features are available in the Lookout Advanced query feature. By default, the system will run this query using the last five minutes of data compared to the previous hour. Some examples of the syntax for changing the comparison and evaluation time windows are below. Click Analyze to begin analyzing the signal you’ve selected. Query: Compare the last 15 minutes to the same time 1 day ago Please note that the UNTIL NOW portion is required here unlike in standard NRQL. Without the UNTIL NOW added, the system will query a 5 minute slice of data starting 15 minutes ago SINCE 15 minutes AGO UNTIL NOW COMPARE WITH 1 day ago Copy Query: Compare a specific time range to the same range a month ago SINCE '2021-03-07 07:00:00-0500' UNTIL '2021-03-08 07:00:00-0500' COMPARE WITH 1 month ago Copy Or: SINCE 'today at midnight' UNTIL 'now' COMPARE WITH 1 MONTH AGO Copy Example: Unusual increases in error count The default view of New Relic Lookout shows application status across your estate, comparing the last five minutes to the hour before. Under regular operation, most large systems may have a handful of abnormalities, but usually most things will indicate normal behavior. Suddenly, several circles begin to change to red under the Errors section. This indicates that several applications are experiencing unusual increases in error count. It may be that one or two circles for important systems are red, and perhaps much larger than they usually appear. Clicking one of these can provide more information on what is happening. You might see that the error rate is substantially elevated, even thousands of percent higher than normal. To troubleshoot this issue, here's what you might discover in the New Relic Lookout tabs: Performance would show you data about other signals, illuminating the characteristics of the change in system dynamics. Correlations would surface other applications that are affected and how, as well as opportunities to pivot to other applications that may be closer to the underlying causes. Traces, in turn, would show distributed traces, which can provide specific examples of traffic running through those systems. Abnormal history would show other times in the past week with elevated errors, showing whether or not this problem happens regularly, such as every day at the same time or whenever there is a deployment. Profiles might show that all or most of the new errors share common properties, such as all being isolated to just one region/account/user. Combining the information from these sections, not only can you get a sense of what is going on, but also where to focus actions to resolve the problem.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.21616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "sections": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in <em>New</em> <em>Relic</em> database (NRDB), including third-party, open, and custom data. Launch into other areas of <em>New</em> <em>Relic</em> <em>One</em> for deeper"
      },
      "id": "603e821e64441f5a444e8845"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data": [
    {
      "sections": [
        "What is an entity in New Relic?",
        "What's an entity?",
        "Find and explore entities and entity data",
        "Tip",
        "Group and organize entities",
        "Customize entity data with entity synthesis",
        "Reserved attributes for synthesized entities",
        "Entity relationships",
        "Important",
        "Which relationships are created?",
        "Source: New Relic agent",
        "Source: Infrastructure",
        "Source: Synthetics monitor",
        "Source: Kubernetes",
        "External services"
      ],
      "title": "What is an entity in New Relic?",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "52a3e08bc9103c717d27b153e4fd4f547d6ecc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/",
      "published_at": "2021-10-12T15:06:27Z",
      "updated_at": "2021-09-01T17:25:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic monitoring is built around the concept of entities. In this doc, you'll learn how we define entities, what you can do with them, and how you can create your own entities or groupings of entities. What's an entity? From a New Relic perspective, entity is purposefully a broad concept. An entity is anything that a) reports data to New Relic or that contains data that we have access to, and b) is something we've identified with a unique entity ID. For most entities, the ID is indicated by the attribute entityGuid. An entity can be any fundamental data-reporting component, like an application, a host, or a database service, but it can also refer to larger groupings of those components. For example, to monitor a data center, you could aggregate those hosts in New Relic to be a workload (a custom grouping of entities). That workload is, itself, also an entity. Also very important is the relationships between entities. Our behind-the-scenes relationship-mapping helps us understand how entities are connected, how they affect each other. And this allows us to give you the power to configure how any data you're bringing in is related to existing entities, or how it's related to other entities. Our focus on entities and their relationships is important because our goal is to give you practical information about your business-important entities, and not give you an unhelpfully huge stream of data from a huge list of monitored things. With more insight at the entity level, you can better monitor and troubleshoot complex, modern systems. Find and explore entities and entity data Tip You can create new entity types for monitoring any data source. Learn more about entity synthesis. Some tips for finding and understanding entity data: To find an entity's entityGuid and entityName and other metadata: from any list of monitored entities in the New Relic Explorer, click an entity's icon, and click See metadata and tags. For most entities, its GUID is reported as the attribute entityGuid. For workloads, it's workloadGuid. You can run NRQL queries to find entities by their GUID. To see connections between entities, you have several options: When viewing an entity in the UI, use the Related entities UI. Service maps. Distributed tracing. Our NerdGraph API. To group entities together, see Group entities. Customize entity definitions and relationships. To learn technical details about entity types, see our GitHub repo. In an entity type's definition file, you'll see information like: The domain: for example, APM, or Infra. Its type: for example, Application or AWSECSCONTAINERINSTANCE. Default tags. The entityExpirationTime: how long data from that entity lasts in the UI, which is different from database data retention. Group and organize entities You can place entities into groups that reflect business-important relationships in your organization. For example, you might group all entities related to a specific team or department, or related to a specific service. Or you might group multiple hosts together to reflect their grouping in a data center. To group your entities, see: Tag entities. Create workloads, which allow you to group business-important sets of entities. Create entities and customize entity data Customize entity data with entity synthesis If you have telemetry from any source that's not supported by New Relic out of the box, you can propose a mapping for it. Once approved, any telemetry received by New Relic that matches your definition file will be synthesized into an entity. To learn more: For reserved attributes and how entity relationships are defined, keep reading this doc. For how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Reserved attributes for synthesized entities These attributes are meant to be synthesized from the telemetry we receive. Do not set them unless you're aware of the implications and consequences. Attribute Description entity.guid Generally, you should not set this attribute field on your telemetry data. New Relic may add this field to ingested data to store a unique identifier for the entity associated with the data point. If telemetry arrives with the entity.guid attribute already present, then New Relic will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. One use case for passing this attribute is to associate ingested telemetry with an entity already created by New Relic. When the entity.guid attribute is sent, the value will override New Relic’s entity identification system (such as entity synthesis definitions) and instead will use the attribute as the data. entity.name This attribute shouldn't be put on ingested telemetry data unless you're trying to override the entity name that would have been selected by New Relic’s entity identification system. While New Relic won't change the value if it's already present on the data, New Relic may add the attribute to your data. Therefore invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. If this field is present on ingested telemetry, its value will be used to name the entity associated with the data point. This name will be used instead of the name selected by New Relic’s entity identification system (for example, entity synthesis definitions). Note that many entities use the name as part of their identification, so changing this field may result in the generation of a new entity. entity.type This attribute shouldn't be put on ingested telemetry data except for certain legacy cases where it's required to distinguish entity types. Passing this field may interfere with entity detection, particularly if unrecognized values are sent in this field. While New Relic won't change the value if already present on the data, the field is not guaranteed to provide unambiguous filtering of telemetry at query-time. Existing entity definitions already have overlapping values, and we recommend avoiding entity.type in favor of other fields for filtering telemetry queries. This field is used by New Relic, meaning that invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. To learn how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Entity relationships Connections between entities are automatically created by New Relic based on what we can infer from your telemetry. For example, when two services that communicate using HTTP are instrumented with New Relic, we infer a \"calls/called-by\" relationship between them. When viewing a specific entity in either the New Relic Explorer, Navigator, or Lookout, you can see its Related entities in the entity's mini overview. This gives a visualization of the various entities connected directly to the current entity. You can quickly view important metrics for these related entities and navigate from one entity to another, through all the connected parts of your stack. Tip Learn more about how entities are related with our NerdGraph API. When relationships are not automatically detected, you can manually create them using the \"Add/edit related entities\" link in Related entities. Important Currently, you can only manually create calls/called-by relationships between service entities. Tip To manage manual relationships, you need to have modify and delete capabilities on entity relationships. If you don’t see the edit relationships button, contact your account admin. Which relationships are created? These are the relationships created between entities: Source: New Relic agent Relationship source Relationship type Relationship target Why is the relationship created? Application instrumented with a New Relic agent CALLS Application instrumented with a New Relic agent Relationships between applications monitored by New Relic agents are reported using the DurationByCaller metric. The callee reports the metric. For example, the metric DurationByCaller/Mobile/100/1234/HTTP/all indicates that the caller is APPLICATION 1234 for account 100. Application instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent An application (caller) that calls a service (callee) monitored by New Relic creates a relationship that's reported by the caller using the ExternalApp metric. For example, the metric ExternalApp/dirac.vips.net/100#1234/all indicates that the callee is APPLICATION 1234 for account 100. The metric is reported if the callee successfully responds to the caller. Service instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent When a New Relic agent detects that a service (caller) calls another service (callee) instrumented by New Relic, the callee reports the metric ClientApplication. For example, the metric ClientApplication/100#1234/all indicates that the caller is APPLICATION 1234 for account 100. Service instrumented with a New Relic agent CALLS A datastore instance When an application calls a datastore instance it creates a relationship reported with the DatastoreInstance metric. For example, the metric Datastore/instance/MySQL/172.16.16.3/3306 indicates the datastore instance is vendor: MySQL, host: 172.16.16.3, port: 3306. This metric also supports the legacy datastore instance format Datastore/instance/MySQL/172.16.16.3:3306. Currently we cannot determine whether the datastore instance is instrumented by New Relic and has an entity associated to it. APM agent SERVES Browser agent This relationship is created when an APM agent injects the browser agent into a page. Workload entity CONTAINS Any entity When a workload is created or updated, relationships for each of the entities that belong to the workload are created. Because some workloads are “dynamic” (defined by tags), relationships are re-created every 5 minutes. This way entities can join or leave the workload. Source: Infrastructure Relationship source Relationship type Relationship target Why is the relationship created? Infrastructure host HOSTS Application This relationship is created when an application is running in one or more hosts, and the infra agent is running in those hosts. Infrastructure host HOSTS Container This relationship is created when containers are running in one or more hosts, and the host is instrumented with the infra agent. Source: Synthetics monitor Relationship source Relationship type Relationship target Why is the relationship created? Synthetics Monitor CALLS Browser agent This relationship is created when a synthetics monitor checks a page instrumented with the browser agent. Synthetics Monitor CALLS APM application Agent events that contain the attribute nr.syntheticsMonitorId have been described as synthetics monitors (the source) interacting with an APM application (the target). If the header exists and the APM application Id exists, a relationship is created between the monitor and the app. Source: Kubernetes Relationship source Relationship type Relationship target Why is the relationship created? Cluster CONTAINS Pod This relationship is created when a pod is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Deployment This relationship is created when a deployment is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS DaemonSet This relationship is created when a DaemonSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS StatefulSet This relationship is created when a StatefulSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Host This relationship is created when a host that's part of a cluster is instrumented with the New Relic Kubernetes integration. Deployment CONTAINS Pod This relationship is created when a deployment creates a pod in a cluster instrumented with the New Relic Kubernetes integration. DaemonSet CONTAINS Pod This relationship is created when a DaemonSet is created a pod in a cluster instrumented with the New Relic Kubernetes integration. StatefulSet CONTAINS Pod This relationship is created when a StatefulSet creates a pod in a cluster instrumented with the New Relic Kubernetes integration. Pod CONTAINS Container This relationship is created when a pod creates a container in a cluster instrumented with the New Relic Kubernetes integration. Host HOSTS Pod This relationship is created when a pod is running in a host that's part of a cluster instrumented with the New Relic Kubernetes integration. Container HOSTS Application This relationship is created when an application is running in docker, and the hosts where docker is running are instrumented by the the infra agent. External services Relationship source Relationship type Relationship target Why is the relationship created? External service CALLS External service When the relationship is created, the external service reports a span with its name on the service.name attribute and the name of the service that initiates the call in the parent.service.name attribute. Application IS External service A relationship between an application and an external service is created so that users can navigate between them using the related entities component. Browser application instrumented with a New Relic agent CALLS External service A browser application reports an Ajax/HostTransaction metric when calling an external service (URL). Example metric: Ajax/HostTransaction/api.segment.io:443/CallbackTime' Cluster CONTAINS External service When the relationship is created, the external service reports a span with the attribute k8s.cluster.name, the name of the cluster. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span. Pod HOSTS External service When the relationship is created, the external service reports a span with the following attributes: service.name: The name of the service. k8s.cluster.name: The name of the cluster. k8s.pod.name: The name of the pod that’s running the service. k8s.namespace.name: The namespace where the pod was created. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.73877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "What is an entity in <em>New</em> <em>Relic</em>?",
        "sections": "What is an entity in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ". If telemetry arrives with the entity.guid attribute already present, then <em>New</em> <em>Relic</em> will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. <em>One</em> <em>use</em> case for passing this attribute is to associate"
      },
      "id": "603ec160e7b9d295f72a07fc"
    },
    {
      "sections": [
        "New Relic Lookout: Monitor your estate at a glance",
        "Why it matters",
        "Requirements",
        "Get started with New Relic Lookout",
        "Circle visualization and table view",
        "Abnormal golden signals",
        "Instant search",
        "Change view",
        "Drill down into the details",
        "Performance tab",
        "Abnormal History tab",
        "Correlations tab",
        "Profile tab",
        "Traces tab",
        "Create a custom view",
        "Query: Compare the last 15 minutes to the same time 1 day ago",
        "Query: Compare a specific time range to the same range a month ago",
        "Example: Unusual increases in error count"
      ],
      "title": "New Relic Lookout: Monitor your estate at a glance",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "9193dcc8851c185ff5d96f6f93ab412bd1be69e9",
      "image": "https://docs.newrelic.com/static/178b37068bad2a68cff027c8bdcf663a/c1b63/lookout-intro.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-lookout-monitor-your-estate-glance/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-08-21T09:27:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Lookout provides visibility into your entire estate. It doesn't require any configuration — you can query anything in your estate that matters to you right now and understand your system as a whole, or dive deep into causes and effects, so you can quickly get the data you need to take action. Know exactly where to focus your attention with New Relic Lookout. The brighter the color, the more severe the change, and the bigger the size, the bigger the scale. Then dig deeper with correlations and abnormal history to see how it impacts your whole system—no configuration needed. Why it matters New Relic Lookout helps software teams of any size discover potential issues before they have an impact. Fill gaps in monitoring with full coverage out-of-the-box, no configuration or setup required. Immediately see anything deviating from normal across your entire estate. Proactively spot emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in New Relic database (NRDB), including third-party, open, and custom data. Launch into other areas of New Relic One for deeper understanding Requirements New Relic Lookout requires Pro or Enterprise edition. If you are on Standard edition, you can still use the New Relic Lookout view in the New Relic Explorer. If you want to see data spanning 13-months, correlations, profiles, traces, and other details, you must upgrade to a higher edition. Get started with New Relic Lookout To access New Relic Lookout, click the Apps button in New Relic One and locate the New Relic Lookout launcher. You can also access New Relic Lookout directly from the New Relic One header bar, via the More dropdown. Enablement of key service performance indicator data is required for New Relic Lookout to provide value from the data you already have. The default view provides insight into three key Service performance indicators broken down by application: throughput, response time, and errors. These metrics are analyzed to show how the data has behaved during the last five minutes compared to the prior hour. one.newrelic.com > Apps > New Relic Lookout: Anything that significantly deviates from the trend is automatically discovered by New Relic Lookout, which doesn't require any configuration. Circle visualization and table view Each application (or other facet) is represented by a circle. The size of the circles indicate the magnitude of the signal for that application and the color indicates whether the value has significantly decreased or increased in the last five minutes, based on the standard deviation of the prior hour (default evaluation and comparison time windows.) Please note that the type of signal is important when interpreting your results. When you first look at the legend below, you might be tempted to interpret yellow as good and dark purple as bad, but that is not always the case. Here are some examples: In the APM/services golden signals, a dark yellow circle in Throughput might signify that something bad has occurred and led to a drop in traffic. At the same time, a dark purple circle might also be concerning due to unexpected load. Both are significant findings worth exploring. In browser golden signals, a dark purple circle in Page Views might be great, as you are seeing more traffic to your site! With errors golden signals (in all entity types), a large circle, even if gray (not deviating from normal volume), is worth exploring because a high count of errors in your system is important to investigate. The legend allows you to change the colors used to highlight deviating services To change the color palette, click the gear icon by the low-high color legend. This allows you to change the colors used to highlight deviating services. To get a table view of the same data, click the toggle on the right. You can also hover over each color to filter the view by degree lower or higher deviance. Abnormal golden signals On the right, New Relic Lookout displays the most significantly deviating applications (or other facet) in a side panel, weighted by both the magnitude of the performance indicators and the scale of their deviations. Details include the name of the key performance indicator, their magnitude during the recent time window, and the difference between the averages from one time compared to the other. Instant search Click the magnifying glass icon in the side panel to open a search box. Typing into the search box filters the circles, table, and abnormal signals to applications (or other facets) that contain the text. This is a good way to quickly zoom to various subsystems. New Relic Lookout doesn't rerun the analysis when using the instant search. Change view Click the Change View button on the right side panel. The panel that appears shows you all the entity-specific golden signals you can toggle between out of the box. By choosing the Browser Golden Signal or other views, you can change from the default view. Each new view will have the golden signals appropriate for that entity type. Drill down into the details To analyze an application or facet, click a circle, table row, or abnormal golden signal. The details panel shows the degree of deviation of the performance indicator, a link to the affected entity, and recent alert and deployment activity for that entity, when available. There’s also an indication of whether the selected evaluation time period would be abnormal or not in reference to other comparison time windows, such as the same time yesterday or the same time last week. This allows you to quickly see if the abnormal behavior is odd in general, or just based on the comparison time window. Performance tab The default tab shows charts for other key performance indicators for the selected application or facet. The charts compare the two time windows being analyzed. You can click their titles to rerun the analysis, focusing on the selected key performance indicator. When the target is a New Relic One application, we show the top transactions, error classes, external services, and database operations, alongside links to the relevant New Relic One features. Abnormal History tab This section analyzes past performance of the selected signal and calls out any time periods with notable abnormalities. Each card represents an abnormal time window and can be clicked for more details. The charts will display any relevant violations and deployments in New Relic. Correlations tab New Relic Lookout can find other signals that began behaving differently around the same time as the selected signal for that entity type. Clicking the name of the signal reruns the analysis, focusing on that key performance indicator. The chart titles link to New Relic One when there’s an associated entity in your account. Note that correlations currently do not analyze across accounts. The correlated signals displayed are for others in the account of the original application you are viewing. This helps focus the data on correlations that are more likely related to your issue. Profile tab Based on the same technology as New Relic’s error profiles, this tab compares the last five minutes to the prior hour by default (or whatever time windows you’ve selected with query editing) and surfaces any attributes that have significantly different distributions in the events being targeted by the selected signal. For example, if a custom attribute indicated that a recent throughput spike came from one user, that would surface highly in Profiles if most of the traffic usually comes from many users. Traces tab If the entity has distributed traces configured and available in the selected evaluated time window, the Traces section is enabled. Each card shows a summary of a trace and can be clicked for details. The Explore all traces links to the distributed traces application, filtered to the selected entity. Create a custom view To target signals and time windows beyond the default values, click the Change view button and select Custom view. To create your own view: Select the account or subaccount. Select the data type (metrics or events). Different functionality is available depending on the type. In View a chart with, select the metric or event you are interested in. Default is golden signals (throughput, response time, and errors). You can also build custom queries (filters) to target a signal that isn't on the list. In Facet by, select what the circles represent. Default is appName, but you can also choose host or any other facetable attribute available for the signal you’ve selected. If you plan to save/favorite this new view, provide a name in the Name your view box. Keep in mind that you can edit this view at any time using the pencil icon. The default time windows analyzed by New Relic Lookout are the last five minutes compared to the hour before. Use the time controls (View data from and Compare data to) to target other time windows. one.newrelic.com > Apps > New Relic Lookout: All event and metric data in the New Relic database can be queried using the Edit query feature. Click Analyze to begin analyzing the signal you’ve selected. You can also create your own query: Create your query. This query is comparing data from the past thirty minutes to data from the same range a day ago. Change from Basic to Advanced after clicking the Custom view button. Select the data type (metrics or events). Different functionality is available depending on the type. Enter your query using NRQL. Please note that not all NRQL features are available in the Lookout Advanced query feature. By default, the system will run this query using the last five minutes of data compared to the previous hour. Some examples of the syntax for changing the comparison and evaluation time windows are below. Click Analyze to begin analyzing the signal you’ve selected. Query: Compare the last 15 minutes to the same time 1 day ago Please note that the UNTIL NOW portion is required here unlike in standard NRQL. Without the UNTIL NOW added, the system will query a 5 minute slice of data starting 15 minutes ago SINCE 15 minutes AGO UNTIL NOW COMPARE WITH 1 day ago Copy Query: Compare a specific time range to the same range a month ago SINCE '2021-03-07 07:00:00-0500' UNTIL '2021-03-08 07:00:00-0500' COMPARE WITH 1 month ago Copy Or: SINCE 'today at midnight' UNTIL 'now' COMPARE WITH 1 MONTH AGO Copy Example: Unusual increases in error count The default view of New Relic Lookout shows application status across your estate, comparing the last five minutes to the hour before. Under regular operation, most large systems may have a handful of abnormalities, but usually most things will indicate normal behavior. Suddenly, several circles begin to change to red under the Errors section. This indicates that several applications are experiencing unusual increases in error count. It may be that one or two circles for important systems are red, and perhaps much larger than they usually appear. Clicking one of these can provide more information on what is happening. You might see that the error rate is substantially elevated, even thousands of percent higher than normal. To troubleshoot this issue, here's what you might discover in the New Relic Lookout tabs: Performance would show you data about other signals, illuminating the characteristics of the change in system dynamics. Correlations would surface other applications that are affected and how, as well as opportunities to pivot to other applications that may be closer to the underlying causes. Traces, in turn, would show distributed traces, which can provide specific examples of traffic running through those systems. Abnormal history would show other times in the past week with elevated errors, showing whether or not this problem happens regularly, such as every day at the same time or whenever there is a deployment. Profiles might show that all or most of the new errors share common properties, such as all being isolated to just one region/account/user. Combining the information from these sections, not only can you get a sense of what is going on, but also where to focus actions to resolve the problem.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.21616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "sections": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in <em>New</em> <em>Relic</em> database (NRDB), including third-party, open, and custom data. Launch into other areas of <em>New</em> <em>Relic</em> <em>One</em> for deeper"
      },
      "id": "603e821e64441f5a444e8845"
    },
    {
      "sections": [
        "New Relic Explorer: View performance across apps, services, hosts",
        "Why it matters",
        "View and connect the performance of your entities",
        "Tip",
        "List view",
        "New Relic Navigator",
        "New Relic Lookout",
        "Understand the state of your system with the health (alert) status",
        "Important",
        "Filter entities using the filterbar",
        "Entity data retention"
      ],
      "title": "New Relic Explorer: View performance across apps, services, hosts",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e1029a5f385863d0feffa2a6ebedcc417bbc9fbf",
      "image": "https://docs.newrelic.com/static/418c556bcaa53ce2b71a5b5fdfee88d8/be86f/new-relic-one-entity-alert-status-red.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-explorer-view-performance-across-apps-services-hosts/",
      "published_at": "2021-10-13T05:59:04Z",
      "updated_at": "2021-07-28T06:53:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In digital business, systems are becoming increasingly large, complex, and interdependent. You have hundreds of applications and services running at the same time, and you need to monitor thousands of elements emitting data (we call those data sources entities). With the New Relic Explorer, we give you a new, efficient front-door experience to easily observe the full stack of your software. We automatically create and maintain visibility from the data you send us. Use the New Relic Explorer to access and give context to the performance data from all your monitored applications, services, hosts, containers, synthetic monitors, etc. You can quickly see the entities related to a problem, exposing possible root causes and what other systems might be affected. Why it matters With the New Relic Explorer, it’s more than just observing the metrics: understand the root of what’s happening, not just the symptoms. Gain extensive visibility of each entity in your solution, its alert status, and how the entities are connected, at a glance. See all your workloads, and create a new one in a click. Get a high level view of how your system’s doing with the New Relic Navigator. Quickly grasp unusual trends and behaviors with New Relic Lookout. Filter and group related entities to quickly drill down to the issues. Troubleshoot issues with tools that are faster, less cumbersome, and more accurate. Identify areas of improvement, and plan your changes. Want to learn more? See the video (it's only 45 seconds!): Short guide to using the New Relic Explorer. View and connect the performance of your entities Access the New Relic Explorer at one.newrelic.com and see together data reported by any entity from across all of your New Relic accounts. Entity categories include: Services: APM-monitored applications and services monitored. Hosts: your monitored infrastructure (your servers and hosts). Mobile applications: your mobile apps. Browser applications: your front-end browser apps. Integration-reported data: data from services monitored by our integrations, including our on-host integrations (like Kubernetes, StatsD, and NGINX), and cloud platform integrations, like Amazon, Microsoft Azure, and Google Cloud Platform (GCP). Workloads, your customized entity groupings. Containers, such as Kubernetes or Docker. Synthetic monitors, for simulations. Tip You can create new entity types to monitor any data source. Learn more about entity synthesis. Toggle between the Explorer's three views and the following features: one.newrelic.com > Explorer: Use the New Relic Explorer to locate and examine the entities you monitor. List. Browse and filter from a list of all the entities in your account. Use this landing interface to navigate, group, and filter your entities. New Relic Navigator. Get a high density overview of all your entities, grouped by entity type or by tags. Use this to detect any issues and health patterns at a glance. New Relic Lookout. Spot entities that have recent performance deviations. Use this to quickly identify unusual behaviors. Saved views. Save your favorite filters as a view and recover them in a click each time you return to the Explorer. Filterbar. Drill down and locate problematic entities easily with our improved search capabilities, and benefit from the AND and OR operators in one place. See everything. All the different entity types you have access to are listed in the collapsible sidebar on the left of the screen. This sidebar is interactive and used for exploratory purposes. It allows you to see only entities of the selected type, as it updates the filter from the filterbar. Create a new workload for meaningful groupings of your monitored entities. Add more data to instrument more elements of your system and achieve full stack observability. List view Your monitored entities are on the left, in a collapsable menu. You may need to scroll your list of entities to see them all. The list view also has a collapsable activity stream on the right side. You can see different useful events related to the first 25 alerting entities which are currently being filtered. Click on any entity for more details on its performance. The entity overview also incorporates the relationship between the selected entity and other entities in your system. New Relic Navigator The New Relic Navigator makes it easy to explore large numbers of entities as it intuitively displays the entire estate of your system in a highly dense honeycomb view with traffic light colors based on alerts. With the New Relic Navigator you can: Quickly explore the health of your environment at a glance. See all the entities that belong to all your accounts, and focus on specific entity types or specific groups of entities grouped by tags. Group and filter across all your entities to quickly zero in on issues. Click on any entity to see a mini-overview of its activity, metrics, and meta-data. New Relic Lookout New Relic Lookout provides an intuitive view of entities that are deviating from normal behavior, using circle visualization with color indicating severity and size conveying the scale of recent changes. You don’t need to configure anything: New Relic Lookout automatically compares performance within the last five minutes against the previous hour. Use New Relic Lookout to: Select the entity type to see golden signals of throughput, response time, and errors across all your accounts. Zoom in with correlations, abnormal history, traces, and the ability to leverage New Relic’s profiles across your estate. Click on an entity of interest to access the mini-overview component. Read more about New Relic Lookout. Tip You can modify the color palette to focus on clusters of interest. Understand the state of your system with the health (alert) status The New Relic Explorer shows a color-coded health status for entities. For example, you may see a red alert status indicating a critical violation in progress. To see what an alert status means, mouse over it. To see details about an entity's alerting status, select the entity. NRQL alert conditions aren't used to determine alert status because they aren't associated with specific entities. Important Starting June 8, 2020, New Relic One will not continue to display any APM application that hasn't reported data for 93 days. To match our published APM data retention guidelines, applications that have not reported data will be available within the New Relic UI for 90 days. After 90 days, those applications will be removed from the UI; however, key metrics will continue to be available via the New Relic REST API based on subscription level. For more information, see New Relic's Explorers Hub post. Filter entities using the filterbar The filterbar lets you select the entities displayed according to the conditions you enter: Type in a string of characters and/or numbers (for example, an environment) to find any entity that has this string in their name or ID. When typing, the UI suggests items that coincide with the string you're entering, so you can select one of those from the dropdown. You can also filter by the name of the entity, the entity type, account ID, environment, or a tag. Tip Selection parameters, once created, have a blue background. If you filter using a string, the filter will have the = operator. If you filter using the dropdown menu, once the first element of the searched item (tag key or attribute) is entered, you need to select an operator (=, !=, LIKE, NOT_LIKE, IN, NOT IN) for your filter. Once the operator is selected, complete the filter by selecting the value to complete the search item. To add more filters, first you have to select an operator, AND or OR. Use AND to indicate you want to restrict the selection removing entities from the list of results. You can also use the AND operator to add conditions that need to be met in the list of results, for example, entityType = Services AND location = APAC. Note that entityType = Services AND entityType = Hosts doesn’t return any results, as entities can only have one type and no entity would match this condition. Use OR to add more entities to the selection. For example, the filter entityType = Services OR entityType = Hosts returns every entity you have access to that is of type Services or Hosts. Entity data retention Availability of data depends on these factors: Scope Data retention New Relic Explorer and search In the UI, data is available for eight days after an entity no longer exists, with one exception: data reported by integrations, such as Amazon AWS, is only available for one day after an entity ceases to exist. Our database (accessible via NRQL query) For querying our database (for example, via the query builder or data explorer), availability is dependent on the data retention for that data type. As a result of these factors, a short-lived entity (like a cloud host) may not be available in the explorer list or via search, but its data may still be available via NRQL query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Explorer: View performance across apps, services, hosts",
        "sections": "<em>New</em> <em>Relic</em> Explorer: View performance across apps, services, hosts",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to monitor any data source. Learn more about entity synthesis. Toggle between the Explorer&#x27;s three views and the following features: <em>one</em>.newrelic.com &gt; Explorer: <em>Use</em> the <em>New</em> <em>Relic</em> Explorer to locate and examine the entities you monitor. List. Browse and filter from a list of all the entities in your"
      },
      "id": "603ec1f928ccbca50ceba7b6"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic": [
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-10-12T15:16:12Z",
      "updated_at": "2021-08-21T09:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters When using our API to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.21648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to filter the UI <em>Use</em> the filter field at the top of the <em>New</em> <em>Relic</em> Explorer to filter down to the entities you care about. You can <em>use</em> multiple filter conditions. To filter down to certain entities using tags: From <em>one</em>.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "sections": [
        "New Relic Lookout: Monitor your estate at a glance",
        "Why it matters",
        "Requirements",
        "Get started with New Relic Lookout",
        "Circle visualization and table view",
        "Abnormal golden signals",
        "Instant search",
        "Change view",
        "Drill down into the details",
        "Performance tab",
        "Abnormal History tab",
        "Correlations tab",
        "Profile tab",
        "Traces tab",
        "Create a custom view",
        "Query: Compare the last 15 minutes to the same time 1 day ago",
        "Query: Compare a specific time range to the same range a month ago",
        "Example: Unusual increases in error count"
      ],
      "title": "New Relic Lookout: Monitor your estate at a glance",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "9193dcc8851c185ff5d96f6f93ab412bd1be69e9",
      "image": "https://docs.newrelic.com/static/178b37068bad2a68cff027c8bdcf663a/c1b63/lookout-intro.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-lookout-monitor-your-estate-glance/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-08-21T09:27:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Lookout provides visibility into your entire estate. It doesn't require any configuration — you can query anything in your estate that matters to you right now and understand your system as a whole, or dive deep into causes and effects, so you can quickly get the data you need to take action. Know exactly where to focus your attention with New Relic Lookout. The brighter the color, the more severe the change, and the bigger the size, the bigger the scale. Then dig deeper with correlations and abnormal history to see how it impacts your whole system—no configuration needed. Why it matters New Relic Lookout helps software teams of any size discover potential issues before they have an impact. Fill gaps in monitoring with full coverage out-of-the-box, no configuration or setup required. Immediately see anything deviating from normal across your entire estate. Proactively spot emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in New Relic database (NRDB), including third-party, open, and custom data. Launch into other areas of New Relic One for deeper understanding Requirements New Relic Lookout requires Pro or Enterprise edition. If you are on Standard edition, you can still use the New Relic Lookout view in the New Relic Explorer. If you want to see data spanning 13-months, correlations, profiles, traces, and other details, you must upgrade to a higher edition. Get started with New Relic Lookout To access New Relic Lookout, click the Apps button in New Relic One and locate the New Relic Lookout launcher. You can also access New Relic Lookout directly from the New Relic One header bar, via the More dropdown. Enablement of key service performance indicator data is required for New Relic Lookout to provide value from the data you already have. The default view provides insight into three key Service performance indicators broken down by application: throughput, response time, and errors. These metrics are analyzed to show how the data has behaved during the last five minutes compared to the prior hour. one.newrelic.com > Apps > New Relic Lookout: Anything that significantly deviates from the trend is automatically discovered by New Relic Lookout, which doesn't require any configuration. Circle visualization and table view Each application (or other facet) is represented by a circle. The size of the circles indicate the magnitude of the signal for that application and the color indicates whether the value has significantly decreased or increased in the last five minutes, based on the standard deviation of the prior hour (default evaluation and comparison time windows.) Please note that the type of signal is important when interpreting your results. When you first look at the legend below, you might be tempted to interpret yellow as good and dark purple as bad, but that is not always the case. Here are some examples: In the APM/services golden signals, a dark yellow circle in Throughput might signify that something bad has occurred and led to a drop in traffic. At the same time, a dark purple circle might also be concerning due to unexpected load. Both are significant findings worth exploring. In browser golden signals, a dark purple circle in Page Views might be great, as you are seeing more traffic to your site! With errors golden signals (in all entity types), a large circle, even if gray (not deviating from normal volume), is worth exploring because a high count of errors in your system is important to investigate. The legend allows you to change the colors used to highlight deviating services To change the color palette, click the gear icon by the low-high color legend. This allows you to change the colors used to highlight deviating services. To get a table view of the same data, click the toggle on the right. You can also hover over each color to filter the view by degree lower or higher deviance. Abnormal golden signals On the right, New Relic Lookout displays the most significantly deviating applications (or other facet) in a side panel, weighted by both the magnitude of the performance indicators and the scale of their deviations. Details include the name of the key performance indicator, their magnitude during the recent time window, and the difference between the averages from one time compared to the other. Instant search Click the magnifying glass icon in the side panel to open a search box. Typing into the search box filters the circles, table, and abnormal signals to applications (or other facets) that contain the text. This is a good way to quickly zoom to various subsystems. New Relic Lookout doesn't rerun the analysis when using the instant search. Change view Click the Change View button on the right side panel. The panel that appears shows you all the entity-specific golden signals you can toggle between out of the box. By choosing the Browser Golden Signal or other views, you can change from the default view. Each new view will have the golden signals appropriate for that entity type. Drill down into the details To analyze an application or facet, click a circle, table row, or abnormal golden signal. The details panel shows the degree of deviation of the performance indicator, a link to the affected entity, and recent alert and deployment activity for that entity, when available. There’s also an indication of whether the selected evaluation time period would be abnormal or not in reference to other comparison time windows, such as the same time yesterday or the same time last week. This allows you to quickly see if the abnormal behavior is odd in general, or just based on the comparison time window. Performance tab The default tab shows charts for other key performance indicators for the selected application or facet. The charts compare the two time windows being analyzed. You can click their titles to rerun the analysis, focusing on the selected key performance indicator. When the target is a New Relic One application, we show the top transactions, error classes, external services, and database operations, alongside links to the relevant New Relic One features. Abnormal History tab This section analyzes past performance of the selected signal and calls out any time periods with notable abnormalities. Each card represents an abnormal time window and can be clicked for more details. The charts will display any relevant violations and deployments in New Relic. Correlations tab New Relic Lookout can find other signals that began behaving differently around the same time as the selected signal for that entity type. Clicking the name of the signal reruns the analysis, focusing on that key performance indicator. The chart titles link to New Relic One when there’s an associated entity in your account. Note that correlations currently do not analyze across accounts. The correlated signals displayed are for others in the account of the original application you are viewing. This helps focus the data on correlations that are more likely related to your issue. Profile tab Based on the same technology as New Relic’s error profiles, this tab compares the last five minutes to the prior hour by default (or whatever time windows you’ve selected with query editing) and surfaces any attributes that have significantly different distributions in the events being targeted by the selected signal. For example, if a custom attribute indicated that a recent throughput spike came from one user, that would surface highly in Profiles if most of the traffic usually comes from many users. Traces tab If the entity has distributed traces configured and available in the selected evaluated time window, the Traces section is enabled. Each card shows a summary of a trace and can be clicked for details. The Explore all traces links to the distributed traces application, filtered to the selected entity. Create a custom view To target signals and time windows beyond the default values, click the Change view button and select Custom view. To create your own view: Select the account or subaccount. Select the data type (metrics or events). Different functionality is available depending on the type. In View a chart with, select the metric or event you are interested in. Default is golden signals (throughput, response time, and errors). You can also build custom queries (filters) to target a signal that isn't on the list. In Facet by, select what the circles represent. Default is appName, but you can also choose host or any other facetable attribute available for the signal you’ve selected. If you plan to save/favorite this new view, provide a name in the Name your view box. Keep in mind that you can edit this view at any time using the pencil icon. The default time windows analyzed by New Relic Lookout are the last five minutes compared to the hour before. Use the time controls (View data from and Compare data to) to target other time windows. one.newrelic.com > Apps > New Relic Lookout: All event and metric data in the New Relic database can be queried using the Edit query feature. Click Analyze to begin analyzing the signal you’ve selected. You can also create your own query: Create your query. This query is comparing data from the past thirty minutes to data from the same range a day ago. Change from Basic to Advanced after clicking the Custom view button. Select the data type (metrics or events). Different functionality is available depending on the type. Enter your query using NRQL. Please note that not all NRQL features are available in the Lookout Advanced query feature. By default, the system will run this query using the last five minutes of data compared to the previous hour. Some examples of the syntax for changing the comparison and evaluation time windows are below. Click Analyze to begin analyzing the signal you’ve selected. Query: Compare the last 15 minutes to the same time 1 day ago Please note that the UNTIL NOW portion is required here unlike in standard NRQL. Without the UNTIL NOW added, the system will query a 5 minute slice of data starting 15 minutes ago SINCE 15 minutes AGO UNTIL NOW COMPARE WITH 1 day ago Copy Query: Compare a specific time range to the same range a month ago SINCE '2021-03-07 07:00:00-0500' UNTIL '2021-03-08 07:00:00-0500' COMPARE WITH 1 month ago Copy Or: SINCE 'today at midnight' UNTIL 'now' COMPARE WITH 1 MONTH AGO Copy Example: Unusual increases in error count The default view of New Relic Lookout shows application status across your estate, comparing the last five minutes to the hour before. Under regular operation, most large systems may have a handful of abnormalities, but usually most things will indicate normal behavior. Suddenly, several circles begin to change to red under the Errors section. This indicates that several applications are experiencing unusual increases in error count. It may be that one or two circles for important systems are red, and perhaps much larger than they usually appear. Clicking one of these can provide more information on what is happening. You might see that the error rate is substantially elevated, even thousands of percent higher than normal. To troubleshoot this issue, here's what you might discover in the New Relic Lookout tabs: Performance would show you data about other signals, illuminating the characteristics of the change in system dynamics. Correlations would surface other applications that are affected and how, as well as opportunities to pivot to other applications that may be closer to the underlying causes. Traces, in turn, would show distributed traces, which can provide specific examples of traffic running through those systems. Abnormal history would show other times in the past week with elevated errors, showing whether or not this problem happens regularly, such as every day at the same time or whenever there is a deployment. Profiles might show that all or most of the new errors share common properties, such as all being isolated to just one region/account/user. Combining the information from these sections, not only can you get a sense of what is going on, but also where to focus actions to resolve the problem.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.21614,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "sections": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in <em>New</em> <em>Relic</em> database (NRDB), including third-party, open, and custom data. Launch into other areas of <em>New</em> <em>Relic</em> <em>One</em> for deeper"
      },
      "id": "603e821e64441f5a444e8845"
    },
    {
      "sections": [
        "New Relic Explorer: View performance across apps, services, hosts",
        "Why it matters",
        "View and connect the performance of your entities",
        "Tip",
        "List view",
        "New Relic Navigator",
        "New Relic Lookout",
        "Understand the state of your system with the health (alert) status",
        "Important",
        "Filter entities using the filterbar",
        "Entity data retention"
      ],
      "title": "New Relic Explorer: View performance across apps, services, hosts",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e1029a5f385863d0feffa2a6ebedcc417bbc9fbf",
      "image": "https://docs.newrelic.com/static/418c556bcaa53ce2b71a5b5fdfee88d8/be86f/new-relic-one-entity-alert-status-red.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-explorer-view-performance-across-apps-services-hosts/",
      "published_at": "2021-10-13T05:59:04Z",
      "updated_at": "2021-07-28T06:53:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In digital business, systems are becoming increasingly large, complex, and interdependent. You have hundreds of applications and services running at the same time, and you need to monitor thousands of elements emitting data (we call those data sources entities). With the New Relic Explorer, we give you a new, efficient front-door experience to easily observe the full stack of your software. We automatically create and maintain visibility from the data you send us. Use the New Relic Explorer to access and give context to the performance data from all your monitored applications, services, hosts, containers, synthetic monitors, etc. You can quickly see the entities related to a problem, exposing possible root causes and what other systems might be affected. Why it matters With the New Relic Explorer, it’s more than just observing the metrics: understand the root of what’s happening, not just the symptoms. Gain extensive visibility of each entity in your solution, its alert status, and how the entities are connected, at a glance. See all your workloads, and create a new one in a click. Get a high level view of how your system’s doing with the New Relic Navigator. Quickly grasp unusual trends and behaviors with New Relic Lookout. Filter and group related entities to quickly drill down to the issues. Troubleshoot issues with tools that are faster, less cumbersome, and more accurate. Identify areas of improvement, and plan your changes. Want to learn more? See the video (it's only 45 seconds!): Short guide to using the New Relic Explorer. View and connect the performance of your entities Access the New Relic Explorer at one.newrelic.com and see together data reported by any entity from across all of your New Relic accounts. Entity categories include: Services: APM-monitored applications and services monitored. Hosts: your monitored infrastructure (your servers and hosts). Mobile applications: your mobile apps. Browser applications: your front-end browser apps. Integration-reported data: data from services monitored by our integrations, including our on-host integrations (like Kubernetes, StatsD, and NGINX), and cloud platform integrations, like Amazon, Microsoft Azure, and Google Cloud Platform (GCP). Workloads, your customized entity groupings. Containers, such as Kubernetes or Docker. Synthetic monitors, for simulations. Tip You can create new entity types to monitor any data source. Learn more about entity synthesis. Toggle between the Explorer's three views and the following features: one.newrelic.com > Explorer: Use the New Relic Explorer to locate and examine the entities you monitor. List. Browse and filter from a list of all the entities in your account. Use this landing interface to navigate, group, and filter your entities. New Relic Navigator. Get a high density overview of all your entities, grouped by entity type or by tags. Use this to detect any issues and health patterns at a glance. New Relic Lookout. Spot entities that have recent performance deviations. Use this to quickly identify unusual behaviors. Saved views. Save your favorite filters as a view and recover them in a click each time you return to the Explorer. Filterbar. Drill down and locate problematic entities easily with our improved search capabilities, and benefit from the AND and OR operators in one place. See everything. All the different entity types you have access to are listed in the collapsible sidebar on the left of the screen. This sidebar is interactive and used for exploratory purposes. It allows you to see only entities of the selected type, as it updates the filter from the filterbar. Create a new workload for meaningful groupings of your monitored entities. Add more data to instrument more elements of your system and achieve full stack observability. List view Your monitored entities are on the left, in a collapsable menu. You may need to scroll your list of entities to see them all. The list view also has a collapsable activity stream on the right side. You can see different useful events related to the first 25 alerting entities which are currently being filtered. Click on any entity for more details on its performance. The entity overview also incorporates the relationship between the selected entity and other entities in your system. New Relic Navigator The New Relic Navigator makes it easy to explore large numbers of entities as it intuitively displays the entire estate of your system in a highly dense honeycomb view with traffic light colors based on alerts. With the New Relic Navigator you can: Quickly explore the health of your environment at a glance. See all the entities that belong to all your accounts, and focus on specific entity types or specific groups of entities grouped by tags. Group and filter across all your entities to quickly zero in on issues. Click on any entity to see a mini-overview of its activity, metrics, and meta-data. New Relic Lookout New Relic Lookout provides an intuitive view of entities that are deviating from normal behavior, using circle visualization with color indicating severity and size conveying the scale of recent changes. You don’t need to configure anything: New Relic Lookout automatically compares performance within the last five minutes against the previous hour. Use New Relic Lookout to: Select the entity type to see golden signals of throughput, response time, and errors across all your accounts. Zoom in with correlations, abnormal history, traces, and the ability to leverage New Relic’s profiles across your estate. Click on an entity of interest to access the mini-overview component. Read more about New Relic Lookout. Tip You can modify the color palette to focus on clusters of interest. Understand the state of your system with the health (alert) status The New Relic Explorer shows a color-coded health status for entities. For example, you may see a red alert status indicating a critical violation in progress. To see what an alert status means, mouse over it. To see details about an entity's alerting status, select the entity. NRQL alert conditions aren't used to determine alert status because they aren't associated with specific entities. Important Starting June 8, 2020, New Relic One will not continue to display any APM application that hasn't reported data for 93 days. To match our published APM data retention guidelines, applications that have not reported data will be available within the New Relic UI for 90 days. After 90 days, those applications will be removed from the UI; however, key metrics will continue to be available via the New Relic REST API based on subscription level. For more information, see New Relic's Explorers Hub post. Filter entities using the filterbar The filterbar lets you select the entities displayed according to the conditions you enter: Type in a string of characters and/or numbers (for example, an environment) to find any entity that has this string in their name or ID. When typing, the UI suggests items that coincide with the string you're entering, so you can select one of those from the dropdown. You can also filter by the name of the entity, the entity type, account ID, environment, or a tag. Tip Selection parameters, once created, have a blue background. If you filter using a string, the filter will have the = operator. If you filter using the dropdown menu, once the first element of the searched item (tag key or attribute) is entered, you need to select an operator (=, !=, LIKE, NOT_LIKE, IN, NOT IN) for your filter. Once the operator is selected, complete the filter by selecting the value to complete the search item. To add more filters, first you have to select an operator, AND or OR. Use AND to indicate you want to restrict the selection removing entities from the list of results. You can also use the AND operator to add conditions that need to be met in the list of results, for example, entityType = Services AND location = APAC. Note that entityType = Services AND entityType = Hosts doesn’t return any results, as entities can only have one type and no entity would match this condition. Use OR to add more entities to the selection. For example, the filter entityType = Services OR entityType = Hosts returns every entity you have access to that is of type Services or Hosts. Entity data retention Availability of data depends on these factors: Scope Data retention New Relic Explorer and search In the UI, data is available for eight days after an entity no longer exists, with one exception: data reported by integrations, such as Amazon AWS, is only available for one day after an entity ceases to exist. Our database (accessible via NRQL query) For querying our database (for example, via the query builder or data explorer), availability is dependent on the data retention for that data type. As a result of these factors, a short-lived entity (like a cloud host) may not be available in the explorer list or via search, but its data may still be available via NRQL query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.86299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Explorer: View performance across apps, services, hosts",
        "sections": "<em>New</em> <em>Relic</em> Explorer: View performance across apps, services, hosts",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to monitor any data source. Learn more about entity synthesis. Toggle between the Explorer&#x27;s three views and the following features: <em>one</em>.newrelic.com &gt; Explorer: <em>Use</em> the <em>New</em> <em>Relic</em> Explorer to locate and examine the entities you monitor. List. Browse and filter from a list of all the entities in your"
      },
      "id": "603ec1f928ccbca50ceba7b6"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/get-started/introduction-new-relic-one": [
    {
      "sections": [
        "New Relic Lookout: Monitor your estate at a glance",
        "Why it matters",
        "Requirements",
        "Get started with New Relic Lookout",
        "Circle visualization and table view",
        "Abnormal golden signals",
        "Instant search",
        "Change view",
        "Drill down into the details",
        "Performance tab",
        "Abnormal History tab",
        "Correlations tab",
        "Profile tab",
        "Traces tab",
        "Create a custom view",
        "Query: Compare the last 15 minutes to the same time 1 day ago",
        "Query: Compare a specific time range to the same range a month ago",
        "Example: Unusual increases in error count"
      ],
      "title": "New Relic Lookout: Monitor your estate at a glance",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "9193dcc8851c185ff5d96f6f93ab412bd1be69e9",
      "image": "https://docs.newrelic.com/static/178b37068bad2a68cff027c8bdcf663a/c1b63/lookout-intro.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/new-relic-lookout-monitor-your-estate-glance/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-08-21T09:27:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Lookout provides visibility into your entire estate. It doesn't require any configuration — you can query anything in your estate that matters to you right now and understand your system as a whole, or dive deep into causes and effects, so you can quickly get the data you need to take action. Know exactly where to focus your attention with New Relic Lookout. The brighter the color, the more severe the change, and the bigger the size, the bigger the scale. Then dig deeper with correlations and abnormal history to see how it impacts your whole system—no configuration needed. Why it matters New Relic Lookout helps software teams of any size discover potential issues before they have an impact. Fill gaps in monitoring with full coverage out-of-the-box, no configuration or setup required. Immediately see anything deviating from normal across your entire estate. Proactively spot emerging problems in a real-time visualization of all system components. Gain faster incidents resolution through automatically surfaced causes and effects. Analyze any data in New Relic database (NRDB), including third-party, open, and custom data. Launch into other areas of New Relic One for deeper understanding Requirements New Relic Lookout requires Pro or Enterprise edition. If you are on Standard edition, you can still use the New Relic Lookout view in the New Relic Explorer. If you want to see data spanning 13-months, correlations, profiles, traces, and other details, you must upgrade to a higher edition. Get started with New Relic Lookout To access New Relic Lookout, click the Apps button in New Relic One and locate the New Relic Lookout launcher. You can also access New Relic Lookout directly from the New Relic One header bar, via the More dropdown. Enablement of key service performance indicator data is required for New Relic Lookout to provide value from the data you already have. The default view provides insight into three key Service performance indicators broken down by application: throughput, response time, and errors. These metrics are analyzed to show how the data has behaved during the last five minutes compared to the prior hour. one.newrelic.com > Apps > New Relic Lookout: Anything that significantly deviates from the trend is automatically discovered by New Relic Lookout, which doesn't require any configuration. Circle visualization and table view Each application (or other facet) is represented by a circle. The size of the circles indicate the magnitude of the signal for that application and the color indicates whether the value has significantly decreased or increased in the last five minutes, based on the standard deviation of the prior hour (default evaluation and comparison time windows.) Please note that the type of signal is important when interpreting your results. When you first look at the legend below, you might be tempted to interpret yellow as good and dark purple as bad, but that is not always the case. Here are some examples: In the APM/services golden signals, a dark yellow circle in Throughput might signify that something bad has occurred and led to a drop in traffic. At the same time, a dark purple circle might also be concerning due to unexpected load. Both are significant findings worth exploring. In browser golden signals, a dark purple circle in Page Views might be great, as you are seeing more traffic to your site! With errors golden signals (in all entity types), a large circle, even if gray (not deviating from normal volume), is worth exploring because a high count of errors in your system is important to investigate. The legend allows you to change the colors used to highlight deviating services To change the color palette, click the gear icon by the low-high color legend. This allows you to change the colors used to highlight deviating services. To get a table view of the same data, click the toggle on the right. You can also hover over each color to filter the view by degree lower or higher deviance. Abnormal golden signals On the right, New Relic Lookout displays the most significantly deviating applications (or other facet) in a side panel, weighted by both the magnitude of the performance indicators and the scale of their deviations. Details include the name of the key performance indicator, their magnitude during the recent time window, and the difference between the averages from one time compared to the other. Instant search Click the magnifying glass icon in the side panel to open a search box. Typing into the search box filters the circles, table, and abnormal signals to applications (or other facets) that contain the text. This is a good way to quickly zoom to various subsystems. New Relic Lookout doesn't rerun the analysis when using the instant search. Change view Click the Change View button on the right side panel. The panel that appears shows you all the entity-specific golden signals you can toggle between out of the box. By choosing the Browser Golden Signal or other views, you can change from the default view. Each new view will have the golden signals appropriate for that entity type. Drill down into the details To analyze an application or facet, click a circle, table row, or abnormal golden signal. The details panel shows the degree of deviation of the performance indicator, a link to the affected entity, and recent alert and deployment activity for that entity, when available. There’s also an indication of whether the selected evaluation time period would be abnormal or not in reference to other comparison time windows, such as the same time yesterday or the same time last week. This allows you to quickly see if the abnormal behavior is odd in general, or just based on the comparison time window. Performance tab The default tab shows charts for other key performance indicators for the selected application or facet. The charts compare the two time windows being analyzed. You can click their titles to rerun the analysis, focusing on the selected key performance indicator. When the target is a New Relic One application, we show the top transactions, error classes, external services, and database operations, alongside links to the relevant New Relic One features. Abnormal History tab This section analyzes past performance of the selected signal and calls out any time periods with notable abnormalities. Each card represents an abnormal time window and can be clicked for more details. The charts will display any relevant violations and deployments in New Relic. Correlations tab New Relic Lookout can find other signals that began behaving differently around the same time as the selected signal for that entity type. Clicking the name of the signal reruns the analysis, focusing on that key performance indicator. The chart titles link to New Relic One when there’s an associated entity in your account. Note that correlations currently do not analyze across accounts. The correlated signals displayed are for others in the account of the original application you are viewing. This helps focus the data on correlations that are more likely related to your issue. Profile tab Based on the same technology as New Relic’s error profiles, this tab compares the last five minutes to the prior hour by default (or whatever time windows you’ve selected with query editing) and surfaces any attributes that have significantly different distributions in the events being targeted by the selected signal. For example, if a custom attribute indicated that a recent throughput spike came from one user, that would surface highly in Profiles if most of the traffic usually comes from many users. Traces tab If the entity has distributed traces configured and available in the selected evaluated time window, the Traces section is enabled. Each card shows a summary of a trace and can be clicked for details. The Explore all traces links to the distributed traces application, filtered to the selected entity. Create a custom view To target signals and time windows beyond the default values, click the Change view button and select Custom view. To create your own view: Select the account or subaccount. Select the data type (metrics or events). Different functionality is available depending on the type. In View a chart with, select the metric or event you are interested in. Default is golden signals (throughput, response time, and errors). You can also build custom queries (filters) to target a signal that isn't on the list. In Facet by, select what the circles represent. Default is appName, but you can also choose host or any other facetable attribute available for the signal you’ve selected. If you plan to save/favorite this new view, provide a name in the Name your view box. Keep in mind that you can edit this view at any time using the pencil icon. The default time windows analyzed by New Relic Lookout are the last five minutes compared to the hour before. Use the time controls (View data from and Compare data to) to target other time windows. one.newrelic.com > Apps > New Relic Lookout: All event and metric data in the New Relic database can be queried using the Edit query feature. Click Analyze to begin analyzing the signal you’ve selected. You can also create your own query: Create your query. This query is comparing data from the past thirty minutes to data from the same range a day ago. Change from Basic to Advanced after clicking the Custom view button. Select the data type (metrics or events). Different functionality is available depending on the type. Enter your query using NRQL. Please note that not all NRQL features are available in the Lookout Advanced query feature. By default, the system will run this query using the last five minutes of data compared to the previous hour. Some examples of the syntax for changing the comparison and evaluation time windows are below. Click Analyze to begin analyzing the signal you’ve selected. Query: Compare the last 15 minutes to the same time 1 day ago Please note that the UNTIL NOW portion is required here unlike in standard NRQL. Without the UNTIL NOW added, the system will query a 5 minute slice of data starting 15 minutes ago SINCE 15 minutes AGO UNTIL NOW COMPARE WITH 1 day ago Copy Query: Compare a specific time range to the same range a month ago SINCE '2021-03-07 07:00:00-0500' UNTIL '2021-03-08 07:00:00-0500' COMPARE WITH 1 month ago Copy Or: SINCE 'today at midnight' UNTIL 'now' COMPARE WITH 1 MONTH AGO Copy Example: Unusual increases in error count The default view of New Relic Lookout shows application status across your estate, comparing the last five minutes to the hour before. Under regular operation, most large systems may have a handful of abnormalities, but usually most things will indicate normal behavior. Suddenly, several circles begin to change to red under the Errors section. This indicates that several applications are experiencing unusual increases in error count. It may be that one or two circles for important systems are red, and perhaps much larger than they usually appear. Clicking one of these can provide more information on what is happening. You might see that the error rate is substantially elevated, even thousands of percent higher than normal. To troubleshoot this issue, here's what you might discover in the New Relic Lookout tabs: Performance would show you data about other signals, illuminating the characteristics of the change in system dynamics. Correlations would surface other applications that are affected and how, as well as opportunities to pivot to other applications that may be closer to the underlying causes. Traces, in turn, would show distributed traces, which can provide specific examples of traffic running through those systems. Abnormal history would show other times in the past week with elevated errors, showing whether or not this problem happens regularly, such as every day at the same time or whenever there is a deployment. Profiles might show that all or most of the new errors share common properties, such as all being isolated to just one region/account/user. Combining the information from these sections, not only can you get a sense of what is going on, but also where to focus actions to resolve the problem.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.14711,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Lookout: Monitor your estate at a glance",
        "sections": "<em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em> Lookout",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to a higher edition. <em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em> Lookout To access <em>New</em> <em>Relic</em> Lookout, click the Apps button in <em>New</em> <em>Relic</em> <em>One</em> and locate the <em>New</em> <em>Relic</em> Lookout launcher. You can also access <em>New</em> <em>Relic</em> Lookout directly from the <em>New</em> <em>Relic</em> <em>One</em> header bar, via the More dropdown. Enablement of key service"
      },
      "id": "603e821e64441f5a444e8845"
    },
    {
      "sections": [
        "What is an entity in New Relic?",
        "What's an entity?",
        "Find and explore entities and entity data",
        "Tip",
        "Group and organize entities",
        "Customize entity data with entity synthesis",
        "Reserved attributes for synthesized entities",
        "Entity relationships",
        "Important",
        "Which relationships are created?",
        "Source: New Relic agent",
        "Source: Infrastructure",
        "Source: Synthetics monitor",
        "Source: Kubernetes",
        "External services"
      ],
      "title": "What is an entity in New Relic?",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "52a3e08bc9103c717d27b153e4fd4f547d6ecc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/",
      "published_at": "2021-10-12T15:06:27Z",
      "updated_at": "2021-09-01T17:25:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic monitoring is built around the concept of entities. In this doc, you'll learn how we define entities, what you can do with them, and how you can create your own entities or groupings of entities. What's an entity? From a New Relic perspective, entity is purposefully a broad concept. An entity is anything that a) reports data to New Relic or that contains data that we have access to, and b) is something we've identified with a unique entity ID. For most entities, the ID is indicated by the attribute entityGuid. An entity can be any fundamental data-reporting component, like an application, a host, or a database service, but it can also refer to larger groupings of those components. For example, to monitor a data center, you could aggregate those hosts in New Relic to be a workload (a custom grouping of entities). That workload is, itself, also an entity. Also very important is the relationships between entities. Our behind-the-scenes relationship-mapping helps us understand how entities are connected, how they affect each other. And this allows us to give you the power to configure how any data you're bringing in is related to existing entities, or how it's related to other entities. Our focus on entities and their relationships is important because our goal is to give you practical information about your business-important entities, and not give you an unhelpfully huge stream of data from a huge list of monitored things. With more insight at the entity level, you can better monitor and troubleshoot complex, modern systems. Find and explore entities and entity data Tip You can create new entity types for monitoring any data source. Learn more about entity synthesis. Some tips for finding and understanding entity data: To find an entity's entityGuid and entityName and other metadata: from any list of monitored entities in the New Relic Explorer, click an entity's icon, and click See metadata and tags. For most entities, its GUID is reported as the attribute entityGuid. For workloads, it's workloadGuid. You can run NRQL queries to find entities by their GUID. To see connections between entities, you have several options: When viewing an entity in the UI, use the Related entities UI. Service maps. Distributed tracing. Our NerdGraph API. To group entities together, see Group entities. Customize entity definitions and relationships. To learn technical details about entity types, see our GitHub repo. In an entity type's definition file, you'll see information like: The domain: for example, APM, or Infra. Its type: for example, Application or AWSECSCONTAINERINSTANCE. Default tags. The entityExpirationTime: how long data from that entity lasts in the UI, which is different from database data retention. Group and organize entities You can place entities into groups that reflect business-important relationships in your organization. For example, you might group all entities related to a specific team or department, or related to a specific service. Or you might group multiple hosts together to reflect their grouping in a data center. To group your entities, see: Tag entities. Create workloads, which allow you to group business-important sets of entities. Create entities and customize entity data Customize entity data with entity synthesis If you have telemetry from any source that's not supported by New Relic out of the box, you can propose a mapping for it. Once approved, any telemetry received by New Relic that matches your definition file will be synthesized into an entity. To learn more: For reserved attributes and how entity relationships are defined, keep reading this doc. For how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Reserved attributes for synthesized entities These attributes are meant to be synthesized from the telemetry we receive. Do not set them unless you're aware of the implications and consequences. Attribute Description entity.guid Generally, you should not set this attribute field on your telemetry data. New Relic may add this field to ingested data to store a unique identifier for the entity associated with the data point. If telemetry arrives with the entity.guid attribute already present, then New Relic will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. One use case for passing this attribute is to associate ingested telemetry with an entity already created by New Relic. When the entity.guid attribute is sent, the value will override New Relic’s entity identification system (such as entity synthesis definitions) and instead will use the attribute as the data. entity.name This attribute shouldn't be put on ingested telemetry data unless you're trying to override the entity name that would have been selected by New Relic’s entity identification system. While New Relic won't change the value if it's already present on the data, New Relic may add the attribute to your data. Therefore invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. If this field is present on ingested telemetry, its value will be used to name the entity associated with the data point. This name will be used instead of the name selected by New Relic’s entity identification system (for example, entity synthesis definitions). Note that many entities use the name as part of their identification, so changing this field may result in the generation of a new entity. entity.type This attribute shouldn't be put on ingested telemetry data except for certain legacy cases where it's required to distinguish entity types. Passing this field may interfere with entity detection, particularly if unrecognized values are sent in this field. While New Relic won't change the value if already present on the data, the field is not guaranteed to provide unambiguous filtering of telemetry at query-time. Existing entity definitions already have overlapping values, and we recommend avoiding entity.type in favor of other fields for filtering telemetry queries. This field is used by New Relic, meaning that invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. To learn how to do the work of modifying existing entity types or creating new ones, see our GitHub repo on entity synthesis. Entity relationships Connections between entities are automatically created by New Relic based on what we can infer from your telemetry. For example, when two services that communicate using HTTP are instrumented with New Relic, we infer a \"calls/called-by\" relationship between them. When viewing a specific entity in either the New Relic Explorer, Navigator, or Lookout, you can see its Related entities in the entity's mini overview. This gives a visualization of the various entities connected directly to the current entity. You can quickly view important metrics for these related entities and navigate from one entity to another, through all the connected parts of your stack. Tip Learn more about how entities are related with our NerdGraph API. When relationships are not automatically detected, you can manually create them using the \"Add/edit related entities\" link in Related entities. Important Currently, you can only manually create calls/called-by relationships between service entities. Tip To manage manual relationships, you need to have modify and delete capabilities on entity relationships. If you don’t see the edit relationships button, contact your account admin. Which relationships are created? These are the relationships created between entities: Source: New Relic agent Relationship source Relationship type Relationship target Why is the relationship created? Application instrumented with a New Relic agent CALLS Application instrumented with a New Relic agent Relationships between applications monitored by New Relic agents are reported using the DurationByCaller metric. The callee reports the metric. For example, the metric DurationByCaller/Mobile/100/1234/HTTP/all indicates that the caller is APPLICATION 1234 for account 100. Application instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent An application (caller) that calls a service (callee) monitored by New Relic creates a relationship that's reported by the caller using the ExternalApp metric. For example, the metric ExternalApp/dirac.vips.net/100#1234/all indicates that the callee is APPLICATION 1234 for account 100. The metric is reported if the callee successfully responds to the caller. Service instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent When a New Relic agent detects that a service (caller) calls another service (callee) instrumented by New Relic, the callee reports the metric ClientApplication. For example, the metric ClientApplication/100#1234/all indicates that the caller is APPLICATION 1234 for account 100. Service instrumented with a New Relic agent CALLS A datastore instance When an application calls a datastore instance it creates a relationship reported with the DatastoreInstance metric. For example, the metric Datastore/instance/MySQL/172.16.16.3/3306 indicates the datastore instance is vendor: MySQL, host: 172.16.16.3, port: 3306. This metric also supports the legacy datastore instance format Datastore/instance/MySQL/172.16.16.3:3306. Currently we cannot determine whether the datastore instance is instrumented by New Relic and has an entity associated to it. APM agent SERVES Browser agent This relationship is created when an APM agent injects the browser agent into a page. Workload entity CONTAINS Any entity When a workload is created or updated, relationships for each of the entities that belong to the workload are created. Because some workloads are “dynamic” (defined by tags), relationships are re-created every 5 minutes. This way entities can join or leave the workload. Source: Infrastructure Relationship source Relationship type Relationship target Why is the relationship created? Infrastructure host HOSTS Application This relationship is created when an application is running in one or more hosts, and the infra agent is running in those hosts. Infrastructure host HOSTS Container This relationship is created when containers are running in one or more hosts, and the host is instrumented with the infra agent. Source: Synthetics monitor Relationship source Relationship type Relationship target Why is the relationship created? Synthetics Monitor CALLS Browser agent This relationship is created when a synthetics monitor checks a page instrumented with the browser agent. Synthetics Monitor CALLS APM application Agent events that contain the attribute nr.syntheticsMonitorId have been described as synthetics monitors (the source) interacting with an APM application (the target). If the header exists and the APM application Id exists, a relationship is created between the monitor and the app. Source: Kubernetes Relationship source Relationship type Relationship target Why is the relationship created? Cluster CONTAINS Pod This relationship is created when a pod is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Deployment This relationship is created when a deployment is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS DaemonSet This relationship is created when a DaemonSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS StatefulSet This relationship is created when a StatefulSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Host This relationship is created when a host that's part of a cluster is instrumented with the New Relic Kubernetes integration. Deployment CONTAINS Pod This relationship is created when a deployment creates a pod in a cluster instrumented with the New Relic Kubernetes integration. DaemonSet CONTAINS Pod This relationship is created when a DaemonSet is created a pod in a cluster instrumented with the New Relic Kubernetes integration. StatefulSet CONTAINS Pod This relationship is created when a StatefulSet creates a pod in a cluster instrumented with the New Relic Kubernetes integration. Pod CONTAINS Container This relationship is created when a pod creates a container in a cluster instrumented with the New Relic Kubernetes integration. Host HOSTS Pod This relationship is created when a pod is running in a host that's part of a cluster instrumented with the New Relic Kubernetes integration. Container HOSTS Application This relationship is created when an application is running in docker, and the hosts where docker is running are instrumented by the the infra agent. External services Relationship source Relationship type Relationship target Why is the relationship created? External service CALLS External service When the relationship is created, the external service reports a span with its name on the service.name attribute and the name of the service that initiates the call in the parent.service.name attribute. Application IS External service A relationship between an application and an external service is created so that users can navigate between them using the related entities component. Browser application instrumented with a New Relic agent CALLS External service A browser application reports an Ajax/HostTransaction metric when calling an external service (URL). Example metric: Ajax/HostTransaction/api.segment.io:443/CallbackTime' Cluster CONTAINS External service When the relationship is created, the external service reports a span with the attribute k8s.cluster.name, the name of the cluster. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span. Pod HOSTS External service When the relationship is created, the external service reports a span with the following attributes: service.name: The name of the service. k8s.cluster.name: The name of the cluster. k8s.pod.name: The name of the pod that’s running the service. k8s.namespace.name: The namespace where the pod was created. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.4317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "What is an entity in <em>New</em> <em>Relic</em>?",
        "sections": "What is an entity in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ". If telemetry arrives with the entity.guid attribute already present, then <em>New</em> <em>Relic</em> will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. <em>One</em> <em>use</em> case for passing this attribute is to associate"
      },
      "id": "603ec160e7b9d295f72a07fc"
    },
    {
      "sections": [
        "Build a custom New Relic One application",
        "Get started",
        "New Relic One: a programmable platform",
        "Tip"
      ],
      "title": "Build a custom New Relic One application ",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Build on New Relic One"
      ],
      "external_id": "0fd7afcf4cd3c15157668bf349e84968062140ed",
      "image": "https://docs.newrelic.com/static/2caff7bdf3bb0fb46bee7c214448c921/c1b63/new-relic-one-browser-analyzer-example-application_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/build-new-relic-one/build-custom-new-relic-one-application/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-07-27T13:37:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic gives you a framework to build your own React JavaScript applications that: Reside on the New Relic One platform, alongside your other dashboards and data. Feature visualizations that you've tailored specifically for your organization. Display data from any source you want, whether from a New Relic-monitored entity or data from another service or API. Get started Keep reading to learn more about what you can do with New Relic One apps. If you want to get started building quickly, first read the requirements. New Relic One: a programmable platform We strive to have an automated user experience that provides optimal value for all users. But we also know that some organizations have unique business needs that can’t be met with our standard visualization options. Now, we give you control over the fundamental building blocks of our platform. Using the same tools our engineers use to build New Relic One, you can build custom applications that align with your unique organizational structure and business needs. If you know how to use React, GraphQL, and NRQL (our query language), building an application will take you only a few minutes. Check out these guides for help building custom applications. Solve any data-driven challenge, no matter how complex. You can: Use our APIs to get data into New Relic from any source. Visualize that data in your custom applications. one.newrelic.com: Here’s an example of a custom application built on New Relic One. This application gives a highly detailed analysis of a website, using the PageView events reported from New Relic's browser monitoring. Tip If your visualization needs are relatively simple, consider using custom charts and custom dashboards. Now, visit our developer site and start building!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.08862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Build a custom <em>New</em> <em>Relic</em> <em>One</em> application ",
        "sections": "Build a custom <em>New</em> <em>Relic</em> <em>One</em> application",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " a <em>New</em> <em>Relic</em>-monitored entity or data from another service or API. <em>Get</em> <em>started</em> Keep reading to learn more about what you can do with <em>New</em> <em>Relic</em> <em>One</em> apps. If you want to <em>get</em> <em>started</em> building quickly, first read the requirements. <em>New</em> <em>Relic</em> <em>One</em>: a programmable platform We strive to have an automated user"
      },
      "id": "603eaaa6e7b9d251572a07d0"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/ui-data/automaps": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/10/nr1-automap/",
      "sections": [
        "Get a Visual Map of Related Entities with New Relic One Automap"
      ],
      "published_at": "2021-10-17T12:53:52Z",
      "title": "Get a Visual Map of Related Entities with New Relic One Automap",
      "updated_at": "2021-10-17T11:31:05Z",
      "type": "docs",
      "external_id": "4b8bc363a4ce4508e7ac829bc190ac09d5615ebe",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "To resolve issues affecting a cluster of services in your architecture, you need to identify both where AND when issues originate. Today, with New Relic One Automap, you can. When selecting a service, you can locate Automap in the Related entities section of the slide-out panel. Click the Map view button. Then, using Automap Timewarp, you can step backward in time and understand how the issue propagated through the architecture and track the issue back to where and when it all started. Check out the documentation to learn more.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.79315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get a Visual Map of Related <em>Entities</em> with New Relic One <em>Automap</em>",
        "sections": "Get a Visual Map of Related <em>Entities</em> with New Relic One <em>Automap</em>",
        "body": "To resolve issues affecting a cluster of services in your architecture, you need to identify both where AND when issues originate. Today, with New Relic One <em>Automap</em>, you can. When selecting a service, you can locate <em>Automap</em> in the Related <em>entities</em> section of the slide-out panel. Click the Map view"
      },
      "id": "616c097a28ccbc6387002225"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/mobile-apps-release-notes/new-relic-android-release-notes/new-relic-android-4000/",
      "sections": [
        "Mobile app for Android v4.0.0",
        "Notes"
      ],
      "published_at": "2021-10-17T12:52:57Z",
      "title": "Mobile app for Android v4.0.0",
      "updated_at": "2021-10-17T11:42:52Z",
      "type": "docs",
      "external_id": "fc390a953c21c1b656a2a775a32cba81167d4d82",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes New Explorer view to navigate through all entity types New bottom navigation for easily switching between favorites, entities, dashboards, alerts and queries",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 83.40344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile app <em>for</em> Android v4.0.0",
        "sections": "Mobile app <em>for</em> Android v4.0.0",
        "body": "Notes New Explorer view to navigate through all entity types New bottom navigation for easily switching between favorites, <em>entities</em>, dashboards, alerts and queries"
      },
      "id": "616c0c3c196a674dfc3c9bb7"
    },
    {
      "sections": [
        "Dashboard API migration: from Insights API to NerdGraph",
        "Why a new dashboards API?",
        "Get started with NerdGraph",
        "Operations mapping table",
        "Dashboard properties mapping table",
        "Widget properties mapping table",
        "Tip",
        "Visualizations mapping table",
        "Examples: from REST endpoints to GraphQL queries/mutations",
        "List (GET) -> entitySearch query",
        "List all dashboard entities you have access to",
        "List all dashboards by name",
        "List all dashboards by creator’s email",
        "List all dashboards by creator’s user id",
        "Show (GET) -> entity query",
        "Get dashboard info given its entity guid",
        "Create (POST) -> dashboardCreate mutation",
        "Create dashboard with two pages and two widgets per page",
        "Update (PUT) -> dashboardUpdate mutation",
        "Update previously created dashboard to 1 page and 1 widget per page",
        "Delete (DELETE) -> dashboardDelete mutation",
        "Delete previously created dashboard"
      ],
      "title": "Dashboard API migration: from Insights API to NerdGraph",
      "type": "docs",
      "tags": [
        "NerdGraph",
        "Dashboards",
        "Dashboards API"
      ],
      "external_id": "7a1a086f45b7aefccb5d2cd5f42b3a0f0dd526c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/dashboards-api-migration-insights-api-nerdgraph/",
      "published_at": "2021-10-13T02:05:11Z",
      "updated_at": "2021-10-13T02:05:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Insights Dashboard API is deprecated, but you can use NerdGraph (our GraphQL API) to create and configure dashboards. If you're not migrating from the old Insights API, you can skip this doc and go to the new Dashboards API. Why a new dashboards API? Our Insights product, which was a way to query data and create charts and dashboards, has been deprecated and its set of features moved over to be a core part of the New Relic One platform. To learn more about this transition and new features, see the Insights to New Relic One migration guide. The Insights Dashboard API will be deprecated in July of 2021. Until then, if you're using the Insights Dashboard API, you should attempt to switch over to using NerdGraph. (The Insights query API will not be deprecated but NerdGraph is preferred.) Keep reading to learn how to get started with NerdGraph and learn about equivalent operations. Get started with NerdGraph NerdGraph is the preferred API for making NRQL queries of your New Relic data. Every user who uses NerdGraph needs their own user key. When using NerdGraph, it helps to understand that our dashboards are entities that report data from other entities, such as monitored apps, hosts and services. If you're new to NerdGraph and GraphQL, you may want to first read our Introduction to NerdGraph and some of Create dashboards with NerdGraph. The NerdGraph API explorer is located at api.newrelic.com/graphiql. Operations mapping table The table below maps every Insights API operation to the new dashboards API. Insights API operation NerdGraph API query/mutation Notes List (GET) entitySearch() View a paginated list of dashboards that match the filter. Show (GET) entity() View an existing dashboard given its entity guid. Create (POST) dashboardCreate() Create a new dashboard. Update (PUT) dashboardUpdate() Update an existing dashboard given its entity guid. Delete (DELETE) dashboardDelete() Delete an existing dashboard given its entity guid. Dashboard properties mapping table For more information about all the fields in the new dashboards GraphQL schema, have a look at NerdGraph's GraphiQL explorer. The table below maps dashboard properties from the Insights API to the new dashboards API. Insights API dashboard property NerdGraph API dashboard property Notes id guid ID of the New Relic entity the dashboard now represents createdAt createdAt updatedAt updatedAt title name editable permissions editable and visibility merged in the same concept visibility permissions editable and visibility merged in the same concept description description metadata - No need of versioning in GraphQL APIs icon - Not translated to New Relic One grid_column_count - 12 column dashboards by default in New Relic One filter - Not translated to New Relic One yet Widget properties mapping table For more information about all the fields in the new dashboards GraphQL schema, have a look at NerdGraph's GraphiQL explorer. The table below maps widget properties from the Insights API to the new dashboards API. Insights API dashboard property NerdGraph API dashboard property Notes id id account_id - Translated into widget configuration for those that require one visualization visualization presentation.title title presentation.drilldown_dashboard_id linkedEntities Used to link a widget to a dashboard for the facet linking feature presentation.notes - Not translated to New Relic One yet layout layout data configuration + rawConfiguration Tip To learn how to build every type of widget, see Create dashboard widgets. Visualizations mapping table We have simplified our widget visualizations by grouping the ones that were in fact the same but obtained through different types of queries. For instance, a line widget is plotted the same way regardless of the type of query: old line_chart vs. comparison_line_chart in Insights. Insights API visualization NerdGraph API visualization uniques_list viz.table single_event viz.table facet_table viz.table event_table viz.table faceted_area_chart viz.area predefined_metric_chart.application_breakdown viz.area predefined_metric_chart.scope_breakdown viz.area predefined_metric_chart.browser_breakdown viz.area predefined_metric_chart.background_breakdown viz.area predefined_metric_chart.solr_breakdown viz.area predefined_metric_chart.gc_runs_breakdown viz.area facet_bar_chart viz.bar billboard viz.billboard attribute_sheet viz.billboard billboard_comparison viz.billboard gauge viz.bullet event_feed viz.event-feed funnel viz.funnel heatmap viz.heatmap histogram viz.histogram inventory infra.inventory raw_json viz.json line_chart viz.line comparison_line_chart viz.line faceted_line_chart viz.line metric_line_chart viz.line markdown viz.markdown facet_pie_chart viz.pie Examples: from REST endpoints to GraphQL queries/mutations One of the main benefits of NerdGraph being a GraphQL-format API is that it provides a complete and understandable description of the APIs' data. By using the NerdGraph API explorer, you can discover GraphQL types and fields, along with a brief explanation. We want to facilitate your migration from the Insights API to the new New Relic One dashboards API. Find below some examples that illustrate how the old REST endpoints map to the new GraphQL queries or mutations. List (GET) -> entitySearch query Dashboards in New Relic One embrace the concept of entity. They are now another entity in New Relic’s entity ecosystem. Try it out using the NerdGraph GraphiQL explorer. List all dashboard entities you have access to { actor { entitySearch(queryBuilder: {type: DASHBOARD}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by name { actor { entitySearch(queryBuilder: {name: \"My dashboard\"}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by creator’s email { actor { entitySearch(queryBuilder: {type: DASHBOARD, tags: {key: \"createdBy\", value: \"email@domain.com\"}}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by creator’s user id { actor { entitySearch(query: \"type ='DASHBOARD' and ownerId = '2357322'\") { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy Show (GET) -> entity query In order to get information on a dashboard, all you need is to provide its unique entity identifier or entity guid. Then you can access all the dashboard properties that you are interested in by adding them in the GraphQL query. Try it out using the NerdGraph GraphiQL explorer. Get dashboard info given its entity guid { actor { entity(guid: \"MY_DASHBOARD_GUID\") { ... on DashboardEntity { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } } Copy Create (POST) -> dashboardCreate mutation Operations that mutate the state of the system are mutations in GraphQL APIs. You can create a dashboard by providing the required input for the dashboardCreate mutation. Although GraphQL APIs aim to be self-explanatory, Nerdgraph docs can help you with some information about the fields, like the doc about how to build dashboard widgets. Try it out using the NerdGraph GraphiQL explorer. Create dashboard with two pages and two widgets per page mutation { dashboardCreate(accountId: 1, dashboard: { name: \"My awesome dashboard\", permissions: PUBLIC_READ_WRITE, pages: [{ name: \"My first page\", widgets: [{ visualization: { id: \"viz.markdown\" }, title: \"My markdown widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { text: \"#My markdown\" } }, { visualization: { id: \"viz.line\" }, title: \"My line widget\", layout: { row: 1, column: 5, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction FACET appName TIMESERIES\" }] } }] }, { name: \"My second page\", widgets: [{ visualization: { id: \"viz.billboard\" }, title: \"My billboard widget with thresholds\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction\" }], thresholds: [{ alertSeverity: WARNING, value: 650 }, { alertSeverity: CRITICAL, value: 1500 }] } }, { visualization: { id: \"viz.table\" }, title: \"My table widget\", layout: { row: 1, column: 5, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ query: \"SELECT * FROM Transaction\", accountId: 1 }] } }] }] }) { errors { description type } entityResult { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } Copy Update (PUT) -> dashboardUpdate mutation The dashboardUpdate mutation allows you to update an existing dashboard by providing the existing dashboard guid and the new configuration. Similarly to creating a dashboard, the mutation tries to be self-explanatory, but you can look up the doc about how to build dashboard widgets. Try it out using the NerdGraph GraphiQL explorer. Update previously created dashboard to 1 page and 1 widget per page mutation { dashboardUpdate(guid: \"MY_DASHBOARD_GUID\" dashboard: { name: \"My awesome dashboard\", permissions: PUBLIC_READ_WRITE, pages: [{ name: \"My first page\", widgets: [{ visualization: { id: \"viz.line\" }, title: \"My line widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction FACET appName TIMESERIES\" }] } }] }, { name: \"My second page\", widgets: [{ visualization: { id: \"viz.table\" }, title: \"My table widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ query: \"SELECT * FROM Transaction\", accountId: 1 }] } }] }] }) { errors { description type } entityResult { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } Copy Delete (DELETE) -> dashboardDelete mutation The dashboardDelete mutation allows you to delete an existing dashboard by providing its entity guid. Try it out using the NerdGraph GraphiQL explorer. Delete previously created dashboard mutation { dashboardDelete(guid:\"MY_DASHBOARD_GUID\") { status errors { type description } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 66.77646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "List all dashboard <em>entities</em> you have access to",
        "body": " started with NerdGraph NerdGraph is the preferred API for making NRQL queries of your New Relic data. Every user who uses NerdGraph needs their own user key. When using NerdGraph, it helps to understand that our dashboards are <em>entities</em> that report data from other <em>entities</em>, such as monitored apps"
      },
      "id": "60441442e7b9d2020b5799b9"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/ui-data/basic-ui-features": [
    {
      "sections": [
        "Dependencies UI: View an entity's upstream and downstream dependencies",
        "Requirements",
        "View dependencies"
      ],
      "title": "Dependencies UI: View an entity's upstream and downstream dependencies",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "2b2f328a6281bb155bcde07efec7f42eae943048",
      "image": "https://docs.newrelic.com/static/aabc5f64a91cc01b6e226df53c62458f/c1b63/new-relic-one-dependencies-UI.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/explore-downstream-dependencies-new-relic-one/",
      "published_at": "2021-10-13T08:57:23Z",
      "updated_at": "2021-08-21T09:29:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic Explorer, an entity's Dependencies page shows a filterable list of all the applications, services, databases, and hosts connected to the entity. It shows upstream and downstream dependencies, and provides paths to explore them. Similar to service maps, the dependencies page helps you understand how all of your upstream and downstream services are connected. It also uses the same color coding system used by service maps to show you what's performing well and what isn't. Requirements To view an entity's dependencies, make sure your app uses the minimum required APM agent version: C 1.0.0 or higher Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher View dependencies To view dependencies for applications, services, databases, and hosts connected to an entity: Go to one.newrelic.com, select Explorer, and select an entity. Select Dependencies. To drill down further, filter the apps, services, databases, or hosts. one.newrelic.com > Explorer > (select an entity) > Dependencies: View a filterable list of all the apps, services, databases, and hosts connected to an entity, and their color-coded health status. You can filter the dependencies page to view specific things that report to the entity. Dependencies include: Services: APM-monitored applications and services. Mobile applications: your mobile apps. Browser applications: your front-end browser apps. External services: external services monitored by APM. External services include out-of-process services such as web services, resources in the cloud, and any other network calls. Databases: your application's database and cache data. Databases are agentless. Because of this, alerts cannot be set for the database, as only the service call is reported to New Relic. Hosts: your infrastructure (servers and hosts).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.1795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Dependencies <em>UI</em>: View an entity&#x27;s upstream <em>and</em> downstream dependencies",
        "sections": "Dependencies <em>UI</em>: View an entity&#x27;s upstream <em>and</em> downstream dependencies",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " services: external services monitored by APM. External services include out-of-process services such as web services, resources in the cloud, and any other network calls. Databases: your application&#x27;s database and cache <em>data</em>. Databases are agentless. Because of this, alerts cannot be set for the database, as only the service call is reported to <em>New</em> <em>Relic</em>. Hosts: your infrastructure (servers and hosts)."
      },
      "id": "603eb2e564441f0fe44e889b"
    },
    {
      "sections": [
        "New Relic feature end of life announcements July 2020",
        "Old Kubernetes integration agent versions",
        "Monitor listing page and Synthetic labels",
        "\"Rollup by\" in Synthetics",
        "Embedded charts",
        "Legacy distributed tracing UI",
        "Violations changes",
        "Connected agents page",
        "Inactive apps in New Relic One",
        "Synthetic monitor alert notifications and conditions"
      ],
      "title": "New Relic feature end of life announcements July 2020",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "1db1d6b3df6d5ac3b983f78f3264cab332cff05a",
      "image": "https://docs.newrelic.com/static/f2b139d12bd8cdc13a9907b7874a4452/0a867/nrone-embed-bb062520.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/new-relic-feature-end-life-announcements-july-2020/",
      "published_at": "2021-10-13T08:58:49Z",
      "updated_at": "2021-07-22T05:05:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to improve your New Relic experience we've made some big improvements to our platform. As a result, we'll be ending support for some old features over the next few weeks. Many have already been publicly announced as \"end-of-life.\" These changes represent our commitment to improve your interactions with our platform. Our mission is one observability platform that unites your telemetry data, connects your full stack, and helps you build more perfect software. To that end we're focusing on simplifying your experience for troubleshooting, alerting, and visualizing data. Here are more details on what's changed, with some helpful links and guides on how to take advantage of new capabilities to achieve the same goals. As always, we're here to help. Please connect with us in the Explorers Hub, or contact your account team with any questions. Old Kubernetes integration agent versions To improve our unified experience, starting from Wednesday, August 12, 2020, Kubernetes integrations that use v1.7 or older will be deprecated. The UI experience in the infrastructure.newrelic.com domain will no longer be available; it will only be available in New Relic One. If you are already using the latest Kubernetes agent version, no action is necessary. If you are using v1.7 or older, you must update your integration in order to continue viewing Kubernetes performance data. Follow the instructions in our documentation to upgrade to the latest version of the Kubernetes integration. Action items for a successful transition: Review the Kubernetes agent deprecation notice. Follow standard procedures to upgrade your Kubernetes agent to the latest version. Learn about the Kubernetes cluster explorer UI in New Relic One. For more information, see the Explorers Hub post. Monitor listing page and Synthetic labels To improve the experience of Synthetic monitors and labels, we've moved both experiences into the New Relic One platform. If you use the REST API for Synthetic label management, you must update to the tags API moving forward. The good news: with the NerdGraph tags API, you can organize and group all your entities in a single request. For more information about any of the following, see the Explorers Hub post. Action items for a successful transition: Synthetic monitors transition Comments Monitor index list When migration is completed, no action is needed on your part to use the new Synthetics entity listing pages. The new experience will be available to you automatically after July 20, 2020. For more information, learn how the explorer in New Relic One replaces the Synthetics monitors index. Existing Synthetics labels You may have already seen an option in the UI to migrate your Synthetics monitor labels to New Relic One tags. If you did not select that option, we've got you covered. Automatic migration from labels to tags starts begins July 8, 2020. For more information, learn how tagging in New Relic One replaces labels for Synthetics monitors. REST API If you use the REST API for Synthetics label management, follow these steps to update to the tags API: Learn more about NerdGraph. Review the NerdGraph tagging API tutorial. Make sure you have a Personal API key to use NerdGraph. Follow the procedures in the Explorers Hub post (look for the How do I transition my scripts from the Synthetics API to the tag API (NerdGraph)? section), and update your existing tags with the GraphiQL explorer at api.newrelic.com/graphiql. NerdGraph is our GraphQL API, a query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph calls get all the data you need in a single request. NerdGraph also makes it easier to evolve APIs over time. \"Rollup by\" in Synthetics Synthetics is moving to New Relic One to provide a single platform for observability of your complex software systems. To do this we are unifying the tools you use to tag (or label) your services, applications, and monitors. The specific feature that is end-of-life is the Rollup by feature under the Search monitors dropdown menu. You can group monitors by tags in New Relic One without needing a separate Rollup by dropdown. No changes will be required to use the new Synthetic monitor listing pages. The new experiences will be available to you after July 20, 2020. Documentation: Tagging in New Relic One replaces labels for Synthetics monitors. Explorer in New Relic One replaces Synthetics monitors index. Action items for a successful transition: If you currently use Synthetics rollups: Follow the procedures in the Explorer Hub post to recreate the rollups that are being retired. Go to the Explorers Hub post about the rollups EOL. In particular, look for How can New Relic Workloads help me visualize groups of applications and monitors? in the post's FAQs section. Follow the procedures in the Explorers Hub post to recreate the rollups that are being retired. Embedded charts In order to reduce redundancy and provide a more unified experience, the embedded charts functionality will be replaced by the New Relic One Get chart. Embedded charts currently in use and hosted outside the New Relic domain will continue to function. The changes will include: The name on the chart's menu that generates them will change from Embed to Get chart link. For charts that are no longer supported, Embed will be replaced with Get chart link is not supported for this chart. The APM UI page that lists all embedded chart links will no longer be available. Documentation: Explorers Hub post New Relic One's enhanced query builder functionality replaces the EOL embed chart functionality. Action items for a successful transition: You can generate a publicly accessible link to add to internal and external websites. Users do not need to be logged in to New Relic to see the chart link. The ability to embed a chart will remain, but instead of clicking Embed (which will be removed from the UI), you will click Get chart link (which is in the same location). This gives you the ability to get links with an even broader range of chart visuals and behaviors than the one we are retiring. Here's an example of how it looks in New Relic One: To replace existing chart links you created with Embed, create new URLs with New Relic One's Get chart link, and insert them in webpages where they're used. If you have an embedded chart and get the message Get chart link is not supported for this chart, simply run a different query, select an available chart type, and then select Embed. Legacy distributed tracing UI To standardize our user experience, we will be deprecating the older distributed tracing UI, which exists within the rpm.newrelic.com domain. You can access distributed tracing through New Relic One, which provides a superior experience with all the functionality supported in the duplicate UI that is end-of-life. Documentation: Global and service-specific distributed tracing views in New Relic One Deprecated distributed tracing UI Action items for a successful transition: No action required, but you can get ready for the new UI experience. New Relic One's distributed tracing page builds on capabilities you are already familiar with. Get acquainted with the enhanced distributed tracing features in New Relic One, including search and filter capabilities with cross-account trace details, query options with the NerdGraph API, and histogram charts (which can help you quickly understand trace distribution for important values such as duration). Review the trace sampling options available with head-based sampling (standard distributed tracing) and tail-based sampling (Infinite Tracing). Violations changes In order to provide a unified experience, we're deprecating browser, mobile, and synthetics monitor violations and replacing them with the New Relic One equivalent. New Relic One users can access violations by using any of these options: Click the Alerts and AI link in New Relic One's main UI. Review the entity list activity stream. See alert details from inside a specific entity via the new indicator for Operational, Warning, and Critical violations. You will see alert details automatically when navigating to one.newrelic.com. Documentation: Applied Intelligence and alerting in New Relic One Browser alert violations (moving to New Relic One) Mobile violations (moving to New Relic One) Monitor violations (moving to New Relic One) Action items for a successful transition: No action required, but you can get ready for the new UI experience. Here's an example of the detailed information about an Alerts violation for a selected entity in New Relic One. Violation details in New Relic One Comments Holistic view From New Relic One's homepage, the entity list presents an activity stream of all entities with alert violations. You no longer need to jump around individual lists of end-user, mobile, or monitor violations. Enhanced troubleshooting tools From New Relic One's homepage, you will also see an Alerts & AI (Applied Intelligence) link. From here you can solve problems faster with anomaly detection, incident correlation, and noise reduction. Specific violation From a selected entity, you will see a new button identifying the violation as Operational, Warning, or Critical, as well as entity metadata and useful details about the incident. Connected agents page Finding your connected agents has never been easier! You can already do this via the Query your data link in New Relic One. Simply run these NrDailyUsage queries to get a list of connected agents and hosts. The old Connected agents page is end-of-life and will be removed. Documentation: Explorers Hub post NRQL query tools NrDailyUsage data definition Action items for a successful transition: To query your connected apps and hosts, you can use existing NRQL query tools, such as New Relic One's query builder or the GraphQL API. Recommendation: For best results exploring comprehensive data about your apps and hosts, use the query builder in New Relic One or the NerdGraph API. Inactive apps in New Relic One Starting June 8, 2020, New Relic One will not continue to display any APM application that hasn't reported data for 93 days. To match our published APM data retention guidelines, applications that have not reported data will be available within the New Relic UI for 90 days. After 90 days, those applications will be removed from the UI. However, key metrics will continue to be available via the New Relic REST API based on subscription level. This is why the application name will remain reserved until the application is permanently deleted via the REST API Explorer. Action items for a successful transition: If you want to reuse an app name for an old app that is no longer reporting data: Use the REST API v2 or API Explorer to get summary data, including app ID, name, health status (look for gray), last reported, etc. Uninstall the agent for your app. Use the REST API or API Explorer to delete the apps. Synthetic monitor alert notifications and conditions In order to provide a unified experience, we're deprecating Synthetics monitor alert notifications and condition violations. We are replacing these pages with a new Synthetics monitor overview experience in New Relic One. This new experience provides visibility into a monitor's open violations and alert conditions with the monitor results in a single view, removing the need to open multiple tabs to view violations or alert conditions. Action items for a successful transition: No action required, but you can get ready for the new UI experience by reviewing our documentation about New Relic Applied Intelligence, which includes: The alerting functionality you are already familiar with in New Relic Alerts, and more Incident Intelligence, which reduces noise and accelerates your incident resolution process Proactive Detection, which surfaces relevant issues and provides automatic explanations to their cause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.94138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> feature end of life announcements July 2020",
        "sections": "Inactive apps in <em>New</em> <em>Relic</em> <em>One</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " To improve our unified experience, starting from Wednesday, August 12, 2020, Kubernetes integrations that <em>use</em> v1.7 or older will be deprecated. The <em>UI</em> experience in the infrastructure.newrelic.com domain will no longer be available; it will only be available in <em>New</em> <em>Relic</em> <em>One</em>. If you are already using"
      },
      "id": "603e795364441ff1924e8872"
    },
    {
      "sections": [
        "Metric normalization rules",
        "Metric normalization rules management"
      ],
      "title": "Metric normalization rules",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "3c55e4717f145ac7ae0d88e860878f4e8d18cd6b",
      "image": "https://docs.newrelic.com/static/83edfb6f5b1b68712cac34d138bb8cb8/3996e/create-new-rule-window.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/metric-normalization-rules/",
      "published_at": "2021-10-13T08:57:23Z",
      "updated_at": "2021-03-29T20:39:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There may be cases where an application sends many individual metrics that could be better managed in groups. Most of these occur with web transactions metrics named from URLs. For more information on this issue, see Metric grouping issues (MGIs). To reduce high cardinality and prevent metric grouping issues, New Relic supports rules for grouping or filtering out metrics (normalization). In some cases, when MGIs with a significant high number of metrics are detected, a rule is created automatically to protect the platform from performance degradation. Metric normalization rules management You can create and manage new rules that deal with the noise produced from high cardinality metrics by using the metric normalization tool, which is accessible from each service dashboard in the New Relic Explorer. Once there, select Metric Normalization in the left sidebar. There you can see the existing rules or create new ones. Click a rule to modify it, or click Create a new rule to create a new one. A new pane to configure the rule will be displayed. Available fields are: Match expression: enter the regular expression to group all the metrics you want to include in the rule. Matches: here you will see a preview of the metrics matched by the regular expression above. Action: the action you want to perform on the metrics. Replace: replace the matched metrics by the regular expression with the value described in the Replacement field. Ignore: ignore any metric that matches the regular expression. Deny new metrics: only write metrics that have already been reported, and ignore those that match the regular expression. Replacement: only active when Replace is enabled. Matched metrics are replaced with the field's value. If the regular expression is capturing groups, you can use placeholders for them with \\1 or \\2 for the groups 1 and 2 respectively. Active: rules can’t be deleted, but can be deactivated. Click the toggle to enable or disable the rule. If you want the rule to be removed, reach out to New Relic's support. Notes: internal notes on the rule. Has no effect on the rule. Once you have set up the fields, click Create (or Edit in case you are editing an existing rule), and the rule will be applied immediately as long as it's Active.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.0911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " grouping issues, <em>New</em> <em>Relic</em> supports rules for grouping or filtering out metrics (normalization). In some cases, when MGIs with a significant high number of metrics are detected, a rule is created automatically to protect the platform from performance degradation. Metric normalization rules management You"
      },
      "id": "603e810b64441ff3a74e8862"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/ui-data/explore-downstream-dependencies-new-relic-one": [
    {
      "sections": [
        "Basic platform UI: search, share, chart UI, customize navigation, and more",
        "Observe your platform",
        "Customize the navigation bar and shortcuts",
        "Light and dark mode",
        "Search accounts and entities",
        "Chart and query features",
        "Share New Relic views with others",
        "Account and user settings",
        "Other UI experiences"
      ],
      "title": "Basic platform UI: search, share, chart UI, customize navigation, and more",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "b3cdcfc60a2821dfa5bee9766aba483cc3389398",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/basic-ui-features/",
      "published_at": "2021-10-13T08:56:03Z",
      "updated_at": "2021-08-21T09:29:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One has some basic UI functions that are widely available across the platform. Understanding these features will help you find and analyze your data more easily. Observe your platform New Relic One gives you full access to the data from all the entities in your stack. Go to the New Relic Explorer at one.newrelic.com to see a full list of entities, identify overall behaviors, filter them to locate sources of performance issues, or plan improvements for your system. Customize the navigation bar and shortcuts Select the edit icon at the right end of the navigation bar to customize your view. Home, Explorer, Browse data, Dashboards, and Alerts & AI are fixed, but you can favorite up to six more elements to display on the bar as well. The rest will go on the More group. Navigation shortcuts are a faster way to find entities and apps that are relevant to you. Mouse over any menu item for quick access to your favorite entities, those you recently visited, or just to search without having to navigate to a specific section. If you click on an entity, you can choose to open it in the same browser tab or in a new one. Light and dark mode See Light and dark mode. Search accounts and entities Access Quick find clicking the button, near the top right of the New Relic One UI. Some details about your search: You can search across all accounts that you have been granted access to in your organization. For more about account access, see Factors affecting access. Entities that cease to exist are available in search for eight days. If your organization has multiple accounts, use the account picker at the top left corner to select accounts. Chart and query features You can add most charts to a new or existing dashboard. Here are some query and chart features available across all or most of the platform: If you want to... Do this... Start querying your data Mouse over Browse data and select metrics, events, logs, or traces for a direct access to any of those types of data. Also, at the top of any UI page, select Query your data to access the data explorer and query builder. View a chart's query For some charts, you can view the NRQL query used to generate that chart. This can help you understand a chart better or use it as the basis for a new query. Choose time range Drag across a section of a chart to zoom in on that time range. Or, use the time picker in the top right corner of the UI to select pre-set time ranges or set a custom one. View chart details Mouse over a chart to see a pop-up with more detail. For some charts, selecting a point on the chart will take you to a UI page with more information about that metric. Hide or return chart elements To hide or unhide a displayed chart element, select that element's name below the chart. The chart display will adjust to reflect the absence or presence of that element. Share New Relic views with others Here are some options for sharing New Relic UI pages and visualizations. If you want to... Do this... Share UI pages and dashboards To share an entire New Relic UI page, click Share near the top of the UI to copy the URL. Share charts If New Relic charts are built with NRQL queries, they have a menu that exposes various options, including sharing options like Get as image and Get chart link. Some notes about sharing: The person you share with may not have access to view the data from that account. To solve that, someone on your team with New Relic user management abilities must add that person to the account. If someone can't access a custom dashboard, it may be that it is set to private. Read more about dashboard permissions. Some sharing options have associated time ranges, which may impact later viewings of it. For example, if you use a chart's Get chart link option and that chart is set to 'Last 30 minutes', when viewed it will show the last 30 minutes, not the time range displayed when it was shared. To share a specific time range, you must select that time range in the UI. Account and user settings To find account settings and user preferences, use the account dropdown, located at the top right of the UI, beside your user name. Other UI experiences This has been a look at a few basic platform UI experiences. For more about the UI, search for docs related to the specific New Relic solution you're using.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.17949,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic platform <em>UI</em>: search, share, chart <em>UI</em>, customize navigation, <em>and</em> more",
        "sections": "Share <em>New</em> <em>Relic</em> views with others",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": "<em>New</em> <em>Relic</em> <em>One</em> has some basic <em>UI</em> functions that are widely available across the platform. Understanding these features will help you find and analyze your <em>data</em> more easily. Observe your platform <em>New</em> <em>Relic</em> <em>One</em> gives you full access to the <em>data</em> from all the entities in your stack. Go to the <em>New</em> <em>Relic</em>"
      },
      "id": "603ec1f964441f5b0e4e8860"
    },
    {
      "sections": [
        "New Relic feature end of life announcements July 2020",
        "Old Kubernetes integration agent versions",
        "Monitor listing page and Synthetic labels",
        "\"Rollup by\" in Synthetics",
        "Embedded charts",
        "Legacy distributed tracing UI",
        "Violations changes",
        "Connected agents page",
        "Inactive apps in New Relic One",
        "Synthetic monitor alert notifications and conditions"
      ],
      "title": "New Relic feature end of life announcements July 2020",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "1db1d6b3df6d5ac3b983f78f3264cab332cff05a",
      "image": "https://docs.newrelic.com/static/f2b139d12bd8cdc13a9907b7874a4452/0a867/nrone-embed-bb062520.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/new-relic-feature-end-life-announcements-july-2020/",
      "published_at": "2021-10-13T08:58:49Z",
      "updated_at": "2021-07-22T05:05:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to improve your New Relic experience we've made some big improvements to our platform. As a result, we'll be ending support for some old features over the next few weeks. Many have already been publicly announced as \"end-of-life.\" These changes represent our commitment to improve your interactions with our platform. Our mission is one observability platform that unites your telemetry data, connects your full stack, and helps you build more perfect software. To that end we're focusing on simplifying your experience for troubleshooting, alerting, and visualizing data. Here are more details on what's changed, with some helpful links and guides on how to take advantage of new capabilities to achieve the same goals. As always, we're here to help. Please connect with us in the Explorers Hub, or contact your account team with any questions. Old Kubernetes integration agent versions To improve our unified experience, starting from Wednesday, August 12, 2020, Kubernetes integrations that use v1.7 or older will be deprecated. The UI experience in the infrastructure.newrelic.com domain will no longer be available; it will only be available in New Relic One. If you are already using the latest Kubernetes agent version, no action is necessary. If you are using v1.7 or older, you must update your integration in order to continue viewing Kubernetes performance data. Follow the instructions in our documentation to upgrade to the latest version of the Kubernetes integration. Action items for a successful transition: Review the Kubernetes agent deprecation notice. Follow standard procedures to upgrade your Kubernetes agent to the latest version. Learn about the Kubernetes cluster explorer UI in New Relic One. For more information, see the Explorers Hub post. Monitor listing page and Synthetic labels To improve the experience of Synthetic monitors and labels, we've moved both experiences into the New Relic One platform. If you use the REST API for Synthetic label management, you must update to the tags API moving forward. The good news: with the NerdGraph tags API, you can organize and group all your entities in a single request. For more information about any of the following, see the Explorers Hub post. Action items for a successful transition: Synthetic monitors transition Comments Monitor index list When migration is completed, no action is needed on your part to use the new Synthetics entity listing pages. The new experience will be available to you automatically after July 20, 2020. For more information, learn how the explorer in New Relic One replaces the Synthetics monitors index. Existing Synthetics labels You may have already seen an option in the UI to migrate your Synthetics monitor labels to New Relic One tags. If you did not select that option, we've got you covered. Automatic migration from labels to tags starts begins July 8, 2020. For more information, learn how tagging in New Relic One replaces labels for Synthetics monitors. REST API If you use the REST API for Synthetics label management, follow these steps to update to the tags API: Learn more about NerdGraph. Review the NerdGraph tagging API tutorial. Make sure you have a Personal API key to use NerdGraph. Follow the procedures in the Explorers Hub post (look for the How do I transition my scripts from the Synthetics API to the tag API (NerdGraph)? section), and update your existing tags with the GraphiQL explorer at api.newrelic.com/graphiql. NerdGraph is our GraphQL API, a query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph calls get all the data you need in a single request. NerdGraph also makes it easier to evolve APIs over time. \"Rollup by\" in Synthetics Synthetics is moving to New Relic One to provide a single platform for observability of your complex software systems. To do this we are unifying the tools you use to tag (or label) your services, applications, and monitors. The specific feature that is end-of-life is the Rollup by feature under the Search monitors dropdown menu. You can group monitors by tags in New Relic One without needing a separate Rollup by dropdown. No changes will be required to use the new Synthetic monitor listing pages. The new experiences will be available to you after July 20, 2020. Documentation: Tagging in New Relic One replaces labels for Synthetics monitors. Explorer in New Relic One replaces Synthetics monitors index. Action items for a successful transition: If you currently use Synthetics rollups: Follow the procedures in the Explorer Hub post to recreate the rollups that are being retired. Go to the Explorers Hub post about the rollups EOL. In particular, look for How can New Relic Workloads help me visualize groups of applications and monitors? in the post's FAQs section. Follow the procedures in the Explorers Hub post to recreate the rollups that are being retired. Embedded charts In order to reduce redundancy and provide a more unified experience, the embedded charts functionality will be replaced by the New Relic One Get chart. Embedded charts currently in use and hosted outside the New Relic domain will continue to function. The changes will include: The name on the chart's menu that generates them will change from Embed to Get chart link. For charts that are no longer supported, Embed will be replaced with Get chart link is not supported for this chart. The APM UI page that lists all embedded chart links will no longer be available. Documentation: Explorers Hub post New Relic One's enhanced query builder functionality replaces the EOL embed chart functionality. Action items for a successful transition: You can generate a publicly accessible link to add to internal and external websites. Users do not need to be logged in to New Relic to see the chart link. The ability to embed a chart will remain, but instead of clicking Embed (which will be removed from the UI), you will click Get chart link (which is in the same location). This gives you the ability to get links with an even broader range of chart visuals and behaviors than the one we are retiring. Here's an example of how it looks in New Relic One: To replace existing chart links you created with Embed, create new URLs with New Relic One's Get chart link, and insert them in webpages where they're used. If you have an embedded chart and get the message Get chart link is not supported for this chart, simply run a different query, select an available chart type, and then select Embed. Legacy distributed tracing UI To standardize our user experience, we will be deprecating the older distributed tracing UI, which exists within the rpm.newrelic.com domain. You can access distributed tracing through New Relic One, which provides a superior experience with all the functionality supported in the duplicate UI that is end-of-life. Documentation: Global and service-specific distributed tracing views in New Relic One Deprecated distributed tracing UI Action items for a successful transition: No action required, but you can get ready for the new UI experience. New Relic One's distributed tracing page builds on capabilities you are already familiar with. Get acquainted with the enhanced distributed tracing features in New Relic One, including search and filter capabilities with cross-account trace details, query options with the NerdGraph API, and histogram charts (which can help you quickly understand trace distribution for important values such as duration). Review the trace sampling options available with head-based sampling (standard distributed tracing) and tail-based sampling (Infinite Tracing). Violations changes In order to provide a unified experience, we're deprecating browser, mobile, and synthetics monitor violations and replacing them with the New Relic One equivalent. New Relic One users can access violations by using any of these options: Click the Alerts and AI link in New Relic One's main UI. Review the entity list activity stream. See alert details from inside a specific entity via the new indicator for Operational, Warning, and Critical violations. You will see alert details automatically when navigating to one.newrelic.com. Documentation: Applied Intelligence and alerting in New Relic One Browser alert violations (moving to New Relic One) Mobile violations (moving to New Relic One) Monitor violations (moving to New Relic One) Action items for a successful transition: No action required, but you can get ready for the new UI experience. Here's an example of the detailed information about an Alerts violation for a selected entity in New Relic One. Violation details in New Relic One Comments Holistic view From New Relic One's homepage, the entity list presents an activity stream of all entities with alert violations. You no longer need to jump around individual lists of end-user, mobile, or monitor violations. Enhanced troubleshooting tools From New Relic One's homepage, you will also see an Alerts & AI (Applied Intelligence) link. From here you can solve problems faster with anomaly detection, incident correlation, and noise reduction. Specific violation From a selected entity, you will see a new button identifying the violation as Operational, Warning, or Critical, as well as entity metadata and useful details about the incident. Connected agents page Finding your connected agents has never been easier! You can already do this via the Query your data link in New Relic One. Simply run these NrDailyUsage queries to get a list of connected agents and hosts. The old Connected agents page is end-of-life and will be removed. Documentation: Explorers Hub post NRQL query tools NrDailyUsage data definition Action items for a successful transition: To query your connected apps and hosts, you can use existing NRQL query tools, such as New Relic One's query builder or the GraphQL API. Recommendation: For best results exploring comprehensive data about your apps and hosts, use the query builder in New Relic One or the NerdGraph API. Inactive apps in New Relic One Starting June 8, 2020, New Relic One will not continue to display any APM application that hasn't reported data for 93 days. To match our published APM data retention guidelines, applications that have not reported data will be available within the New Relic UI for 90 days. After 90 days, those applications will be removed from the UI. However, key metrics will continue to be available via the New Relic REST API based on subscription level. This is why the application name will remain reserved until the application is permanently deleted via the REST API Explorer. Action items for a successful transition: If you want to reuse an app name for an old app that is no longer reporting data: Use the REST API v2 or API Explorer to get summary data, including app ID, name, health status (look for gray), last reported, etc. Uninstall the agent for your app. Use the REST API or API Explorer to delete the apps. Synthetic monitor alert notifications and conditions In order to provide a unified experience, we're deprecating Synthetics monitor alert notifications and condition violations. We are replacing these pages with a new Synthetics monitor overview experience in New Relic One. This new experience provides visibility into a monitor's open violations and alert conditions with the monitor results in a single view, removing the need to open multiple tabs to view violations or alert conditions. Action items for a successful transition: No action required, but you can get ready for the new UI experience by reviewing our documentation about New Relic Applied Intelligence, which includes: The alerting functionality you are already familiar with in New Relic Alerts, and more Incident Intelligence, which reduces noise and accelerates your incident resolution process Proactive Detection, which surfaces relevant issues and provides automatic explanations to their cause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.94136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> feature end of life announcements July 2020",
        "sections": "Inactive apps in <em>New</em> <em>Relic</em> <em>One</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " To improve our unified experience, starting from Wednesday, August 12, 2020, Kubernetes integrations that <em>use</em> v1.7 or older will be deprecated. The <em>UI</em> experience in the infrastructure.newrelic.com domain will no longer be available; it will only be available in <em>New</em> <em>Relic</em> <em>One</em>. If you are already using"
      },
      "id": "603e795364441ff1924e8872"
    },
    {
      "sections": [
        "Metric normalization rules",
        "Metric normalization rules management"
      ],
      "title": "Metric normalization rules",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "3c55e4717f145ac7ae0d88e860878f4e8d18cd6b",
      "image": "https://docs.newrelic.com/static/83edfb6f5b1b68712cac34d138bb8cb8/3996e/create-new-rule-window.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/metric-normalization-rules/",
      "published_at": "2021-10-13T08:57:23Z",
      "updated_at": "2021-03-29T20:39:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There may be cases where an application sends many individual metrics that could be better managed in groups. Most of these occur with web transactions metrics named from URLs. For more information on this issue, see Metric grouping issues (MGIs). To reduce high cardinality and prevent metric grouping issues, New Relic supports rules for grouping or filtering out metrics (normalization). In some cases, when MGIs with a significant high number of metrics are detected, a rule is created automatically to protect the platform from performance degradation. Metric normalization rules management You can create and manage new rules that deal with the noise produced from high cardinality metrics by using the metric normalization tool, which is accessible from each service dashboard in the New Relic Explorer. Once there, select Metric Normalization in the left sidebar. There you can see the existing rules or create new ones. Click a rule to modify it, or click Create a new rule to create a new one. A new pane to configure the rule will be displayed. Available fields are: Match expression: enter the regular expression to group all the metrics you want to include in the rule. Matches: here you will see a preview of the metrics matched by the regular expression above. Action: the action you want to perform on the metrics. Replace: replace the matched metrics by the regular expression with the value described in the Replacement field. Ignore: ignore any metric that matches the regular expression. Deny new metrics: only write metrics that have already been reported, and ignore those that match the regular expression. Replacement: only active when Replace is enabled. Matched metrics are replaced with the field's value. If the regular expression is capturing groups, you can use placeholders for them with \\1 or \\2 for the groups 1 and 2 respectively. Active: rules can’t be deleted, but can be deactivated. Click the toggle to enable or disable the rule. If you want the rule to be removed, reach out to New Relic's support. Notes: internal notes on the rule. Has no effect on the rule. Once you have set up the fields, click Create (or Edit in case you are editing an existing rule), and the rule will be applied immediately as long as it's Active.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.0911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " grouping issues, <em>New</em> <em>Relic</em> supports rules for grouping or filtering out metrics (normalization). In some cases, when MGIs with a significant high number of metrics are detected, a rule is created automatically to protect the platform from performance degradation. Metric normalization rules management You"
      },
      "id": "603e810b64441ff3a74e8862"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/ui-data/maps-in-context": [
    {
      "image": "https://docs.newrelic.com/static/4ddf877f5025e8c91b680450e6d61f22/2bef9/automaps-overview.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/automaps/",
      "sections": [
        "Automap for troubleshooting entities",
        "How it works",
        "Important",
        "Open automap",
        "Explore the history",
        "Timewarp cursor: go back in time",
        "Controls: See only what you need to see",
        "Map symbols"
      ],
      "published_at": "2021-10-17T12:50:23Z",
      "title": "Automap for troubleshooting entities",
      "updated_at": "2021-10-13T02:05:10Z",
      "type": "docs",
      "external_id": "fda18aaaf60b60b39db33b2d22fd89523cb6ae20",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic automap feature displays entity-centric maps to help you troubleshoot incidents that cascade through interconnected services. With automap, you can pinpoint when and where an issue began by viewing the dependencies that affect your services. Here's an example of where you could start troubleshooting with automap. How it works New Relic automap displays relationships between entities in your architecture. For version 1, the relationships displayed in automap are based on direct calls between services. For example, APM services are represented as vertices (hexagons) and direct calls are represented as edges (lines) on the graph. This shows you how these services depend on one another. Automap displays only the entities related to the source entity that have experienced a change in health status within three hours after the automap was launched. So, it may not show all entities related to the source entity. To understand entities and relationships, as well as how the entity platform synthesizes both from telemetry data, see entities and relationships. Important Automap auto-expand logic relies on the health status of an entity, which is largely determined by the alert status of that entity. For optimal troubleshooting with automap, ensure that your alerts are properly configured. Open automap Automap appears on any Related entities pane for supported entity types: In Explorer, insert a filter to find your entity/service (for example, alerts). Click on the entity/service. On the Summary page, go to Related entities in the right pane. Click Map view: The Map view button is only available for the following types of entities: Entity type Description Icon APM|APPLICATION Application service instrumented with a New Relic APM agent BROWSER|APPLICATION Browser application instrumented with New Relic Browser agent EXT|SERVICE Services instrumented with OpenTelemetry, including Pixie-instrumented services MOBILE|APPLICATION Mobile app instrumented with a New Relic agent NR1|WORKLOAD Workload SYNTH|MONITOR Synthetic monitor Explore the history Unlike simple navigation maps, such as New Relic maps in context, automap helps you understand how problems developed by allowing you to scroll backwards and forwards in time. You can also screen out entities you're not interested in. Timewarp cursor: go back in time To identify exactly when and where an incident originated, simply move the Timewarp cursor to see health status changes for the entities on the map. If you don't see the Timewarp cursor, click the clock icon in the upper-right of the automap. When you scroll through the history, you see when anomalous behavior was detected by New Relic Lookout. Here’s an example of scrolling that reveals that the issue occurred between FulfillmentService and BillingService: Controls: See only what you need to see With the controls menu available below the Timewarp cursor, you can de-emphasize certain entities on the map by unchecking those options. For example, you can hide the healthy service to focus only on those alerting as you browse the timeline: Here is an example of how the controls work: Map symbols Here's a table showing the various health status icons: Health status Icon Critical Warning Not alerting Not configured Anomaly",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 253.85669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Automap for troubleshooting <em>entities</em>",
        "sections": "Automap for troubleshooting <em>entities</em>",
        "body": "The New Relic automap feature displays <em>entity</em>-centric <em>maps</em> to help you troubleshoot incidents that cascade through interconnected services. With automap, you can pinpoint when and where an issue began by viewing the dependencies that affect your services. Here&#x27;s an example of where you could start"
      },
      "id": "61663ed6196a67c3bd3c717b"
    },
    {
      "sections": [
        "NerdGraph tutorial: Understand entity relationships and dependencies",
        "Relationship types",
        "Read relationships of an entity"
      ],
      "title": "NerdGraph tutorial: Understand entity relationships and dependencies",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "3699777ea1a7bf17213ccdaad3b44793e1561948",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/examples/nerdgraph-relationships-api-tutorial/",
      "published_at": "2021-10-12T13:01:55Z",
      "updated_at": "2021-09-02T03:46:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to understand how your entities relate to each other is using our NerdGraph API. You can use the relatedEntities field to see how pairs of entities interact and how they're related. This can help troubleshoot upstream and downstream services and understand how minor issues may have larger repercussions, similar to how service maps can be used. To learn general information about entities, their relationships, and how to use them, see Entities. Relationship types Relationship types provide additional information about how two entities are related. The supported relationship types are: Type Description CALLS The relationship between one service or application calling another. Used to display upstream and downstream services. CONTAINS The relationship and hierarchical use cases common to modern and cloud infrastructure. For example, this could indicate that the HOST contains a container. HOSTS The relationship between an application or process and the system it runs on. SERVES The relationship between a back-end application and the browser application it returns in the response. is The relationship between an entity captured as a separate entity by another telemetry data source in addition to the one you are currently viewing. Read relationships of an entity You can use NerdGraph to return the relationships between your monitored entities. The following example shows how to query an entity by its specific GUID, using the NerdGraph GraphiQL explorer. For more information, see Use NerdGraph to query entities. query{ actor{ entity(guid: YOUR_ENTITY_GUID){ name relatedEntities { results { source { entity { guid name } } target { entity { guid name } } type } } } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.70181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: Understand <em>entity</em> <em>relationships</em> and dependencies",
        "sections": "NerdGraph tutorial: Understand <em>entity</em> <em>relationships</em> and dependencies",
        "body": " repercussions, similar to how service <em>maps</em> can be used. To learn general information about entities, their <em>relationships</em>, and how to use them, see Entities. <em>Relationship</em> types <em>Relationship</em> types provide additional information about how two entities are related. The supported <em>relationship</em> types"
      },
      "id": "603ec1c664441fb7ff4e8852"
    },
    {
      "sections": [
        "How to use service maps",
        "Requirements",
        "Minimum versions when distributed tracing is enabled",
        "Minimum versions when distributed tracing is NOT enabled",
        "Add or remove connections to an entity",
        "Color coded for alerts",
        "Understand dependencies using API",
        "Externals and databases in maps",
        "Missing nodes"
      ],
      "title": "How to use service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "edc5ecde0c7ac8348afbcc6b82de546b0b60d349",
      "image": "",
      "url": "https://docs.newrelic.com/docs/understand-dependencies/understand-system-dependencies/service-maps/how-use-service-maps/",
      "published_at": "2021-10-12T23:41:36Z",
      "updated_at": "2021-08-21T10:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is information about how to use the current service maps feature. For help using the earlier service maps feature, see Legacy APM service maps. Service maps helps you visualize dependencies quickly and easily across your environment. They help you see how all your entities work together across your system. You can use service maps to troubleshoot problems, see how your environment works together, and ensure that issues don’t have downstream repercussions. Service maps also supports cross-account access so help you see relationships between entities for all your accounts. Requirements Service maps work with distributed tracing to connect relationships between entities. Service maps are still functional if you have not enabled distributed tracing, but we recommend having distributed tracing enabled for all agents. This ensures a more consistent experience while using service maps. For best results, update existing agents to the latest version. The required minimum agent versions for maps are: Minimum versions when distributed tracing is enabled The required minimum agent versions for maps using distributed tracing are: C SDK 1.1.0 or higher Go agent 2.1.0 or higher Java agent 4.3.0 or higher .NET agent 8.6.45.0 or higher Node.js agent 4.7.0 or higher PHP agent 8.4 or higher Python agent 4.2.0.100 or higher Ruby agent 5.3.0.346 or higher Minimum versions when distributed tracing is NOT enabled The minimum version requirements for maps not using distributed tracing are: C SDK: not available Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher Add or remove connections to an entity To view service maps, from one.newrelic.com click Explorer. Once you select an entity to view, you can select service maps from the sidebar. The map shows your upstream and downstream services: entities toward the left are upstream, entities toward the right are downstream. To add or remove connections to an entity: Hover over the entity in the map that you want to alter. Click add or remove more connections. In the connection list, keep boxes checked for the entities that you want to appear in the map. Unchecked entities will be removed from the map. Color coded for alerts Each entity in a map displays a color dependent on its performance. Green: there are currently no violations for this entities performance. Yellow: there is an open warning violation for this entity. Red: there is an open critical violation for this entity. Gray: no alert conditions have been set for the entity White: agent not reporting. This means that the agent installed on the entity is not reporting any data. This is expected behavior for databases or externals. Understand dependencies using API You can discover the same relationship connections available in service maps with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals and databases in maps In the New Relic UI, your out-of-process services are referred to as web external or background external data. Externals and databases have slightly different features in service maps than other entity types: Unlike other entities that appear in service maps, externals are aggregates. Clicking on an external service in the map shows you the list of all the external services that are rolled up into the one external entity. This is to reduce map clutter, as some entities can have dozens of externals being reported. Databases are agentless. Because of this, alerts cannot be set for the database, as only see the service call is reported to New Relic. Missing nodes If you are unable to view certain entities in New Relic One service maps, see Troubleshooting: Missing or obfuscated data in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.65572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to use service <em>maps</em>",
        "sections": "Externals and databases <em>in</em> <em>maps</em>",
        "tags": "Service <em>maps</em>",
        "body": " to view, you can select service <em>maps</em> from the sidebar. The <em>map</em> shows your upstream and downstream services: entities toward the left are upstream, entities toward the right are downstream. To add or remove connections to an <em>entity</em>: Hover over the <em>entity</em> in the <em>map</em> that you want to alter. Click add"
      },
      "id": "603ec23264441fb02c4e8893"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/ui-data/metric-normalization-rules": [
    {
      "sections": [
        "Basic platform UI: search, share, chart UI, customize navigation, and more",
        "Observe your platform",
        "Customize the navigation bar and shortcuts",
        "Light and dark mode",
        "Search accounts and entities",
        "Chart and query features",
        "Share New Relic views with others",
        "Account and user settings",
        "Other UI experiences"
      ],
      "title": "Basic platform UI: search, share, chart UI, customize navigation, and more",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "b3cdcfc60a2821dfa5bee9766aba483cc3389398",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/basic-ui-features/",
      "published_at": "2021-10-13T08:56:03Z",
      "updated_at": "2021-08-21T09:29:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One has some basic UI functions that are widely available across the platform. Understanding these features will help you find and analyze your data more easily. Observe your platform New Relic One gives you full access to the data from all the entities in your stack. Go to the New Relic Explorer at one.newrelic.com to see a full list of entities, identify overall behaviors, filter them to locate sources of performance issues, or plan improvements for your system. Customize the navigation bar and shortcuts Select the edit icon at the right end of the navigation bar to customize your view. Home, Explorer, Browse data, Dashboards, and Alerts & AI are fixed, but you can favorite up to six more elements to display on the bar as well. The rest will go on the More group. Navigation shortcuts are a faster way to find entities and apps that are relevant to you. Mouse over any menu item for quick access to your favorite entities, those you recently visited, or just to search without having to navigate to a specific section. If you click on an entity, you can choose to open it in the same browser tab or in a new one. Light and dark mode See Light and dark mode. Search accounts and entities Access Quick find clicking the button, near the top right of the New Relic One UI. Some details about your search: You can search across all accounts that you have been granted access to in your organization. For more about account access, see Factors affecting access. Entities that cease to exist are available in search for eight days. If your organization has multiple accounts, use the account picker at the top left corner to select accounts. Chart and query features You can add most charts to a new or existing dashboard. Here are some query and chart features available across all or most of the platform: If you want to... Do this... Start querying your data Mouse over Browse data and select metrics, events, logs, or traces for a direct access to any of those types of data. Also, at the top of any UI page, select Query your data to access the data explorer and query builder. View a chart's query For some charts, you can view the NRQL query used to generate that chart. This can help you understand a chart better or use it as the basis for a new query. Choose time range Drag across a section of a chart to zoom in on that time range. Or, use the time picker in the top right corner of the UI to select pre-set time ranges or set a custom one. View chart details Mouse over a chart to see a pop-up with more detail. For some charts, selecting a point on the chart will take you to a UI page with more information about that metric. Hide or return chart elements To hide or unhide a displayed chart element, select that element's name below the chart. The chart display will adjust to reflect the absence or presence of that element. Share New Relic views with others Here are some options for sharing New Relic UI pages and visualizations. If you want to... Do this... Share UI pages and dashboards To share an entire New Relic UI page, click Share near the top of the UI to copy the URL. Share charts If New Relic charts are built with NRQL queries, they have a menu that exposes various options, including sharing options like Get as image and Get chart link. Some notes about sharing: The person you share with may not have access to view the data from that account. To solve that, someone on your team with New Relic user management abilities must add that person to the account. If someone can't access a custom dashboard, it may be that it is set to private. Read more about dashboard permissions. Some sharing options have associated time ranges, which may impact later viewings of it. For example, if you use a chart's Get chart link option and that chart is set to 'Last 30 minutes', when viewed it will show the last 30 minutes, not the time range displayed when it was shared. To share a specific time range, you must select that time range in the UI. Account and user settings To find account settings and user preferences, use the account dropdown, located at the top right of the UI, beside your user name. Other UI experiences This has been a look at a few basic platform UI experiences. For more about the UI, search for docs related to the specific New Relic solution you're using.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.17949,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic platform <em>UI</em>: search, share, chart <em>UI</em>, customize navigation, <em>and</em> more",
        "sections": "Share <em>New</em> <em>Relic</em> views with others",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": "<em>New</em> <em>Relic</em> <em>One</em> has some basic <em>UI</em> functions that are widely available across the platform. Understanding these features will help you find and analyze your <em>data</em> more easily. Observe your platform <em>New</em> <em>Relic</em> <em>One</em> gives you full access to the <em>data</em> from all the entities in your stack. Go to the <em>New</em> <em>Relic</em>"
      },
      "id": "603ec1f964441f5b0e4e8860"
    },
    {
      "sections": [
        "Dependencies UI: View an entity's upstream and downstream dependencies",
        "Requirements",
        "View dependencies"
      ],
      "title": "Dependencies UI: View an entity's upstream and downstream dependencies",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "2b2f328a6281bb155bcde07efec7f42eae943048",
      "image": "https://docs.newrelic.com/static/aabc5f64a91cc01b6e226df53c62458f/c1b63/new-relic-one-dependencies-UI.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/explore-downstream-dependencies-new-relic-one/",
      "published_at": "2021-10-13T08:57:23Z",
      "updated_at": "2021-08-21T09:29:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic Explorer, an entity's Dependencies page shows a filterable list of all the applications, services, databases, and hosts connected to the entity. It shows upstream and downstream dependencies, and provides paths to explore them. Similar to service maps, the dependencies page helps you understand how all of your upstream and downstream services are connected. It also uses the same color coding system used by service maps to show you what's performing well and what isn't. Requirements To view an entity's dependencies, make sure your app uses the minimum required APM agent version: C 1.0.0 or higher Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher View dependencies To view dependencies for applications, services, databases, and hosts connected to an entity: Go to one.newrelic.com, select Explorer, and select an entity. Select Dependencies. To drill down further, filter the apps, services, databases, or hosts. one.newrelic.com > Explorer > (select an entity) > Dependencies: View a filterable list of all the apps, services, databases, and hosts connected to an entity, and their color-coded health status. You can filter the dependencies page to view specific things that report to the entity. Dependencies include: Services: APM-monitored applications and services. Mobile applications: your mobile apps. Browser applications: your front-end browser apps. External services: external services monitored by APM. External services include out-of-process services such as web services, resources in the cloud, and any other network calls. Databases: your application's database and cache data. Databases are agentless. Because of this, alerts cannot be set for the database, as only the service call is reported to New Relic. Hosts: your infrastructure (servers and hosts).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.17949,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Dependencies <em>UI</em>: View an entity&#x27;s upstream <em>and</em> downstream dependencies",
        "sections": "Dependencies <em>UI</em>: View an entity&#x27;s upstream <em>and</em> downstream dependencies",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " services: external services monitored by APM. External services include out-of-process services such as web services, resources in the cloud, and any other network calls. Databases: your application&#x27;s database and cache <em>data</em>. Databases are agentless. Because of this, alerts cannot be set for the database, as only the service call is reported to <em>New</em> <em>Relic</em>. Hosts: your infrastructure (servers and hosts)."
      },
      "id": "603eb2e564441f0fe44e889b"
    },
    {
      "sections": [
        "New Relic feature end of life announcements July 2020",
        "Old Kubernetes integration agent versions",
        "Monitor listing page and Synthetic labels",
        "\"Rollup by\" in Synthetics",
        "Embedded charts",
        "Legacy distributed tracing UI",
        "Violations changes",
        "Connected agents page",
        "Inactive apps in New Relic One",
        "Synthetic monitor alert notifications and conditions"
      ],
      "title": "New Relic feature end of life announcements July 2020",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "1db1d6b3df6d5ac3b983f78f3264cab332cff05a",
      "image": "https://docs.newrelic.com/static/f2b139d12bd8cdc13a9907b7874a4452/0a867/nrone-embed-bb062520.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/new-relic-feature-end-life-announcements-july-2020/",
      "published_at": "2021-10-13T08:58:49Z",
      "updated_at": "2021-07-22T05:05:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to improve your New Relic experience we've made some big improvements to our platform. As a result, we'll be ending support for some old features over the next few weeks. Many have already been publicly announced as \"end-of-life.\" These changes represent our commitment to improve your interactions with our platform. Our mission is one observability platform that unites your telemetry data, connects your full stack, and helps you build more perfect software. To that end we're focusing on simplifying your experience for troubleshooting, alerting, and visualizing data. Here are more details on what's changed, with some helpful links and guides on how to take advantage of new capabilities to achieve the same goals. As always, we're here to help. Please connect with us in the Explorers Hub, or contact your account team with any questions. Old Kubernetes integration agent versions To improve our unified experience, starting from Wednesday, August 12, 2020, Kubernetes integrations that use v1.7 or older will be deprecated. The UI experience in the infrastructure.newrelic.com domain will no longer be available; it will only be available in New Relic One. If you are already using the latest Kubernetes agent version, no action is necessary. If you are using v1.7 or older, you must update your integration in order to continue viewing Kubernetes performance data. Follow the instructions in our documentation to upgrade to the latest version of the Kubernetes integration. Action items for a successful transition: Review the Kubernetes agent deprecation notice. Follow standard procedures to upgrade your Kubernetes agent to the latest version. Learn about the Kubernetes cluster explorer UI in New Relic One. For more information, see the Explorers Hub post. Monitor listing page and Synthetic labels To improve the experience of Synthetic monitors and labels, we've moved both experiences into the New Relic One platform. If you use the REST API for Synthetic label management, you must update to the tags API moving forward. The good news: with the NerdGraph tags API, you can organize and group all your entities in a single request. For more information about any of the following, see the Explorers Hub post. Action items for a successful transition: Synthetic monitors transition Comments Monitor index list When migration is completed, no action is needed on your part to use the new Synthetics entity listing pages. The new experience will be available to you automatically after July 20, 2020. For more information, learn how the explorer in New Relic One replaces the Synthetics monitors index. Existing Synthetics labels You may have already seen an option in the UI to migrate your Synthetics monitor labels to New Relic One tags. If you did not select that option, we've got you covered. Automatic migration from labels to tags starts begins July 8, 2020. For more information, learn how tagging in New Relic One replaces labels for Synthetics monitors. REST API If you use the REST API for Synthetics label management, follow these steps to update to the tags API: Learn more about NerdGraph. Review the NerdGraph tagging API tutorial. Make sure you have a Personal API key to use NerdGraph. Follow the procedures in the Explorers Hub post (look for the How do I transition my scripts from the Synthetics API to the tag API (NerdGraph)? section), and update your existing tags with the GraphiQL explorer at api.newrelic.com/graphiql. NerdGraph is our GraphQL API, a query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph calls get all the data you need in a single request. NerdGraph also makes it easier to evolve APIs over time. \"Rollup by\" in Synthetics Synthetics is moving to New Relic One to provide a single platform for observability of your complex software systems. To do this we are unifying the tools you use to tag (or label) your services, applications, and monitors. The specific feature that is end-of-life is the Rollup by feature under the Search monitors dropdown menu. You can group monitors by tags in New Relic One without needing a separate Rollup by dropdown. No changes will be required to use the new Synthetic monitor listing pages. The new experiences will be available to you after July 20, 2020. Documentation: Tagging in New Relic One replaces labels for Synthetics monitors. Explorer in New Relic One replaces Synthetics monitors index. Action items for a successful transition: If you currently use Synthetics rollups: Follow the procedures in the Explorer Hub post to recreate the rollups that are being retired. Go to the Explorers Hub post about the rollups EOL. In particular, look for How can New Relic Workloads help me visualize groups of applications and monitors? in the post's FAQs section. Follow the procedures in the Explorers Hub post to recreate the rollups that are being retired. Embedded charts In order to reduce redundancy and provide a more unified experience, the embedded charts functionality will be replaced by the New Relic One Get chart. Embedded charts currently in use and hosted outside the New Relic domain will continue to function. The changes will include: The name on the chart's menu that generates them will change from Embed to Get chart link. For charts that are no longer supported, Embed will be replaced with Get chart link is not supported for this chart. The APM UI page that lists all embedded chart links will no longer be available. Documentation: Explorers Hub post New Relic One's enhanced query builder functionality replaces the EOL embed chart functionality. Action items for a successful transition: You can generate a publicly accessible link to add to internal and external websites. Users do not need to be logged in to New Relic to see the chart link. The ability to embed a chart will remain, but instead of clicking Embed (which will be removed from the UI), you will click Get chart link (which is in the same location). This gives you the ability to get links with an even broader range of chart visuals and behaviors than the one we are retiring. Here's an example of how it looks in New Relic One: To replace existing chart links you created with Embed, create new URLs with New Relic One's Get chart link, and insert them in webpages where they're used. If you have an embedded chart and get the message Get chart link is not supported for this chart, simply run a different query, select an available chart type, and then select Embed. Legacy distributed tracing UI To standardize our user experience, we will be deprecating the older distributed tracing UI, which exists within the rpm.newrelic.com domain. You can access distributed tracing through New Relic One, which provides a superior experience with all the functionality supported in the duplicate UI that is end-of-life. Documentation: Global and service-specific distributed tracing views in New Relic One Deprecated distributed tracing UI Action items for a successful transition: No action required, but you can get ready for the new UI experience. New Relic One's distributed tracing page builds on capabilities you are already familiar with. Get acquainted with the enhanced distributed tracing features in New Relic One, including search and filter capabilities with cross-account trace details, query options with the NerdGraph API, and histogram charts (which can help you quickly understand trace distribution for important values such as duration). Review the trace sampling options available with head-based sampling (standard distributed tracing) and tail-based sampling (Infinite Tracing). Violations changes In order to provide a unified experience, we're deprecating browser, mobile, and synthetics monitor violations and replacing them with the New Relic One equivalent. New Relic One users can access violations by using any of these options: Click the Alerts and AI link in New Relic One's main UI. Review the entity list activity stream. See alert details from inside a specific entity via the new indicator for Operational, Warning, and Critical violations. You will see alert details automatically when navigating to one.newrelic.com. Documentation: Applied Intelligence and alerting in New Relic One Browser alert violations (moving to New Relic One) Mobile violations (moving to New Relic One) Monitor violations (moving to New Relic One) Action items for a successful transition: No action required, but you can get ready for the new UI experience. Here's an example of the detailed information about an Alerts violation for a selected entity in New Relic One. Violation details in New Relic One Comments Holistic view From New Relic One's homepage, the entity list presents an activity stream of all entities with alert violations. You no longer need to jump around individual lists of end-user, mobile, or monitor violations. Enhanced troubleshooting tools From New Relic One's homepage, you will also see an Alerts & AI (Applied Intelligence) link. From here you can solve problems faster with anomaly detection, incident correlation, and noise reduction. Specific violation From a selected entity, you will see a new button identifying the violation as Operational, Warning, or Critical, as well as entity metadata and useful details about the incident. Connected agents page Finding your connected agents has never been easier! You can already do this via the Query your data link in New Relic One. Simply run these NrDailyUsage queries to get a list of connected agents and hosts. The old Connected agents page is end-of-life and will be removed. Documentation: Explorers Hub post NRQL query tools NrDailyUsage data definition Action items for a successful transition: To query your connected apps and hosts, you can use existing NRQL query tools, such as New Relic One's query builder or the GraphQL API. Recommendation: For best results exploring comprehensive data about your apps and hosts, use the query builder in New Relic One or the NerdGraph API. Inactive apps in New Relic One Starting June 8, 2020, New Relic One will not continue to display any APM application that hasn't reported data for 93 days. To match our published APM data retention guidelines, applications that have not reported data will be available within the New Relic UI for 90 days. After 90 days, those applications will be removed from the UI. However, key metrics will continue to be available via the New Relic REST API based on subscription level. This is why the application name will remain reserved until the application is permanently deleted via the REST API Explorer. Action items for a successful transition: If you want to reuse an app name for an old app that is no longer reporting data: Use the REST API v2 or API Explorer to get summary data, including app ID, name, health status (look for gray), last reported, etc. Uninstall the agent for your app. Use the REST API or API Explorer to delete the apps. Synthetic monitor alert notifications and conditions In order to provide a unified experience, we're deprecating Synthetics monitor alert notifications and condition violations. We are replacing these pages with a new Synthetics monitor overview experience in New Relic One. This new experience provides visibility into a monitor's open violations and alert conditions with the monitor results in a single view, removing the need to open multiple tabs to view violations or alert conditions. Action items for a successful transition: No action required, but you can get ready for the new UI experience by reviewing our documentation about New Relic Applied Intelligence, which includes: The alerting functionality you are already familiar with in New Relic Alerts, and more Incident Intelligence, which reduces noise and accelerates your incident resolution process Proactive Detection, which surfaces relevant issues and provides automatic explanations to their cause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.94136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> feature end of life announcements July 2020",
        "sections": "Inactive apps in <em>New</em> <em>Relic</em> <em>One</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " To improve our unified experience, starting from Wednesday, August 12, 2020, Kubernetes integrations that <em>use</em> v1.7 or older will be deprecated. The <em>UI</em> experience in the infrastructure.newrelic.com domain will no longer be available; it will only be available in <em>New</em> <em>Relic</em> <em>One</em>. If you are already using"
      },
      "id": "603e795364441ff1924e8872"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/ui-data/new-relic-feature-end-life-announcements-july-2020": [
    {
      "sections": [
        "Basic platform UI: search, share, chart UI, customize navigation, and more",
        "Observe your platform",
        "Customize the navigation bar and shortcuts",
        "Light and dark mode",
        "Search accounts and entities",
        "Chart and query features",
        "Share New Relic views with others",
        "Account and user settings",
        "Other UI experiences"
      ],
      "title": "Basic platform UI: search, share, chart UI, customize navigation, and more",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "b3cdcfc60a2821dfa5bee9766aba483cc3389398",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/basic-ui-features/",
      "published_at": "2021-10-13T08:56:03Z",
      "updated_at": "2021-08-21T09:29:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One has some basic UI functions that are widely available across the platform. Understanding these features will help you find and analyze your data more easily. Observe your platform New Relic One gives you full access to the data from all the entities in your stack. Go to the New Relic Explorer at one.newrelic.com to see a full list of entities, identify overall behaviors, filter them to locate sources of performance issues, or plan improvements for your system. Customize the navigation bar and shortcuts Select the edit icon at the right end of the navigation bar to customize your view. Home, Explorer, Browse data, Dashboards, and Alerts & AI are fixed, but you can favorite up to six more elements to display on the bar as well. The rest will go on the More group. Navigation shortcuts are a faster way to find entities and apps that are relevant to you. Mouse over any menu item for quick access to your favorite entities, those you recently visited, or just to search without having to navigate to a specific section. If you click on an entity, you can choose to open it in the same browser tab or in a new one. Light and dark mode See Light and dark mode. Search accounts and entities Access Quick find clicking the button, near the top right of the New Relic One UI. Some details about your search: You can search across all accounts that you have been granted access to in your organization. For more about account access, see Factors affecting access. Entities that cease to exist are available in search for eight days. If your organization has multiple accounts, use the account picker at the top left corner to select accounts. Chart and query features You can add most charts to a new or existing dashboard. Here are some query and chart features available across all or most of the platform: If you want to... Do this... Start querying your data Mouse over Browse data and select metrics, events, logs, or traces for a direct access to any of those types of data. Also, at the top of any UI page, select Query your data to access the data explorer and query builder. View a chart's query For some charts, you can view the NRQL query used to generate that chart. This can help you understand a chart better or use it as the basis for a new query. Choose time range Drag across a section of a chart to zoom in on that time range. Or, use the time picker in the top right corner of the UI to select pre-set time ranges or set a custom one. View chart details Mouse over a chart to see a pop-up with more detail. For some charts, selecting a point on the chart will take you to a UI page with more information about that metric. Hide or return chart elements To hide or unhide a displayed chart element, select that element's name below the chart. The chart display will adjust to reflect the absence or presence of that element. Share New Relic views with others Here are some options for sharing New Relic UI pages and visualizations. If you want to... Do this... Share UI pages and dashboards To share an entire New Relic UI page, click Share near the top of the UI to copy the URL. Share charts If New Relic charts are built with NRQL queries, they have a menu that exposes various options, including sharing options like Get as image and Get chart link. Some notes about sharing: The person you share with may not have access to view the data from that account. To solve that, someone on your team with New Relic user management abilities must add that person to the account. If someone can't access a custom dashboard, it may be that it is set to private. Read more about dashboard permissions. Some sharing options have associated time ranges, which may impact later viewings of it. For example, if you use a chart's Get chart link option and that chart is set to 'Last 30 minutes', when viewed it will show the last 30 minutes, not the time range displayed when it was shared. To share a specific time range, you must select that time range in the UI. Account and user settings To find account settings and user preferences, use the account dropdown, located at the top right of the UI, beside your user name. Other UI experiences This has been a look at a few basic platform UI experiences. For more about the UI, search for docs related to the specific New Relic solution you're using.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.17947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic platform <em>UI</em>: search, share, chart <em>UI</em>, customize navigation, <em>and</em> more",
        "sections": "Share <em>New</em> <em>Relic</em> views with others",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": "<em>New</em> <em>Relic</em> <em>One</em> has some basic <em>UI</em> functions that are widely available across the platform. Understanding these features will help you find and analyze your <em>data</em> more easily. Observe your platform <em>New</em> <em>Relic</em> <em>One</em> gives you full access to the <em>data</em> from all the entities in your stack. Go to the <em>New</em> <em>Relic</em>"
      },
      "id": "603ec1f964441f5b0e4e8860"
    },
    {
      "sections": [
        "Dependencies UI: View an entity's upstream and downstream dependencies",
        "Requirements",
        "View dependencies"
      ],
      "title": "Dependencies UI: View an entity's upstream and downstream dependencies",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "2b2f328a6281bb155bcde07efec7f42eae943048",
      "image": "https://docs.newrelic.com/static/aabc5f64a91cc01b6e226df53c62458f/c1b63/new-relic-one-dependencies-UI.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/explore-downstream-dependencies-new-relic-one/",
      "published_at": "2021-10-13T08:57:23Z",
      "updated_at": "2021-08-21T09:29:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic Explorer, an entity's Dependencies page shows a filterable list of all the applications, services, databases, and hosts connected to the entity. It shows upstream and downstream dependencies, and provides paths to explore them. Similar to service maps, the dependencies page helps you understand how all of your upstream and downstream services are connected. It also uses the same color coding system used by service maps to show you what's performing well and what isn't. Requirements To view an entity's dependencies, make sure your app uses the minimum required APM agent version: C 1.0.0 or higher Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher View dependencies To view dependencies for applications, services, databases, and hosts connected to an entity: Go to one.newrelic.com, select Explorer, and select an entity. Select Dependencies. To drill down further, filter the apps, services, databases, or hosts. one.newrelic.com > Explorer > (select an entity) > Dependencies: View a filterable list of all the apps, services, databases, and hosts connected to an entity, and their color-coded health status. You can filter the dependencies page to view specific things that report to the entity. Dependencies include: Services: APM-monitored applications and services. Mobile applications: your mobile apps. Browser applications: your front-end browser apps. External services: external services monitored by APM. External services include out-of-process services such as web services, resources in the cloud, and any other network calls. Databases: your application's database and cache data. Databases are agentless. Because of this, alerts cannot be set for the database, as only the service call is reported to New Relic. Hosts: your infrastructure (servers and hosts).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.17947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Dependencies <em>UI</em>: View an entity&#x27;s upstream <em>and</em> downstream dependencies",
        "sections": "Dependencies <em>UI</em>: View an entity&#x27;s upstream <em>and</em> downstream dependencies",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " services: external services monitored by APM. External services include out-of-process services such as web services, resources in the cloud, and any other network calls. Databases: your application&#x27;s database and cache <em>data</em>. Databases are agentless. Because of this, alerts cannot be set for the database, as only the service call is reported to <em>New</em> <em>Relic</em>. Hosts: your infrastructure (servers and hosts)."
      },
      "id": "603eb2e564441f0fe44e889b"
    },
    {
      "sections": [
        "Metric normalization rules",
        "Metric normalization rules management"
      ],
      "title": "Metric normalization rules",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "UI and data"
      ],
      "external_id": "3c55e4717f145ac7ae0d88e860878f4e8d18cd6b",
      "image": "https://docs.newrelic.com/static/83edfb6f5b1b68712cac34d138bb8cb8/3996e/create-new-rule-window.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/metric-normalization-rules/",
      "published_at": "2021-10-13T08:57:23Z",
      "updated_at": "2021-03-29T20:39:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There may be cases where an application sends many individual metrics that could be better managed in groups. Most of these occur with web transactions metrics named from URLs. For more information on this issue, see Metric grouping issues (MGIs). To reduce high cardinality and prevent metric grouping issues, New Relic supports rules for grouping or filtering out metrics (normalization). In some cases, when MGIs with a significant high number of metrics are detected, a rule is created automatically to protect the platform from performance degradation. Metric normalization rules management You can create and manage new rules that deal with the noise produced from high cardinality metrics by using the metric normalization tool, which is accessible from each service dashboard in the New Relic Explorer. Once there, select Metric Normalization in the left sidebar. There you can see the existing rules or create new ones. Click a rule to modify it, or click Create a new rule to create a new one. A new pane to configure the rule will be displayed. Available fields are: Match expression: enter the regular expression to group all the metrics you want to include in the rule. Matches: here you will see a preview of the metrics matched by the regular expression above. Action: the action you want to perform on the metrics. Replace: replace the matched metrics by the regular expression with the value described in the Replacement field. Ignore: ignore any metric that matches the regular expression. Deny new metrics: only write metrics that have already been reported, and ignore those that match the regular expression. Replacement: only active when Replace is enabled. Matched metrics are replaced with the field's value. If the regular expression is capturing groups, you can use placeholders for them with \\1 or \\2 for the groups 1 and 2 respectively. Active: rules can’t be deleted, but can be deactivated. Click the toggle to enable or disable the rule. If you want the rule to be removed, reach out to New Relic's support. Notes: internal notes on the rule. Has no effect on the rule. Once you have set up the fields, click Create (or Edit in case you are editing an existing rule), and the rule will be applied immediately as long as it's Active.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.0911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " grouping issues, <em>New</em> <em>Relic</em> supports rules for grouping or filtering out metrics (normalization). In some cases, when MGIs with a significant high number of metrics are detected, a rule is created automatically to protect the platform from performance degradation. Metric normalization rules management You"
      },
      "id": "603e810b64441ff3a74e8862"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/workloads/use-workloads": [
    {
      "sections": [
        "Workloads: Isolate and resolve incidents faster",
        "What is a workload in New Relic?",
        "Tip",
        "Why it matters",
        "Requirements",
        "Impact of accounts on the workload permissions and content",
        "Workload account",
        "Scope accounts"
      ],
      "title": "Workloads: Isolate and resolve incidents faster",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "858e74779a209ac0eb948405c311e59a71eb8d9b",
      "image": "https://docs.newrelic.com/static/bb2929677005af573675e7eceead70de/c1b63/1_workload_health_tab.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster/",
      "published_at": "2021-10-12T04:16:31Z",
      "updated_at": "2021-07-30T01:57:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our workloads feature gives you the ability to group and monitor entities based on a team or a set of responsibilities, providing aggregated health and activity data from frontend to backend services across your entire stack. Workloads help you understand the status of complex systems, detect issues, understand the cause and impact of an incident, and resolve those issues quickly. Want to try it? Create a New Relic account for free! No credit card required. What is a workload in New Relic? New Relic monitors a wide range of entities and data, from client-side applications and backend APIs, to the underlying infrastructure. To make sense of this large data set, we give you the ability to create and monitor workloads. Workloads give you the ability to group and monitor entities based on a team or a set of responsibilities, and provide an aggregated view of the health and activity of the entities in the workload. Thus, you can understand better how your business logic is working, from frontend to backend services, across your entire stack. Here are some workload examples: A serverless application that includes an API gateway, a few serverless functions, and a managed database and storage. A browser application and the backend APIs that support it. A collection of Java microservices and the infrastructure they run on. Here's a workload: one.newrelic.com > Explorer > Workloads > (selected workload): The workloads UI provides a curated view of how the entities in your workload are performing. The charts you see will depend on the types of entities you've included to the workload. Tip Learn how to use workloads. Why it matters Workloads give you visibility into the end-to-end availability and consumption of resources across an entire service, and provide you a way to define what’s relevant to you. You can use workloads to group together entities that are important to a specific team or project, so you can better browse and isolate the most relevant data for that service. Because our UI gives you cross-account access, you can add entities to your workload from any of the accounts you have access to. A workload can include: Any New Relic-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other workloads: this is useful for complex teams who need to divide and overlap workloads. Requirements Requirements for creating and managing workloads: All users for an account can view that account's workloads. To create, edit, and delete workloads, you must have a user role with that permission. Impact of accounts on the workload permissions and content Workloads can group and display entities from multiple accounts to provide complete observability of complex systems. When creating a workload, you must set: The workload account Scope accounts Learn how to find a New Relic account ID. Workload account The workload account is where any workload-specific data is stored. For example, a workload might generate NrAuditEvent data, and you would find that data by querying the workload account. The workload account determines the user permissions that govern which users can see and manage the workload, through the account roles. Once created, the workload account can’t be changed. Scope accounts Scope accounts are the accounts from which a workload fetches entity data. In other words, the scope accounts provide the content for a workload. Users who don’t have access to all of a workload's scope accounts may not be able to see complete workload data. Scope accounts can be updated at any point in time by any user with workload management capabilities on the workload account. By default, all accounts that the workload creator has access to at the moment of the workload creation are set as scope accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.23222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workloads</em>: Isolate and resolve incidents faster",
        "sections": "What is a <em>workload</em> in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of the accounts you have access to. A <em>workload</em> can include: Any <em>New</em> <em>Relic</em>-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other <em>workloads</em>: this is useful for complex teams who need to divide and overlap <em>workloads</em>. Requirements Requirements for creating"
      },
      "id": "6043cb93196a67f988960f76"
    },
    {
      "sections": [
        "Workload status views and notifications",
        "Why it matters",
        "Get started with workload status",
        "Obtain your workload status",
        "Save views with sets of workloads",
        "Get notified when the workload status changes"
      ],
      "title": "Workload status views and notifications",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "1633f322d9f0c907a9636e0c71aee7a0a38ba85b",
      "image": "https://docs.newrelic.com/static/5ea6d75d1efb047eda59eee3f12e08a9/c1b63/workloads_views.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workload-status-views-notifications/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-05-10T14:02:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The workload status, which is derived from the alerting status of the entities in your workload, informs you about how your workload is behaving. Why it matters Workload status: Is a quick indicator of how your system is doing, and tells you if you need to take action on any of your workloads in just a glance. Adapts to your needs and to how important each entity is. Allows you to share the status of your workloads. Other teams that depend on your services or infrastructure can learn the status of the workload without them needing to understand your system’s architecture details, or look at custom dashboards. Get started with workload status New Relic One provides a status value for all entities, which is based on the results of New Relic alerts. You can check the color-coded alert status for each entity on the New Relic Explorer, or consume the alert status value through the API. For example, you may see a red alert status indicating that a critical violation is in progress. With Workloads you can group entities that are part of a complex system and obtain a single, global value that summarizes the status of all the entities in your workload. Thus, you can quickly detect when the workload stops being operational, or anticipate any potential incident or loss of quality of service. Obtain your workload status A workload can have one of the following status values: Operational: The workload is working fine. Degraded: The workload is showing some degradation in performance or errors, but it’s still providing an acceptable level of service, and you don’t need to take any urgent action. Critical or Disrupted: The workload is not providing an acceptable level of service, and you need to take urgent action. Unknown: You haven’t configured how to calculate workload status, or there aren’t any alert conditions set up that can determine the status of the workload entities. To learn how to define or edit the workload status, refer to Workload status configuration. Save views with sets of workloads If you usually need to see the status of a certain group of workloads, you can save views that contain only those workloads. The tile view mode helps you quickly find your workloads and see their status at a glance. To create a view, follow these steps: Go to one.newrelic.com and click on More > Workload views. Click on Add view. Give the view a meaningful name (such as the name of a team or business unit), and select an account to associate the view with. Select the workloads you want to include in the view, by their name or tags. Save the new view. Status views are most useful for teams that are accountable for more than one workload, support roles, and business unit managers. Get notified when the workload status changes You may need to follow the status of a workload, either because it represents the services your team is accountable for, or because your own services depend on that workload, which is managed by another team. The status of all workloads is calculated regularly and the result is stored in NRDB through a WorkloadStatus event. This allows you to set up an alert condition to notify you whenever the Workload goes into a Disrupted or Degraded status. To set up the alert condition follow these steps: Go to one.newrelic.com and select Alerts & AI. Select the policy where you want to add the new alert condition, or create a new policy with the appropriate notification channel. Then click on Create a condition. Where prompted to Select a product, click NRQL. Add the following NRQL query: SELECT latest(statusValueCode) FROM WorkloadStatus WHERE workloadGuid = '<GUID>' FACET workloadGuid as 'entity.guid', entity.name Copy You can obtain the workload GUID by clicking on the See metadata and manage tags on the workload UI. Write the WHERE clause so the alert condition applies to just one workload (as in the example) or more than one. Or remove the WHERE clause if you want the alert condition to apply to all the workloads on the account. By adding the FACET you can use these fields on the alert description, as explained below. Set one of the following static thresholds: (Recommended) Critical when the query returns a value equal to 3 for at least 1 minute, if you want to be notified when the workload status is disrupted. Critical when the query returns a value equal to 2 for at least 1 minute, if you want to be notified when the workload status is degraded. Remember that a warning threshold doesn't generate an incident or send a notification. As a result, you need to create two alert conditions with a critical threshold (as explained above) if you want to be notified of any status change. Complete the alert condition: Set a violation time limit, to automatically force-close a long-lasting violation after the selected amount of time you select. Choose to fill data gaps with last known value. Optionally, you can also add a custom violation description that includes the workload name and permanent link to the UI in the alert notification: Workload: {{tag.entity.name}} Direct link: https://one.newrelic.com/redirect/entity/{{tag.entity.guid}} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.04434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workload</em> status views and notifications",
        "sections": "Save views with sets of <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " at custom dashboards. Get started with <em>workload</em> status <em>New</em> <em>Relic</em> <em>One</em> provides a status value for all entities, which is based on the results of <em>New</em> <em>Relic</em> alerts. You can check the color-coded alert status for each entity on the <em>New</em> <em>Relic</em> Explorer, or consume the alert status value through the API"
      },
      "id": "603e967564441ff8cd4e8855"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-10-12T15:16:12Z",
      "updated_at": "2021-08-21T09:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters When using our API to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50928,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to filter the UI <em>Use</em> the filter field at the top of the <em>New</em> <em>Relic</em> Explorer to filter down to the entities you care about. You can <em>use</em> multiple filter conditions. To filter down to certain entities using tags: From <em>one</em>.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown"
      },
      "id": "603ebd1228ccbc6278eba754"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/workloads/workload-status-configuration": [
    {
      "sections": [
        "Workloads: Isolate and resolve incidents faster",
        "What is a workload in New Relic?",
        "Tip",
        "Why it matters",
        "Requirements",
        "Impact of accounts on the workload permissions and content",
        "Workload account",
        "Scope accounts"
      ],
      "title": "Workloads: Isolate and resolve incidents faster",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "858e74779a209ac0eb948405c311e59a71eb8d9b",
      "image": "https://docs.newrelic.com/static/bb2929677005af573675e7eceead70de/c1b63/1_workload_health_tab.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster/",
      "published_at": "2021-10-12T04:16:31Z",
      "updated_at": "2021-07-30T01:57:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our workloads feature gives you the ability to group and monitor entities based on a team or a set of responsibilities, providing aggregated health and activity data from frontend to backend services across your entire stack. Workloads help you understand the status of complex systems, detect issues, understand the cause and impact of an incident, and resolve those issues quickly. Want to try it? Create a New Relic account for free! No credit card required. What is a workload in New Relic? New Relic monitors a wide range of entities and data, from client-side applications and backend APIs, to the underlying infrastructure. To make sense of this large data set, we give you the ability to create and monitor workloads. Workloads give you the ability to group and monitor entities based on a team or a set of responsibilities, and provide an aggregated view of the health and activity of the entities in the workload. Thus, you can understand better how your business logic is working, from frontend to backend services, across your entire stack. Here are some workload examples: A serverless application that includes an API gateway, a few serverless functions, and a managed database and storage. A browser application and the backend APIs that support it. A collection of Java microservices and the infrastructure they run on. Here's a workload: one.newrelic.com > Explorer > Workloads > (selected workload): The workloads UI provides a curated view of how the entities in your workload are performing. The charts you see will depend on the types of entities you've included to the workload. Tip Learn how to use workloads. Why it matters Workloads give you visibility into the end-to-end availability and consumption of resources across an entire service, and provide you a way to define what’s relevant to you. You can use workloads to group together entities that are important to a specific team or project, so you can better browse and isolate the most relevant data for that service. Because our UI gives you cross-account access, you can add entities to your workload from any of the accounts you have access to. A workload can include: Any New Relic-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other workloads: this is useful for complex teams who need to divide and overlap workloads. Requirements Requirements for creating and managing workloads: All users for an account can view that account's workloads. To create, edit, and delete workloads, you must have a user role with that permission. Impact of accounts on the workload permissions and content Workloads can group and display entities from multiple accounts to provide complete observability of complex systems. When creating a workload, you must set: The workload account Scope accounts Learn how to find a New Relic account ID. Workload account The workload account is where any workload-specific data is stored. For example, a workload might generate NrAuditEvent data, and you would find that data by querying the workload account. The workload account determines the user permissions that govern which users can see and manage the workload, through the account roles. Once created, the workload account can’t be changed. Scope accounts Scope accounts are the accounts from which a workload fetches entity data. In other words, the scope accounts provide the content for a workload. Users who don’t have access to all of a workload's scope accounts may not be able to see complete workload data. Scope accounts can be updated at any point in time by any user with workload management capabilities on the workload account. By default, all accounts that the workload creator has access to at the moment of the workload creation are set as scope accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.23222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workloads</em>: Isolate and resolve incidents faster",
        "sections": "What is a <em>workload</em> in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of the accounts you have access to. A <em>workload</em> can include: Any <em>New</em> <em>Relic</em>-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other <em>workloads</em>: this is useful for complex teams who need to divide and overlap <em>workloads</em>. Requirements Requirements for creating"
      },
      "id": "6043cb93196a67f988960f76"
    },
    {
      "sections": [
        "Workload status views and notifications",
        "Why it matters",
        "Get started with workload status",
        "Obtain your workload status",
        "Save views with sets of workloads",
        "Get notified when the workload status changes"
      ],
      "title": "Workload status views and notifications",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "1633f322d9f0c907a9636e0c71aee7a0a38ba85b",
      "image": "https://docs.newrelic.com/static/5ea6d75d1efb047eda59eee3f12e08a9/c1b63/workloads_views.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workload-status-views-notifications/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-05-10T14:02:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The workload status, which is derived from the alerting status of the entities in your workload, informs you about how your workload is behaving. Why it matters Workload status: Is a quick indicator of how your system is doing, and tells you if you need to take action on any of your workloads in just a glance. Adapts to your needs and to how important each entity is. Allows you to share the status of your workloads. Other teams that depend on your services or infrastructure can learn the status of the workload without them needing to understand your system’s architecture details, or look at custom dashboards. Get started with workload status New Relic One provides a status value for all entities, which is based on the results of New Relic alerts. You can check the color-coded alert status for each entity on the New Relic Explorer, or consume the alert status value through the API. For example, you may see a red alert status indicating that a critical violation is in progress. With Workloads you can group entities that are part of a complex system and obtain a single, global value that summarizes the status of all the entities in your workload. Thus, you can quickly detect when the workload stops being operational, or anticipate any potential incident or loss of quality of service. Obtain your workload status A workload can have one of the following status values: Operational: The workload is working fine. Degraded: The workload is showing some degradation in performance or errors, but it’s still providing an acceptable level of service, and you don’t need to take any urgent action. Critical or Disrupted: The workload is not providing an acceptable level of service, and you need to take urgent action. Unknown: You haven’t configured how to calculate workload status, or there aren’t any alert conditions set up that can determine the status of the workload entities. To learn how to define or edit the workload status, refer to Workload status configuration. Save views with sets of workloads If you usually need to see the status of a certain group of workloads, you can save views that contain only those workloads. The tile view mode helps you quickly find your workloads and see their status at a glance. To create a view, follow these steps: Go to one.newrelic.com and click on More > Workload views. Click on Add view. Give the view a meaningful name (such as the name of a team or business unit), and select an account to associate the view with. Select the workloads you want to include in the view, by their name or tags. Save the new view. Status views are most useful for teams that are accountable for more than one workload, support roles, and business unit managers. Get notified when the workload status changes You may need to follow the status of a workload, either because it represents the services your team is accountable for, or because your own services depend on that workload, which is managed by another team. The status of all workloads is calculated regularly and the result is stored in NRDB through a WorkloadStatus event. This allows you to set up an alert condition to notify you whenever the Workload goes into a Disrupted or Degraded status. To set up the alert condition follow these steps: Go to one.newrelic.com and select Alerts & AI. Select the policy where you want to add the new alert condition, or create a new policy with the appropriate notification channel. Then click on Create a condition. Where prompted to Select a product, click NRQL. Add the following NRQL query: SELECT latest(statusValueCode) FROM WorkloadStatus WHERE workloadGuid = '<GUID>' FACET workloadGuid as 'entity.guid', entity.name Copy You can obtain the workload GUID by clicking on the See metadata and manage tags on the workload UI. Write the WHERE clause so the alert condition applies to just one workload (as in the example) or more than one. Or remove the WHERE clause if you want the alert condition to apply to all the workloads on the account. By adding the FACET you can use these fields on the alert description, as explained below. Set one of the following static thresholds: (Recommended) Critical when the query returns a value equal to 3 for at least 1 minute, if you want to be notified when the workload status is disrupted. Critical when the query returns a value equal to 2 for at least 1 minute, if you want to be notified when the workload status is degraded. Remember that a warning threshold doesn't generate an incident or send a notification. As a result, you need to create two alert conditions with a critical threshold (as explained above) if you want to be notified of any status change. Complete the alert condition: Set a violation time limit, to automatically force-close a long-lasting violation after the selected amount of time you select. Choose to fill data gaps with last known value. Optionally, you can also add a custom violation description that includes the workload name and permanent link to the UI in the alert notification: Workload: {{tag.entity.name}} Direct link: https://one.newrelic.com/redirect/entity/{{tag.entity.guid}} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.04434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workload</em> status views and notifications",
        "sections": "Save views with sets of <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " at custom dashboards. Get started with <em>workload</em> status <em>New</em> <em>Relic</em> <em>One</em> provides a status value for all entities, which is based on the results of <em>New</em> <em>Relic</em> alerts. You can check the color-coded alert status for each entity on the <em>New</em> <em>Relic</em> Explorer, or consume the alert status value through the API"
      },
      "id": "603e967564441ff8cd4e8855"
    },
    {
      "sections": [
        "Use workloads",
        "Create a workload",
        "Use tags to define the workload content",
        "How the dynamic query logic works",
        "Add dashboards to workloads",
        "Use the API"
      ],
      "title": "Use workloads",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "c39090bde9b797940e7f5ba0c9610ba39879677b",
      "image": "https://docs.newrelic.com/static/14c811e218cfc8793bb4d2bd4b2aad0b/c1b63/new-relic-workloads-add-dashboards.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/use-workloads/",
      "published_at": "2021-10-12T12:32:28Z",
      "updated_at": "2021-06-03T10:04:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view workloads, go to one.newrelic.com and find them on the Explorer. There are three main tabs (Health, Activity, and Owner) plus the header. The Health tab in a workload provides relevant status data that helps you operate the workload: It shows the global status of the workload, as well as the individual status of all the entities that make up the workload at each point in time. It looks like this: It comprises the following: The navigator view shows the entities that make up the workload, and provides controls to group and sort them. If you’ve used queries to dynamically select entities, the workload entities will change over time. The workload status informs about how your workload is performing, based on the individual alerting status of the entities in your workload. With health over time you’ll see whether and how the workload status has changed in the past three hours. If one or more entities are alerting, you’ll get a count of criticals and warnings and a summary of the open conditions, which will make it easier to identify and troubleshoot the most important issues. The Activity tab shows performance data related to the entities in the workload, along with the events that could explain any changes in those time series. It looks like this: Here's the most important sections: Linked dashboards. You can add links to dashboards from your workload, and create pre-filtered, workload-relevant links to dashboards. Golden metrics. These are charts with the most relevant metrics for each entity type, such as number of requests, response time, and error rate for an application. Explore the charts to detect correlations among different entities (for example, two applications) and different stack layers (for example, applications and hosts). The golden metrics that you see for each entity type on a workload can be customized either at the account or the workload level through the NerdGraph API. Events timeline. This includes the start and end time of incidents and anomalies that refer to the workload entities. It also shows other event types that can explain a change in the status or performance of the workload, such as deployments and configuration changes. The Owner tab gives you information about the team responsible for the workload. It looks like this: It contains: The team responsible for the workload. You can include more than one team. The workload description. Share the mission of the workload, and the business logic it represents: Is it a web application? An API? A backend process? Fill in any details that are relevant to your team, or to other teams in your organization. Contact information. From the drop-down menu, choose how your team prefers to be contacted. Links to the most relevant resources to operate the workload. Here you can add links to runbooks, code repositories, productivity tools, or anything else related to the workload that you need at hand. Finally, the header contains the filter bar and the edition controls: Filter bar. Use the advanced filtering options when you need to focus only on certain entities within the workload. Edit workload. Define the entities that are part of the workload, and the accounts they’ll be fetched from. Setup status. Configure how the global workload status will be determined, based on the workload entities health. Summary page. See all the tags that have been added to the workload, as well as metadata such as the workload's identifier (GUID) and account. Create a workload A workload should contain the entities you and your team want to see. Your choice of entities depends on your organization structure and goals. one.newrelic.com > Explorer > Workloads > Create a workload: When you create a workload, you choose the associated accounts and monitored entities. You can use New Relic One or the NerdGraph API to create a workload. Follow these steps to create a workload using the UI: Go to one.newrelic.com and click on the Explorer, and then click + Create a workload. Give the workload a name that will be meaningful for you and your team later. From the Select an account dropdown, select the workload account you'd like to use. Click Choose the scope accounts to check all of the accounts related to this workload. Find and choose the entities that make up the workload. When you have the results you're looking for, you can add specific entities or add the query to dynamically update the entities in the workload. You can search by entity type, tags, or attributes (like entity name, account ID, and AWS region). Click + Add this query to create a list of dynamically updated entities for your workload. We recommend this if you want your workload to update its entities as your system changes. Click + Add next to an entity to add it to your workload. This is a good choice if you know that the entities will stay useful even as your system changes. You can add a combination of queries and specific entities to the workload, which combine according to the query logic. Click Create a workload to save the workload. Once you've created the workload, you can edit it at any time If your workload contains one or more dashboards, you can set filters on those dashboard links. Below are more details about some aspects of how to define workloads: Use tags to define the workload content You can query and select workload entities using both tags and attributes. Therefore, to optimize your use of workloads, it helps to have a good entity-tagging strategy. We recommend reading the tagging documentation. How the dynamic query logic works You can add several individual entities and queries to define a workload. Queries can include multiple search terms. These are combined with an AND operator. Separate queries within a workload are combined with an OR operator. You can wrap strings between percent signs (%) to match exact substrings within a query. If you use substrings in entity names to categorize those entities (for example, <team>-<env>-<appName>), consider using tags complementarily, which are more powerful for filtering and grouping (for example, team:awesome, env:production). We recommend not to use percent signs (%) in dynamic queries that might return over 500 entities. This way, you get a more consistent experience in the user interface. Add dashboards to workloads If you have custom dashboards and you already know which data is relevant to your team for observing and operating their workloads, you can link those dashboards from your workload. You can also set filters on dashboards to scope them to a workload-specific context. When a user selects that dashboard from the workload, it opens with the filter already applied. one.newrelic.com > Apps > Workloads: You can add dashboards to a workload. To add dashboards to a workload: When creating or editing a workload, type Dashboard in the workload search bar to filter to dashboard entities. Add other search terms to filter to specific dashboards. Click Add. one.newrelic.com > Apps > Workloads: You can set filters on the dashboards you've linked to a workload. To filter a workload’s dashboard: From a workload’s Overview page, select a dashboard. Add search terms to filter the dashboard to a view that’s relevant for that workload. Select Save filter for this workload. Use the API You can query, create, and update workloads with our NerdGraph API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.82089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>workloads</em>",
        "sections": "<em>Use</em> <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " on your organization structure and goals. <em>one</em>.newrelic.com &gt; Explorer &gt; <em>Workloads</em> &gt; Create a <em>workload</em>: When you create a <em>workload</em>, you choose the associated accounts and monitored entities. You can <em>use</em> <em>New</em> <em>Relic</em> <em>One</em> or the NerdGraph API to create a <em>workload</em>. Follow these steps to create a <em>workload</em> using"
      },
      "id": "603e81e8196a67c972a83db1"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/workloads/workload-status-views-notifications": [
    {
      "sections": [
        "Workloads: Isolate and resolve incidents faster",
        "What is a workload in New Relic?",
        "Tip",
        "Why it matters",
        "Requirements",
        "Impact of accounts on the workload permissions and content",
        "Workload account",
        "Scope accounts"
      ],
      "title": "Workloads: Isolate and resolve incidents faster",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "858e74779a209ac0eb948405c311e59a71eb8d9b",
      "image": "https://docs.newrelic.com/static/bb2929677005af573675e7eceead70de/c1b63/1_workload_health_tab.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster/",
      "published_at": "2021-10-12T04:16:31Z",
      "updated_at": "2021-07-30T01:57:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our workloads feature gives you the ability to group and monitor entities based on a team or a set of responsibilities, providing aggregated health and activity data from frontend to backend services across your entire stack. Workloads help you understand the status of complex systems, detect issues, understand the cause and impact of an incident, and resolve those issues quickly. Want to try it? Create a New Relic account for free! No credit card required. What is a workload in New Relic? New Relic monitors a wide range of entities and data, from client-side applications and backend APIs, to the underlying infrastructure. To make sense of this large data set, we give you the ability to create and monitor workloads. Workloads give you the ability to group and monitor entities based on a team or a set of responsibilities, and provide an aggregated view of the health and activity of the entities in the workload. Thus, you can understand better how your business logic is working, from frontend to backend services, across your entire stack. Here are some workload examples: A serverless application that includes an API gateway, a few serverless functions, and a managed database and storage. A browser application and the backend APIs that support it. A collection of Java microservices and the infrastructure they run on. Here's a workload: one.newrelic.com > Explorer > Workloads > (selected workload): The workloads UI provides a curated view of how the entities in your workload are performing. The charts you see will depend on the types of entities you've included to the workload. Tip Learn how to use workloads. Why it matters Workloads give you visibility into the end-to-end availability and consumption of resources across an entire service, and provide you a way to define what’s relevant to you. You can use workloads to group together entities that are important to a specific team or project, so you can better browse and isolate the most relevant data for that service. Because our UI gives you cross-account access, you can add entities to your workload from any of the accounts you have access to. A workload can include: Any New Relic-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other workloads: this is useful for complex teams who need to divide and overlap workloads. Requirements Requirements for creating and managing workloads: All users for an account can view that account's workloads. To create, edit, and delete workloads, you must have a user role with that permission. Impact of accounts on the workload permissions and content Workloads can group and display entities from multiple accounts to provide complete observability of complex systems. When creating a workload, you must set: The workload account Scope accounts Learn how to find a New Relic account ID. Workload account The workload account is where any workload-specific data is stored. For example, a workload might generate NrAuditEvent data, and you would find that data by querying the workload account. The workload account determines the user permissions that govern which users can see and manage the workload, through the account roles. Once created, the workload account can’t be changed. Scope accounts Scope accounts are the accounts from which a workload fetches entity data. In other words, the scope accounts provide the content for a workload. Users who don’t have access to all of a workload's scope accounts may not be able to see complete workload data. Scope accounts can be updated at any point in time by any user with workload management capabilities on the workload account. By default, all accounts that the workload creator has access to at the moment of the workload creation are set as scope accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.23222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workloads</em>: Isolate and resolve incidents faster",
        "sections": "What is a <em>workload</em> in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of the accounts you have access to. A <em>workload</em> can include: Any <em>New</em> <em>Relic</em>-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other <em>workloads</em>: this is useful for complex teams who need to divide and overlap <em>workloads</em>. Requirements Requirements for creating"
      },
      "id": "6043cb93196a67f988960f76"
    },
    {
      "sections": [
        "Use workloads",
        "Create a workload",
        "Use tags to define the workload content",
        "How the dynamic query logic works",
        "Add dashboards to workloads",
        "Use the API"
      ],
      "title": "Use workloads",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "c39090bde9b797940e7f5ba0c9610ba39879677b",
      "image": "https://docs.newrelic.com/static/14c811e218cfc8793bb4d2bd4b2aad0b/c1b63/new-relic-workloads-add-dashboards.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/use-workloads/",
      "published_at": "2021-10-12T12:32:28Z",
      "updated_at": "2021-06-03T10:04:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view workloads, go to one.newrelic.com and find them on the Explorer. There are three main tabs (Health, Activity, and Owner) plus the header. The Health tab in a workload provides relevant status data that helps you operate the workload: It shows the global status of the workload, as well as the individual status of all the entities that make up the workload at each point in time. It looks like this: It comprises the following: The navigator view shows the entities that make up the workload, and provides controls to group and sort them. If you’ve used queries to dynamically select entities, the workload entities will change over time. The workload status informs about how your workload is performing, based on the individual alerting status of the entities in your workload. With health over time you’ll see whether and how the workload status has changed in the past three hours. If one or more entities are alerting, you’ll get a count of criticals and warnings and a summary of the open conditions, which will make it easier to identify and troubleshoot the most important issues. The Activity tab shows performance data related to the entities in the workload, along with the events that could explain any changes in those time series. It looks like this: Here's the most important sections: Linked dashboards. You can add links to dashboards from your workload, and create pre-filtered, workload-relevant links to dashboards. Golden metrics. These are charts with the most relevant metrics for each entity type, such as number of requests, response time, and error rate for an application. Explore the charts to detect correlations among different entities (for example, two applications) and different stack layers (for example, applications and hosts). The golden metrics that you see for each entity type on a workload can be customized either at the account or the workload level through the NerdGraph API. Events timeline. This includes the start and end time of incidents and anomalies that refer to the workload entities. It also shows other event types that can explain a change in the status or performance of the workload, such as deployments and configuration changes. The Owner tab gives you information about the team responsible for the workload. It looks like this: It contains: The team responsible for the workload. You can include more than one team. The workload description. Share the mission of the workload, and the business logic it represents: Is it a web application? An API? A backend process? Fill in any details that are relevant to your team, or to other teams in your organization. Contact information. From the drop-down menu, choose how your team prefers to be contacted. Links to the most relevant resources to operate the workload. Here you can add links to runbooks, code repositories, productivity tools, or anything else related to the workload that you need at hand. Finally, the header contains the filter bar and the edition controls: Filter bar. Use the advanced filtering options when you need to focus only on certain entities within the workload. Edit workload. Define the entities that are part of the workload, and the accounts they’ll be fetched from. Setup status. Configure how the global workload status will be determined, based on the workload entities health. Summary page. See all the tags that have been added to the workload, as well as metadata such as the workload's identifier (GUID) and account. Create a workload A workload should contain the entities you and your team want to see. Your choice of entities depends on your organization structure and goals. one.newrelic.com > Explorer > Workloads > Create a workload: When you create a workload, you choose the associated accounts and monitored entities. You can use New Relic One or the NerdGraph API to create a workload. Follow these steps to create a workload using the UI: Go to one.newrelic.com and click on the Explorer, and then click + Create a workload. Give the workload a name that will be meaningful for you and your team later. From the Select an account dropdown, select the workload account you'd like to use. Click Choose the scope accounts to check all of the accounts related to this workload. Find and choose the entities that make up the workload. When you have the results you're looking for, you can add specific entities or add the query to dynamically update the entities in the workload. You can search by entity type, tags, or attributes (like entity name, account ID, and AWS region). Click + Add this query to create a list of dynamically updated entities for your workload. We recommend this if you want your workload to update its entities as your system changes. Click + Add next to an entity to add it to your workload. This is a good choice if you know that the entities will stay useful even as your system changes. You can add a combination of queries and specific entities to the workload, which combine according to the query logic. Click Create a workload to save the workload. Once you've created the workload, you can edit it at any time If your workload contains one or more dashboards, you can set filters on those dashboard links. Below are more details about some aspects of how to define workloads: Use tags to define the workload content You can query and select workload entities using both tags and attributes. Therefore, to optimize your use of workloads, it helps to have a good entity-tagging strategy. We recommend reading the tagging documentation. How the dynamic query logic works You can add several individual entities and queries to define a workload. Queries can include multiple search terms. These are combined with an AND operator. Separate queries within a workload are combined with an OR operator. You can wrap strings between percent signs (%) to match exact substrings within a query. If you use substrings in entity names to categorize those entities (for example, <team>-<env>-<appName>), consider using tags complementarily, which are more powerful for filtering and grouping (for example, team:awesome, env:production). We recommend not to use percent signs (%) in dynamic queries that might return over 500 entities. This way, you get a more consistent experience in the user interface. Add dashboards to workloads If you have custom dashboards and you already know which data is relevant to your team for observing and operating their workloads, you can link those dashboards from your workload. You can also set filters on dashboards to scope them to a workload-specific context. When a user selects that dashboard from the workload, it opens with the filter already applied. one.newrelic.com > Apps > Workloads: You can add dashboards to a workload. To add dashboards to a workload: When creating or editing a workload, type Dashboard in the workload search bar to filter to dashboard entities. Add other search terms to filter to specific dashboards. Click Add. one.newrelic.com > Apps > Workloads: You can set filters on the dashboards you've linked to a workload. To filter a workload’s dashboard: From a workload’s Overview page, select a dashboard. Add search terms to filter the dashboard to a view that’s relevant for that workload. Select Save filter for this workload. Use the API You can query, create, and update workloads with our NerdGraph API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.82089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>workloads</em>",
        "sections": "<em>Use</em> <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " on your organization structure and goals. <em>one</em>.newrelic.com &gt; Explorer &gt; <em>Workloads</em> &gt; Create a <em>workload</em>: When you create a <em>workload</em>, you choose the associated accounts and monitored entities. You can <em>use</em> <em>New</em> <em>Relic</em> <em>One</em> or the NerdGraph API to create a <em>workload</em>. Follow these steps to create a <em>workload</em> using"
      },
      "id": "603e81e8196a67c972a83db1"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-10-12T15:16:12Z",
      "updated_at": "2021-08-21T09:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters When using our API to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50928,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to filter the UI <em>Use</em> the filter field at the top of the <em>New</em> <em>Relic</em> Explorer to filter down to the entities you care about. You can <em>use</em> multiple filter conditions. To filter down to certain entities using tags: From <em>one</em>.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown"
      },
      "id": "603ebd1228ccbc6278eba754"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster": [
    {
      "sections": [
        "Workload status views and notifications",
        "Why it matters",
        "Get started with workload status",
        "Obtain your workload status",
        "Save views with sets of workloads",
        "Get notified when the workload status changes"
      ],
      "title": "Workload status views and notifications",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "1633f322d9f0c907a9636e0c71aee7a0a38ba85b",
      "image": "https://docs.newrelic.com/static/5ea6d75d1efb047eda59eee3f12e08a9/c1b63/workloads_views.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workload-status-views-notifications/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-05-10T14:02:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The workload status, which is derived from the alerting status of the entities in your workload, informs you about how your workload is behaving. Why it matters Workload status: Is a quick indicator of how your system is doing, and tells you if you need to take action on any of your workloads in just a glance. Adapts to your needs and to how important each entity is. Allows you to share the status of your workloads. Other teams that depend on your services or infrastructure can learn the status of the workload without them needing to understand your system’s architecture details, or look at custom dashboards. Get started with workload status New Relic One provides a status value for all entities, which is based on the results of New Relic alerts. You can check the color-coded alert status for each entity on the New Relic Explorer, or consume the alert status value through the API. For example, you may see a red alert status indicating that a critical violation is in progress. With Workloads you can group entities that are part of a complex system and obtain a single, global value that summarizes the status of all the entities in your workload. Thus, you can quickly detect when the workload stops being operational, or anticipate any potential incident or loss of quality of service. Obtain your workload status A workload can have one of the following status values: Operational: The workload is working fine. Degraded: The workload is showing some degradation in performance or errors, but it’s still providing an acceptable level of service, and you don’t need to take any urgent action. Critical or Disrupted: The workload is not providing an acceptable level of service, and you need to take urgent action. Unknown: You haven’t configured how to calculate workload status, or there aren’t any alert conditions set up that can determine the status of the workload entities. To learn how to define or edit the workload status, refer to Workload status configuration. Save views with sets of workloads If you usually need to see the status of a certain group of workloads, you can save views that contain only those workloads. The tile view mode helps you quickly find your workloads and see their status at a glance. To create a view, follow these steps: Go to one.newrelic.com and click on More > Workload views. Click on Add view. Give the view a meaningful name (such as the name of a team or business unit), and select an account to associate the view with. Select the workloads you want to include in the view, by their name or tags. Save the new view. Status views are most useful for teams that are accountable for more than one workload, support roles, and business unit managers. Get notified when the workload status changes You may need to follow the status of a workload, either because it represents the services your team is accountable for, or because your own services depend on that workload, which is managed by another team. The status of all workloads is calculated regularly and the result is stored in NRDB through a WorkloadStatus event. This allows you to set up an alert condition to notify you whenever the Workload goes into a Disrupted or Degraded status. To set up the alert condition follow these steps: Go to one.newrelic.com and select Alerts & AI. Select the policy where you want to add the new alert condition, or create a new policy with the appropriate notification channel. Then click on Create a condition. Where prompted to Select a product, click NRQL. Add the following NRQL query: SELECT latest(statusValueCode) FROM WorkloadStatus WHERE workloadGuid = '<GUID>' FACET workloadGuid as 'entity.guid', entity.name Copy You can obtain the workload GUID by clicking on the See metadata and manage tags on the workload UI. Write the WHERE clause so the alert condition applies to just one workload (as in the example) or more than one. Or remove the WHERE clause if you want the alert condition to apply to all the workloads on the account. By adding the FACET you can use these fields on the alert description, as explained below. Set one of the following static thresholds: (Recommended) Critical when the query returns a value equal to 3 for at least 1 minute, if you want to be notified when the workload status is disrupted. Critical when the query returns a value equal to 2 for at least 1 minute, if you want to be notified when the workload status is degraded. Remember that a warning threshold doesn't generate an incident or send a notification. As a result, you need to create two alert conditions with a critical threshold (as explained above) if you want to be notified of any status change. Complete the alert condition: Set a violation time limit, to automatically force-close a long-lasting violation after the selected amount of time you select. Choose to fill data gaps with last known value. Optionally, you can also add a custom violation description that includes the workload name and permanent link to the UI in the alert notification: Workload: {{tag.entity.name}} Direct link: https://one.newrelic.com/redirect/entity/{{tag.entity.guid}} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.04434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workload</em> status views and notifications",
        "sections": "Save views with sets of <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " at custom dashboards. Get started with <em>workload</em> status <em>New</em> <em>Relic</em> <em>One</em> provides a status value for all entities, which is based on the results of <em>New</em> <em>Relic</em> alerts. You can check the color-coded alert status for each entity on the <em>New</em> <em>Relic</em> Explorer, or consume the alert status value through the API"
      },
      "id": "603e967564441ff8cd4e8855"
    },
    {
      "sections": [
        "Use workloads",
        "Create a workload",
        "Use tags to define the workload content",
        "How the dynamic query logic works",
        "Add dashboards to workloads",
        "Use the API"
      ],
      "title": "Use workloads",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "c39090bde9b797940e7f5ba0c9610ba39879677b",
      "image": "https://docs.newrelic.com/static/14c811e218cfc8793bb4d2bd4b2aad0b/c1b63/new-relic-workloads-add-dashboards.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/use-workloads/",
      "published_at": "2021-10-12T12:32:28Z",
      "updated_at": "2021-06-03T10:04:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view workloads, go to one.newrelic.com and find them on the Explorer. There are three main tabs (Health, Activity, and Owner) plus the header. The Health tab in a workload provides relevant status data that helps you operate the workload: It shows the global status of the workload, as well as the individual status of all the entities that make up the workload at each point in time. It looks like this: It comprises the following: The navigator view shows the entities that make up the workload, and provides controls to group and sort them. If you’ve used queries to dynamically select entities, the workload entities will change over time. The workload status informs about how your workload is performing, based on the individual alerting status of the entities in your workload. With health over time you’ll see whether and how the workload status has changed in the past three hours. If one or more entities are alerting, you’ll get a count of criticals and warnings and a summary of the open conditions, which will make it easier to identify and troubleshoot the most important issues. The Activity tab shows performance data related to the entities in the workload, along with the events that could explain any changes in those time series. It looks like this: Here's the most important sections: Linked dashboards. You can add links to dashboards from your workload, and create pre-filtered, workload-relevant links to dashboards. Golden metrics. These are charts with the most relevant metrics for each entity type, such as number of requests, response time, and error rate for an application. Explore the charts to detect correlations among different entities (for example, two applications) and different stack layers (for example, applications and hosts). The golden metrics that you see for each entity type on a workload can be customized either at the account or the workload level through the NerdGraph API. Events timeline. This includes the start and end time of incidents and anomalies that refer to the workload entities. It also shows other event types that can explain a change in the status or performance of the workload, such as deployments and configuration changes. The Owner tab gives you information about the team responsible for the workload. It looks like this: It contains: The team responsible for the workload. You can include more than one team. The workload description. Share the mission of the workload, and the business logic it represents: Is it a web application? An API? A backend process? Fill in any details that are relevant to your team, or to other teams in your organization. Contact information. From the drop-down menu, choose how your team prefers to be contacted. Links to the most relevant resources to operate the workload. Here you can add links to runbooks, code repositories, productivity tools, or anything else related to the workload that you need at hand. Finally, the header contains the filter bar and the edition controls: Filter bar. Use the advanced filtering options when you need to focus only on certain entities within the workload. Edit workload. Define the entities that are part of the workload, and the accounts they’ll be fetched from. Setup status. Configure how the global workload status will be determined, based on the workload entities health. Summary page. See all the tags that have been added to the workload, as well as metadata such as the workload's identifier (GUID) and account. Create a workload A workload should contain the entities you and your team want to see. Your choice of entities depends on your organization structure and goals. one.newrelic.com > Explorer > Workloads > Create a workload: When you create a workload, you choose the associated accounts and monitored entities. You can use New Relic One or the NerdGraph API to create a workload. Follow these steps to create a workload using the UI: Go to one.newrelic.com and click on the Explorer, and then click + Create a workload. Give the workload a name that will be meaningful for you and your team later. From the Select an account dropdown, select the workload account you'd like to use. Click Choose the scope accounts to check all of the accounts related to this workload. Find and choose the entities that make up the workload. When you have the results you're looking for, you can add specific entities or add the query to dynamically update the entities in the workload. You can search by entity type, tags, or attributes (like entity name, account ID, and AWS region). Click + Add this query to create a list of dynamically updated entities for your workload. We recommend this if you want your workload to update its entities as your system changes. Click + Add next to an entity to add it to your workload. This is a good choice if you know that the entities will stay useful even as your system changes. You can add a combination of queries and specific entities to the workload, which combine according to the query logic. Click Create a workload to save the workload. Once you've created the workload, you can edit it at any time If your workload contains one or more dashboards, you can set filters on those dashboard links. Below are more details about some aspects of how to define workloads: Use tags to define the workload content You can query and select workload entities using both tags and attributes. Therefore, to optimize your use of workloads, it helps to have a good entity-tagging strategy. We recommend reading the tagging documentation. How the dynamic query logic works You can add several individual entities and queries to define a workload. Queries can include multiple search terms. These are combined with an AND operator. Separate queries within a workload are combined with an OR operator. You can wrap strings between percent signs (%) to match exact substrings within a query. If you use substrings in entity names to categorize those entities (for example, <team>-<env>-<appName>), consider using tags complementarily, which are more powerful for filtering and grouping (for example, team:awesome, env:production). We recommend not to use percent signs (%) in dynamic queries that might return over 500 entities. This way, you get a more consistent experience in the user interface. Add dashboards to workloads If you have custom dashboards and you already know which data is relevant to your team for observing and operating their workloads, you can link those dashboards from your workload. You can also set filters on dashboards to scope them to a workload-specific context. When a user selects that dashboard from the workload, it opens with the filter already applied. one.newrelic.com > Apps > Workloads: You can add dashboards to a workload. To add dashboards to a workload: When creating or editing a workload, type Dashboard in the workload search bar to filter to dashboard entities. Add other search terms to filter to specific dashboards. Click Add. one.newrelic.com > Apps > Workloads: You can set filters on the dashboards you've linked to a workload. To filter a workload’s dashboard: From a workload’s Overview page, select a dashboard. Add search terms to filter the dashboard to a view that’s relevant for that workload. Select Save filter for this workload. Use the API You can query, create, and update workloads with our NerdGraph API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.82089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>workloads</em>",
        "sections": "<em>Use</em> <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " on your organization structure and goals. <em>one</em>.newrelic.com &gt; Explorer &gt; <em>Workloads</em> &gt; Create a <em>workload</em>: When you create a <em>workload</em>, you choose the associated accounts and monitored entities. You can <em>use</em> <em>New</em> <em>Relic</em> <em>One</em> or the NerdGraph API to create a <em>workload</em>. Follow these steps to create a <em>workload</em> using"
      },
      "id": "603e81e8196a67c972a83db1"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2021-10-12T15:16:12Z",
      "updated_at": "2021-08-21T09:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters When using our API to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " to filter the UI <em>Use</em> the filter field at the top of the <em>New</em> <em>Relic</em> Explorer to filter down to the entities you care about. You can <em>use</em> multiple filter conditions. To filter down to certain entities using tags: From <em>one</em>.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown"
      },
      "id": "603ebd1228ccbc6278eba754"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/appendix/version-history": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/project-scoping-cheatsheet/",
      "sections": [
        "Project scoping cheatsheet",
        "What is this",
        "Dates",
        "Scope",
        "Resources",
        "People",
        "Before meeting ends",
        "For more help"
      ],
      "published_at": "2021-10-17T12:53:52Z",
      "title": "Project scoping cheatsheet",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "57d5de7b1eeb1ae1800d8186e1302ff677d1e278",
      "document_type": "page",
      "popularity": 1,
      "body": "We use this cheatsheet to help us scope projects in a consistent way. What is this What's the elevator pitch for the feature? What's the user value? What are the most exciting tasks/stories we can tell for this feature? Who is the primary audience? Any docs deliverables you already have in mind? Dates What are you working on right now? When does this \"release\" (private beta, public beta, GA, etc.)? If private beta, how many customers and do they need docs? Scope Who will write first drafts? Do you need any templates? Does this need a liaison? Resources Is there a test account/is this in staging? Are there mockups or other resources? Do you have any other collateral to share? People Who is the primary reviewer (and backups)? Who is product manager? Who is lead dev? Who is the designer? Who is program manager? Who is the researcher? Are we doing any user research? Who is the PMM? Who is the support point person? Before meeting ends Who is writing? When is it due? Do we need tickets? Who is following up with who? ← Appendix: Ticket best practices Appendix: Backlog review → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.98337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " is the support point person? Before meeting ends Who is writing? When is it due? Do we need tickets? Who is following up with who? ← <em>Appendix</em>: Ticket best practices <em>Appendix</em>: Backlog review → For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dfa28ccbc90b0002530"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.11214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2021-10-13T05:59:05Z",
      "updated_at": "2021-09-14T13:44:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing plan or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing plan. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing plan or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing plan can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.46933,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Our <em>Partnership</em> API allows <em>New</em> <em>Relic</em> partners, and <em>New</em> <em>Relic</em> accounts set up as customer <em>partnerships</em>, to manage accounts, users, and subscription-related settings. Requirements The <em>Partnership</em> API can be used by two types of <em>New</em> <em>Relic</em> accounts: partners (managed service providers, resellers"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/co-branding-new-relic-partners": [
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.10187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.71179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    },
    {
      "sections": [
        "Partner integration requirements",
        "Process",
        "Accelerated process",
        "Typical component tasks"
      ],
      "title": "Partner integration requirements",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "5df8f0dc281afba95823d8896a55ceec56cd4a8a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partner-integration-requirements/",
      "published_at": "2021-10-12T15:04:25Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Thank you for your interest in partnering with New Relic. We look forward to providing your customers with powerful, easy-to-use application performance monitoring. This guide explains how to bundle New Relic services with yours. An effective bundling includes technical tasks (such as agent provisioning and console integration) as well as marketing and promotional activities (such as branding and awareness generation). Process To achieve a full and productive integration with New Relic you will need to: What How Integrate your user console with New Relic. Update your user portal to automatically create New Relic accounts and make them available to your customers in a convenient, compelling, co-branded way. Provision the New Relic agent. For your customers to benefit from New Relic, they will need our monitoring agent installed into their apps. Update your provisioning systems to install New Relic automatically. Generate awareness. Integrate and deploy New Relic facilities for displaying sample application reporting data to customers. Establish support and sustaining engineering processes. Agree on a process for support coordination and refresh of New Relic software. Set up communication. Tip: We've found that partners typically complete integration with one to two developer weeks of effort. For more information, see Typical component tasks. Accelerated process Where circumstances and/or proximity permit, we have found that bringing your developers on site to New Relic's San Francisco offices can dramatically accelerate development of your integration. At New Relic's offices your developers will work in close proximity to the engineering team that is responsible for the development and maintenance of New Relic's APIs. Development issues that would under other circumstances require hours or days to resolve can be addressed in minutes. Typically development time for an integration can be cut in half. Should you elect to pursue this option, please talk to your New Relic technical contact. Typical component tasks The checklist for creating a successful integration will vary with each partner and specific circumstances. As a general guide, here's a typical outline of the components and rough sequencing of tasks involved in creating an integration with New Relic. Done Component tasks of a typical partner integration Finalize business relationship. Have introductory conference call or meeting for technical team. Review partner integration documentation and other integration materials. Review roles and responsibilities. Develop integration plan with timeline. Plan account and agent provisioning. Create and deploy account provisioning system. Determine which agents and how to provision. Create and deploy webpages to support provisioning and deployment. Set up test partnership and accounts on New Relic's staging server. Plan for co-branding. Create and deploy CSS. Create and deploy header and footer. Create branded URL (cname). Drive adoption through creating awareness. Add the New Relic widget to the user console. Use data API integration. Test integration on staging. Set up partnership on New Relic's production server. Modify integration to point to production server. Test integration on production. Establish a support plan. Designate support contacts. Introduce New Relic Support to your technical support team. Create sustaining engineering plans. Get test account. Prepare for launch. Walk through integration review and signoff (conference call). Document final signup flow. Coordinate on launch co-marketing and PR. Go live!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.4426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>integration</em> requirements",
        "sections": "<em>Partner</em> <em>integration</em> requirements",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " will vary with each <em>partner</em> and specific circumstances. As a general <em>guide</em>, here&#x27;s a typical outline of the components and rough sequencing of tasks involved in creating an <em>integration</em> with <em>New</em> <em>Relic</em>. Done Component tasks of a typical <em>partner</em> <em>integration</em> Finalize business relationship. Have"
      },
      "id": "603ed3e728ccbcba09eba7b7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/partner-integration-requirements": [
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.10187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.71179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    },
    {
      "sections": [
        "Co-branding for New Relic partners",
        "Co-branding example",
        "Headers and footers",
        "Tip",
        "Layouts and styles",
        "Sub-domains"
      ],
      "title": "Co-branding for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "62a555ec5ade26eda9c5f40b96ab25873c89da1a",
      "image": "https://docs.newrelic.com/static/9bc57293646e4fe206ffe0a20ce06406/3996e/screen-co-branding-heroku.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/co-branding-new-relic-partners/",
      "published_at": "2021-10-13T07:34:20Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who bundle New Relic into their console can \"skin\" New Relic with their own look and feel, including customized layouts, menus, and sub-domains. Co-branding example This example is from Heroku's New Relic integration. In this case Heroku has chosen to use a header only. New Relic partner co-branding example: Here is an example of co-branding with New Relic by using a header. Headers and footers To implement headers and footers: Create a header and/or footer page, consisting of content enclosed in < div> tags. Make sure the pages do not import any CSS or contain any inline CSS. Take any CSS needed for the header and footer, and make it available in a separate CSS file. For example, prepend a custom string such as yourcompany_ to the various style names, to avoid overriding New Relic's standard style definitions. Post the three files to publicly accessible locations hosted by the partner. Use https so your customers do not see any mixed content warnings. For example: https://yourcompany.com/newrelic_header.htm https://yourcompany.com/newrelic_footer.htm https://yourcompany.com/newrelic_styles.css Copy Enter the URLs for the header, footer, and CSS page locations into the appropriate fields in the New Relic Partnership console. Tip To view the headers, log in to one of the accounts in the partnership. Layouts and styles Header and footer layouts and styles are loaded and cached on New Relic's collector servers for insertion into each page output. Updates made to the layout on the partner's site are automatically refreshed hourly. Customized links to the partner's website may be added to the layout. If single sign-on is enabled, the partner may inject customer-specific information into the New Relic user session for use by the layout. For more information, see Single sign on and access control. Sub-domains Partners can optionally display a custom subdomain; for example, yourcompany.newrelic.com, to customers accessing New Relic accounts. To arrange this, contact New Relic's Business Enablement team.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.4426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Co-branding for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Co-branding for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Partners who bundle <em>New</em> <em>Relic</em> into their console can &quot;skin&quot; <em>New</em> <em>Relic</em> with their own look and feel, including customized layouts, menus, and sub-domains. Co-branding example This example is from Heroku&#x27;s <em>New</em> <em>Relic</em> <em>integration</em>. In this case Heroku has chosen to use a header only. <em>New</em> <em>Relic</em> <em>partner</em>"
      },
      "id": "603ec8b428ccbc9be1eba7a8"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/partners-contact-new-relic": [
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.10185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.71179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    },
    {
      "sections": [
        "Partner integration requirements",
        "Process",
        "Accelerated process",
        "Typical component tasks"
      ],
      "title": "Partner integration requirements",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "5df8f0dc281afba95823d8896a55ceec56cd4a8a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partner-integration-requirements/",
      "published_at": "2021-10-12T15:04:25Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Thank you for your interest in partnering with New Relic. We look forward to providing your customers with powerful, easy-to-use application performance monitoring. This guide explains how to bundle New Relic services with yours. An effective bundling includes technical tasks (such as agent provisioning and console integration) as well as marketing and promotional activities (such as branding and awareness generation). Process To achieve a full and productive integration with New Relic you will need to: What How Integrate your user console with New Relic. Update your user portal to automatically create New Relic accounts and make them available to your customers in a convenient, compelling, co-branded way. Provision the New Relic agent. For your customers to benefit from New Relic, they will need our monitoring agent installed into their apps. Update your provisioning systems to install New Relic automatically. Generate awareness. Integrate and deploy New Relic facilities for displaying sample application reporting data to customers. Establish support and sustaining engineering processes. Agree on a process for support coordination and refresh of New Relic software. Set up communication. Tip: We've found that partners typically complete integration with one to two developer weeks of effort. For more information, see Typical component tasks. Accelerated process Where circumstances and/or proximity permit, we have found that bringing your developers on site to New Relic's San Francisco offices can dramatically accelerate development of your integration. At New Relic's offices your developers will work in close proximity to the engineering team that is responsible for the development and maintenance of New Relic's APIs. Development issues that would under other circumstances require hours or days to resolve can be addressed in minutes. Typically development time for an integration can be cut in half. Should you elect to pursue this option, please talk to your New Relic technical contact. Typical component tasks The checklist for creating a successful integration will vary with each partner and specific circumstances. As a general guide, here's a typical outline of the components and rough sequencing of tasks involved in creating an integration with New Relic. Done Component tasks of a typical partner integration Finalize business relationship. Have introductory conference call or meeting for technical team. Review partner integration documentation and other integration materials. Review roles and responsibilities. Develop integration plan with timeline. Plan account and agent provisioning. Create and deploy account provisioning system. Determine which agents and how to provision. Create and deploy webpages to support provisioning and deployment. Set up test partnership and accounts on New Relic's staging server. Plan for co-branding. Create and deploy CSS. Create and deploy header and footer. Create branded URL (cname). Drive adoption through creating awareness. Add the New Relic widget to the user console. Use data API integration. Test integration on staging. Set up partnership on New Relic's production server. Modify integration to point to production server. Test integration on production. Establish a support plan. Designate support contacts. Introduce New Relic Support to your technical support team. Create sustaining engineering plans. Get test account. Prepare for launch. Walk through integration review and signoff (conference call). Document final signup flow. Coordinate on launch co-marketing and PR. Go live!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.4426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>integration</em> requirements",
        "sections": "<em>Partner</em> <em>integration</em> requirements",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " will vary with each <em>partner</em> and specific circumstances. As a general <em>guide</em>, here&#x27;s a typical outline of the components and rough sequencing of tasks involved in creating an <em>integration</em> with <em>New</em> <em>Relic</em>. Done Component tasks of a typical <em>partner</em> <em>integration</em> Finalize business relationship. Have"
      },
      "id": "603ed3e728ccbcba09eba7b7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console": [
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.10185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partner integration requirements",
        "Process",
        "Accelerated process",
        "Typical component tasks"
      ],
      "title": "Partner integration requirements",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "5df8f0dc281afba95823d8896a55ceec56cd4a8a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partner-integration-requirements/",
      "published_at": "2021-10-12T15:04:25Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Thank you for your interest in partnering with New Relic. We look forward to providing your customers with powerful, easy-to-use application performance monitoring. This guide explains how to bundle New Relic services with yours. An effective bundling includes technical tasks (such as agent provisioning and console integration) as well as marketing and promotional activities (such as branding and awareness generation). Process To achieve a full and productive integration with New Relic you will need to: What How Integrate your user console with New Relic. Update your user portal to automatically create New Relic accounts and make them available to your customers in a convenient, compelling, co-branded way. Provision the New Relic agent. For your customers to benefit from New Relic, they will need our monitoring agent installed into their apps. Update your provisioning systems to install New Relic automatically. Generate awareness. Integrate and deploy New Relic facilities for displaying sample application reporting data to customers. Establish support and sustaining engineering processes. Agree on a process for support coordination and refresh of New Relic software. Set up communication. Tip: We've found that partners typically complete integration with one to two developer weeks of effort. For more information, see Typical component tasks. Accelerated process Where circumstances and/or proximity permit, we have found that bringing your developers on site to New Relic's San Francisco offices can dramatically accelerate development of your integration. At New Relic's offices your developers will work in close proximity to the engineering team that is responsible for the development and maintenance of New Relic's APIs. Development issues that would under other circumstances require hours or days to resolve can be addressed in minutes. Typically development time for an integration can be cut in half. Should you elect to pursue this option, please talk to your New Relic technical contact. Typical component tasks The checklist for creating a successful integration will vary with each partner and specific circumstances. As a general guide, here's a typical outline of the components and rough sequencing of tasks involved in creating an integration with New Relic. Done Component tasks of a typical partner integration Finalize business relationship. Have introductory conference call or meeting for technical team. Review partner integration documentation and other integration materials. Review roles and responsibilities. Develop integration plan with timeline. Plan account and agent provisioning. Create and deploy account provisioning system. Determine which agents and how to provision. Create and deploy webpages to support provisioning and deployment. Set up test partnership and accounts on New Relic's staging server. Plan for co-branding. Create and deploy CSS. Create and deploy header and footer. Create branded URL (cname). Drive adoption through creating awareness. Add the New Relic widget to the user console. Use data API integration. Test integration on staging. Set up partnership on New Relic's production server. Modify integration to point to production server. Test integration on production. Establish a support plan. Designate support contacts. Introduce New Relic Support to your technical support team. Create sustaining engineering plans. Get test account. Prepare for launch. Walk through integration review and signoff (conference call). Document final signup flow. Coordinate on launch co-marketing and PR. Go live!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.4426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>integration</em> requirements",
        "sections": "<em>Partner</em> <em>integration</em> requirements",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " will vary with each <em>partner</em> and specific circumstances. As a general <em>guide</em>, here&#x27;s a typical outline of the components and rough sequencing of tasks involved in creating an <em>integration</em> with <em>New</em> <em>Relic</em>. Done Component tasks of a typical <em>partner</em> <em>integration</em> Finalize business relationship. Have"
      },
      "id": "603ed3e728ccbcba09eba7b7"
    },
    {
      "sections": [
        "Co-branding for New Relic partners",
        "Co-branding example",
        "Headers and footers",
        "Tip",
        "Layouts and styles",
        "Sub-domains"
      ],
      "title": "Co-branding for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "62a555ec5ade26eda9c5f40b96ab25873c89da1a",
      "image": "https://docs.newrelic.com/static/9bc57293646e4fe206ffe0a20ce06406/3996e/screen-co-branding-heroku.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/co-branding-new-relic-partners/",
      "published_at": "2021-10-13T07:34:20Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who bundle New Relic into their console can \"skin\" New Relic with their own look and feel, including customized layouts, menus, and sub-domains. Co-branding example This example is from Heroku's New Relic integration. In this case Heroku has chosen to use a header only. New Relic partner co-branding example: Here is an example of co-branding with New Relic by using a header. Headers and footers To implement headers and footers: Create a header and/or footer page, consisting of content enclosed in < div> tags. Make sure the pages do not import any CSS or contain any inline CSS. Take any CSS needed for the header and footer, and make it available in a separate CSS file. For example, prepend a custom string such as yourcompany_ to the various style names, to avoid overriding New Relic's standard style definitions. Post the three files to publicly accessible locations hosted by the partner. Use https so your customers do not see any mixed content warnings. For example: https://yourcompany.com/newrelic_header.htm https://yourcompany.com/newrelic_footer.htm https://yourcompany.com/newrelic_styles.css Copy Enter the URLs for the header, footer, and CSS page locations into the appropriate fields in the New Relic Partnership console. Tip To view the headers, log in to one of the accounts in the partnership. Layouts and styles Header and footer layouts and styles are loaded and cached on New Relic's collector servers for insertion into each page output. Updates made to the layout on the partner's site are automatically refreshed hourly. Customized links to the partner's website may be added to the layout. If single sign-on is enabled, the partner may inject customer-specific information into the New Relic user session for use by the layout. For more information, see Single sign on and access control. Sub-domains Partners can optionally display a custom subdomain; for example, yourcompany.newrelic.com, to customers accessing New Relic accounts. To arrange this, contact New Relic's Business Enablement team.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.4426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Co-branding for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Co-branding for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Partners who bundle <em>New</em> <em>Relic</em> into their console can &quot;skin&quot; <em>New</em> <em>Relic</em> with their own look and feel, including customized layouts, menus, and sub-domains. Co-branding example This example is from Heroku&#x27;s <em>New</em> <em>Relic</em> <em>integration</em>. In this case Heroku has chosen to use a header only. <em>New</em> <em>Relic</em> <em>partner</em>"
      },
      "id": "603ec8b428ccbc9be1eba7a8"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners": [
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.71179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    },
    {
      "sections": [
        "Partner integration requirements",
        "Process",
        "Accelerated process",
        "Typical component tasks"
      ],
      "title": "Partner integration requirements",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "5df8f0dc281afba95823d8896a55ceec56cd4a8a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partner-integration-requirements/",
      "published_at": "2021-10-12T15:04:25Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Thank you for your interest in partnering with New Relic. We look forward to providing your customers with powerful, easy-to-use application performance monitoring. This guide explains how to bundle New Relic services with yours. An effective bundling includes technical tasks (such as agent provisioning and console integration) as well as marketing and promotional activities (such as branding and awareness generation). Process To achieve a full and productive integration with New Relic you will need to: What How Integrate your user console with New Relic. Update your user portal to automatically create New Relic accounts and make them available to your customers in a convenient, compelling, co-branded way. Provision the New Relic agent. For your customers to benefit from New Relic, they will need our monitoring agent installed into their apps. Update your provisioning systems to install New Relic automatically. Generate awareness. Integrate and deploy New Relic facilities for displaying sample application reporting data to customers. Establish support and sustaining engineering processes. Agree on a process for support coordination and refresh of New Relic software. Set up communication. Tip: We've found that partners typically complete integration with one to two developer weeks of effort. For more information, see Typical component tasks. Accelerated process Where circumstances and/or proximity permit, we have found that bringing your developers on site to New Relic's San Francisco offices can dramatically accelerate development of your integration. At New Relic's offices your developers will work in close proximity to the engineering team that is responsible for the development and maintenance of New Relic's APIs. Development issues that would under other circumstances require hours or days to resolve can be addressed in minutes. Typically development time for an integration can be cut in half. Should you elect to pursue this option, please talk to your New Relic technical contact. Typical component tasks The checklist for creating a successful integration will vary with each partner and specific circumstances. As a general guide, here's a typical outline of the components and rough sequencing of tasks involved in creating an integration with New Relic. Done Component tasks of a typical partner integration Finalize business relationship. Have introductory conference call or meeting for technical team. Review partner integration documentation and other integration materials. Review roles and responsibilities. Develop integration plan with timeline. Plan account and agent provisioning. Create and deploy account provisioning system. Determine which agents and how to provision. Create and deploy webpages to support provisioning and deployment. Set up test partnership and accounts on New Relic's staging server. Plan for co-branding. Create and deploy CSS. Create and deploy header and footer. Create branded URL (cname). Drive adoption through creating awareness. Add the New Relic widget to the user console. Use data API integration. Test integration on staging. Set up partnership on New Relic's production server. Modify integration to point to production server. Test integration on production. Establish a support plan. Designate support contacts. Introduce New Relic Support to your technical support team. Create sustaining engineering plans. Get test account. Prepare for launch. Walk through integration review and signoff (conference call). Document final signup flow. Coordinate on launch co-marketing and PR. Go live!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.4426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>integration</em> requirements",
        "sections": "<em>Partner</em> <em>integration</em> requirements",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " will vary with each <em>partner</em> and specific circumstances. As a general <em>guide</em>, here&#x27;s a typical outline of the components and rough sequencing of tasks involved in creating an <em>integration</em> with <em>New</em> <em>Relic</em>. Done Component tasks of a typical <em>partner</em> <em>integration</em> Finalize business relationship. Have"
      },
      "id": "603ed3e728ccbcba09eba7b7"
    },
    {
      "sections": [
        "Co-branding for New Relic partners",
        "Co-branding example",
        "Headers and footers",
        "Tip",
        "Layouts and styles",
        "Sub-domains"
      ],
      "title": "Co-branding for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "62a555ec5ade26eda9c5f40b96ab25873c89da1a",
      "image": "https://docs.newrelic.com/static/9bc57293646e4fe206ffe0a20ce06406/3996e/screen-co-branding-heroku.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/co-branding-new-relic-partners/",
      "published_at": "2021-10-13T07:34:20Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who bundle New Relic into their console can \"skin\" New Relic with their own look and feel, including customized layouts, menus, and sub-domains. Co-branding example This example is from Heroku's New Relic integration. In this case Heroku has chosen to use a header only. New Relic partner co-branding example: Here is an example of co-branding with New Relic by using a header. Headers and footers To implement headers and footers: Create a header and/or footer page, consisting of content enclosed in < div> tags. Make sure the pages do not import any CSS or contain any inline CSS. Take any CSS needed for the header and footer, and make it available in a separate CSS file. For example, prepend a custom string such as yourcompany_ to the various style names, to avoid overriding New Relic's standard style definitions. Post the three files to publicly accessible locations hosted by the partner. Use https so your customers do not see any mixed content warnings. For example: https://yourcompany.com/newrelic_header.htm https://yourcompany.com/newrelic_footer.htm https://yourcompany.com/newrelic_styles.css Copy Enter the URLs for the header, footer, and CSS page locations into the appropriate fields in the New Relic Partnership console. Tip To view the headers, log in to one of the accounts in the partnership. Layouts and styles Header and footer layouts and styles are loaded and cached on New Relic's collector servers for insertion into each page output. Updates made to the layout on the partner's site are automatically refreshed hourly. Customized links to the partner's website may be added to the layout. If single sign-on is enabled, the partner may inject customer-specific information into the New Relic user session for use by the layout. For more information, see Single sign on and access control. Sub-domains Partners can optionally display a custom subdomain; for example, yourcompany.newrelic.com, to customers accessing New Relic accounts. To arrange this, contact New Relic's Business Enablement team.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.4426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Co-branding for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Co-branding for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Partners who bundle <em>New</em> <em>Relic</em> into their console can &quot;skin&quot; <em>New</em> <em>Relic</em> with their own look and feel, including customized layouts, menus, and sub-domains. Co-branding example This example is from Heroku&#x27;s <em>New</em> <em>Relic</em> <em>integration</em>. In this case Heroku has chosen to use a header only. <em>New</em> <em>Relic</em> <em>partner</em>"
      },
      "id": "603ec8b428ccbc9be1eba7a8"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/walkthrough-signoff": [
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.10184,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.71179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    },
    {
      "sections": [
        "Partner integration requirements",
        "Process",
        "Accelerated process",
        "Typical component tasks"
      ],
      "title": "Partner integration requirements",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "5df8f0dc281afba95823d8896a55ceec56cd4a8a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partner-integration-requirements/",
      "published_at": "2021-10-12T15:04:25Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Thank you for your interest in partnering with New Relic. We look forward to providing your customers with powerful, easy-to-use application performance monitoring. This guide explains how to bundle New Relic services with yours. An effective bundling includes technical tasks (such as agent provisioning and console integration) as well as marketing and promotional activities (such as branding and awareness generation). Process To achieve a full and productive integration with New Relic you will need to: What How Integrate your user console with New Relic. Update your user portal to automatically create New Relic accounts and make them available to your customers in a convenient, compelling, co-branded way. Provision the New Relic agent. For your customers to benefit from New Relic, they will need our monitoring agent installed into their apps. Update your provisioning systems to install New Relic automatically. Generate awareness. Integrate and deploy New Relic facilities for displaying sample application reporting data to customers. Establish support and sustaining engineering processes. Agree on a process for support coordination and refresh of New Relic software. Set up communication. Tip: We've found that partners typically complete integration with one to two developer weeks of effort. For more information, see Typical component tasks. Accelerated process Where circumstances and/or proximity permit, we have found that bringing your developers on site to New Relic's San Francisco offices can dramatically accelerate development of your integration. At New Relic's offices your developers will work in close proximity to the engineering team that is responsible for the development and maintenance of New Relic's APIs. Development issues that would under other circumstances require hours or days to resolve can be addressed in minutes. Typically development time for an integration can be cut in half. Should you elect to pursue this option, please talk to your New Relic technical contact. Typical component tasks The checklist for creating a successful integration will vary with each partner and specific circumstances. As a general guide, here's a typical outline of the components and rough sequencing of tasks involved in creating an integration with New Relic. Done Component tasks of a typical partner integration Finalize business relationship. Have introductory conference call or meeting for technical team. Review partner integration documentation and other integration materials. Review roles and responsibilities. Develop integration plan with timeline. Plan account and agent provisioning. Create and deploy account provisioning system. Determine which agents and how to provision. Create and deploy webpages to support provisioning and deployment. Set up test partnership and accounts on New Relic's staging server. Plan for co-branding. Create and deploy CSS. Create and deploy header and footer. Create branded URL (cname). Drive adoption through creating awareness. Add the New Relic widget to the user console. Use data API integration. Test integration on staging. Set up partnership on New Relic's production server. Modify integration to point to production server. Test integration on production. Establish a support plan. Designate support contacts. Introduce New Relic Support to your technical support team. Create sustaining engineering plans. Get test account. Prepare for launch. Walk through integration review and signoff (conference call). Document final signup flow. Coordinate on launch co-marketing and PR. Go live!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.4426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>integration</em> requirements",
        "sections": "<em>Partner</em> <em>integration</em> requirements",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " will vary with each <em>partner</em> and specific circumstances. As a general <em>guide</em>, here&#x27;s a typical outline of the components and rough sequencing of tasks involved in creating an <em>integration</em> with <em>New</em> <em>Relic</em>. Done Component tasks of a typical <em>partner</em> <em>integration</em> Finalize business relationship. Have"
      },
      "id": "603ed3e728ccbcba09eba7b7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/other-partnership-settings": [
    {
      "sections": [
        "Partner products, pricing, and billing",
        "Important",
        "Commitment levels",
        "Customized partnership pricing",
        "Partnership billing options",
        "Cancellations",
        "Promotions",
        "Legacy products and commitment levels",
        "For more help"
      ],
      "title": "Partner products, pricing, and billing",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "05d2d31e3eb7c18d7d0b13eac2d3fead6fd58bbf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/partner-products-pricing-billing/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-05-16T01:10:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This information is for New Relic partners. If you are not a New Relic partner, refer to the information about pricing and billing for New Relic accounts. Partners: For account setup procedures, see New Relic's Partner API documentation. For specific product pricing details (such as New Relic APM), visit New Relic's website, or contact your Alliance & Channels representative at New Relic. Commitment levels When customers choose a product, they also choose a monthly or annual commitment level. Existing partnerships have the option of limiting available product offerings for their customers. Reseller partners may be able to modify these subscription terms based on the contractual terms in the partner agreement with New Relic. Customized partnership pricing Partnership accounts may offer customized pricing. Customized pricing models, rates, minimums, discounts, and options vary by partnership--the actual pricing model used is subject to the contractual terms of the partner's agreement with New Relic. Contact your Alliance & Channels representative at New Relic to learn more. Partnership billing options New Relic supports the following billing options for partnerships. All subscriptions commence and expire at midnight GMT. For host-based subscriptions, fees are charged in advance for the month. Upgrade requests are honored immediately without any billing for partial use during the month. Downgrades take effect at the next payment date. To view New Relic account billing details and history from the user interface: From one.newrelic.com, select (account dropdown) > Account settings > Account > Billing. Billing option Description Credit card When partners choose credit card billing, your customers are directly charged using the credit card information provided during their New Relic subscription signup. This does not include any license fees paid directly by the partner for their customers' accounts. Invoice When partners choose invoice billing, your customers are billed directly by New Relic via invoice for their subscriptions. This option is normally provided on special request to customers with large monthly costs for which credit card billing would be impractical. Reseller For resellers, partners are billed directly for all customer accounts based on the calendar month. Partners may be responsible for accounting for customer usage, pricing, and subscriptions. Resellers have the option to implement an integration between our respective accounting systems. New Relic will invoice the partner monthly, using the Billing integration API for each of the paying accounts under the partnership. Cancellations Once a New Relic account cancellation takes effect, you must uninstall and/or delete all agents or other data-reporting integrations. For uninstallation details, see the documentation for the relevant agents and integrations. Customers may continue to access their data on New Relic until it is purged in accordance with the data retention policy corresponding to the product level. For existing accounts with paid, fixed host subscriptions, cancellations take effect at the next payment date. New Relic will continue to accept data for cancelled accounts until this date. Cancellations for accounts with free or paid based subscriptions take effect immediately. Promotions New Relic allows promotions for accounts offered through partnerships. Promotions associated with a specific partnership may only be redeemed on accounts associated with the partnership. Each promotion has a unique code. This promotion code may be applied only once per account. New Relic may impose further limits on the number of promotions that a customer may apply to an account. Promotion Description Free trials New Relic may include a free trial period for features normally available only through a paid subscription level. This option is provided for a specified number of days. The customer's subscription automatically reverts to its prior level at the conclusion of the trial. Payments for paid subscriptions are not interrupted by the redemption of a free trial promotion on the account. Single use Single use trials expire after they are used once. Discount (deprecated) A one-time percentage discount is applied to a paid subscription. This discount is applied in addition to any volume discounts and customized partner prices. The discount remains in effect until the subscription is modified or cancelled. Legacy products and commitment levels If you have questions about older New Relic products that have been converted to new pricing models, contact your Alliance & Channels representative at New Relic. For more help Additional documentation resources include: Partnership API account object (the primary JSON container object in the API) Partnership API user object (defined as an array within the account object) Partnership API subscription object (the level of service a customer purchases for one or more New Relic products) Billing integration API (functions to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.97751,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>products</em>, pricing, and billing",
        "sections": "<em>Partner</em> <em>products</em>, pricing, and billing",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": " API user object (defined as an array within the account object) <em>Partnership</em> API subscription object (the level of service a customer purchases for one or more <em>New</em> <em>Relic</em> <em>products</em>) Billing <em>integration</em> API (functions to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts)"
      },
      "id": "603ece55e7b9d254192a080c"
    },
    {
      "sections": [
        "Partnership accounts: Single sign on and access control",
        "Implement Single Sign On",
        "Use shared secret method",
        "SSO API",
        "Description",
        "Method",
        "URI",
        "Parameters",
        "**cURL examples**",
        "For more help"
      ],
      "title": "Partnership accounts: Single sign on and access control",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "7054f72ececf6692e3abdcc1573276559be841ca",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/single-sign-access-control/",
      "published_at": "2021-10-13T07:38:10Z",
      "updated_at": "2021-03-13T02:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic supports Single Sign On (SSO) as a convenience for partner customers. Partners implementing SSO also have the option to restrict access by requiring customers to access New Relic via the partner's management site or product login. Single Sign On is a convenience for your customers, eliminating the requirement of entering sign on credentials multiple times, and it creates a more unified experience for the user. In situations where this distinction is desired, SSO is recommended. Where it is desirable to maintain a distinction between the services or where technical considerations preclude implementing SSO, a fully functioning integration is still achievable. Implement Single Sign On Two methods for SSO are supported by New Relic. New Relic upgraded its single sign on system during 2011. If you implemented single sign on with New Relic prior to September 2011, you will have used the old system. That method of implementing SSO has been deprecated. All new integrations must use the new system. Existing implementations using the old system will continue to work indefinitely. However, we encourage all partners using the old system to upgrade to the new model. Use shared secret method The upgraded shared secret version of New Relic's SSO implementation offers several improvements over the old handshake version. Most important, the system is more secure. Security is enhanced by the use of passing a SHA1 digest of a shared secret, a timestamp, and request specific data in the authentication SSO request. The shared secret can be any string. Whatever shared secret is chosen, enter it in the appropriate field in the New Relic Partner console. To edit the SSO settings: Log in to the partnership owner account. From the account dropdown in the New Relic UI, select Account settings > Partnerships > Edit settings. For SSO type, select signature. For SSO data, type the shared secret. Select Save. In addition to enhanced security, the new SSO method supports a session cookie. Nav data may be stored in the session cookie to support enhanced functionality of headers and footers. The name of the cookie is specified through the Partner console. If unspecified the cookie name defaults to nav_data. To successfully use this SSO method, the SSO URI must be invoked from the user's browser. On success the browser will be automatically logged into New Relic and the redirect URL to that account returned. The SSO URI however should not be generated on the browser, as this would expose the shared secret and allow the login to be spoofed. The URI should be generated on a host and passed to the user's browser. SSO API Description SSO authentication request Method POST or GET URI https://rpm.newrelic.com/accounts/sso_access Copy Parameters Name Required Description id Yes ID of the New Relic account. email No Email address of user logging in (optional). If given, the user must already have been added to the account. By default, the account Owner role is used. Account Owners have full privileges on accounts. If some lesser degree of account privileges or a different user is desired, the email must be provided. timestamp Yes Timestamp used to generate token, in seconds since the epoch. Only timestamps within five minutes (300 seconds) of the New Relic system clock are accepted. nav-data OR nav_data No Partner navigation data. This data will be set in the session cookie using the name as specified in the partnership configuration, or nav_data by default. token Yes Signed token. The signature token is generated by applying a SHA1 hex digest on a seed string, which is composed as Account_id:secret:timestamp or Account_id:secret:timestamp:email. Each component is separated by a colon (:). Example without email: \"12345:MySecret:0987654321\" Using Ruby syntax: \"#{account_id}:#{secret}:#{timestamp}\" Example with email: \"12345:MySecret:0987654321:user@host.com\" Using Ruby syntax: \"#{account_id}:#{secret}:#{timestamp}:#{email}\" remote_url No Relative path of a New Relic page to which the users will be directed. ** cURL examples * * curl -X POST -d \"id=63790\" -d \"timestamp=1319659982\" -d \"token=a4d30d6f1f1a5b6c2872ab\" https://rpm.newrelic.com/accounts/sso_access Copy curl -X POST -d \"id=63790\" -d \"timestamp=1319659982\" -d \"token=a4d30d6f1f1a5b6c2872ab\" -d \"remote_url=/account/63790/servers\" https://rpm.newrelic.com/accounts/sso_access Copy On success returns: <html><body>You are being redirected.</body></html> Copy For more help Additional documentation resources include: SAML service providers (overview of New Relic's SSO feature, providers supported by New Relic) New Relic Partners and SAML SSO (additional options for partner accounts)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.51895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> accounts: Single sign on and access control",
        "sections": "<em>Partnership</em> accounts: Single sign on and access control",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": "<em>New</em> <em>Relic</em> supports Single Sign On (SSO) as a convenience for <em>partner</em> customers. Partners implementing SSO also have the option to restrict access by requiring customers to access <em>New</em> <em>Relic</em> via the <em>partner</em>&#x27;s management site or <em>product</em> login. Single Sign On is a convenience for your customers"
      },
      "id": "6044175564441fd3fa378f1f"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.82603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>New</em> <em>Relic</em> <em>products</em> and <em>features</em> by category. Tip The docs site includes a <em>Partnerships</em> category with information for <em>New</em> <em>Relic</em> partners and some <em>partnership</em> customers. Here are the five most commonly consulted articles on the <em>New</em> <em>Relic</em> docs site. Providing easily found and direct links"
      },
      "id": "60450ecf28ccbc45632c6095"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/partner-products-pricing-billing": [
    {
      "sections": [
        "Other partnership settings",
        "Types of settings",
        "For more help"
      ],
      "title": "Other partnership settings",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "df23328a14acab54c7f100c723f6feee68927c6b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/other-partnership-settings/",
      "published_at": "2021-10-13T07:36:53Z",
      "updated_at": "2021-03-16T10:07:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are a number of miscellaneous settings that are available to partners for customization of their partnership integration. Most of these settings enable or disable the presentation of New Relic features. These settings must be set by New Relic and are not configurable through the Partnership Console. Types of settings Contact your partnership technical contact to have any of these settings modified. Download links: Show agent link Show configuration file link Welcome messages: Signup message: A customized welcome message Hide or show banner welcome message Hide or show invoice message Email control: Send deploy reminders Send trial emails Billing email: This is for partnerships where the billing method is \"Reseller\" and invoices should be directed to the attention of a specific party. Feature access: Server monitoring User administration For more help Additional documentation resources include: Partnership console (overview of how to use the Partnership Console to change account settings in New Relic) The New Relic user interface (overview of how to use the UI)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.6492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Other <em>partnership</em> settings",
        "sections": "Other <em>partnership</em> settings",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": "There are a number of miscellaneous settings that are available to partners for customization of their <em>partnership</em> <em>integration</em>. Most of these settings enable or disable the presentation of <em>New</em> <em>Relic</em> <em>features</em>. These settings must be set by <em>New</em> <em>Relic</em> and are not configurable through the <em>Partnership</em>"
      },
      "id": "603ed42364441fb51f4e88a9"
    },
    {
      "sections": [
        "Partnership accounts: Single sign on and access control",
        "Implement Single Sign On",
        "Use shared secret method",
        "SSO API",
        "Description",
        "Method",
        "URI",
        "Parameters",
        "**cURL examples**",
        "For more help"
      ],
      "title": "Partnership accounts: Single sign on and access control",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "7054f72ececf6692e3abdcc1573276559be841ca",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/single-sign-access-control/",
      "published_at": "2021-10-13T07:38:10Z",
      "updated_at": "2021-03-13T02:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic supports Single Sign On (SSO) as a convenience for partner customers. Partners implementing SSO also have the option to restrict access by requiring customers to access New Relic via the partner's management site or product login. Single Sign On is a convenience for your customers, eliminating the requirement of entering sign on credentials multiple times, and it creates a more unified experience for the user. In situations where this distinction is desired, SSO is recommended. Where it is desirable to maintain a distinction between the services or where technical considerations preclude implementing SSO, a fully functioning integration is still achievable. Implement Single Sign On Two methods for SSO are supported by New Relic. New Relic upgraded its single sign on system during 2011. If you implemented single sign on with New Relic prior to September 2011, you will have used the old system. That method of implementing SSO has been deprecated. All new integrations must use the new system. Existing implementations using the old system will continue to work indefinitely. However, we encourage all partners using the old system to upgrade to the new model. Use shared secret method The upgraded shared secret version of New Relic's SSO implementation offers several improvements over the old handshake version. Most important, the system is more secure. Security is enhanced by the use of passing a SHA1 digest of a shared secret, a timestamp, and request specific data in the authentication SSO request. The shared secret can be any string. Whatever shared secret is chosen, enter it in the appropriate field in the New Relic Partner console. To edit the SSO settings: Log in to the partnership owner account. From the account dropdown in the New Relic UI, select Account settings > Partnerships > Edit settings. For SSO type, select signature. For SSO data, type the shared secret. Select Save. In addition to enhanced security, the new SSO method supports a session cookie. Nav data may be stored in the session cookie to support enhanced functionality of headers and footers. The name of the cookie is specified through the Partner console. If unspecified the cookie name defaults to nav_data. To successfully use this SSO method, the SSO URI must be invoked from the user's browser. On success the browser will be automatically logged into New Relic and the redirect URL to that account returned. The SSO URI however should not be generated on the browser, as this would expose the shared secret and allow the login to be spoofed. The URI should be generated on a host and passed to the user's browser. SSO API Description SSO authentication request Method POST or GET URI https://rpm.newrelic.com/accounts/sso_access Copy Parameters Name Required Description id Yes ID of the New Relic account. email No Email address of user logging in (optional). If given, the user must already have been added to the account. By default, the account Owner role is used. Account Owners have full privileges on accounts. If some lesser degree of account privileges or a different user is desired, the email must be provided. timestamp Yes Timestamp used to generate token, in seconds since the epoch. Only timestamps within five minutes (300 seconds) of the New Relic system clock are accepted. nav-data OR nav_data No Partner navigation data. This data will be set in the session cookie using the name as specified in the partnership configuration, or nav_data by default. token Yes Signed token. The signature token is generated by applying a SHA1 hex digest on a seed string, which is composed as Account_id:secret:timestamp or Account_id:secret:timestamp:email. Each component is separated by a colon (:). Example without email: \"12345:MySecret:0987654321\" Using Ruby syntax: \"#{account_id}:#{secret}:#{timestamp}\" Example with email: \"12345:MySecret:0987654321:user@host.com\" Using Ruby syntax: \"#{account_id}:#{secret}:#{timestamp}:#{email}\" remote_url No Relative path of a New Relic page to which the users will be directed. ** cURL examples * * curl -X POST -d \"id=63790\" -d \"timestamp=1319659982\" -d \"token=a4d30d6f1f1a5b6c2872ab\" https://rpm.newrelic.com/accounts/sso_access Copy curl -X POST -d \"id=63790\" -d \"timestamp=1319659982\" -d \"token=a4d30d6f1f1a5b6c2872ab\" -d \"remote_url=/account/63790/servers\" https://rpm.newrelic.com/accounts/sso_access Copy On success returns: <html><body>You are being redirected.</body></html> Copy For more help Additional documentation resources include: SAML service providers (overview of New Relic's SSO feature, providers supported by New Relic) New Relic Partners and SAML SSO (additional options for partner accounts)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.51895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> accounts: Single sign on and access control",
        "sections": "<em>Partnership</em> accounts: Single sign on and access control",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": "<em>New</em> <em>Relic</em> supports Single Sign On (SSO) as a convenience for <em>partner</em> customers. Partners implementing SSO also have the option to restrict access by requiring customers to access <em>New</em> <em>Relic</em> via the <em>partner</em>&#x27;s management site or <em>product</em> login. Single Sign On is a convenience for your customers"
      },
      "id": "6044175564441fd3fa378f1f"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.82603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>New</em> <em>Relic</em> <em>products</em> and <em>features</em> by category. Tip The docs site includes a <em>Partnerships</em> category with information for <em>New</em> <em>Relic</em> partners and some <em>partnership</em> customers. Here are the five most commonly consulted articles on the <em>New</em> <em>Relic</em> docs site. Providing easily found and direct links"
      },
      "id": "60450ecf28ccbc45632c6095"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/single-sign-access-control": [
    {
      "sections": [
        "Partner products, pricing, and billing",
        "Important",
        "Commitment levels",
        "Customized partnership pricing",
        "Partnership billing options",
        "Cancellations",
        "Promotions",
        "Legacy products and commitment levels",
        "For more help"
      ],
      "title": "Partner products, pricing, and billing",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "05d2d31e3eb7c18d7d0b13eac2d3fead6fd58bbf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/partner-products-pricing-billing/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-05-16T01:10:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This information is for New Relic partners. If you are not a New Relic partner, refer to the information about pricing and billing for New Relic accounts. Partners: For account setup procedures, see New Relic's Partner API documentation. For specific product pricing details (such as New Relic APM), visit New Relic's website, or contact your Alliance & Channels representative at New Relic. Commitment levels When customers choose a product, they also choose a monthly or annual commitment level. Existing partnerships have the option of limiting available product offerings for their customers. Reseller partners may be able to modify these subscription terms based on the contractual terms in the partner agreement with New Relic. Customized partnership pricing Partnership accounts may offer customized pricing. Customized pricing models, rates, minimums, discounts, and options vary by partnership--the actual pricing model used is subject to the contractual terms of the partner's agreement with New Relic. Contact your Alliance & Channels representative at New Relic to learn more. Partnership billing options New Relic supports the following billing options for partnerships. All subscriptions commence and expire at midnight GMT. For host-based subscriptions, fees are charged in advance for the month. Upgrade requests are honored immediately without any billing for partial use during the month. Downgrades take effect at the next payment date. To view New Relic account billing details and history from the user interface: From one.newrelic.com, select (account dropdown) > Account settings > Account > Billing. Billing option Description Credit card When partners choose credit card billing, your customers are directly charged using the credit card information provided during their New Relic subscription signup. This does not include any license fees paid directly by the partner for their customers' accounts. Invoice When partners choose invoice billing, your customers are billed directly by New Relic via invoice for their subscriptions. This option is normally provided on special request to customers with large monthly costs for which credit card billing would be impractical. Reseller For resellers, partners are billed directly for all customer accounts based on the calendar month. Partners may be responsible for accounting for customer usage, pricing, and subscriptions. Resellers have the option to implement an integration between our respective accounting systems. New Relic will invoice the partner monthly, using the Billing integration API for each of the paying accounts under the partnership. Cancellations Once a New Relic account cancellation takes effect, you must uninstall and/or delete all agents or other data-reporting integrations. For uninstallation details, see the documentation for the relevant agents and integrations. Customers may continue to access their data on New Relic until it is purged in accordance with the data retention policy corresponding to the product level. For existing accounts with paid, fixed host subscriptions, cancellations take effect at the next payment date. New Relic will continue to accept data for cancelled accounts until this date. Cancellations for accounts with free or paid based subscriptions take effect immediately. Promotions New Relic allows promotions for accounts offered through partnerships. Promotions associated with a specific partnership may only be redeemed on accounts associated with the partnership. Each promotion has a unique code. This promotion code may be applied only once per account. New Relic may impose further limits on the number of promotions that a customer may apply to an account. Promotion Description Free trials New Relic may include a free trial period for features normally available only through a paid subscription level. This option is provided for a specified number of days. The customer's subscription automatically reverts to its prior level at the conclusion of the trial. Payments for paid subscriptions are not interrupted by the redemption of a free trial promotion on the account. Single use Single use trials expire after they are used once. Discount (deprecated) A one-time percentage discount is applied to a paid subscription. This discount is applied in addition to any volume discounts and customized partner prices. The discount remains in effect until the subscription is modified or cancelled. Legacy products and commitment levels If you have questions about older New Relic products that have been converted to new pricing models, contact your Alliance & Channels representative at New Relic. For more help Additional documentation resources include: Partnership API account object (the primary JSON container object in the API) Partnership API user object (defined as an array within the account object) Partnership API subscription object (the level of service a customer purchases for one or more New Relic products) Billing integration API (functions to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.97751,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>products</em>, pricing, and billing",
        "sections": "<em>Partner</em> <em>products</em>, pricing, and billing",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": " API user object (defined as an array within the account object) <em>Partnership</em> API subscription object (the level of service a customer purchases for one or more <em>New</em> <em>Relic</em> <em>products</em>) Billing <em>integration</em> API (functions to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts)"
      },
      "id": "603ece55e7b9d254192a080c"
    },
    {
      "sections": [
        "Other partnership settings",
        "Types of settings",
        "For more help"
      ],
      "title": "Other partnership settings",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "df23328a14acab54c7f100c723f6feee68927c6b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/other-partnership-settings/",
      "published_at": "2021-10-13T07:36:53Z",
      "updated_at": "2021-03-16T10:07:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are a number of miscellaneous settings that are available to partners for customization of their partnership integration. Most of these settings enable or disable the presentation of New Relic features. These settings must be set by New Relic and are not configurable through the Partnership Console. Types of settings Contact your partnership technical contact to have any of these settings modified. Download links: Show agent link Show configuration file link Welcome messages: Signup message: A customized welcome message Hide or show banner welcome message Hide or show invoice message Email control: Send deploy reminders Send trial emails Billing email: This is for partnerships where the billing method is \"Reseller\" and invoices should be directed to the attention of a specific party. Feature access: Server monitoring User administration For more help Additional documentation resources include: Partnership console (overview of how to use the Partnership Console to change account settings in New Relic) The New Relic user interface (overview of how to use the UI)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.6492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Other <em>partnership</em> settings",
        "sections": "Other <em>partnership</em> settings",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": "There are a number of miscellaneous settings that are available to partners for customization of their <em>partnership</em> <em>integration</em>. Most of these settings enable or disable the presentation of <em>New</em> <em>Relic</em> <em>features</em>. These settings must be set by <em>New</em> <em>Relic</em> and are not configurable through the <em>Partnership</em>"
      },
      "id": "603ed42364441fb51f4e88a9"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.82603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>New</em> <em>Relic</em> <em>products</em> and <em>features</em> by category. Tip The docs site includes a <em>Partnerships</em> category with information for <em>New</em> <em>Relic</em> partners and some <em>partnership</em> customers. Here are the five most commonly consulted articles on the <em>New</em> <em>Relic</em> docs site. Providing easily found and direct links"
      },
      "id": "60450ecf28ccbc45632c6095"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2021-10-13T05:59:05Z",
      "updated_at": "2021-09-14T13:44:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing plan or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing plan. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing plan or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing plan can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.3003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.24304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    },
    {
      "sections": [
        "Tips and tricks",
        "Account creation and deletion",
        "Partnership owner account"
      ],
      "title": "Tips and tricks",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ba123e58f5acafea5b65e09350eba65abf430b2e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/tips-tricks/",
      "published_at": "2021-10-13T07:38:11Z",
      "updated_at": "2021-03-13T03:11:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some tips and tricks for creating and deleting New Relic partner accounts. Account creation and deletion When you create an account through the New Relic Partner API, the system checks the string submitted as the account name to ensure it is unique. If it is not unique, the system will append a number to the submitted string to ensure uniqueness; for example, account-name_1. When an account is canceled, it is not deleted from the New Relic database. Rather, it is made inactive by removing all subscriptions from the account. If you attempt to reinstate an account by calling the Account Creation API using the same account name, the system will check for uniqueness, determine that the name is not unique and create a new account with an appended number. This is in most cases not what is desired. To avoid this problem, as part of account creation, store the numeric account_id with the account name. When re-creating an account, check for the existence of this ID. If detected, rather than using the Account Creation API, use the Change Subscription API to add a new subscription to the account. Adding an active subscription to the account will re-activate the account. Partnership owner account The Partnership Owner Account is not part of the partnership. It owns the partnership. Attempts to treat it as if it were in the partnership will fail. This includes but is not limited to: Attempting to SSO into the partnership owner account using the partnership shared secret Expecting the partnership pricing to apply to the partnership owner account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.34583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Partnership</em> owner <em>account</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Here are some tips and tricks for creating and deleting <em>New</em> <em>Relic</em> <em>partner</em> accounts. <em>Account</em> creation and deletion When you create an <em>account</em> through the <em>New</em> <em>Relic</em> <em>Partner</em> API, the system checks the string submitted as the <em>account</em> name to ensure it is unique. If it is not unique, the system"
      },
      "id": "60441785196a676aed960f46"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api": [
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.24304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.4657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    },
    {
      "sections": [
        "Tips and tricks",
        "Account creation and deletion",
        "Partnership owner account"
      ],
      "title": "Tips and tricks",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ba123e58f5acafea5b65e09350eba65abf430b2e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/tips-tricks/",
      "published_at": "2021-10-13T07:38:11Z",
      "updated_at": "2021-03-13T03:11:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some tips and tricks for creating and deleting New Relic partner accounts. Account creation and deletion When you create an account through the New Relic Partner API, the system checks the string submitted as the account name to ensure it is unique. If it is not unique, the system will append a number to the submitted string to ensure uniqueness; for example, account-name_1. When an account is canceled, it is not deleted from the New Relic database. Rather, it is made inactive by removing all subscriptions from the account. If you attempt to reinstate an account by calling the Account Creation API using the same account name, the system will check for uniqueness, determine that the name is not unique and create a new account with an appended number. This is in most cases not what is desired. To avoid this problem, as part of account creation, store the numeric account_id with the account name. When re-creating an account, check for the existence of this ID. If detected, rather than using the Account Creation API, use the Change Subscription API to add a new subscription to the account. Adding an active subscription to the account will re-activate the account. Partnership owner account The Partnership Owner Account is not part of the partnership. It owns the partnership. Attempts to treat it as if it were in the partnership will fail. This includes but is not limited to: Attempting to SSO into the partnership owner account using the partnership shared secret Expecting the partnership pricing to apply to the partnership owner account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.34583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Partnership</em> owner <em>account</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Here are some tips and tricks for creating and deleting <em>New</em> <em>Relic</em> <em>partner</em> accounts. <em>Account</em> creation and deletion When you create an <em>account</em> through the <em>New</em> <em>Relic</em> <em>Partner</em> API, the system checks the string submitted as the <em>account</em> name to ensure it is unique. If it is not unique, the system"
      },
      "id": "60441785196a676aed960f46"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2021-10-13T05:59:05Z",
      "updated_at": "2021-09-14T13:44:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing plan or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing plan. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing plan or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing plan can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.30026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.4657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    },
    {
      "sections": [
        "Tips and tricks",
        "Account creation and deletion",
        "Partnership owner account"
      ],
      "title": "Tips and tricks",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ba123e58f5acafea5b65e09350eba65abf430b2e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/tips-tricks/",
      "published_at": "2021-10-13T07:38:11Z",
      "updated_at": "2021-03-13T03:11:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some tips and tricks for creating and deleting New Relic partner accounts. Account creation and deletion When you create an account through the New Relic Partner API, the system checks the string submitted as the account name to ensure it is unique. If it is not unique, the system will append a number to the submitted string to ensure uniqueness; for example, account-name_1. When an account is canceled, it is not deleted from the New Relic database. Rather, it is made inactive by removing all subscriptions from the account. If you attempt to reinstate an account by calling the Account Creation API using the same account name, the system will check for uniqueness, determine that the name is not unique and create a new account with an appended number. This is in most cases not what is desired. To avoid this problem, as part of account creation, store the numeric account_id with the account name. When re-creating an account, check for the existence of this ID. If detected, rather than using the Account Creation API, use the Change Subscription API to add a new subscription to the account. Adding an active subscription to the account will re-activate the account. Partnership owner account The Partnership Owner Account is not part of the partnership. It owns the partnership. Attempts to treat it as if it were in the partnership will fail. This includes but is not limited to: Attempting to SSO into the partnership owner account using the partnership shared secret Expecting the partnership pricing to apply to the partnership owner account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.34583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Partnership</em> owner <em>account</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Here are some tips and tricks for creating and deleting <em>New</em> <em>Relic</em> <em>partner</em> accounts. <em>Account</em> creation and deletion When you create an <em>account</em> through the <em>New</em> <em>Relic</em> <em>Partner</em> API, the system checks the string submitted as the <em>account</em> name to ensure it is unique. If it is not unique, the system"
      },
      "id": "60441785196a676aed960f46"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/restricted-access-partnerships": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2021-10-13T05:59:05Z",
      "updated_at": "2021-09-14T13:44:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing plan or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing plan. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing plan or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing plan can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.30026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.24304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.4657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/staging-production": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2021-10-13T05:59:05Z",
      "updated_at": "2021-09-14T13:44:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing plan or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing plan. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing plan or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing plan can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.30026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.24303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.4657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/tips-tricks": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2021-10-13T05:59:05Z",
      "updated_at": "2021-09-14T13:44:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing plan or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing plan. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing plan or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing plan can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.30026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.24303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.4657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/welcome-messages-partnerships": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2021-10-13T05:59:05Z",
      "updated_at": "2021-09-14T13:44:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing plan or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing plan. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing plan or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing plan can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.30025,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.24303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2021-10-13T05:58:15Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.4657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/getting-started/partner-marketing": [
    {
      "sections": [
        "Using the Partner Portal",
        "For more help"
      ],
      "title": "Using the Partner Portal",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Getting started"
      ],
      "external_id": "2f149ab0c15dadf598fa1833be58caeecb6ed493",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/getting-started/using-partner-portal/",
      "published_at": "2021-10-13T08:59:51Z",
      "updated_at": "2021-03-16T10:09:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides a web portal for partners to easily access valuable resources provided to them by the New Relic Partner Program, such as partner sales enablement content, training, marketing materials, etc. If you are a partner and do not have access to this already, contact your Partner Sales Manager or email partnersales @ newrelic.com. To access the Partner Portal: From your browser, type (or bookmark) the following URL, and then log in with your user name and password. https://partners.newrelic-external.com/English/ Copy For more help For more information about partner content provided by New Relic, see Partner marketing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.90616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> provides a web portal for partners to easily access valuable resources provided to them by the <em>New</em> <em>Relic</em> Partner Program, such as partner sales enablement content, training, marketing materials, etc. If you are a partner and do not have access to this already, contact your Partner Sales"
      },
      "id": "603ebb3528ccbc63d5eba791"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.7851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> partners",
        "sections": "Support resources for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>New</em> <em>Relic</em> products and features by category. Tip The docs site includes a <em>Partnerships</em> category with information for <em>New</em> <em>Relic</em> partners and some <em>partnership</em> customers. Here are the five most commonly consulted articles on the <em>New</em> <em>Relic</em> docs site. Providing easily found and direct links"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.16515,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " the console from the <em>New</em> <em>Relic</em> UI: Go to one.newrelic.com &gt; (account dropdown) &gt; Account settings. From the left menu bar, select <em>Partnerships</em>. one.newrelic.com &gt; (account dropdown) &gt; Account settings &gt; <em>Partnerships</em>: <em>Partnership</em> owners can access the <em>Partnership</em> Admin Console from their account settings"
      },
      "id": "603ed3e3196a6735baa83dad"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/getting-started/using-partner-portal": [
    {
      "sections": [
        "Partner marketing",
        "Marketing tools",
        "Marketing activities",
        "Guest blog posts",
        "What's in it for you?",
        "How does it work?",
        "How do you create a great blog post?"
      ],
      "title": "Partner marketing",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Getting started"
      ],
      "external_id": "3c8149518849df6b00f17244aec711aad64f3952",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/getting-started/partner-marketing/",
      "published_at": "2021-10-13T08:58:50Z",
      "updated_at": "2021-08-02T12:01:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic loves to help our partners tell the world about our joint offerings. Here is a non-exhaustive list of marketing activities that we can pull into our co-marketing plan. To proceed with any co-marketing activity or to plan your strategy, email your Business Development rep at New Relic or email partners @ newrelic.com. Marketing tools If you have new ideas that are not listed here, let us know! Marketing tools Description Email template Use New Relic's HTML and/or plain text email templates to send to your customers to introduce them to New Relic. To request templates, email your Business Development rep at New Relic, or email partners @ newrelic.com. Content boilerplate New Relic's content boilerplate has everything you need to create a New Relic page on your website. To request it, email your Business Development rep at New Relic, or email partners @ newrelic.com. Blog content Follow New Relic's guidelines to post on New Relic's blog. Twitter Use sample tweets to promote our partnership, include appropriate links, and mention @newrelic. To request re-tweets, email your Business Development rep at New Relic, or email partners @ newrelic.com. New Relic media assets Get our logo and other materials from New Relic's media assets webpage. To request additional assets, email your Business Development rep at New Relic, or email partners @ newrelic.com. Joint customer case study Identify a joint customer, and work with New Relic to write and publish a joint customer case study. For more information, contact your Business Development rep at New Relic, or email partners @ newrelic.com. Marketing activities If you have new ideas that are not listed here, let us know! Marketing activity Description Social media support Let New Relic help amplify your social media through tweets, retweets, Facebook likes, shares, etc. Event opportunities Participate in local meetups or find out about other events or co-sponsorship opportunities. Webinar Co-host a webinar; for example, see: Three Powerful Tools for Improving the Performance of Your Drupal Site Guest blog posts New Relic loves great blog content, and partners are often an essential source. You're encouraged to write a guest blog post for http://blog.newrelic.com. What's in it for you? It's a great opportunity for you to promote your company and the integration you've built. Our blog is popular reading for the New Relic community, and our customers are frequently among the fastest growing innovators. How does it work? You draft the post and supply screenshots and/or video as applicable. New Relic will edit, format, publish, and promote the post. You'll get credit as the author, and you can include a paragraph at the end mentioning your product. How do you create a great blog post? The goal is to be insightful, useful, thought provoking, smart, surprising, and entertaining—or at least some combination of those elements. Blog post guidelines Comments Writing style Recommendation: Write your blog post in the first person. New Relic's target audience includes developers, DevOps, IT ops, execs, marketers, and data scientists working with big data, but we have no problem attracting a wider readership than that. We want to intrigue them and help them do their jobs better and more passionately. Passion and connection are essential. If you do not care about the topic you are blogging about or, more importantly, you do not appear to care about it, neither will the reader. Length A typical blog post runs approximately 500 words, but it may be longer or shorter if there is a good reason. Technical blog posts may run much longer, while posts with video may not need much text at all. Content Each post should focus on a single main idea. If you have a mashup of multiple ideas, consider breaking them up into a series of multiple, related posts. Posts do not have to be based on the latest news, but they shouldn't pretend that old news is new. If you're writing about something that's not brand new, you need to acknowledge that and come up with a fresh take or new angle. Posts should be fact based, and not mere opinion without a grounding in reality. The magic is in the details. Posts should be grounded in specifics, not just general pronouncements. If you say something is bad, you need to describe why; for example, what can or did happen because of it. Similarly, if you suggest best practices, the more specific examples you provide, the better. Links Links to outside content are encouraged, but just pointing to something on the web is not enough for a post, no matter how interesting the link is. You need to bring something unique to the post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.26414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " Follow <em>New</em> <em>Relic</em>&#x27;s guidelines to post on <em>New</em> <em>Relic</em>&#x27;s blog. Twitter Use sample tweets to promote our <em>partnership</em>, include appropriate links, and mention @newrelic. To request re-tweets, email your Business Development rep at <em>New</em> <em>Relic</em>, or email partners @ newrelic.com. <em>New</em> <em>Relic</em> media assets <em>Get</em> our"
      },
      "id": "603eb147e7b9d2f0012a07de"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-13T07:35:34Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.7851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> partners",
        "sections": "Support resources for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>New</em> <em>Relic</em> products and features by category. Tip The docs site includes a <em>Partnerships</em> category with information for <em>New</em> <em>Relic</em> partners and some <em>partnership</em> customers. Here are the five most commonly consulted articles on the <em>New</em> <em>Relic</em> docs site. Providing easily found and direct links"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2021-10-13T07:36:52Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.16515,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " the console from the <em>New</em> <em>Relic</em> UI: Go to one.newrelic.com &gt; (account dropdown) &gt; Account settings. From the left menu bar, select <em>Partnerships</em>. one.newrelic.com &gt; (account dropdown) &gt; Account settings &gt; <em>Partnerships</em>: <em>Partnership</em> owners can access the <em>Partnership</em> Admin Console from their account settings"
      },
      "id": "603ed3e3196a6735baa83dad"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partner-api-reference": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2021-10-13T06:00:09Z",
      "updated_at": "2021-09-14T02:59:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing plan: ignore this field because it applies to the original pricing plan, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing plan. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing plans. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing plan and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.9629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "&#x27;s subscription was downgraded. cancelled The <em>New</em> <em>Relic</em> account subscription has been cancelled. suspended The <em>New</em> <em>Relic</em> account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the <em>Partnership</em> <em>API</em>"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2021-10-13T09:01:02Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.76022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    },
    {
      "sections": [
        "Partnership billing integration API",
        "Requirements",
        "Communication endpoint",
        "Billing API",
        "Customer subscription notification API",
        "Invoice notification API"
      ],
      "title": "Partnership billing integration API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "73da7e096ce56bb45e39bb95a1c2e0a0011be597",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-03-30T21:12:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Partnership API includes functionality for partners to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts. This is particularly useful for partners acting as resellers or managed service providers of New Relic accounts. For example, when customers of a New Relic reseller partner purchase a higher subscription level from New Relic's Sales team, New Relic replaces the old subscription with a new subscription. New Relic then uses the API to communicate this information to the partner. Requirements Before using this object, please read the Partnership API requirements. Communication endpoint Partners must implement a billing communication endpoint that identifies the partner's URL and PARTNER_ID. New Relic uses this endpoint to notify the partner that New Relic has made a change to a partner account's subscription or invoice information. The endpoint must support HTTPS. The partner-specified portion of the URL is identified from the Settings tab of New Relic's Partner Portal. The PARTNER_ID is the partner's external ID for this account. This value must be passed when the account is created by using the partner_external_identifier parameter. Billing API Supported functionality for the Partnership billing API includes: Customer subscription notification Invoice information notification Customer subscription notification API To communicate changes to a partner about a customer's subscription, New Relic uses the POST method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy Authentication is done via headers with the partner's REST API key or Admin user's API key. The Partnership API returns the results as JSON. Parameters: Name Type Description id String The customer's New Relic account ID subscription_id Integer Subscription's numeric ID subscription_string String Description of subscription for display price Integer Monthly price of subscription in cents number_of_hosts Integer Number of hosts starts Date Subscription's start date (yyyymmdd) expires Date Subscription's end date (yyyymmdd) Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed. Invoice notification API New Relic uses this endpoint to notify the partner of changes to a partner account's subscription level and invoice information. New Relic uses the PUT method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy OR https://partner-specified/partner-specified/PARTNER_ID.xml Copy The Partnership API returns the results as JSON or XML. Parameters: Name Type Description id string The customer's New Relic account ID subscription_id integer Subscription's numeric ID subscription_string string Description of subscription for display price integer Monthly price of subscription in cents Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.92021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> billing integration <em>API</em>",
        "sections": "<em>Partnership</em> billing integration <em>API</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>Partnership</em> <em>API</em> includes functionality for partners to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts. This is particularly useful for partners acting as resellers or managed service providers of <em>New</em> <em>Relic</em>"
      },
      "id": "603ec86e64441f09e44e8871"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object": [
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2021-10-13T09:01:02Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.76022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    },
    {
      "sections": [
        "Partnership billing integration API",
        "Requirements",
        "Communication endpoint",
        "Billing API",
        "Customer subscription notification API",
        "Invoice notification API"
      ],
      "title": "Partnership billing integration API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "73da7e096ce56bb45e39bb95a1c2e0a0011be597",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-03-30T21:12:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Partnership API includes functionality for partners to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts. This is particularly useful for partners acting as resellers or managed service providers of New Relic accounts. For example, when customers of a New Relic reseller partner purchase a higher subscription level from New Relic's Sales team, New Relic replaces the old subscription with a new subscription. New Relic then uses the API to communicate this information to the partner. Requirements Before using this object, please read the Partnership API requirements. Communication endpoint Partners must implement a billing communication endpoint that identifies the partner's URL and PARTNER_ID. New Relic uses this endpoint to notify the partner that New Relic has made a change to a partner account's subscription or invoice information. The endpoint must support HTTPS. The partner-specified portion of the URL is identified from the Settings tab of New Relic's Partner Portal. The PARTNER_ID is the partner's external ID for this account. This value must be passed when the account is created by using the partner_external_identifier parameter. Billing API Supported functionality for the Partnership billing API includes: Customer subscription notification Invoice information notification Customer subscription notification API To communicate changes to a partner about a customer's subscription, New Relic uses the POST method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy Authentication is done via headers with the partner's REST API key or Admin user's API key. The Partnership API returns the results as JSON. Parameters: Name Type Description id String The customer's New Relic account ID subscription_id Integer Subscription's numeric ID subscription_string String Description of subscription for display price Integer Monthly price of subscription in cents number_of_hosts Integer Number of hosts starts Date Subscription's start date (yyyymmdd) expires Date Subscription's end date (yyyymmdd) Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed. Invoice notification API New Relic uses this endpoint to notify the partner of changes to a partner account's subscription level and invoice information. New Relic uses the PUT method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy OR https://partner-specified/partner-specified/PARTNER_ID.xml Copy The Partnership API returns the results as JSON or XML. Parameters: Name Type Description id string The customer's New Relic account ID subscription_id integer Subscription's numeric ID subscription_string string Description of subscription for display price integer Monthly price of subscription in cents Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.92021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> billing integration <em>API</em>",
        "sections": "<em>Partnership</em> billing integration <em>API</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>Partnership</em> <em>API</em> includes functionality for partners to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts. This is particularly useful for partners acting as resellers or managed service providers of <em>New</em> <em>Relic</em>"
      },
      "id": "603ec86e64441f09e44e8871"
    },
    {
      "sections": [
        "Partnership API reference",
        "Requirements",
        "Find your Partnership API key",
        "Find your Partner ID",
        "Authenticate the API call",
        "Notes for partners who manage New Relic accounts",
        "Errors"
      ],
      "title": "Partnership API reference",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7bc374ae0e6f6917aa82a70e582606ea4a9878ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partner-api-reference/",
      "published_at": "2021-10-13T08:59:52Z",
      "updated_at": "2021-03-30T03:04:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains technical details about using the Partnership API. For an introduction and requirements, first read Intro to Partnership API. Requirements For requirements, see Intro to Partnership API. Find your Partnership API key The Partnership API requires that you authenticate with the REST API key that is specific to your partnership owner account (you cannot use the other REST API keys). When using your Partnership API key with calls to REST API (v2) endpoints that require the use of an Admin user's API key, see Admin user's API Key and partnerships. Find your Partner ID The Partnership API also requires that you authenticate by providing a Partner ID specific to your partnership. This is unique from the account ID for your partnership owner account. To obtain your Partner ID, go to your partner admin console and retrieve the partner ID number that is listed in your URL: https://partner-admin-console.newrelic.com/accounts/​$ACCOUNT_ID/admin_console/partnerships/$PARTNER_ID Copy You must include the Partner ID as part of the base URL for the Partner API. URL component URL pattern Partner API endpoint https://rpm.newrelic.com/api/v2/partners/PARTNER_ID Copy Resource URL patterns /accounts /accounts/ACCOUNT_ID /accounts/ACCOUNT_ID/users /accounts/ACCOUNT_ID/users/USER_ID /accounts/ACCOUNT_ID/subscriptions /accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Example https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Authenticate the API call To authenticate to the Partner API when making an API call: Add a request header labeled x-api-key and set its value to your Partner API key. Include your Partner ID at the specified point in the request URI. Notes for partners who manage New Relic accounts For partners who manage New Relic accounts for their customers, the initial API call for all account-level interactions is to \"create account.\" This call returns an xml record of the newly created account. Part of this record is the account_id. All of the other calls in the Partnership API require the account_id as a parameter. Provision will need to be made by the partner to parse the returned xml extract, store the account_id, and associate it with the users' partner account record. Errors New Relic uses conventional HTTP response codes to indicate success or failure of an API request. In general, codes in the 2xx range indicate success and codes in the 4xx range indicate an error that resulted from the provided information (for example, a required parameter was missing). Error Probable cause 400 Bad Request Most commonly the call is missing a required parameter. 401 Unauthorized A valid API key was not provided. 402 Request Failed Parameters were valid but request failed for some reason. 404 Not Found The requested item doesn't exist. 422 Unprocessable Entity Your account has special terms and cannot be changed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.89436,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> reference",
        "sections": "Notes for <em>partners</em> who manage <em>New</em> <em>Relic</em> accounts",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>API</em> key that is specific to your <em>partnership</em> owner account (you cannot use the other REST <em>API</em> keys). When using your <em>Partnership</em> <em>API</em> key with calls to REST <em>API</em> (v2) endpoints that require the use of an Admin user&#x27;s <em>API</em> key, see Admin user&#x27;s <em>API</em> Key and <em>partnerships</em>. Find your <em>Partner</em> ID"
      },
      "id": "603ebc5f28ccbc22b6eba780"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-keys": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2021-10-13T06:00:09Z",
      "updated_at": "2021-09-14T02:59:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing plan: ignore this field because it applies to the original pricing plan, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing plan. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing plans. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing plan and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.96289,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "&#x27;s subscription was downgraded. cancelled The <em>New</em> <em>Relic</em> account subscription has been cancelled. suspended The <em>New</em> <em>Relic</em> account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the <em>Partnership</em> <em>API</em>"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2021-10-13T09:01:02Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.76022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    },
    {
      "sections": [
        "Partnership billing integration API",
        "Requirements",
        "Communication endpoint",
        "Billing API",
        "Customer subscription notification API",
        "Invoice notification API"
      ],
      "title": "Partnership billing integration API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "73da7e096ce56bb45e39bb95a1c2e0a0011be597",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-03-30T21:12:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Partnership API includes functionality for partners to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts. This is particularly useful for partners acting as resellers or managed service providers of New Relic accounts. For example, when customers of a New Relic reseller partner purchase a higher subscription level from New Relic's Sales team, New Relic replaces the old subscription with a new subscription. New Relic then uses the API to communicate this information to the partner. Requirements Before using this object, please read the Partnership API requirements. Communication endpoint Partners must implement a billing communication endpoint that identifies the partner's URL and PARTNER_ID. New Relic uses this endpoint to notify the partner that New Relic has made a change to a partner account's subscription or invoice information. The endpoint must support HTTPS. The partner-specified portion of the URL is identified from the Settings tab of New Relic's Partner Portal. The PARTNER_ID is the partner's external ID for this account. This value must be passed when the account is created by using the partner_external_identifier parameter. Billing API Supported functionality for the Partnership billing API includes: Customer subscription notification Invoice information notification Customer subscription notification API To communicate changes to a partner about a customer's subscription, New Relic uses the POST method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy Authentication is done via headers with the partner's REST API key or Admin user's API key. The Partnership API returns the results as JSON. Parameters: Name Type Description id String The customer's New Relic account ID subscription_id Integer Subscription's numeric ID subscription_string String Description of subscription for display price Integer Monthly price of subscription in cents number_of_hosts Integer Number of hosts starts Date Subscription's start date (yyyymmdd) expires Date Subscription's end date (yyyymmdd) Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed. Invoice notification API New Relic uses this endpoint to notify the partner of changes to a partner account's subscription level and invoice information. New Relic uses the PUT method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy OR https://partner-specified/partner-specified/PARTNER_ID.xml Copy The Partnership API returns the results as JSON or XML. Parameters: Name Type Description id string The customer's New Relic account ID subscription_id integer Subscription's numeric ID subscription_string string Description of subscription for display price integer Monthly price of subscription in cents Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.92021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> billing integration <em>API</em>",
        "sections": "<em>Partnership</em> billing integration <em>API</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>Partnership</em> <em>API</em> includes functionality for partners to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts. This is particularly useful for partners acting as resellers or managed service providers of <em>New</em> <em>Relic</em>"
      },
      "id": "603ec86e64441f09e44e8871"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2021-10-13T06:00:09Z",
      "updated_at": "2021-09-14T02:59:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing plan: ignore this field because it applies to the original pricing plan, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing plan. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing plans. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing plan and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.96289,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "&#x27;s subscription was downgraded. cancelled The <em>New</em> <em>Relic</em> account subscription has been cancelled. suspended The <em>New</em> <em>Relic</em> account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the <em>Partnership</em> <em>API</em>"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership billing integration API",
        "Requirements",
        "Communication endpoint",
        "Billing API",
        "Customer subscription notification API",
        "Invoice notification API"
      ],
      "title": "Partnership billing integration API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "73da7e096ce56bb45e39bb95a1c2e0a0011be597",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-03-30T21:12:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Partnership API includes functionality for partners to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts. This is particularly useful for partners acting as resellers or managed service providers of New Relic accounts. For example, when customers of a New Relic reseller partner purchase a higher subscription level from New Relic's Sales team, New Relic replaces the old subscription with a new subscription. New Relic then uses the API to communicate this information to the partner. Requirements Before using this object, please read the Partnership API requirements. Communication endpoint Partners must implement a billing communication endpoint that identifies the partner's URL and PARTNER_ID. New Relic uses this endpoint to notify the partner that New Relic has made a change to a partner account's subscription or invoice information. The endpoint must support HTTPS. The partner-specified portion of the URL is identified from the Settings tab of New Relic's Partner Portal. The PARTNER_ID is the partner's external ID for this account. This value must be passed when the account is created by using the partner_external_identifier parameter. Billing API Supported functionality for the Partnership billing API includes: Customer subscription notification Invoice information notification Customer subscription notification API To communicate changes to a partner about a customer's subscription, New Relic uses the POST method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy Authentication is done via headers with the partner's REST API key or Admin user's API key. The Partnership API returns the results as JSON. Parameters: Name Type Description id String The customer's New Relic account ID subscription_id Integer Subscription's numeric ID subscription_string String Description of subscription for display price Integer Monthly price of subscription in cents number_of_hosts Integer Number of hosts starts Date Subscription's start date (yyyymmdd) expires Date Subscription's end date (yyyymmdd) Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed. Invoice notification API New Relic uses this endpoint to notify the partner of changes to a partner account's subscription level and invoice information. New Relic uses the PUT method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy OR https://partner-specified/partner-specified/PARTNER_ID.xml Copy The Partnership API returns the results as JSON or XML. Parameters: Name Type Description id string The customer's New Relic account ID subscription_id integer Subscription's numeric ID subscription_string string Description of subscription for display price integer Monthly price of subscription in cents Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.92021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> billing integration <em>API</em>",
        "sections": "<em>Partnership</em> billing integration <em>API</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>Partnership</em> <em>API</em> includes functionality for partners to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts. This is particularly useful for partners acting as resellers or managed service providers of <em>New</em> <em>Relic</em>"
      },
      "id": "603ec86e64441f09e44e8871"
    },
    {
      "sections": [
        "Partnership API reference",
        "Requirements",
        "Find your Partnership API key",
        "Find your Partner ID",
        "Authenticate the API call",
        "Notes for partners who manage New Relic accounts",
        "Errors"
      ],
      "title": "Partnership API reference",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7bc374ae0e6f6917aa82a70e582606ea4a9878ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partner-api-reference/",
      "published_at": "2021-10-13T08:59:52Z",
      "updated_at": "2021-03-30T03:04:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains technical details about using the Partnership API. For an introduction and requirements, first read Intro to Partnership API. Requirements For requirements, see Intro to Partnership API. Find your Partnership API key The Partnership API requires that you authenticate with the REST API key that is specific to your partnership owner account (you cannot use the other REST API keys). When using your Partnership API key with calls to REST API (v2) endpoints that require the use of an Admin user's API key, see Admin user's API Key and partnerships. Find your Partner ID The Partnership API also requires that you authenticate by providing a Partner ID specific to your partnership. This is unique from the account ID for your partnership owner account. To obtain your Partner ID, go to your partner admin console and retrieve the partner ID number that is listed in your URL: https://partner-admin-console.newrelic.com/accounts/​$ACCOUNT_ID/admin_console/partnerships/$PARTNER_ID Copy You must include the Partner ID as part of the base URL for the Partner API. URL component URL pattern Partner API endpoint https://rpm.newrelic.com/api/v2/partners/PARTNER_ID Copy Resource URL patterns /accounts /accounts/ACCOUNT_ID /accounts/ACCOUNT_ID/users /accounts/ACCOUNT_ID/users/USER_ID /accounts/ACCOUNT_ID/subscriptions /accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Example https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Authenticate the API call To authenticate to the Partner API when making an API call: Add a request header labeled x-api-key and set its value to your Partner API key. Include your Partner ID at the specified point in the request URI. Notes for partners who manage New Relic accounts For partners who manage New Relic accounts for their customers, the initial API call for all account-level interactions is to \"create account.\" This call returns an xml record of the newly created account. Part of this record is the account_id. All of the other calls in the Partnership API require the account_id as a parameter. Provision will need to be made by the partner to parse the returned xml extract, store the account_id, and associate it with the users' partner account record. Errors New Relic uses conventional HTTP response codes to indicate success or failure of an API request. In general, codes in the 2xx range indicate success and codes in the 4xx range indicate an error that resulted from the provided information (for example, a required parameter was missing). Error Probable cause 400 Bad Request Most commonly the call is missing a required parameter. 401 Unauthorized A valid API key was not provided. 402 Request Failed Parameters were valid but request failed for some reason. 404 Not Found The requested item doesn't exist. 422 Unprocessable Entity Your account has special terms and cannot be changed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.89436,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> reference",
        "sections": "Notes for <em>partners</em> who manage <em>New</em> <em>Relic</em> accounts",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>API</em> key that is specific to your <em>partnership</em> owner account (you cannot use the other REST <em>API</em> keys). When using your <em>Partnership</em> <em>API</em> key with calls to REST <em>API</em> (v2) endpoints that require the use of an Admin user&#x27;s <em>API</em> key, see Admin user&#x27;s <em>API</em> Key and <em>partnerships</em>. Find your <em>Partner</em> ID"
      },
      "id": "603ebc5f28ccbc22b6eba780"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2021-10-13T06:00:09Z",
      "updated_at": "2021-09-14T02:59:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing plan: ignore this field because it applies to the original pricing plan, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing plan. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing plans. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing plan and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.96289,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "&#x27;s subscription was downgraded. cancelled The <em>New</em> <em>Relic</em> account subscription has been cancelled. suspended The <em>New</em> <em>Relic</em> account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the <em>Partnership</em> <em>API</em>"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2021-10-13T09:01:02Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.76022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    },
    {
      "sections": [
        "Partnership billing integration API",
        "Requirements",
        "Communication endpoint",
        "Billing API",
        "Customer subscription notification API",
        "Invoice notification API"
      ],
      "title": "Partnership billing integration API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "73da7e096ce56bb45e39bb95a1c2e0a0011be597",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-03-30T21:12:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Partnership API includes functionality for partners to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts. This is particularly useful for partners acting as resellers or managed service providers of New Relic accounts. For example, when customers of a New Relic reseller partner purchase a higher subscription level from New Relic's Sales team, New Relic replaces the old subscription with a new subscription. New Relic then uses the API to communicate this information to the partner. Requirements Before using this object, please read the Partnership API requirements. Communication endpoint Partners must implement a billing communication endpoint that identifies the partner's URL and PARTNER_ID. New Relic uses this endpoint to notify the partner that New Relic has made a change to a partner account's subscription or invoice information. The endpoint must support HTTPS. The partner-specified portion of the URL is identified from the Settings tab of New Relic's Partner Portal. The PARTNER_ID is the partner's external ID for this account. This value must be passed when the account is created by using the partner_external_identifier parameter. Billing API Supported functionality for the Partnership billing API includes: Customer subscription notification Invoice information notification Customer subscription notification API To communicate changes to a partner about a customer's subscription, New Relic uses the POST method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy Authentication is done via headers with the partner's REST API key or Admin user's API key. The Partnership API returns the results as JSON. Parameters: Name Type Description id String The customer's New Relic account ID subscription_id Integer Subscription's numeric ID subscription_string String Description of subscription for display price Integer Monthly price of subscription in cents number_of_hosts Integer Number of hosts starts Date Subscription's start date (yyyymmdd) expires Date Subscription's end date (yyyymmdd) Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed. Invoice notification API New Relic uses this endpoint to notify the partner of changes to a partner account's subscription level and invoice information. New Relic uses the PUT method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy OR https://partner-specified/partner-specified/PARTNER_ID.xml Copy The Partnership API returns the results as JSON or XML. Parameters: Name Type Description id string The customer's New Relic account ID subscription_id integer Subscription's numeric ID subscription_string string Description of subscription for display price integer Monthly price of subscription in cents Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.92021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> billing integration <em>API</em>",
        "sections": "<em>Partnership</em> billing integration <em>API</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>Partnership</em> <em>API</em> includes functionality for partners to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts. This is particularly useful for partners acting as resellers or managed service providers of <em>New</em> <em>Relic</em>"
      },
      "id": "603ec86e64441f09e44e8871"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-user-object": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2021-10-13T06:00:09Z",
      "updated_at": "2021-09-14T02:59:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing plan: ignore this field because it applies to the original pricing plan, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing plan. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing plans. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing plan and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.96288,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "&#x27;s subscription was downgraded. cancelled The <em>New</em> <em>Relic</em> account subscription has been cancelled. suspended The <em>New</em> <em>Relic</em> account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the <em>Partnership</em> <em>API</em>"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2021-10-13T09:01:02Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.76022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    },
    {
      "sections": [
        "Partnership billing integration API",
        "Requirements",
        "Communication endpoint",
        "Billing API",
        "Customer subscription notification API",
        "Invoice notification API"
      ],
      "title": "Partnership billing integration API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "73da7e096ce56bb45e39bb95a1c2e0a0011be597",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-03-30T21:12:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Partnership API includes functionality for partners to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts. This is particularly useful for partners acting as resellers or managed service providers of New Relic accounts. For example, when customers of a New Relic reseller partner purchase a higher subscription level from New Relic's Sales team, New Relic replaces the old subscription with a new subscription. New Relic then uses the API to communicate this information to the partner. Requirements Before using this object, please read the Partnership API requirements. Communication endpoint Partners must implement a billing communication endpoint that identifies the partner's URL and PARTNER_ID. New Relic uses this endpoint to notify the partner that New Relic has made a change to a partner account's subscription or invoice information. The endpoint must support HTTPS. The partner-specified portion of the URL is identified from the Settings tab of New Relic's Partner Portal. The PARTNER_ID is the partner's external ID for this account. This value must be passed when the account is created by using the partner_external_identifier parameter. Billing API Supported functionality for the Partnership billing API includes: Customer subscription notification Invoice information notification Customer subscription notification API To communicate changes to a partner about a customer's subscription, New Relic uses the POST method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy Authentication is done via headers with the partner's REST API key or Admin user's API key. The Partnership API returns the results as JSON. Parameters: Name Type Description id String The customer's New Relic account ID subscription_id Integer Subscription's numeric ID subscription_string String Description of subscription for display price Integer Monthly price of subscription in cents number_of_hosts Integer Number of hosts starts Date Subscription's start date (yyyymmdd) expires Date Subscription's end date (yyyymmdd) Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed. Invoice notification API New Relic uses this endpoint to notify the partner of changes to a partner account's subscription level and invoice information. New Relic uses the PUT method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy OR https://partner-specified/partner-specified/PARTNER_ID.xml Copy The Partnership API returns the results as JSON or XML. Parameters: Name Type Description id string The customer's New Relic account ID subscription_id integer Subscription's numeric ID subscription_string string Description of subscription for display price integer Monthly price of subscription in cents Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.92021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> billing integration <em>API</em>",
        "sections": "<em>Partnership</em> billing integration <em>API</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>Partnership</em> <em>API</em> includes functionality for partners to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts. This is particularly useful for partners acting as resellers or managed service providers of <em>New</em> <em>Relic</em>"
      },
      "id": "603ec86e64441f09e44e8871"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2021-10-13T06:00:09Z",
      "updated_at": "2021-09-14T02:59:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing plan: ignore this field because it applies to the original pricing plan, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing plan. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing plans. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing plan and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.96288,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "&#x27;s subscription was downgraded. cancelled The <em>New</em> <em>Relic</em> account subscription has been cancelled. suspended The <em>New</em> <em>Relic</em> account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the <em>Partnership</em> <em>API</em>"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2021-10-13T09:01:02Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.76022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    },
    {
      "sections": [
        "Partnership API reference",
        "Requirements",
        "Find your Partnership API key",
        "Find your Partner ID",
        "Authenticate the API call",
        "Notes for partners who manage New Relic accounts",
        "Errors"
      ],
      "title": "Partnership API reference",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7bc374ae0e6f6917aa82a70e582606ea4a9878ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partner-api-reference/",
      "published_at": "2021-10-13T08:59:52Z",
      "updated_at": "2021-03-30T03:04:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains technical details about using the Partnership API. For an introduction and requirements, first read Intro to Partnership API. Requirements For requirements, see Intro to Partnership API. Find your Partnership API key The Partnership API requires that you authenticate with the REST API key that is specific to your partnership owner account (you cannot use the other REST API keys). When using your Partnership API key with calls to REST API (v2) endpoints that require the use of an Admin user's API key, see Admin user's API Key and partnerships. Find your Partner ID The Partnership API also requires that you authenticate by providing a Partner ID specific to your partnership. This is unique from the account ID for your partnership owner account. To obtain your Partner ID, go to your partner admin console and retrieve the partner ID number that is listed in your URL: https://partner-admin-console.newrelic.com/accounts/​$ACCOUNT_ID/admin_console/partnerships/$PARTNER_ID Copy You must include the Partner ID as part of the base URL for the Partner API. URL component URL pattern Partner API endpoint https://rpm.newrelic.com/api/v2/partners/PARTNER_ID Copy Resource URL patterns /accounts /accounts/ACCOUNT_ID /accounts/ACCOUNT_ID/users /accounts/ACCOUNT_ID/users/USER_ID /accounts/ACCOUNT_ID/subscriptions /accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Example https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Authenticate the API call To authenticate to the Partner API when making an API call: Add a request header labeled x-api-key and set its value to your Partner API key. Include your Partner ID at the specified point in the request URI. Notes for partners who manage New Relic accounts For partners who manage New Relic accounts for their customers, the initial API call for all account-level interactions is to \"create account.\" This call returns an xml record of the newly created account. Part of this record is the account_id. All of the other calls in the Partnership API require the account_id as a parameter. Provision will need to be made by the partner to parse the returned xml extract, store the account_id, and associate it with the users' partner account record. Errors New Relic uses conventional HTTP response codes to indicate success or failure of an API request. In general, codes in the 2xx range indicate success and codes in the 4xx range indicate an error that resulted from the provided information (for example, a required parameter was missing). Error Probable cause 400 Bad Request Most commonly the call is missing a required parameter. 401 Unauthorized A valid API key was not provided. 402 Request Failed Parameters were valid but request failed for some reason. 404 Not Found The requested item doesn't exist. 422 Unprocessable Entity Your account has special terms and cannot be changed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.89436,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> reference",
        "sections": "Notes for <em>partners</em> who manage <em>New</em> <em>Relic</em> accounts",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>API</em> key that is specific to your <em>partnership</em> owner account (you cannot use the other REST <em>API</em> keys). When using your <em>Partnership</em> <em>API</em> key with calls to REST <em>API</em> (v2) endpoints that require the use of an Admin user&#x27;s <em>API</em> key, see Admin user&#x27;s <em>API</em> Key and <em>partnerships</em>. Find your <em>Partner</em> ID"
      },
      "id": "603ebc5f28ccbc22b6eba780"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/product-buckets": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2021-10-13T06:00:09Z",
      "updated_at": "2021-09-14T02:59:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing plan: ignore this field because it applies to the original pricing plan, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing plan. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing plans. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing plan and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.96286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "&#x27;s subscription was downgraded. cancelled The <em>New</em> <em>Relic</em> account subscription has been cancelled. suspended The <em>New</em> <em>Relic</em> account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the <em>Partnership</em> <em>API</em>"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2021-10-13T09:01:02Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.76022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    },
    {
      "sections": [
        "Partnership billing integration API",
        "Requirements",
        "Communication endpoint",
        "Billing API",
        "Customer subscription notification API",
        "Invoice notification API"
      ],
      "title": "Partnership billing integration API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "73da7e096ce56bb45e39bb95a1c2e0a0011be597",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-03-30T21:12:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Partnership API includes functionality for partners to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts. This is particularly useful for partners acting as resellers or managed service providers of New Relic accounts. For example, when customers of a New Relic reseller partner purchase a higher subscription level from New Relic's Sales team, New Relic replaces the old subscription with a new subscription. New Relic then uses the API to communicate this information to the partner. Requirements Before using this object, please read the Partnership API requirements. Communication endpoint Partners must implement a billing communication endpoint that identifies the partner's URL and PARTNER_ID. New Relic uses this endpoint to notify the partner that New Relic has made a change to a partner account's subscription or invoice information. The endpoint must support HTTPS. The partner-specified portion of the URL is identified from the Settings tab of New Relic's Partner Portal. The PARTNER_ID is the partner's external ID for this account. This value must be passed when the account is created by using the partner_external_identifier parameter. Billing API Supported functionality for the Partnership billing API includes: Customer subscription notification Invoice information notification Customer subscription notification API To communicate changes to a partner about a customer's subscription, New Relic uses the POST method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy Authentication is done via headers with the partner's REST API key or Admin user's API key. The Partnership API returns the results as JSON. Parameters: Name Type Description id String The customer's New Relic account ID subscription_id Integer Subscription's numeric ID subscription_string String Description of subscription for display price Integer Monthly price of subscription in cents number_of_hosts Integer Number of hosts starts Date Subscription's start date (yyyymmdd) expires Date Subscription's end date (yyyymmdd) Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed. Invoice notification API New Relic uses this endpoint to notify the partner of changes to a partner account's subscription level and invoice information. New Relic uses the PUT method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy OR https://partner-specified/partner-specified/PARTNER_ID.xml Copy The Partnership API returns the results as JSON or XML. Parameters: Name Type Description id string The customer's New Relic account ID subscription_id integer Subscription's numeric ID subscription_string string Description of subscription for display price integer Monthly price of subscription in cents Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.92021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> billing integration <em>API</em>",
        "sections": "<em>Partnership</em> billing integration <em>API</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>Partnership</em> <em>API</em> includes functionality for partners to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts. This is particularly useful for partners acting as resellers or managed service providers of <em>New</em> <em>Relic</em>"
      },
      "id": "603ec86e64441f09e44e8871"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/typical-integration-example": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2021-10-13T06:00:09Z",
      "updated_at": "2021-09-14T02:59:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing plan: ignore this field because it applies to the original pricing plan, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing plan. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing plans. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing plan and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.96286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "&#x27;s subscription was downgraded. cancelled The <em>New</em> <em>Relic</em> account subscription has been cancelled. suspended The <em>New</em> <em>Relic</em> account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the <em>Partnership</em> <em>API</em>"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2021-10-13T09:01:02Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.76022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    },
    {
      "sections": [
        "Partnership billing integration API",
        "Requirements",
        "Communication endpoint",
        "Billing API",
        "Customer subscription notification API",
        "Invoice notification API"
      ],
      "title": "Partnership billing integration API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "73da7e096ce56bb45e39bb95a1c2e0a0011be597",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api/",
      "published_at": "2021-10-12T15:21:02Z",
      "updated_at": "2021-03-30T21:12:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Partnership API includes functionality for partners to replace a customer's existing subscription with a new one, or to update invoice information for New Relic partner accounts. This is particularly useful for partners acting as resellers or managed service providers of New Relic accounts. For example, when customers of a New Relic reseller partner purchase a higher subscription level from New Relic's Sales team, New Relic replaces the old subscription with a new subscription. New Relic then uses the API to communicate this information to the partner. Requirements Before using this object, please read the Partnership API requirements. Communication endpoint Partners must implement a billing communication endpoint that identifies the partner's URL and PARTNER_ID. New Relic uses this endpoint to notify the partner that New Relic has made a change to a partner account's subscription or invoice information. The endpoint must support HTTPS. The partner-specified portion of the URL is identified from the Settings tab of New Relic's Partner Portal. The PARTNER_ID is the partner's external ID for this account. This value must be passed when the account is created by using the partner_external_identifier parameter. Billing API Supported functionality for the Partnership billing API includes: Customer subscription notification Invoice information notification Customer subscription notification API To communicate changes to a partner about a customer's subscription, New Relic uses the POST method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy Authentication is done via headers with the partner's REST API key or Admin user's API key. The Partnership API returns the results as JSON. Parameters: Name Type Description id String The customer's New Relic account ID subscription_id Integer Subscription's numeric ID subscription_string String Description of subscription for display price Integer Monthly price of subscription in cents number_of_hosts Integer Number of hosts starts Date Subscription's start date (yyyymmdd) expires Date Subscription's end date (yyyymmdd) Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed. Invoice notification API New Relic uses this endpoint to notify the partner of changes to a partner account's subscription level and invoice information. New Relic uses the PUT method with this URI: https://partner-specified/partner-specified/PARTNER_ID.json Copy OR https://partner-specified/partner-specified/PARTNER_ID.xml Copy The Partnership API returns the results as JSON or XML. Parameters: Name Type Description id string The customer's New Relic account ID subscription_id integer Subscription's numeric ID subscription_string string Description of subscription for display price integer Monthly price of subscription in cents Return codes: 200: Successfully updated. 404: Account not found. 422: Missing or invalid parameters. Authentication failed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.92021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> billing integration <em>API</em>",
        "sections": "<em>Partnership</em> billing integration <em>API</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>Partnership</em> <em>API</em> includes functionality for partners to replace a customer&#x27;s existing subscription with a <em>new</em> one, or to update invoice information for <em>New</em> <em>Relic</em> <em>partner</em> accounts. This is particularly useful for partners acting as resellers or managed service providers of <em>New</em> <em>Relic</em>"
      },
      "id": "603ec86e64441f09e44e8871"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/alerts-applied-intelligence/alerts-best-practices": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-10-12T13:20:28Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.23875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.01707,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.21396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take full advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide": [
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.2069,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.39789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the <em>stack</em>, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take <em>full</em> advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2021-10-13T09:02:11Z",
      "updated_at": "2021-07-27T13:12:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\",\"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function(){ return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function(){ //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function(){ //loops through the navlinks array navlinks.foreach(function(val, i, arr){ //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function(){ //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function(){ //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }) }) }) }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.65128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its <em>full</em> power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/browser-monitoring-best-practices-guide": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-10-12T13:20:28Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.98352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.20688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.39789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the <em>stack</em>, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take <em>full</em> advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/browser-monitoring-best-practices-java": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-10-12T13:20:28Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.98352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.20688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.39789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the <em>stack</em>, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take <em>full</em> advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-10-12T13:20:28Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.9835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.39789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the <em>stack</em>, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take <em>full</em> advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2021-10-13T09:02:11Z",
      "updated_at": "2021-07-27T13:12:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\",\"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function(){ return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function(){ //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function(){ //loops through the navlinks array navlinks.foreach(function(val, i, arr){ //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function(){ //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function(){ //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }) }) }) }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.65128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its <em>full</em> power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-10-12T13:20:28Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.9835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.20688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    },
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2021-10-13T09:02:11Z",
      "updated_at": "2021-07-27T13:12:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\",\"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function(){ return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function(){ //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function(){ //loops through the navlinks array navlinks.foreach(function(val, i, arr){ //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function(){ //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function(){ //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }) }) }) }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.65128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its <em>full</em> power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-10-12T13:20:28Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.98346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.20685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-10-12T12:44:48Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.39787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the <em>stack</em>, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take <em>full</em> advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/new-relic-solutions/index": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 798.6837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the cloud and integrate cloud services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 798.6837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services&#x2F;inventory supporting these applications? 2. Install <em>New</em> <em>Relic</em> agents Based on your"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 798.6837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/cloud-adoption/modern-cloud-services": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/app-remediation-gather-performance-statistics": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/automate-instrumentation": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/customer-experience-improvement-track-experience-indicators": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/establish-objectives-baselines-define-team-slos": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/establish-team-dashboards-gather-visualize-key-metrics": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/guide-measuring-devops-success": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-learning-retrospectives": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "b2fa8c3b13350f5d7800d6fa44f6fd73155c2bd2",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T15:22:00Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with Infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com/apm > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you’re satisfied with the application’s performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with Infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "b2fa8c3b13350f5d7800d6fa44f6fd73155c2bd2",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T15:22:00Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with Infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com/apm > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you’re satisfied with the application’s performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with Infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/iterate-measure-impact-track-metrics-after-deployments": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/measure-code-pipelines": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/operations-review-assess-optimize-team-progress": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues": [
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "b2fa8c3b13350f5d7800d6fa44f6fd73155c2bd2",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T15:22:00Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with Infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com/apm > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you’re satisfied with the application’s performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with Infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/set-proactive-alerting-understand-respond-performance-issues": [
    {
      "sections": [
        "Resolve dependency risk: identify and analyze potential issues",
        "Prerequisites",
        "1. Analyze dependencies with service maps",
        "2. Identify back-end application dependency risks",
        "Tip",
        "3. Identify front-end dependency risk",
        "4. Identify Microservice Dependencies",
        "5. Create an action plan for risk mitigation"
      ],
      "title": "Resolve dependency risk: identify and analyze potential issues",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "4911ddf0c6fca572b52e22fbe464f21f0c6f338f",
      "image": "https://docs.newrelic.com/static/d1d4cf78d193ae770219cfdb9f6f792f/c1b63/distributed-trace_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/resolve-dependency-risk-identify-analyze-potential-issues/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-09-14T06:06:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Successfully scaling DevOps requires a robust understanding of dependencies across application teams and related services. Use New Relics service maps to discover and mitigate risky dependencies from upstream and downstream services. Prerequisites This tutorial assumes you’ve completed the previous DevOps procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. New Relic recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com > Service Maps > App/Service list This initial view shows all applications that are configured in your account. Applications that have violated a warning threshold are shown in yellow, and those with an active alert are shown in red. Healthy applications appear in green. New Relic uses a bold line to map applications to the services (such as databases) they connect to. Familiarize yourself with these maps to see how applications and their services fit together. Take note of which applications have the most dependencies and which rely on the same dependency, such as an API. Click an application to see high level metrics about that app, including throughput, response time, Apdex score, and error rate for the last 30 minutes. Tracking throughput is a good way to determine which of your applications are serving the most traffic. After looking at the architecture as a whole, review the applications that have the most dependencies. Select the App/Services list to see a full list of your applications. one.newrelic.com > Service Maps > App/Service list In this example, we’ve chosen Tower-Chicago from the App/Services list. All of the traffic being sent to Tower-Chicago is coming from Proxy-East. In this case, Tower-Chicago is showing 48.3 requests per minute, or 11.3% of the 426 requests per minute flowing through Proxy-East. one.newrelic.com > Service Maps > App/Service list In most cases, the separate applications and services represented in service maps are created and maintained by separate teams. This exercise of walking through the dependencies of your architecture should involve representatives from each of those teams. Teams should work together to ask questions such as: How critical is this particular dependency? What would happen if it were to go down? What happened last time it went down? Was there a revenue loss? 2. Identify back-end application dependency risks Once you’ve analyzed your applications’ dependencies, you’ll want to examine the quality of dependency execution. For example, is the dependency stable and predictable for each application or transaction you’ve identified? To do this, you’ll first need to gather as much information as you can about the applications from New Relic Insights, which helps you analyze data that is collected about the applications in more detail. Here is an example NRQL query to further analyze back-end service performance: SELECT count(appName)/30 as 'Throughput', apdex(duration), average(duration), stddev(duration), max(duration), count(error_type), uniquecount(host) FROM Transaction FACET appName SINCE 30 MINUTES AGO Copy This query shows you each application’s request per minute (throughput), Apdex score, and an overview of how the application is performing overall (through the standard deviation calculation, in which lower numbers are generally better). It also shows errors for the time period and the number of hosts on which the application is running. insights.newrelic.com > query results Next, gather information on incidents and events related to the services from New Relic Alerts: Click Alerts > Incidents > All Incidents. alerts.newrelic.com > Incidents > All Incidents Click Alerts > Events > All Events. alerts.newrelic.com > Incidents > All Events Tip Using webhooks to send alert events to New Relic Insights, allows you to supplement your dashboards with Alerts data. The process is outlined in this community discussion post. Here is a simplified example of the results of this exercise: Application Number of dependencies RPM Hosts APDEX (avg) Last outage TTR (hrs) Routing Service 10 983 4 .93 2/19/18 .75 Tower Austin 1 58 1 .95 10/11/17 1.5 Proxy-East 11 498 4 .92 1/4/18 .25 Proxy-West 11 495 4 .97 12/3/17 .25 WebPortal 7 396 8 .98 4/1/18 2.5 Supplement this data with the data that your teams know about your service and that you gathered from the dependency exercise in step 1, and use that data to develop hypotheses about the highest risk areas in your services that should be mitigated. 3. Identify front-end dependency risk Once you’ve analyzed back-end dependencies, explore front-end dependencies. This is a critical step because as you walk higher up the stack and closer to the user, you will likely have more dependencies and abstractions. Service maps seamlessly integrate data from browser monitoring and mobile monitoring to help you understand the dependencies from front-end user interfaces to back-end services. one.newrelic.com > Service Maps Use the service map view to drill into front-end dependencies, and execute a similar exercise to the one you executed for back-end dependencies. This exercise will again expose data to help you identify risk areas you should address and optimize. We recommend that you conduct the analysis with user interface (UI) teams so that you can also gather a complementary qualitative understanding of what the UI teams consider critical based on their experience. A ranking from the UI teams of the most critical dependency is a useful output of this work. 4. Identify Microservice Dependencies If you are using microservices, you can have dozens, if not hundreds, of services that are calling each other. Use Distributed Tracing to see how all those services connect together and how your requests flow through those different services. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. A distributed trace is composed of multiple \"spans,\" which represent time spent in services or resources of those services. Click on the Distributed tracing menu in APM left nav. You can see “trace listing” view where you’ll be able to quickly identify slow traces and traces with errors. The scatter plot lets you easily see outliers. Below that are the trace summaries, click on a trace to see details. Dive into distributed traces to see how long each span takes. Click into each span to see historical performance charts and associated attributes that layer in the context you need to understand and troubleshoot issues. one.newrelic.com > APM > (select an app) > Distributed tracing This rounds out your list of dependencies. 5. Create an action plan for risk mitigation Once you’ve analyzed the dependencies across your application from both front-end and back-end services, create an action plan to reduce dependency risks and achieve your service level objectives (SLO). As you prioritize these next steps, we recommend you keep these four principles in mind: Understand your risk tolerance. It’s helpful to have a clear picture of your tolerance for risk, which ideally should be informed by your service level objectives (refer to the Establish Objectives and Baselines tutorial for more information). Set an alert policy to monitor dependencies that you’ve determined have a high relationship to SLO achievement. Minimize dependencies. The simpler you keep your code, the less functions you'll have referring to other modules. Removing unnecessary complexity is an important way to ensure you have a maintainable system that meets your customers’ expectations. Localize dependencies. For the code you write, package together functions that depend on each other whenever possible. Stabilize dependencies. When dependencies are unavoidable, mitigate risks by ensuring these dependencies point to modules that are the least likely to change or are easier to substitute. When your action plan is complete, monitor the results of the efforts. The efficacy of your actions to resolve dependency risks should ultimately be measured by your SLOs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " <em>DevOps</em> procedures. 1. Analyze dependencies with service maps Use service maps for each application and note any dependent systems and transactions. <em>New</em> <em>Relic</em> recommends that you start by viewing the entire architecture using the Discover your environment option. one.newrelic.com &gt; Service Maps"
      },
      "id": "60440f13e7b9d2ec025799f0"
    },
    {
      "sections": [
        "Infrastructure resource sizing: analyze operation metrics",
        "Prerequisites",
        "1. Evaluate your environment's current efficiency",
        "2. Identify underutilized hosts and applications",
        "3. Use the Cloud Optimize Nerdpack"
      ],
      "title": "Infrastructure resource sizing: analyze operation metrics",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "228d1ac787a62c7a0719603da0d58754765fd0cc",
      "image": "https://docs.newrelic.com/static/7826dfb3da5f454137c3b4cb8c6c311a/c1b63/new-relic-cloud-optimize-nerdpack.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/infrastructure-resource-sizing-analyze-operation-metrics/",
      "published_at": "2021-10-12T11:53:05Z",
      "updated_at": "2021-09-14T06:05:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Analyzing metrics collected by New Relic Infrastructure allows you to uncover opportunities to optimize your organization's operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using too many resources can lead to unneeded costs. For example, you may find that you can redistribute application instances to hosts that have extra memory and CPU resources, and terminate or repurpose the hosts those instances came from. Use Infrastructure to ensure that your team is providing the right amount of compute power to meet customer expectations at appropriate costs. Prerequisites This tutorial assumes you have reviewed New Relic's Establish objectives and baselines tutorial. 1. Evaluate your environment's current efficiency Use the Cluster Explorer to observe performance and dependencies across any Kubernetes environment, and to troubleshoot failures, bottlenecks, and other abnormal behavior—helping ensure that their applications are always available, running fast, and doing what they’re supposed to do. You get an overall view of the health of each cluster, and can drill down as needed for details on the state of a Kubernetes object, including a view of key metrics and logs. Start at the outer ring to view nodes of the cluster, with each node displaying CPU, memory, and storage performance metrics that provide at-a-glance understanding of the node’s overall health. Specify a lower and upper RAM and CPU limits for each container using requests and limits. one.newrelic.com > Infrastructure > Hosts: To evaluate your operating environment's efficiency, review the Infrastructure metrics (including averages that show as dotted lines), watch for outliers, and expand and sort the table's Memory used column. If you are using on-premise hosts (or Docker without Kubernetes), you can see the health of your hosts and containers in Infrastructure. Again, focus on CPU %, Load Average and Memory Used %. These metrics provide a good overview of your environment’s capacity. 2. Identify underutilized hosts and applications As you identify hosts that have extra capacity, start with memory usage, as that is a common limiting factor: From the Infrastructure Hosts page, expand [Expand icon] the table, then sort the Memory used column in descending order. To identify good redistribution candidates, look for hosts using a small amount of memory that have a small number of applications deployed on them. Also consider the health of an application before moving it to a different host. To ensure that an application has predictable performance, use APM. From the APM Overview page, track metrics for Apdex (user satisfaction) and average response time for transactions. Review other app performance details from the APM UI. Stabilize applications that are volatile before introducing other variables into their runtime performance. 3. Use the Cloud Optimize Nerdpack Cloud Optimize analyzes your cloud environment using the New Relic Infrastructure cloud integrations(for AWS, GCP, Azure and Alibaba). It compares the size of your instances to their utilization, identifying resources that are sized larger than needed. Cloud Optimize will estimate your savings by optimizing resource size. Installation details are on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.45624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "Analyzing metrics collected by <em>New</em> <em>Relic</em> Infrastructure allows you to uncover opportunities to optimize your organization&#x27;s operating environment, whether it is a physical datacenter or thousands of instances. Using too few resources in key areas can lead to errors or performance problems. Using"
      },
      "id": "604415a7e7b9d2b47d579a25"
    },
    {
      "sections": [
        "Incident orchestration: Align teams, tools, processes",
        "Prerequisites",
        "1. Assign first responders to team dashboards",
        "2. Determine incident thresholds for alert conditions",
        "3. Ensure alerts have auditable notification channels",
        "4. Automate triage and resolution steps"
      ],
      "title": "Incident orchestration: Align teams, tools, processes",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6e53e68e2bb4a9824bb361f816bbac2cfd113875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-devops-success/incident-orchestration-align-teams-tools-processes/",
      "published_at": "2021-10-12T11:53:04Z",
      "updated_at": "2021-09-14T06:05:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident orchestration is the alignment of teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites Before starting this tutorial, be sure to complete these New Relic tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as \"pager duty\"). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 2. Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. As you create alert policies with New Relic Alerts, make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 3. Ensure alerts have auditable notification channels Recommendation: Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 4. Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for some common ticketing systems. You can use any of the available integrations to file tickets from APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": ". Prerequisites Before starting this tutorial, be sure to complete these <em>New</em> <em>Relic</em> tutorials: Establish team dashboards Set up proactive alerting 1. Assign first responders to team dashboards Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health"
      },
      "id": "604415a728ccbc26bb2c60bc"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services": [
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-10-12T12:12:51Z",
      "updated_at": "2021-09-14T06:09:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for common ticketing systems. You can use any of these integrations to file tickets from APM. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example questions and KPI <em>solutions</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " alerts and thresholds As you use <em>New</em> <em>Relic</em> to <em>optimize</em> <em>your</em> application and infrastructure performance, tighten <em>your</em> <em>New</em> <em>Relic</em> Alerts policy conditions to keep pace with <em>your</em> improved performance. When rolling out <em>new</em> code or modifications that could negatively impact performance over a period of time"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    },
    {
      "sections": [
        "Iterate and measure impact: Track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: Track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "64fab5d31ae90da92debca9bc0eb802ebe731c2b",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T12:19:02Z",
      "updated_at": "2021-09-14T06:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proper instrumentation gives teams full visibility into the impact of the changes they make in a system. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation and reduce the impact to other work happening in the system. Prerequisite Before starting this tutorial, complete the Establish objectives and baselines. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they're consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make across them are correct, and eliminate any anomalies before pushing code to production. Beyond using instrumentation to measure software performance, also use it to analyze team efficiency. For example, with your alerts data, use NRQL and external integrations to calculate mean time to repair (MTTR) by subtracting the difference in event timestamps as the current state of each event changes from OPEN to ACKNOWLEDGED to CLOSED. Or push events into Insights from a source code management (SCM) system like GitHub, and calculate the amount of time it takes a code change to go live by comparing the timestamp of a commit event to that of a deploy event. Plotted over time, this could become a KPI in a DevOps transformation. 2. Add automated deployment markers It's important to track deployments and the impact code and infrastructure changes have on your end-user experience. Using deployment markers in APM, you can record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (for example, the user, revision, or change-log). APM displays a vertical line, or “marker,” on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application. Additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is a valuable way to determine the root cause of immediate, long-term, or gradual degradations in your application. New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test your pipeline with Infrastructure An important part of optimizing your cloud native environment is a making a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names, which is a good fit for this model. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.3379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test <em>your</em> pipeline with Infrastructure An important part of optimizing <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em> is a making a cultural shift toward smaller, more frequent changes to <em>your</em> code and infrastructure. After you"
      },
      "id": "603ebdad196a67b212a83ded"
    },
    {
      "sections": [
        "Optimize cloud architecture and spend to continuously improve your modern cloud environment",
        "1. Instrument your application and cloud environment",
        "2. Create dashboards to display baseline infrastructure metrics; include AWS budgets if available",
        "Create dashboards for each level of your organization",
        "3. Identify resources for optimization",
        "4. Optional: Set up alerts",
        "Baseline queries",
        "Lean More"
      ],
      "title": "Optimize cloud architecture and spend to continuously improve your modern cloud environment",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "a39e5f962beb7ac37d876516d0d6ddb03f3888ec",
      "image": "https://docs.newrelic.com/static/3e068d910ba2857ad60a1b9c4af0a52d/4d383/image-1.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/optimize-cloud-architecture-spend-continuously-improve-your-modern-cloud-environment/",
      "published_at": "2021-10-12T12:05:21Z",
      "updated_at": "2021-08-02T21:54:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the cloud, it's important to look regularly and closely at how your applications and services are architected and utilized. It's the best way to identify opportunities that will let you right-size your instances, fine tune your databases, modify your storage usage, better configure your load balancers, or even re-architect your applications. For example, if you have a set of 20 instances all running at 10% CPU usage, you might consider using smaller instances or consolidating more work onto those instances. This kind of thinking about your cloud utilization and spend will help you optimize your environment and save money quickly. Optimizing your cloud architecture has three main goals: Improve performance, availability, and end-user experience by taking better advantage of cloud services Optimize your cloud spend, striking the delicate balance between cost and performance Capture business and technical metrics that help justify your current cloud spend that can be referenced as justification for a larger cloud budget as growth dictates In this tutorial, we'll show you how to use the New Relic platform to capture all the data you should leverage to optimize your cloud architecture and spend. 1. Instrument your application and cloud environment Make sure the following products and integrations are instrumented: Instrument Details Install Infrastructure Instrument infrastructure: If you haven't already done so, review the requirements for the Infrastructure agent. Infrastructure comes with several types of integrations, including Amazon Web Services (AWS), Microsoft Azure, and on-host integrations. After you've installed the Infrastructure agent on your host(s), you'll immediately have access to the broad spectrum of metrics the agent collects out-of-the-box. Install the APM agent Instrument your applications with APM. Doing so will let you monitor how your applications are performing while you are optimizing the underlying cloud services. That way, you can confirm that your changes to the infrastructure are in fact improving application performance. Configure the AWS integration New Relic Infrastructure's Amazon integrations let you monitor your AWS data in several New Relic products, including Infrastructure, dashboards, and New Relic Alerts. Connect AWS Billing If you are hosted in an AWS environment, New Relic can help you monitor your cloud spend with our AWS Billing integration. To leverage New Relic's AWS Billing integration, follow the procedures in the Connect AWS Billing documentation 2. Create dashboards to display baseline infrastructure metrics; include AWS budgets if available Dashboards lets you write powerful custom queries about your data and visualize the results in widgets displayed on a common dashboard. You can also feed the results of your queries directly into New Relic Alerts, where you can get immediate notifications on any deviation identified. For this step, you should display baseline infrastructure metrics related to performance and usage (CPU, memory, disk, database, etc.). Include AWS Budgets if available. To get you started, here are ways to use Insights dashboards to visualize your AWS cloud utilization and spend data: This dashboard shows data broken out by the applications and budgets you set up in the AWS budgeting area. Create individual dashboards for each application, and then collect those dashboards into a single “data app,” as shown here. This AWS Production Overview data app displays a set of widgets relevant to an AWS production budget. Data apps are great for presentations where you want to step through a series of topics and also provide a clear overview of an entire environment or service. Create dashboards for each level of your organization Whether you're a developer, operator, or executive, having information about your cloud utilization can help you optimize your cloud environment: Developers: Understanding what applications currently cost can help developers configure applications to use more services more efficiently. For example, could developers cut cloud costs using AWS Lambda or properly sized instances? Operators: Monitoring application utilization allows operators to catch possible overruns due to mis-configured services. For example, is the ops team's auto-scaling configuration scaling down properly? Executives: An overall view of both fore-casted and actual cloud spend, for individual applications, per region, and overall totals, can help executives make better business decisions. Use New Relic to keep track of your cloud spend, and make sure your teams get alerted immediately when you exceed thresholds. 3. Identify resources for optimization This step shows you how to use the metrics New Relic has captured to determine which resources to optimize. In the sample dashboard above, the CPU-usage widget on the left reveals that this application uses many instances sizes. Note that the “c4.xlarge” instance (in coral) consistently consumes only around 20% CPU capacity. However, when you analyze the c4.xlarge Memory usage in the center widget (light green), you'll see that memory usage for this instance ranges from 20% to 80%. This suggests that the application is more memory-intensive than CPU-intensive. In this case, the instance type should be changed from a compute-optimized instance to one that is memory-optimized. (Note: the chart on the right of the dashboard can be used to monitor the application's average response time as you make these optimizations.) This is just one example of how to identify cloud-based resources that could be candidates for optimization. Now that you've identified architecture for optimization, go ahead and do so. Whether you right-size your instances, fine tune your databases, modify your storage usage, better configure your load balancers, or even re-architect your applications, in the end your goal is to be able to compare your new, optimized architecture against the baselines you captured in Step 2. For more about baselines please review the Establish Objectives & Baselines tutorial. 4. Optional: Set up alerts You can create an alert condition for NRQL queries. Be sure to reference the complete documentation as needed. In the data app for the AWS production budget introduced in Step 2, this was one of the widgets: Here is the query that we used to create that widget: SELECT latest(`provider.actualAmount`) as '$ Actual', latest(`provider.forecastedAmount`) as '$ Forecast', max(`provider.limitAmount`) as '$ Limit' FROM FinanceSample WHERE provider = 'BillingBudget' AND `provider.budgetName` = '[Your Cloud Budget]' Copy If you can write queries on your data and show them in Insights, then you can easily use them to generate Alert conditions. Baseline queries New Relic also lets you write “baseline queries” against your data. These are queriesy you write without setting hard limits on the results. Rather, you let New Relic Applied Intelligence “machine-learn” your performance data, and then alert you when your data strays too far outside of your baseline numbers. To create a baseline query, head over the the Alert console, go into Alert policies, and add a New alert policy. Then follow these steps: Create alert policy. Give your policy a concise and descriptive name and select an Incident Preference. Then select Create alert policy. Create a condition. Select NRQL Define your query, and decide how restrictively Applied Intelligence should analyze your data using a simple slider and visualization based on your recent performance. The slider at the bottom of the chart either increases or decreases the gray band around your budget threshold (the blue line). The setting shown would have resulted in zero violations based on recent data, and that is what you're looking for. However, if that blue line spikes up or down out of the gray band, New Relic will immediately notify you. Using New Relic Applied Intelligence is a great way to help you proactively learn about your cloud spending or about any of your performance data. Lean More Review the Proactive alerting and incident orchestration tutorial for a deeper dive on some of the best practices outlined above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.0233,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Optimize</em> <em>cloud</em> architecture and spend to continuously improve <em>your</em> modern <em>cloud</em> <em>environment</em>",
        "sections": "<em>Optimize</em> <em>cloud</em> architecture and spend to continuously improve <em>your</em> modern <em>cloud</em> <em>environment</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " business and technical metrics that help justify <em>your</em> current <em>cloud</em> spend that can be referenced as justification for a larger <em>cloud</em> budget as growth dictates In this tutorial, we&#x27;ll show you how to use the <em>New</em> <em>Relic</em> platform to capture all the data you should leverage to <em>optimize</em> <em>your</em> <em>cloud</em>"
      },
      "id": "603ebf4964441f4bfa4e8841"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/analyze-distributed-systems": [
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-10-12T12:12:51Z",
      "updated_at": "2021-09-14T06:09:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for common ticketing systems. You can use any of these integrations to file tickets from APM. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example questions and KPI <em>solutions</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " alerts and thresholds As you use <em>New</em> <em>Relic</em> to <em>optimize</em> <em>your</em> application and infrastructure performance, tighten <em>your</em> <em>New</em> <em>Relic</em> Alerts policy conditions to keep pace with <em>your</em> improved performance. When rolling out <em>new</em> code or modifications that could negatively impact performance over a period of time"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    },
    {
      "sections": [
        "Adopt cloud services",
        "1. Identify services and technologies",
        "2. Deploy New Relic Infrastructure",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "Tip",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD pipeline integration",
        "8. AWS Lambda Monitoring"
      ],
      "title": "Adopt cloud services",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "4a8e675e4231295287e69402c8c5ff9b05a6103b",
      "image": "https://docs.newrelic.com/static/4159294d05ee078268a7b287af99a72f/c1b63/adopt_cloud.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services/",
      "published_at": "2021-10-12T12:36:54Z",
      "updated_at": "2021-09-14T06:08:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've recently completed your cloud migration, have been using cloud-based services for a while, or have always been in the cloud, you may find yourself deploying modern, cutting-edge technologies and services. It's important to develop the ability to adopt new services easily and with confidence; innovation never stops for companies operating in the cloud, and a company's willingness to embrace new technology can give it a major competitive differentiator. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate, for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions. They may be cloud-based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations, you want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services. This allows your team to deploy faster, to adopt new services with confidence, to make better business decisions, and in general to expand its technology horizons. Here are the steps to using the New Relic Platform to monitor your modern technologies and cloud services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies and new services that might impact your organization's application environment. 2. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified in Step One so that you can monitor your cloud services. If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations As you integrate new cloud services, you can use New Relic to monitor and report data about these services; giving you a single, comprehensive overview of your entire architecture. To configure cloud service integrations, link your Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) service provider account with New Relic. 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. one.newrelic.com > Infrastructure > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of an Insights dashboard with data about vendors, technologies, services, instances, and other important details for DevOps teams. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all changes to a system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all AWS Elastic Load Balancing (ALB) systems for the ALB monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring For full-stack visibility into every aspect of your app, we recommend deploying other types of New Relic monitoring: Use APM to report application-tier performance metrics. Use browser monitoring to report front-end web metrics. Use mobile monitoring to report front-end mobile app metrics. Use synthetic monitoring to monitor websites, critical business transactions, and API endpoints. 7. CI/CD pipeline integration It's important to track deployments and the impact that code and infrastructure changes have on your end-user experience. APM deployment markers allow you to record deployments for each application. A deployment marker is an event indicating that a deployment happened. You can pair markers with metadata from your source code management (SCM) system ( including user IDs, revisions, and change logs.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root causes of immediate, long-term, or gradual degradations in your applications. Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment, as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible Puppet 8. AWS Lambda Monitoring New Relic One features an updated APM agent that is highly optimized from a cost and time perspective for ephemeral Lambda functions. Enable New Relic monitoring of AWS Lambda to to assess invocations, error rate, function duration, cold starts, and more. You can also take advantage of New Relic's Infrastructure integration with Lambda for additional reporting capabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.3379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Adopt <em>cloud</em> services",
        "sections": "2. Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " the <em>New</em> <em>Relic</em> Platform to monitor <em>your</em> modern technologies and <em>cloud</em> services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What <em>cloud</em>-based applications do I have? What are the underlying <em>cloud</em>-based services, technologies"
      },
      "id": "603ebf09e7b9d2071a2a0806"
    },
    {
      "sections": [
        "Iterate and measure impact: Track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: Track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "64fab5d31ae90da92debca9bc0eb802ebe731c2b",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T12:19:02Z",
      "updated_at": "2021-09-14T06:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proper instrumentation gives teams full visibility into the impact of the changes they make in a system. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation and reduce the impact to other work happening in the system. Prerequisite Before starting this tutorial, complete the Establish objectives and baselines. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they're consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make across them are correct, and eliminate any anomalies before pushing code to production. Beyond using instrumentation to measure software performance, also use it to analyze team efficiency. For example, with your alerts data, use NRQL and external integrations to calculate mean time to repair (MTTR) by subtracting the difference in event timestamps as the current state of each event changes from OPEN to ACKNOWLEDGED to CLOSED. Or push events into Insights from a source code management (SCM) system like GitHub, and calculate the amount of time it takes a code change to go live by comparing the timestamp of a commit event to that of a deploy event. Plotted over time, this could become a KPI in a DevOps transformation. 2. Add automated deployment markers It's important to track deployments and the impact code and infrastructure changes have on your end-user experience. Using deployment markers in APM, you can record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (for example, the user, revision, or change-log). APM displays a vertical line, or “marker,” on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application. Additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is a valuable way to determine the root cause of immediate, long-term, or gradual degradations in your application. New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test your pipeline with Infrastructure An important part of optimizing your cloud native environment is a making a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names, which is a good fit for this model. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.3379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test <em>your</em> pipeline with Infrastructure An important part of optimizing <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em> is a making a cultural shift toward smaller, more frequent changes to <em>your</em> code and infrastructure. After you"
      },
      "id": "603ebdad196a67b212a83ded"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/customer-experience-improvement-track-experience-indicators": [
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-10-12T12:12:51Z",
      "updated_at": "2021-09-14T06:09:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for common ticketing systems. You can use any of these integrations to file tickets from APM. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example questions and KPI <em>solutions</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " alerts and thresholds As you use <em>New</em> <em>Relic</em> to <em>optimize</em> <em>your</em> application and infrastructure performance, tighten <em>your</em> <em>New</em> <em>Relic</em> Alerts policy conditions to keep pace with <em>your</em> improved performance. When rolling out <em>new</em> code or modifications that could negatively impact performance over a period of time"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    },
    {
      "sections": [
        "Adopt cloud services",
        "1. Identify services and technologies",
        "2. Deploy New Relic Infrastructure",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "Tip",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD pipeline integration",
        "8. AWS Lambda Monitoring"
      ],
      "title": "Adopt cloud services",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "4a8e675e4231295287e69402c8c5ff9b05a6103b",
      "image": "https://docs.newrelic.com/static/4159294d05ee078268a7b287af99a72f/c1b63/adopt_cloud.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services/",
      "published_at": "2021-10-12T12:36:54Z",
      "updated_at": "2021-09-14T06:08:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've recently completed your cloud migration, have been using cloud-based services for a while, or have always been in the cloud, you may find yourself deploying modern, cutting-edge technologies and services. It's important to develop the ability to adopt new services easily and with confidence; innovation never stops for companies operating in the cloud, and a company's willingness to embrace new technology can give it a major competitive differentiator. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate, for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions. They may be cloud-based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations, you want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services. This allows your team to deploy faster, to adopt new services with confidence, to make better business decisions, and in general to expand its technology horizons. Here are the steps to using the New Relic Platform to monitor your modern technologies and cloud services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies and new services that might impact your organization's application environment. 2. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified in Step One so that you can monitor your cloud services. If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations As you integrate new cloud services, you can use New Relic to monitor and report data about these services; giving you a single, comprehensive overview of your entire architecture. To configure cloud service integrations, link your Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) service provider account with New Relic. 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. one.newrelic.com > Infrastructure > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of an Insights dashboard with data about vendors, technologies, services, instances, and other important details for DevOps teams. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all changes to a system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all AWS Elastic Load Balancing (ALB) systems for the ALB monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring For full-stack visibility into every aspect of your app, we recommend deploying other types of New Relic monitoring: Use APM to report application-tier performance metrics. Use browser monitoring to report front-end web metrics. Use mobile monitoring to report front-end mobile app metrics. Use synthetic monitoring to monitor websites, critical business transactions, and API endpoints. 7. CI/CD pipeline integration It's important to track deployments and the impact that code and infrastructure changes have on your end-user experience. APM deployment markers allow you to record deployments for each application. A deployment marker is an event indicating that a deployment happened. You can pair markers with metadata from your source code management (SCM) system ( including user IDs, revisions, and change logs.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root causes of immediate, long-term, or gradual degradations in your applications. Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment, as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible Puppet 8. AWS Lambda Monitoring New Relic One features an updated APM agent that is highly optimized from a cost and time perspective for ephemeral Lambda functions. Enable New Relic monitoring of AWS Lambda to to assess invocations, error rate, function duration, cold starts, and more. You can also take advantage of New Relic's Infrastructure integration with Lambda for additional reporting capabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.3379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Adopt <em>cloud</em> services",
        "sections": "2. Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " the <em>New</em> <em>Relic</em> Platform to monitor <em>your</em> modern technologies and <em>cloud</em> services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What <em>cloud</em>-based applications do I have? What are the underlying <em>cloud</em>-based services, technologies"
      },
      "id": "603ebf09e7b9d2071a2a0806"
    },
    {
      "sections": [
        "Iterate and measure impact: Track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: Track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "64fab5d31ae90da92debca9bc0eb802ebe731c2b",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T12:19:02Z",
      "updated_at": "2021-09-14T06:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proper instrumentation gives teams full visibility into the impact of the changes they make in a system. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation and reduce the impact to other work happening in the system. Prerequisite Before starting this tutorial, complete the Establish objectives and baselines. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they're consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make across them are correct, and eliminate any anomalies before pushing code to production. Beyond using instrumentation to measure software performance, also use it to analyze team efficiency. For example, with your alerts data, use NRQL and external integrations to calculate mean time to repair (MTTR) by subtracting the difference in event timestamps as the current state of each event changes from OPEN to ACKNOWLEDGED to CLOSED. Or push events into Insights from a source code management (SCM) system like GitHub, and calculate the amount of time it takes a code change to go live by comparing the timestamp of a commit event to that of a deploy event. Plotted over time, this could become a KPI in a DevOps transformation. 2. Add automated deployment markers It's important to track deployments and the impact code and infrastructure changes have on your end-user experience. Using deployment markers in APM, you can record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (for example, the user, revision, or change-log). APM displays a vertical line, or “marker,” on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application. Additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is a valuable way to determine the root cause of immediate, long-term, or gradual degradations in your application. New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test your pipeline with Infrastructure An important part of optimizing your cloud native environment is a making a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names, which is a good fit for this model. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test <em>your</em> pipeline with Infrastructure An important part of optimizing <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em> is a making a cultural shift toward smaller, more frequent changes to <em>your</em> code and infrastructure. After you"
      },
      "id": "603ebdad196a67b212a83ded"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/guide-optimizing-your-cloud-native-environment": [
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-10-12T12:12:51Z",
      "updated_at": "2021-09-14T06:09:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for common ticketing systems. You can use any of these integrations to file tickets from APM. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example questions and KPI <em>solutions</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " alerts and thresholds As you use <em>New</em> <em>Relic</em> to <em>optimize</em> <em>your</em> application and infrastructure performance, tighten <em>your</em> <em>New</em> <em>Relic</em> Alerts policy conditions to keep pace with <em>your</em> improved performance. When rolling out <em>new</em> code or modifications that could negatively impact performance over a period of time"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    },
    {
      "sections": [
        "Adopt cloud services",
        "1. Identify services and technologies",
        "2. Deploy New Relic Infrastructure",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "Tip",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD pipeline integration",
        "8. AWS Lambda Monitoring"
      ],
      "title": "Adopt cloud services",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "4a8e675e4231295287e69402c8c5ff9b05a6103b",
      "image": "https://docs.newrelic.com/static/4159294d05ee078268a7b287af99a72f/c1b63/adopt_cloud.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services/",
      "published_at": "2021-10-12T12:36:54Z",
      "updated_at": "2021-09-14T06:08:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've recently completed your cloud migration, have been using cloud-based services for a while, or have always been in the cloud, you may find yourself deploying modern, cutting-edge technologies and services. It's important to develop the ability to adopt new services easily and with confidence; innovation never stops for companies operating in the cloud, and a company's willingness to embrace new technology can give it a major competitive differentiator. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate, for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions. They may be cloud-based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations, you want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services. This allows your team to deploy faster, to adopt new services with confidence, to make better business decisions, and in general to expand its technology horizons. Here are the steps to using the New Relic Platform to monitor your modern technologies and cloud services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies and new services that might impact your organization's application environment. 2. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified in Step One so that you can monitor your cloud services. If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations As you integrate new cloud services, you can use New Relic to monitor and report data about these services; giving you a single, comprehensive overview of your entire architecture. To configure cloud service integrations, link your Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) service provider account with New Relic. 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. one.newrelic.com > Infrastructure > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of an Insights dashboard with data about vendors, technologies, services, instances, and other important details for DevOps teams. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all changes to a system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all AWS Elastic Load Balancing (ALB) systems for the ALB monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring For full-stack visibility into every aspect of your app, we recommend deploying other types of New Relic monitoring: Use APM to report application-tier performance metrics. Use browser monitoring to report front-end web metrics. Use mobile monitoring to report front-end mobile app metrics. Use synthetic monitoring to monitor websites, critical business transactions, and API endpoints. 7. CI/CD pipeline integration It's important to track deployments and the impact that code and infrastructure changes have on your end-user experience. APM deployment markers allow you to record deployments for each application. A deployment marker is an event indicating that a deployment happened. You can pair markers with metadata from your source code management (SCM) system ( including user IDs, revisions, and change logs.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root causes of immediate, long-term, or gradual degradations in your applications. Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment, as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible Puppet 8. AWS Lambda Monitoring New Relic One features an updated APM agent that is highly optimized from a cost and time perspective for ephemeral Lambda functions. Enable New Relic monitoring of AWS Lambda to to assess invocations, error rate, function duration, cold starts, and more. You can also take advantage of New Relic's Infrastructure integration with Lambda for additional reporting capabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.3379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Adopt <em>cloud</em> services",
        "sections": "2. Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " the <em>New</em> <em>Relic</em> Platform to monitor <em>your</em> modern technologies and <em>cloud</em> services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What <em>cloud</em>-based applications do I have? What are the underlying <em>cloud</em>-based services, technologies"
      },
      "id": "603ebf09e7b9d2071a2a0806"
    },
    {
      "sections": [
        "Iterate and measure impact: Track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: Track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "64fab5d31ae90da92debca9bc0eb802ebe731c2b",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T12:19:02Z",
      "updated_at": "2021-09-14T06:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proper instrumentation gives teams full visibility into the impact of the changes they make in a system. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation and reduce the impact to other work happening in the system. Prerequisite Before starting this tutorial, complete the Establish objectives and baselines. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they're consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make across them are correct, and eliminate any anomalies before pushing code to production. Beyond using instrumentation to measure software performance, also use it to analyze team efficiency. For example, with your alerts data, use NRQL and external integrations to calculate mean time to repair (MTTR) by subtracting the difference in event timestamps as the current state of each event changes from OPEN to ACKNOWLEDGED to CLOSED. Or push events into Insights from a source code management (SCM) system like GitHub, and calculate the amount of time it takes a code change to go live by comparing the timestamp of a commit event to that of a deploy event. Plotted over time, this could become a KPI in a DevOps transformation. 2. Add automated deployment markers It's important to track deployments and the impact code and infrastructure changes have on your end-user experience. Using deployment markers in APM, you can record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (for example, the user, revision, or change-log). APM displays a vertical line, or “marker,” on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application. Additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is a valuable way to determine the root cause of immediate, long-term, or gradual degradations in your application. New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test your pipeline with Infrastructure An important part of optimizing your cloud native environment is a making a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names, which is a good fit for this model. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test <em>your</em> pipeline with Infrastructure An important part of optimizing <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em> is a making a cultural shift toward smaller, more frequent changes to <em>your</em> code and infrastructure. After you"
      },
      "id": "603ebdad196a67b212a83ded"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments": [
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-10-12T12:12:51Z",
      "updated_at": "2021-09-14T06:09:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for common ticketing systems. You can use any of these integrations to file tickets from APM. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example questions and KPI <em>solutions</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " alerts and thresholds As you use <em>New</em> <em>Relic</em> to <em>optimize</em> <em>your</em> application and infrastructure performance, tighten <em>your</em> <em>New</em> <em>Relic</em> Alerts policy conditions to keep pace with <em>your</em> improved performance. When rolling out <em>new</em> code or modifications that could negatively impact performance over a period of time"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    },
    {
      "sections": [
        "Adopt cloud services",
        "1. Identify services and technologies",
        "2. Deploy New Relic Infrastructure",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "Tip",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD pipeline integration",
        "8. AWS Lambda Monitoring"
      ],
      "title": "Adopt cloud services",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "4a8e675e4231295287e69402c8c5ff9b05a6103b",
      "image": "https://docs.newrelic.com/static/4159294d05ee078268a7b287af99a72f/c1b63/adopt_cloud.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services/",
      "published_at": "2021-10-12T12:36:54Z",
      "updated_at": "2021-09-14T06:08:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've recently completed your cloud migration, have been using cloud-based services for a while, or have always been in the cloud, you may find yourself deploying modern, cutting-edge technologies and services. It's important to develop the ability to adopt new services easily and with confidence; innovation never stops for companies operating in the cloud, and a company's willingness to embrace new technology can give it a major competitive differentiator. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate, for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions. They may be cloud-based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations, you want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services. This allows your team to deploy faster, to adopt new services with confidence, to make better business decisions, and in general to expand its technology horizons. Here are the steps to using the New Relic Platform to monitor your modern technologies and cloud services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies and new services that might impact your organization's application environment. 2. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified in Step One so that you can monitor your cloud services. If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations As you integrate new cloud services, you can use New Relic to monitor and report data about these services; giving you a single, comprehensive overview of your entire architecture. To configure cloud service integrations, link your Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) service provider account with New Relic. 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. one.newrelic.com > Infrastructure > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of an Insights dashboard with data about vendors, technologies, services, instances, and other important details for DevOps teams. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all changes to a system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all AWS Elastic Load Balancing (ALB) systems for the ALB monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring For full-stack visibility into every aspect of your app, we recommend deploying other types of New Relic monitoring: Use APM to report application-tier performance metrics. Use browser monitoring to report front-end web metrics. Use mobile monitoring to report front-end mobile app metrics. Use synthetic monitoring to monitor websites, critical business transactions, and API endpoints. 7. CI/CD pipeline integration It's important to track deployments and the impact that code and infrastructure changes have on your end-user experience. APM deployment markers allow you to record deployments for each application. A deployment marker is an event indicating that a deployment happened. You can pair markers with metadata from your source code management (SCM) system ( including user IDs, revisions, and change logs.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root causes of immediate, long-term, or gradual degradations in your applications. Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment, as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible Puppet 8. AWS Lambda Monitoring New Relic One features an updated APM agent that is highly optimized from a cost and time perspective for ephemeral Lambda functions. Enable New Relic monitoring of AWS Lambda to to assess invocations, error rate, function duration, cold starts, and more. You can also take advantage of New Relic's Infrastructure integration with Lambda for additional reporting capabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Adopt <em>cloud</em> services",
        "sections": "2. Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " the <em>New</em> <em>Relic</em> Platform to monitor <em>your</em> modern technologies and <em>cloud</em> services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What <em>cloud</em>-based applications do I have? What are the underlying <em>cloud</em>-based services, technologies"
      },
      "id": "603ebf09e7b9d2071a2a0806"
    },
    {
      "sections": [
        "Optimize cloud architecture and spend to continuously improve your modern cloud environment",
        "1. Instrument your application and cloud environment",
        "2. Create dashboards to display baseline infrastructure metrics; include AWS budgets if available",
        "Create dashboards for each level of your organization",
        "3. Identify resources for optimization",
        "4. Optional: Set up alerts",
        "Baseline queries",
        "Lean More"
      ],
      "title": "Optimize cloud architecture and spend to continuously improve your modern cloud environment",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "a39e5f962beb7ac37d876516d0d6ddb03f3888ec",
      "image": "https://docs.newrelic.com/static/3e068d910ba2857ad60a1b9c4af0a52d/4d383/image-1.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/optimize-cloud-architecture-spend-continuously-improve-your-modern-cloud-environment/",
      "published_at": "2021-10-12T12:05:21Z",
      "updated_at": "2021-08-02T21:54:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the cloud, it's important to look regularly and closely at how your applications and services are architected and utilized. It's the best way to identify opportunities that will let you right-size your instances, fine tune your databases, modify your storage usage, better configure your load balancers, or even re-architect your applications. For example, if you have a set of 20 instances all running at 10% CPU usage, you might consider using smaller instances or consolidating more work onto those instances. This kind of thinking about your cloud utilization and spend will help you optimize your environment and save money quickly. Optimizing your cloud architecture has three main goals: Improve performance, availability, and end-user experience by taking better advantage of cloud services Optimize your cloud spend, striking the delicate balance between cost and performance Capture business and technical metrics that help justify your current cloud spend that can be referenced as justification for a larger cloud budget as growth dictates In this tutorial, we'll show you how to use the New Relic platform to capture all the data you should leverage to optimize your cloud architecture and spend. 1. Instrument your application and cloud environment Make sure the following products and integrations are instrumented: Instrument Details Install Infrastructure Instrument infrastructure: If you haven't already done so, review the requirements for the Infrastructure agent. Infrastructure comes with several types of integrations, including Amazon Web Services (AWS), Microsoft Azure, and on-host integrations. After you've installed the Infrastructure agent on your host(s), you'll immediately have access to the broad spectrum of metrics the agent collects out-of-the-box. Install the APM agent Instrument your applications with APM. Doing so will let you monitor how your applications are performing while you are optimizing the underlying cloud services. That way, you can confirm that your changes to the infrastructure are in fact improving application performance. Configure the AWS integration New Relic Infrastructure's Amazon integrations let you monitor your AWS data in several New Relic products, including Infrastructure, dashboards, and New Relic Alerts. Connect AWS Billing If you are hosted in an AWS environment, New Relic can help you monitor your cloud spend with our AWS Billing integration. To leverage New Relic's AWS Billing integration, follow the procedures in the Connect AWS Billing documentation 2. Create dashboards to display baseline infrastructure metrics; include AWS budgets if available Dashboards lets you write powerful custom queries about your data and visualize the results in widgets displayed on a common dashboard. You can also feed the results of your queries directly into New Relic Alerts, where you can get immediate notifications on any deviation identified. For this step, you should display baseline infrastructure metrics related to performance and usage (CPU, memory, disk, database, etc.). Include AWS Budgets if available. To get you started, here are ways to use Insights dashboards to visualize your AWS cloud utilization and spend data: This dashboard shows data broken out by the applications and budgets you set up in the AWS budgeting area. Create individual dashboards for each application, and then collect those dashboards into a single “data app,” as shown here. This AWS Production Overview data app displays a set of widgets relevant to an AWS production budget. Data apps are great for presentations where you want to step through a series of topics and also provide a clear overview of an entire environment or service. Create dashboards for each level of your organization Whether you're a developer, operator, or executive, having information about your cloud utilization can help you optimize your cloud environment: Developers: Understanding what applications currently cost can help developers configure applications to use more services more efficiently. For example, could developers cut cloud costs using AWS Lambda or properly sized instances? Operators: Monitoring application utilization allows operators to catch possible overruns due to mis-configured services. For example, is the ops team's auto-scaling configuration scaling down properly? Executives: An overall view of both fore-casted and actual cloud spend, for individual applications, per region, and overall totals, can help executives make better business decisions. Use New Relic to keep track of your cloud spend, and make sure your teams get alerted immediately when you exceed thresholds. 3. Identify resources for optimization This step shows you how to use the metrics New Relic has captured to determine which resources to optimize. In the sample dashboard above, the CPU-usage widget on the left reveals that this application uses many instances sizes. Note that the “c4.xlarge” instance (in coral) consistently consumes only around 20% CPU capacity. However, when you analyze the c4.xlarge Memory usage in the center widget (light green), you'll see that memory usage for this instance ranges from 20% to 80%. This suggests that the application is more memory-intensive than CPU-intensive. In this case, the instance type should be changed from a compute-optimized instance to one that is memory-optimized. (Note: the chart on the right of the dashboard can be used to monitor the application's average response time as you make these optimizations.) This is just one example of how to identify cloud-based resources that could be candidates for optimization. Now that you've identified architecture for optimization, go ahead and do so. Whether you right-size your instances, fine tune your databases, modify your storage usage, better configure your load balancers, or even re-architect your applications, in the end your goal is to be able to compare your new, optimized architecture against the baselines you captured in Step 2. For more about baselines please review the Establish Objectives & Baselines tutorial. 4. Optional: Set up alerts You can create an alert condition for NRQL queries. Be sure to reference the complete documentation as needed. In the data app for the AWS production budget introduced in Step 2, this was one of the widgets: Here is the query that we used to create that widget: SELECT latest(`provider.actualAmount`) as '$ Actual', latest(`provider.forecastedAmount`) as '$ Forecast', max(`provider.limitAmount`) as '$ Limit' FROM FinanceSample WHERE provider = 'BillingBudget' AND `provider.budgetName` = '[Your Cloud Budget]' Copy If you can write queries on your data and show them in Insights, then you can easily use them to generate Alert conditions. Baseline queries New Relic also lets you write “baseline queries” against your data. These are queriesy you write without setting hard limits on the results. Rather, you let New Relic Applied Intelligence “machine-learn” your performance data, and then alert you when your data strays too far outside of your baseline numbers. To create a baseline query, head over the the Alert console, go into Alert policies, and add a New alert policy. Then follow these steps: Create alert policy. Give your policy a concise and descriptive name and select an Incident Preference. Then select Create alert policy. Create a condition. Select NRQL Define your query, and decide how restrictively Applied Intelligence should analyze your data using a simple slider and visualization based on your recent performance. The slider at the bottom of the chart either increases or decreases the gray band around your budget threshold (the blue line). The setting shown would have resulted in zero violations based on recent data, and that is what you're looking for. However, if that blue line spikes up or down out of the gray band, New Relic will immediately notify you. Using New Relic Applied Intelligence is a great way to help you proactively learn about your cloud spending or about any of your performance data. Lean More Review the Proactive alerting and incident orchestration tutorial for a deeper dive on some of the best practices outlined above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.02328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Optimize</em> <em>cloud</em> architecture and spend to continuously improve <em>your</em> modern <em>cloud</em> <em>environment</em>",
        "sections": "<em>Optimize</em> <em>cloud</em> architecture and spend to continuously improve <em>your</em> modern <em>cloud</em> <em>environment</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " business and technical metrics that help justify <em>your</em> current <em>cloud</em> spend that can be referenced as justification for a larger <em>cloud</em> budget as growth dictates In this tutorial, we&#x27;ll show you how to use the <em>New</em> <em>Relic</em> platform to capture all the data you should leverage to <em>optimize</em> <em>your</em> <em>cloud</em>"
      },
      "id": "603ebf4964441f4bfa4e8841"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/manage-your-containerized-environment": [
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-10-12T12:12:51Z",
      "updated_at": "2021-09-14T06:09:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for common ticketing systems. You can use any of these integrations to file tickets from APM. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example questions and KPI <em>solutions</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " alerts and thresholds As you use <em>New</em> <em>Relic</em> to <em>optimize</em> <em>your</em> application and infrastructure performance, tighten <em>your</em> <em>New</em> <em>Relic</em> Alerts policy conditions to keep pace with <em>your</em> improved performance. When rolling out <em>new</em> code or modifications that could negatively impact performance over a period of time"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    },
    {
      "sections": [
        "Adopt cloud services",
        "1. Identify services and technologies",
        "2. Deploy New Relic Infrastructure",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "Tip",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD pipeline integration",
        "8. AWS Lambda Monitoring"
      ],
      "title": "Adopt cloud services",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "4a8e675e4231295287e69402c8c5ff9b05a6103b",
      "image": "https://docs.newrelic.com/static/4159294d05ee078268a7b287af99a72f/c1b63/adopt_cloud.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services/",
      "published_at": "2021-10-12T12:36:54Z",
      "updated_at": "2021-09-14T06:08:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've recently completed your cloud migration, have been using cloud-based services for a while, or have always been in the cloud, you may find yourself deploying modern, cutting-edge technologies and services. It's important to develop the ability to adopt new services easily and with confidence; innovation never stops for companies operating in the cloud, and a company's willingness to embrace new technology can give it a major competitive differentiator. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate, for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions. They may be cloud-based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations, you want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services. This allows your team to deploy faster, to adopt new services with confidence, to make better business decisions, and in general to expand its technology horizons. Here are the steps to using the New Relic Platform to monitor your modern technologies and cloud services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies and new services that might impact your organization's application environment. 2. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified in Step One so that you can monitor your cloud services. If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations As you integrate new cloud services, you can use New Relic to monitor and report data about these services; giving you a single, comprehensive overview of your entire architecture. To configure cloud service integrations, link your Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) service provider account with New Relic. 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. one.newrelic.com > Infrastructure > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of an Insights dashboard with data about vendors, technologies, services, instances, and other important details for DevOps teams. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all changes to a system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all AWS Elastic Load Balancing (ALB) systems for the ALB monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring For full-stack visibility into every aspect of your app, we recommend deploying other types of New Relic monitoring: Use APM to report application-tier performance metrics. Use browser monitoring to report front-end web metrics. Use mobile monitoring to report front-end mobile app metrics. Use synthetic monitoring to monitor websites, critical business transactions, and API endpoints. 7. CI/CD pipeline integration It's important to track deployments and the impact that code and infrastructure changes have on your end-user experience. APM deployment markers allow you to record deployments for each application. A deployment marker is an event indicating that a deployment happened. You can pair markers with metadata from your source code management (SCM) system ( including user IDs, revisions, and change logs.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root causes of immediate, long-term, or gradual degradations in your applications. Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment, as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible Puppet 8. AWS Lambda Monitoring New Relic One features an updated APM agent that is highly optimized from a cost and time perspective for ephemeral Lambda functions. Enable New Relic monitoring of AWS Lambda to to assess invocations, error rate, function duration, cold starts, and more. You can also take advantage of New Relic's Infrastructure integration with Lambda for additional reporting capabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Adopt <em>cloud</em> services",
        "sections": "2. Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " the <em>New</em> <em>Relic</em> Platform to monitor <em>your</em> modern technologies and <em>cloud</em> services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What <em>cloud</em>-based applications do I have? What are the underlying <em>cloud</em>-based services, technologies"
      },
      "id": "603ebf09e7b9d2071a2a0806"
    },
    {
      "sections": [
        "Iterate and measure impact: Track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: Track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "64fab5d31ae90da92debca9bc0eb802ebe731c2b",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T12:19:02Z",
      "updated_at": "2021-09-14T06:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proper instrumentation gives teams full visibility into the impact of the changes they make in a system. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation and reduce the impact to other work happening in the system. Prerequisite Before starting this tutorial, complete the Establish objectives and baselines. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they're consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make across them are correct, and eliminate any anomalies before pushing code to production. Beyond using instrumentation to measure software performance, also use it to analyze team efficiency. For example, with your alerts data, use NRQL and external integrations to calculate mean time to repair (MTTR) by subtracting the difference in event timestamps as the current state of each event changes from OPEN to ACKNOWLEDGED to CLOSED. Or push events into Insights from a source code management (SCM) system like GitHub, and calculate the amount of time it takes a code change to go live by comparing the timestamp of a commit event to that of a deploy event. Plotted over time, this could become a KPI in a DevOps transformation. 2. Add automated deployment markers It's important to track deployments and the impact code and infrastructure changes have on your end-user experience. Using deployment markers in APM, you can record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (for example, the user, revision, or change-log). APM displays a vertical line, or “marker,” on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application. Additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is a valuable way to determine the root cause of immediate, long-term, or gradual degradations in your application. New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test your pipeline with Infrastructure An important part of optimizing your cloud native environment is a making a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names, which is a good fit for this model. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test <em>your</em> pipeline with Infrastructure An important part of optimizing <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em> is a making a cultural shift toward smaller, more frequent changes to <em>your</em> code and infrastructure. After you"
      },
      "id": "603ebdad196a67b212a83ded"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/migrate-microservices": [
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-10-12T12:12:51Z",
      "updated_at": "2021-09-14T06:09:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for common ticketing systems. You can use any of these integrations to file tickets from APM. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example questions and KPI <em>solutions</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " alerts and thresholds As you use <em>New</em> <em>Relic</em> to <em>optimize</em> <em>your</em> application and infrastructure performance, tighten <em>your</em> <em>New</em> <em>Relic</em> Alerts policy conditions to keep pace with <em>your</em> improved performance. When rolling out <em>new</em> code or modifications that could negatively impact performance over a period of time"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    },
    {
      "sections": [
        "Adopt cloud services",
        "1. Identify services and technologies",
        "2. Deploy New Relic Infrastructure",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "Tip",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD pipeline integration",
        "8. AWS Lambda Monitoring"
      ],
      "title": "Adopt cloud services",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "4a8e675e4231295287e69402c8c5ff9b05a6103b",
      "image": "https://docs.newrelic.com/static/4159294d05ee078268a7b287af99a72f/c1b63/adopt_cloud.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services/",
      "published_at": "2021-10-12T12:36:54Z",
      "updated_at": "2021-09-14T06:08:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've recently completed your cloud migration, have been using cloud-based services for a while, or have always been in the cloud, you may find yourself deploying modern, cutting-edge technologies and services. It's important to develop the ability to adopt new services easily and with confidence; innovation never stops for companies operating in the cloud, and a company's willingness to embrace new technology can give it a major competitive differentiator. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate, for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions. They may be cloud-based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations, you want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services. This allows your team to deploy faster, to adopt new services with confidence, to make better business decisions, and in general to expand its technology horizons. Here are the steps to using the New Relic Platform to monitor your modern technologies and cloud services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies and new services that might impact your organization's application environment. 2. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified in Step One so that you can monitor your cloud services. If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations As you integrate new cloud services, you can use New Relic to monitor and report data about these services; giving you a single, comprehensive overview of your entire architecture. To configure cloud service integrations, link your Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) service provider account with New Relic. 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. one.newrelic.com > Infrastructure > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of an Insights dashboard with data about vendors, technologies, services, instances, and other important details for DevOps teams. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all changes to a system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all AWS Elastic Load Balancing (ALB) systems for the ALB monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring For full-stack visibility into every aspect of your app, we recommend deploying other types of New Relic monitoring: Use APM to report application-tier performance metrics. Use browser monitoring to report front-end web metrics. Use mobile monitoring to report front-end mobile app metrics. Use synthetic monitoring to monitor websites, critical business transactions, and API endpoints. 7. CI/CD pipeline integration It's important to track deployments and the impact that code and infrastructure changes have on your end-user experience. APM deployment markers allow you to record deployments for each application. A deployment marker is an event indicating that a deployment happened. You can pair markers with metadata from your source code management (SCM) system ( including user IDs, revisions, and change logs.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root causes of immediate, long-term, or gradual degradations in your applications. Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment, as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible Puppet 8. AWS Lambda Monitoring New Relic One features an updated APM agent that is highly optimized from a cost and time perspective for ephemeral Lambda functions. Enable New Relic monitoring of AWS Lambda to to assess invocations, error rate, function duration, cold starts, and more. You can also take advantage of New Relic's Infrastructure integration with Lambda for additional reporting capabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Adopt <em>cloud</em> services",
        "sections": "2. Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " the <em>New</em> <em>Relic</em> Platform to monitor <em>your</em> modern technologies and <em>cloud</em> services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What <em>cloud</em>-based applications do I have? What are the underlying <em>cloud</em>-based services, technologies"
      },
      "id": "603ebf09e7b9d2071a2a0806"
    },
    {
      "sections": [
        "Iterate and measure impact: Track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: Track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "64fab5d31ae90da92debca9bc0eb802ebe731c2b",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T12:19:02Z",
      "updated_at": "2021-09-14T06:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proper instrumentation gives teams full visibility into the impact of the changes they make in a system. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation and reduce the impact to other work happening in the system. Prerequisite Before starting this tutorial, complete the Establish objectives and baselines. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they're consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make across them are correct, and eliminate any anomalies before pushing code to production. Beyond using instrumentation to measure software performance, also use it to analyze team efficiency. For example, with your alerts data, use NRQL and external integrations to calculate mean time to repair (MTTR) by subtracting the difference in event timestamps as the current state of each event changes from OPEN to ACKNOWLEDGED to CLOSED. Or push events into Insights from a source code management (SCM) system like GitHub, and calculate the amount of time it takes a code change to go live by comparing the timestamp of a commit event to that of a deploy event. Plotted over time, this could become a KPI in a DevOps transformation. 2. Add automated deployment markers It's important to track deployments and the impact code and infrastructure changes have on your end-user experience. Using deployment markers in APM, you can record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (for example, the user, revision, or change-log). APM displays a vertical line, or “marker,” on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application. Additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is a valuable way to determine the root cause of immediate, long-term, or gradual degradations in your application. New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test your pipeline with Infrastructure An important part of optimizing your cloud native environment is a making a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names, which is a good fit for this model. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test <em>your</em> pipeline with Infrastructure An important part of optimizing <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em> is a making a cultural shift toward smaller, more frequent changes to <em>your</em> code and infrastructure. After you"
      },
      "id": "603ebdad196a67b212a83ded"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/optimize-cloud-architecture-spend-continuously-improve-your-modern-cloud-environment": [
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-10-12T12:12:51Z",
      "updated_at": "2021-09-14T06:09:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. New Relic also provides integrations for common ticketing systems. You can use any of these integrations to file tickets from APM. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example questions and KPI <em>solutions</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " alerts and thresholds As you use <em>New</em> <em>Relic</em> to <em>optimize</em> <em>your</em> application and infrastructure performance, tighten <em>your</em> <em>New</em> <em>Relic</em> Alerts policy conditions to keep pace with <em>your</em> improved performance. When rolling out <em>new</em> code or modifications that could negatively impact performance over a period of time"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    },
    {
      "sections": [
        "Adopt cloud services",
        "1. Identify services and technologies",
        "2. Deploy New Relic Infrastructure",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "Tip",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD pipeline integration",
        "8. AWS Lambda Monitoring"
      ],
      "title": "Adopt cloud services",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "4a8e675e4231295287e69402c8c5ff9b05a6103b",
      "image": "https://docs.newrelic.com/static/4159294d05ee078268a7b287af99a72f/c1b63/adopt_cloud.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services/",
      "published_at": "2021-10-12T12:36:54Z",
      "updated_at": "2021-09-14T06:08:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've recently completed your cloud migration, have been using cloud-based services for a while, or have always been in the cloud, you may find yourself deploying modern, cutting-edge technologies and services. It's important to develop the ability to adopt new services easily and with confidence; innovation never stops for companies operating in the cloud, and a company's willingness to embrace new technology can give it a major competitive differentiator. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate, for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions. They may be cloud-based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations, you want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services. This allows your team to deploy faster, to adopt new services with confidence, to make better business decisions, and in general to expand its technology horizons. Here are the steps to using the New Relic Platform to monitor your modern technologies and cloud services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies and new services that might impact your organization's application environment. 2. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified in Step One so that you can monitor your cloud services. If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations As you integrate new cloud services, you can use New Relic to monitor and report data about these services; giving you a single, comprehensive overview of your entire architecture. To configure cloud service integrations, link your Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) service provider account with New Relic. 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. one.newrelic.com > Infrastructure > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of an Insights dashboard with data about vendors, technologies, services, instances, and other important details for DevOps teams. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all changes to a system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all AWS Elastic Load Balancing (ALB) systems for the ALB monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring For full-stack visibility into every aspect of your app, we recommend deploying other types of New Relic monitoring: Use APM to report application-tier performance metrics. Use browser monitoring to report front-end web metrics. Use mobile monitoring to report front-end mobile app metrics. Use synthetic monitoring to monitor websites, critical business transactions, and API endpoints. 7. CI/CD pipeline integration It's important to track deployments and the impact that code and infrastructure changes have on your end-user experience. APM deployment markers allow you to record deployments for each application. A deployment marker is an event indicating that a deployment happened. You can pair markers with metadata from your source code management (SCM) system ( including user IDs, revisions, and change logs.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root causes of immediate, long-term, or gradual degradations in your applications. Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment, as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible Puppet 8. AWS Lambda Monitoring New Relic One features an updated APM agent that is highly optimized from a cost and time perspective for ephemeral Lambda functions. Enable New Relic monitoring of AWS Lambda to to assess invocations, error rate, function duration, cold starts, and more. You can also take advantage of New Relic's Infrastructure integration with Lambda for additional reporting capabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Adopt <em>cloud</em> services",
        "sections": "2. Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " the <em>New</em> <em>Relic</em> Platform to monitor <em>your</em> modern technologies and <em>cloud</em> services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What <em>cloud</em>-based applications do I have? What are the underlying <em>cloud</em>-based services, technologies"
      },
      "id": "603ebf09e7b9d2071a2a0806"
    },
    {
      "sections": [
        "Iterate and measure impact: Track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: Track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "64fab5d31ae90da92debca9bc0eb802ebe731c2b",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T12:19:02Z",
      "updated_at": "2021-09-14T06:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proper instrumentation gives teams full visibility into the impact of the changes they make in a system. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation and reduce the impact to other work happening in the system. Prerequisite Before starting this tutorial, complete the Establish objectives and baselines. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they're consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make across them are correct, and eliminate any anomalies before pushing code to production. Beyond using instrumentation to measure software performance, also use it to analyze team efficiency. For example, with your alerts data, use NRQL and external integrations to calculate mean time to repair (MTTR) by subtracting the difference in event timestamps as the current state of each event changes from OPEN to ACKNOWLEDGED to CLOSED. Or push events into Insights from a source code management (SCM) system like GitHub, and calculate the amount of time it takes a code change to go live by comparing the timestamp of a commit event to that of a deploy event. Plotted over time, this could become a KPI in a DevOps transformation. 2. Add automated deployment markers It's important to track deployments and the impact code and infrastructure changes have on your end-user experience. Using deployment markers in APM, you can record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (for example, the user, revision, or change-log). APM displays a vertical line, or “marker,” on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application. Additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is a valuable way to determine the root cause of immediate, long-term, or gradual degradations in your application. New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test your pipeline with Infrastructure An important part of optimizing your cloud native environment is a making a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names, which is a good fit for this model. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test <em>your</em> pipeline with Infrastructure An important part of optimizing <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em> is a making a cultural shift toward smaller, more frequent changes to <em>your</em> code and infrastructure. After you"
      },
      "id": "603ebdad196a67b212a83ded"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response": [
    {
      "sections": [
        "Adopt cloud services",
        "1. Identify services and technologies",
        "2. Deploy New Relic Infrastructure",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "Tip",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD pipeline integration",
        "8. AWS Lambda Monitoring"
      ],
      "title": "Adopt cloud services",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "4a8e675e4231295287e69402c8c5ff9b05a6103b",
      "image": "https://docs.newrelic.com/static/4159294d05ee078268a7b287af99a72f/c1b63/adopt_cloud.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/adopt-cloud-services/",
      "published_at": "2021-10-12T12:36:54Z",
      "updated_at": "2021-09-14T06:08:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've recently completed your cloud migration, have been using cloud-based services for a while, or have always been in the cloud, you may find yourself deploying modern, cutting-edge technologies and services. It's important to develop the ability to adopt new services easily and with confidence; innovation never stops for companies operating in the cloud, and a company's willingness to embrace new technology can give it a major competitive differentiator. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate, for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions. They may be cloud-based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations, you want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services. This allows your team to deploy faster, to adopt new services with confidence, to make better business decisions, and in general to expand its technology horizons. Here are the steps to using the New Relic Platform to monitor your modern technologies and cloud services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies and new services that might impact your organization's application environment. 2. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified in Step One so that you can monitor your cloud services. If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations As you integrate new cloud services, you can use New Relic to monitor and report data about these services; giving you a single, comprehensive overview of your entire architecture. To configure cloud service integrations, link your Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) service provider account with New Relic. 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. one.newrelic.com > Infrastructure > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. one.newrelic.com > Infrastructure > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of an Insights dashboard with data about vendors, technologies, services, instances, and other important details for DevOps teams. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all changes to a system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all AWS Elastic Load Balancing (ALB) systems for the ALB monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring For full-stack visibility into every aspect of your app, we recommend deploying other types of New Relic monitoring: Use APM to report application-tier performance metrics. Use browser monitoring to report front-end web metrics. Use mobile monitoring to report front-end mobile app metrics. Use synthetic monitoring to monitor websites, critical business transactions, and API endpoints. 7. CI/CD pipeline integration It's important to track deployments and the impact that code and infrastructure changes have on your end-user experience. APM deployment markers allow you to record deployments for each application. A deployment marker is an event indicating that a deployment happened. You can pair markers with metadata from your source code management (SCM) system ( including user IDs, revisions, and change logs.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root causes of immediate, long-term, or gradual degradations in your applications. Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment, as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible Puppet 8. AWS Lambda Monitoring New Relic One features an updated APM agent that is highly optimized from a cost and time perspective for ephemeral Lambda functions. Enable New Relic monitoring of AWS Lambda to to assess invocations, error rate, function duration, cold starts, and more. You can also take advantage of New Relic's Infrastructure integration with Lambda for additional reporting capabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.33783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Adopt <em>cloud</em> services",
        "sections": "2. Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " the <em>New</em> <em>Relic</em> Platform to monitor <em>your</em> modern technologies and <em>cloud</em> services: 1. Identify services and technologies Determine the components you need to monitor by answering the following questions: What <em>cloud</em>-based applications do I have? What are the underlying <em>cloud</em>-based services, technologies"
      },
      "id": "603ebf09e7b9d2071a2a0806"
    },
    {
      "sections": [
        "Iterate and measure impact: Track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "3. Test your pipeline with Infrastructure"
      ],
      "title": "Iterate and measure impact: Track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "64fab5d31ae90da92debca9bc0eb802ebe731c2b",
      "image": "https://docs.newrelic.com/static/ad513b871bf0ddd2b1ae654b1bb93a88/d2c2a/APM_Deployments_Catalyst.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2021-10-12T12:19:02Z",
      "updated_at": "2021-09-14T06:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proper instrumentation gives teams full visibility into the impact of the changes they make in a system. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation and reduce the impact to other work happening in the system. Prerequisite Before starting this tutorial, complete the Establish objectives and baselines. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they're consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make across them are correct, and eliminate any anomalies before pushing code to production. Beyond using instrumentation to measure software performance, also use it to analyze team efficiency. For example, with your alerts data, use NRQL and external integrations to calculate mean time to repair (MTTR) by subtracting the difference in event timestamps as the current state of each event changes from OPEN to ACKNOWLEDGED to CLOSED. Or push events into Insights from a source code management (SCM) system like GitHub, and calculate the amount of time it takes a code change to go live by comparing the timestamp of a commit event to that of a deploy event. Plotted over time, this could become a KPI in a DevOps transformation. 2. Add automated deployment markers It's important to track deployments and the impact code and infrastructure changes have on your end-user experience. Using deployment markers in APM, you can record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (for example, the user, revision, or change-log). APM displays a vertical line, or “marker,” on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application. Additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is a valuable way to determine the root cause of immediate, long-term, or gradual degradations in your application. New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test your pipeline with Infrastructure An important part of optimizing your cloud native environment is a making a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. New Relic Infrastructure helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names, which is a good fit for this model. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.3378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " available to help automate this: Chef (see newrelic_deployment) Jenkins Ansible Puppet 3. Test <em>your</em> pipeline with Infrastructure An important part of optimizing <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em> is a making a cultural shift toward smaller, more frequent changes to <em>your</em> code and infrastructure. After you"
      },
      "id": "603ebdad196a67b212a83ded"
    },
    {
      "sections": [
        "Optimize cloud architecture and spend to continuously improve your modern cloud environment",
        "1. Instrument your application and cloud environment",
        "2. Create dashboards to display baseline infrastructure metrics; include AWS budgets if available",
        "Create dashboards for each level of your organization",
        "3. Identify resources for optimization",
        "4. Optional: Set up alerts",
        "Baseline queries",
        "Lean More"
      ],
      "title": "Optimize cloud architecture and spend to continuously improve your modern cloud environment",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "a39e5f962beb7ac37d876516d0d6ddb03f3888ec",
      "image": "https://docs.newrelic.com/static/3e068d910ba2857ad60a1b9c4af0a52d/4d383/image-1.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/optimize-cloud-architecture-spend-continuously-improve-your-modern-cloud-environment/",
      "published_at": "2021-10-12T12:05:21Z",
      "updated_at": "2021-08-02T21:54:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the cloud, it's important to look regularly and closely at how your applications and services are architected and utilized. It's the best way to identify opportunities that will let you right-size your instances, fine tune your databases, modify your storage usage, better configure your load balancers, or even re-architect your applications. For example, if you have a set of 20 instances all running at 10% CPU usage, you might consider using smaller instances or consolidating more work onto those instances. This kind of thinking about your cloud utilization and spend will help you optimize your environment and save money quickly. Optimizing your cloud architecture has three main goals: Improve performance, availability, and end-user experience by taking better advantage of cloud services Optimize your cloud spend, striking the delicate balance between cost and performance Capture business and technical metrics that help justify your current cloud spend that can be referenced as justification for a larger cloud budget as growth dictates In this tutorial, we'll show you how to use the New Relic platform to capture all the data you should leverage to optimize your cloud architecture and spend. 1. Instrument your application and cloud environment Make sure the following products and integrations are instrumented: Instrument Details Install Infrastructure Instrument infrastructure: If you haven't already done so, review the requirements for the Infrastructure agent. Infrastructure comes with several types of integrations, including Amazon Web Services (AWS), Microsoft Azure, and on-host integrations. After you've installed the Infrastructure agent on your host(s), you'll immediately have access to the broad spectrum of metrics the agent collects out-of-the-box. Install the APM agent Instrument your applications with APM. Doing so will let you monitor how your applications are performing while you are optimizing the underlying cloud services. That way, you can confirm that your changes to the infrastructure are in fact improving application performance. Configure the AWS integration New Relic Infrastructure's Amazon integrations let you monitor your AWS data in several New Relic products, including Infrastructure, dashboards, and New Relic Alerts. Connect AWS Billing If you are hosted in an AWS environment, New Relic can help you monitor your cloud spend with our AWS Billing integration. To leverage New Relic's AWS Billing integration, follow the procedures in the Connect AWS Billing documentation 2. Create dashboards to display baseline infrastructure metrics; include AWS budgets if available Dashboards lets you write powerful custom queries about your data and visualize the results in widgets displayed on a common dashboard. You can also feed the results of your queries directly into New Relic Alerts, where you can get immediate notifications on any deviation identified. For this step, you should display baseline infrastructure metrics related to performance and usage (CPU, memory, disk, database, etc.). Include AWS Budgets if available. To get you started, here are ways to use Insights dashboards to visualize your AWS cloud utilization and spend data: This dashboard shows data broken out by the applications and budgets you set up in the AWS budgeting area. Create individual dashboards for each application, and then collect those dashboards into a single “data app,” as shown here. This AWS Production Overview data app displays a set of widgets relevant to an AWS production budget. Data apps are great for presentations where you want to step through a series of topics and also provide a clear overview of an entire environment or service. Create dashboards for each level of your organization Whether you're a developer, operator, or executive, having information about your cloud utilization can help you optimize your cloud environment: Developers: Understanding what applications currently cost can help developers configure applications to use more services more efficiently. For example, could developers cut cloud costs using AWS Lambda or properly sized instances? Operators: Monitoring application utilization allows operators to catch possible overruns due to mis-configured services. For example, is the ops team's auto-scaling configuration scaling down properly? Executives: An overall view of both fore-casted and actual cloud spend, for individual applications, per region, and overall totals, can help executives make better business decisions. Use New Relic to keep track of your cloud spend, and make sure your teams get alerted immediately when you exceed thresholds. 3. Identify resources for optimization This step shows you how to use the metrics New Relic has captured to determine which resources to optimize. In the sample dashboard above, the CPU-usage widget on the left reveals that this application uses many instances sizes. Note that the “c4.xlarge” instance (in coral) consistently consumes only around 20% CPU capacity. However, when you analyze the c4.xlarge Memory usage in the center widget (light green), you'll see that memory usage for this instance ranges from 20% to 80%. This suggests that the application is more memory-intensive than CPU-intensive. In this case, the instance type should be changed from a compute-optimized instance to one that is memory-optimized. (Note: the chart on the right of the dashboard can be used to monitor the application's average response time as you make these optimizations.) This is just one example of how to identify cloud-based resources that could be candidates for optimization. Now that you've identified architecture for optimization, go ahead and do so. Whether you right-size your instances, fine tune your databases, modify your storage usage, better configure your load balancers, or even re-architect your applications, in the end your goal is to be able to compare your new, optimized architecture against the baselines you captured in Step 2. For more about baselines please review the Establish Objectives & Baselines tutorial. 4. Optional: Set up alerts You can create an alert condition for NRQL queries. Be sure to reference the complete documentation as needed. In the data app for the AWS production budget introduced in Step 2, this was one of the widgets: Here is the query that we used to create that widget: SELECT latest(`provider.actualAmount`) as '$ Actual', latest(`provider.forecastedAmount`) as '$ Forecast', max(`provider.limitAmount`) as '$ Limit' FROM FinanceSample WHERE provider = 'BillingBudget' AND `provider.budgetName` = '[Your Cloud Budget]' Copy If you can write queries on your data and show them in Insights, then you can easily use them to generate Alert conditions. Baseline queries New Relic also lets you write “baseline queries” against your data. These are queriesy you write without setting hard limits on the results. Rather, you let New Relic Applied Intelligence “machine-learn” your performance data, and then alert you when your data strays too far outside of your baseline numbers. To create a baseline query, head over the the Alert console, go into Alert policies, and add a New alert policy. Then follow these steps: Create alert policy. Give your policy a concise and descriptive name and select an Incident Preference. Then select Create alert policy. Create a condition. Select NRQL Define your query, and decide how restrictively Applied Intelligence should analyze your data using a simple slider and visualization based on your recent performance. The slider at the bottom of the chart either increases or decreases the gray band around your budget threshold (the blue line). The setting shown would have resulted in zero violations based on recent data, and that is what you're looking for. However, if that blue line spikes up or down out of the gray band, New Relic will immediately notify you. Using New Relic Applied Intelligence is a great way to help you proactively learn about your cloud spending or about any of your performance data. Lean More Review the Proactive alerting and incident orchestration tutorial for a deeper dive on some of the best practices outlined above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.02328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Optimize</em> <em>cloud</em> architecture and spend to continuously improve <em>your</em> modern <em>cloud</em> <em>environment</em>",
        "sections": "<em>Optimize</em> <em>cloud</em> architecture and spend to continuously improve <em>your</em> modern <em>cloud</em> <em>environment</em>",
        "tags": "<em>Optimize</em> <em>your</em> <em>cloud</em> <em>native</em> <em>environment</em>",
        "body": " business and technical metrics that help justify <em>your</em> current <em>cloud</em> spend that can be referenced as justification for a larger <em>cloud</em> budget as growth dictates In this tutorial, we&#x27;ll show you how to use the <em>New</em> <em>Relic</em> platform to capture all the data you should leverage to <em>optimize</em> <em>your</em> <em>cloud</em>"
      },
      "id": "603ebf4964441f4bfa4e8841"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/create-application-baselines": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/guide-planning-your-cloud-adoption-strategy": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    },
    {
      "sections": [
        "Create application baselines",
        "1. Identify components",
        "Tip",
        "Example: List of components",
        "2. Determine compatibility",
        "Example: Components matched to New Relic products",
        "3. Deploy monitoring",
        "Deploy APM",
        "Deploy New Relic Infrastructure",
        "Deploy Infrastructure on-host integrations",
        "Create New Relic Synthetics monitors",
        "4. Gather metrics",
        "5. Set up Dashboards",
        "Example: Component performance compared against baselines",
        "Expert tips"
      ],
      "title": "Create application baselines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "878baea2ae1087d64186b1f08b3b4e7c0326fb70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/create-application-baselines/",
      "published_at": "2021-10-12T13:21:28Z",
      "updated_at": "2021-09-14T06:09:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Cloud migrations can take many forms. Some companies choose to port their applications directly from their data center to the cloud (a “Lift and Shift” migration) while others focus on completely re-architecting their applications to take advantage of benefits available only in the cloud. No matter your approach, there are three primary questions you want to answer after your migration: Has my application gotten slower? Is my application less stable than before? Am I losing customers due to either of the previous questions? To answer these questions, start by performing some basic testing to establish a baseline for the performance and availability of your systems. A baseline is a measurement of the current performance and availability of your application, which you then use as a comparison after your migration to validate your business case. In some cases, you may change a baseline when you perform migration acceptance testing. You can also use a baseline as a comparison point during your migration to make sure that you are on track. 1. Identify components Before you begin a cloud migration, identify all the tiers of your entire application stack. List all of the components (applications, services, etc.) that you want to migrate. Segment the application stack as follows: Application (backend/microservices/cron jobs) Dependency services, such as the message queue Database Website Underlying server and infrastructure Tip Make sure that you have access to applications and instances before you start creating application baselines. Engage your application owners, DevOps engineers, and product managers for access. Example: List of components Here is an example of the list of components in an application stack: Component Name Owner Language Stack Accessibility (Internet, Intranet) Operating System Service 1 John Doe Java Internet RHEL 6 Service 2 Maya Wiz .NET Intranet Win2003 R2 RabbitMQ John Doe Java Intranet AIX Website Maya Wiz Classic ASP Internet Win2000 MS SQL Dave Z NA Intranet Win2003 R2 2. Determine compatibility Once you identify the applications that you want to migrate, it is time to verify which application tiers to monitor with the New Relic platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off, as the more you can instrument, the better your baselines. Here are the New Relic products to use for baselining, depending on the components that you identified: APM: Monitor your web apps with APM. See Compatibility and requirements for New Relic agents and products to learn precise compatibility details for each supported language. Infrastructure: Monitor your hosts with infrastructure. See Compatibility and requirements for infrastructure for supported operating systems and environments. You can also instrument other products and services with on-host integrations. Synthetics: Monitor web frontends and APIs with synthetics. Sometimes, you may not be able to instrument your on-premise environment with APM or Infrastructure. For example, maybe your organization's policy forbids installing an agent behind a firewall. In these cases, if the application has a web frontend, use Synthetics, as it offers non-agent monitoring while still providing the ability to establish a baseline. Example: Components matched to New Relic products Match the components that you identified with their corresponding products: Component Name Tier Owner Language Stack Accessibility (Internet/ Intranet) Operating System New Relic Products Service 1 John Doe Java Internet RHEL 6 APM, Infrastructure, Synthetics Service 2 Maya Wiz .NET Intranet Win2003 R2 APM, Infrastructure ActiveMQ John Doe Java Intranet AIX APM, Plugin Website Maya Wiz Classic ASP Internet Win2000 Synthetics MS SQL Dave Z n/a Intranet Win2003 R2 Infrastructure, On-host Integration 3. Deploy monitoring Based on the component-product matches you made, deploy agents or monitors across your architecture: Deploy APM Install the APM agent on your application stack. The steps to install the APM agent are different based on language. Deploy New Relic Infrastructure After reviewing the requirements for infrastructure, follow the instructions to install the infrastructure agent on your hosts: Install for Linux Install for Windows Server Install on AWS Elastic Beanstalk Install with a configuration management tool Deploy Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations. Available integrations include Apache, MySQL, NGINX, and others. Create New Relic Synthetics monitors New Relic Synthetics is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. To get started add a monitor. Tip Make sure to verify that your website URL is accessible from the public network. You may also need to add New Relic IPs to your allow list. 4. Gather metrics After you deploy the agents and monitors, identify which metrics are the most important to your business and use these metrics to define your KPIs. Some recommendations include: Response time: Time taken to respond to a request. Throughput: Number of requests that came in through the application. Requesting queuing (Apache, IIS, NGINX): Duration of time taken for a request to reach your application. Database call duration: Duration of time taken to complete a database call. DB call counts: Number of calls made by application code to the database. Error rate: Percent of errors reported. Apdex score: An industry standard to measure user satisfaction with the response time of web applications and services. DNS setup timing: The time it takes to connect and receive data from DNS. SSL setup timing: The time it takes to establish an SSL connection. You can find some of these metrics in service maps, as well as on APM, and [browser] (/docs/ /new-relic-browser/getting-started/browser-overview-page-website-performance-summary) overview pages. For more detailed information about navigating, interpreting, and using APM, check out these New Relic University’s tutorials: Overview dashboard tour Transactions dashboard Understanding Apdex 5. Set up Dashboards After you define your KPIs, it is easy to visualize them in dashboards. Dashboards provide a single location to view all the data that New Relic products gather. Dashboards data consists of events, and each event has an event type, a timestamp, and key-value attributes. For more information about events, see Data collection and Default events for New Relic products. You can locate your KPIs and business metrics data in New Relic using the data explorer and the NRQL query language. You can also build dashboards to track the performance of those KPIs: Example: Component performance compared against baselines Continuing the examples in this document, the following table illustrates the maturity of your application performance over a period of time based on deployment milestones. Each milestone will serve as a new baseline for your applications: Component Milestone 1 Milestone 2 Milestone N Environment Component Name Response Time SLA Apdex Response Time SLA Apdex Response On-Prem Service 1 1.5 secs 80% 70% 1.5 secs 68% 0.65 1.4 secs Cloud Service 1 0.9 secs 96.8% 95% 0.9 secs 98% 0.99 0.7 secs On-Prem Service 2 0.7 secs 73% 68% 0.7 secs 80% 0.78 0.85 secs Cloud Service 2 0.6 secs 90% 92% 0.6 secs 89% 0.90 0.5 secs After your migration, compare these baselines against your migration acceptance testing baselines. Expert tips If you find that you need data that is not captured by default instrumentation, New Relic makes it easy to capture custom data: APM custom instrumentation Browser custom data Infrastructure custom attributes Custom event data Mobile custom data Synthetics custom attributes You can also learn more about APM custom instrumentation with the New Relic University Custom data tutorial series.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example: Components matched to <em>New</em> <em>Relic</em> products",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " want to migrate, it is time to verify which application tiers to monitor with the <em>New</em> <em>Relic</em> platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off"
      },
      "id": "6044605c64441f1d15378edf"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Create application baselines",
        "1. Identify components",
        "Tip",
        "Example: List of components",
        "2. Determine compatibility",
        "Example: Components matched to New Relic products",
        "3. Deploy monitoring",
        "Deploy APM",
        "Deploy New Relic Infrastructure",
        "Deploy Infrastructure on-host integrations",
        "Create New Relic Synthetics monitors",
        "4. Gather metrics",
        "5. Set up Dashboards",
        "Example: Component performance compared against baselines",
        "Expert tips"
      ],
      "title": "Create application baselines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "878baea2ae1087d64186b1f08b3b4e7c0326fb70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/create-application-baselines/",
      "published_at": "2021-10-12T13:21:28Z",
      "updated_at": "2021-09-14T06:09:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Cloud migrations can take many forms. Some companies choose to port their applications directly from their data center to the cloud (a “Lift and Shift” migration) while others focus on completely re-architecting their applications to take advantage of benefits available only in the cloud. No matter your approach, there are three primary questions you want to answer after your migration: Has my application gotten slower? Is my application less stable than before? Am I losing customers due to either of the previous questions? To answer these questions, start by performing some basic testing to establish a baseline for the performance and availability of your systems. A baseline is a measurement of the current performance and availability of your application, which you then use as a comparison after your migration to validate your business case. In some cases, you may change a baseline when you perform migration acceptance testing. You can also use a baseline as a comparison point during your migration to make sure that you are on track. 1. Identify components Before you begin a cloud migration, identify all the tiers of your entire application stack. List all of the components (applications, services, etc.) that you want to migrate. Segment the application stack as follows: Application (backend/microservices/cron jobs) Dependency services, such as the message queue Database Website Underlying server and infrastructure Tip Make sure that you have access to applications and instances before you start creating application baselines. Engage your application owners, DevOps engineers, and product managers for access. Example: List of components Here is an example of the list of components in an application stack: Component Name Owner Language Stack Accessibility (Internet, Intranet) Operating System Service 1 John Doe Java Internet RHEL 6 Service 2 Maya Wiz .NET Intranet Win2003 R2 RabbitMQ John Doe Java Intranet AIX Website Maya Wiz Classic ASP Internet Win2000 MS SQL Dave Z NA Intranet Win2003 R2 2. Determine compatibility Once you identify the applications that you want to migrate, it is time to verify which application tiers to monitor with the New Relic platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off, as the more you can instrument, the better your baselines. Here are the New Relic products to use for baselining, depending on the components that you identified: APM: Monitor your web apps with APM. See Compatibility and requirements for New Relic agents and products to learn precise compatibility details for each supported language. Infrastructure: Monitor your hosts with infrastructure. See Compatibility and requirements for infrastructure for supported operating systems and environments. You can also instrument other products and services with on-host integrations. Synthetics: Monitor web frontends and APIs with synthetics. Sometimes, you may not be able to instrument your on-premise environment with APM or Infrastructure. For example, maybe your organization's policy forbids installing an agent behind a firewall. In these cases, if the application has a web frontend, use Synthetics, as it offers non-agent monitoring while still providing the ability to establish a baseline. Example: Components matched to New Relic products Match the components that you identified with their corresponding products: Component Name Tier Owner Language Stack Accessibility (Internet/ Intranet) Operating System New Relic Products Service 1 John Doe Java Internet RHEL 6 APM, Infrastructure, Synthetics Service 2 Maya Wiz .NET Intranet Win2003 R2 APM, Infrastructure ActiveMQ John Doe Java Intranet AIX APM, Plugin Website Maya Wiz Classic ASP Internet Win2000 Synthetics MS SQL Dave Z n/a Intranet Win2003 R2 Infrastructure, On-host Integration 3. Deploy monitoring Based on the component-product matches you made, deploy agents or monitors across your architecture: Deploy APM Install the APM agent on your application stack. The steps to install the APM agent are different based on language. Deploy New Relic Infrastructure After reviewing the requirements for infrastructure, follow the instructions to install the infrastructure agent on your hosts: Install for Linux Install for Windows Server Install on AWS Elastic Beanstalk Install with a configuration management tool Deploy Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations. Available integrations include Apache, MySQL, NGINX, and others. Create New Relic Synthetics monitors New Relic Synthetics is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. To get started add a monitor. Tip Make sure to verify that your website URL is accessible from the public network. You may also need to add New Relic IPs to your allow list. 4. Gather metrics After you deploy the agents and monitors, identify which metrics are the most important to your business and use these metrics to define your KPIs. Some recommendations include: Response time: Time taken to respond to a request. Throughput: Number of requests that came in through the application. Requesting queuing (Apache, IIS, NGINX): Duration of time taken for a request to reach your application. Database call duration: Duration of time taken to complete a database call. DB call counts: Number of calls made by application code to the database. Error rate: Percent of errors reported. Apdex score: An industry standard to measure user satisfaction with the response time of web applications and services. DNS setup timing: The time it takes to connect and receive data from DNS. SSL setup timing: The time it takes to establish an SSL connection. You can find some of these metrics in service maps, as well as on APM, and [browser] (/docs/ /new-relic-browser/getting-started/browser-overview-page-website-performance-summary) overview pages. For more detailed information about navigating, interpreting, and using APM, check out these New Relic University’s tutorials: Overview dashboard tour Transactions dashboard Understanding Apdex 5. Set up Dashboards After you define your KPIs, it is easy to visualize them in dashboards. Dashboards provide a single location to view all the data that New Relic products gather. Dashboards data consists of events, and each event has an event type, a timestamp, and key-value attributes. For more information about events, see Data collection and Default events for New Relic products. You can locate your KPIs and business metrics data in New Relic using the data explorer and the NRQL query language. You can also build dashboards to track the performance of those KPIs: Example: Component performance compared against baselines Continuing the examples in this document, the following table illustrates the maturity of your application performance over a period of time based on deployment milestones. Each milestone will serve as a new baseline for your applications: Component Milestone 1 Milestone 2 Milestone N Environment Component Name Response Time SLA Apdex Response Time SLA Apdex Response On-Prem Service 1 1.5 secs 80% 70% 1.5 secs 68% 0.65 1.4 secs Cloud Service 1 0.9 secs 96.8% 95% 0.9 secs 98% 0.99 0.7 secs On-Prem Service 2 0.7 secs 73% 68% 0.7 secs 80% 0.78 0.85 secs Cloud Service 2 0.6 secs 90% 92% 0.6 secs 89% 0.90 0.5 secs After your migration, compare these baselines against your migration acceptance testing baselines. Expert tips If you find that you need data that is not captured by default instrumentation, New Relic makes it easy to capture custom data: APM custom instrumentation Browser custom data Infrastructure custom attributes Custom event data Mobile custom data Synthetics custom attributes You can also learn more about APM custom instrumentation with the New Relic University Custom data tutorial series.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example: Components matched to <em>New</em> <em>Relic</em> products",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " want to migrate, it is time to verify which application tiers to monitor with the <em>New</em> <em>Relic</em> platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off"
      },
      "id": "6044605c64441f1d15378edf"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/optimize-customer-experience": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/optimize-your-cloud-spend": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/perform-migration-acceptance-testing": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/prioritize-migration-order": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/refactor-your-applications": [
    {
      "sections": [
        "Validate cloud improvements",
        "1. Identify KPIs",
        "2. Deploy monitoring tools",
        "Install APM",
        "Install infrastructure",
        "Tip",
        "Install infrastructure integrations",
        "3. Gather custom data",
        "4. Create baselines",
        "5. Validate improvements with Dashboards"
      ],
      "title": "Validate cloud improvements",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "e8083557674f0bd9a67aadade85517b9f5a517df",
      "image": "https://docs.newrelic.com/static/bd6f185deecee0d1735e167f1831d877/c1b63/KPIs-validate-improvement_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements/",
      "published_at": "2021-10-12T12:43:00Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you migrate your applications to the cloud and integrate cloud services, use New Relic to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blind spots and see the connections between entities—from your application code to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in dashboards in New Relic Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 2. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you want to use. Then, install the New Relic agents: Install APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install New Relic Infrastructure agents on each of those hosts. Install infrastructure After reviewing the requirements for New Relic Infrastructure, install the infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Install infrastructure integrations You can also monitor and report data about services that your code depends on using New Relic integrations. New Relic offers cloud integrations for Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform as well as on-host integrations. Tip If you are using AWS as a cloud provider, take advantage of New Relic’s AWS billing integrations to stay on top of your budget and prove the success of your migration. 3. Gather custom data To manage, search for, and filter resources, assign metadata to your cloud resources in the form of tags. Tags are labels that consist of key-value pairs that you use to annotate your Infrastructure data. Tag formats are different between AWS, Azure, and Google. Google, for example, has the shortest allowable lengths for keys and values. In addition, they all have different requirements for case sensitivity and allowable characters. To make sure that your tags are usable across most cloud providers: Use only lowercase letters, numbers, underscores, and dashes. Keep keys and values under 63 characters. New Relic reports data contained in specific events to your account as part of its “out-of-the-box” functionality. You can add additional data to those events by using custom attributes. If you determine that you need to collect custom data, review custom data requirements, and report custom event data. For more detailed information about sending custom data, check out these New Relic University tutorials: APM custom data overview Adding custom events using the API 4. Create baselines In order to validate the value of moving to the cloud, you need to get baselines for your applications before you move to the cloud. Define pre-migration baselines for applications and their underlying infrastructures that you have designated for cloud service improvements based on your KPIs. To stay on top of your KPIs as you are moving, create baseline alerts for applications monitored by APM and browser and use NRQL alerts to get notified on any spikes or drops in your KPIs. The following dashboard tracks key performance indicators for applications designated to move to the cloud: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs. After you migrate applications to the cloud, apply the same criteria to post-migration baselines so you can compare your results from before and after your migration. 5. Validate improvements with Dashboards Dashboards is a single location to view all the data that New Relic products gather. Use New Relic Dashboards to visualize your KPIs before and after your move: Transaction and TransactionError event types with APM PageView and PageAction event types with browser Default Infrastructure events and attributes for your systems, processes, events, storage, and network, Infrastructure integrations, and custom attributes Mobile event types with Mobile SyntheticCheck, SyntheticRequest, and SyntheticPrivateMinion event types with Synthetics The following dashboard shows KPI data used to validate cloud improvements: one.newrelic.com > Dashboards > Create a dashboard: Create dashboards to track your KPIs pre- and post-migration. Use dashboards to validate the value of adopting a new cloud service and to answer key questions about application performance and customer experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate <em>cloud</em> improvements",
        "sections": "Validate <em>cloud</em> improvements",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": "After you migrate your applications to the <em>cloud</em> and integrate <em>cloud</em> services, use <em>New</em> <em>Relic</em> to measure and validate improvements to your applications. 1. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key"
      },
      "id": "60445c48e7b9d2052c5799d4"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements": [
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "APM",
        "Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: APM APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. Infrastructure Infrastructure monitoring provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for infrastructure. Install the infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " of your migration during your <em>cloud</em> <em>adoption</em> process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, <em>New</em> <em>Relic</em> products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics"
      },
      "id": "60445fcc64441f498e378efb"
    },
    {
      "sections": [
        "Identify issues and roadblocks",
        "1. Identify components",
        "2. Identify KPIs",
        "3. Deploy monitoring tools",
        "Deploy APM",
        "Deploy browser monitoring",
        "Deploy New Relic Infrastructure",
        "Tip",
        "Set up alerts",
        "4. Set up cloud integrations",
        "5. Identify issues and roadblocks",
        "Expert tip for alerting on JavaScript errors"
      ],
      "title": "Identify issues and roadblocks",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "12c79f8e91e131ddf9015d1617760261d71660d1",
      "image": "https://docs.newrelic.com/static/cc629d8a7fe9dd09ac59711b669baedc/c1b63/screen-javascript-errors.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-issues-roadblocks/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-09-14T06:10:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As you migrate your applications to the cloud, you want to catch and correct any unexpected behavior or outcomes as soon as possible. Detecting errors and issues related to your new cloud architecture, performance, and scale is critical—getting the right information at the right time can be the difference between success and failure. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Identify KPIs To provide quantifiable measures that your teams can use to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the New Relic platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your cloud infrastructure (including containers running in highly distributed microservices), to your customer experience. Your goal is to create a collection of metrics in several categories that you can visualize in our Dashboards. To validate cloud improvements, group KPIs in the following categories, from least to most strong: Application and infrastructure performance End-user experience, including website and mobile application performance Audience and content trends DevOps productivity Application revenue analytics Future business goals 3. Deploy monitoring tools To start monitoring your KPIs, verify that the applications that you want to migrate are compatible with the requirements for the New Relic products you will use. Then, install the New Relic agents: Deploy APM Review the compatibility and requirements and then install APM agents on your application stack. After installing the APM agents, review the architecture of the applications that you instrumented with an APM agent. Take note of all hosts that are part of each tier of the application stack (database, application, web server, etc.), so you can install infrastructure monitoring agents on each of those hosts. Deploy browser monitoring In a nutshell, browser monitoring is a snippet of JavaScript that needs to appear in all of your application's webpages. It has no dependencies on other libraries, so it does not cause additional delays when bringing jQuery or other frameworks into the webpage. There are three ways to install the browser agent: Method When to use this method Enable via APM Typically, the quickest path is to let the APM agent dynamically inject the snippet into your pages on the server side. This works for many common web technologies, such as .NET, JSP, and other Java solutions. The documentation provides a complete reference for the languages and frameworks that allow this option. Copy/paste method If you are using an unsupported framework or are in an environment where you can instrument only the webpages but cannot install APM on the backend, use the copy-paste method. The UI generates a simple JavaScript snippet. Copy that snippet, and paste it into a global page template on your end to get browser monitoring deployed across your site. Enable via the API You can perform a manual instrumentation, in which your developers add instrumentation to your webpages using a server-side API. New Relic supports this for many server-side languages. Refer to the documentation for an example of how to do this in Java. Deploy New Relic Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts that you identified so you can start to gather data for your KPIs. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. Set up alerts New Relic Alerts is a single integrated solution with a centralized UI to help you focus on the metrics that you care about most. When you set up New Relic Alerts and NRQL alerting, you establish flexible policies and conditions to receive alerts and notifications on multiple channels (email, Slack, OpsGenie, etc.). For more detailed information about creating, managing, and using alerts, check out the New Relic University tutorials. 4. Set up cloud integrations Tip Cloud-based integrations available through New Relic include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. For example, to capture and record AWS account activity for audit and governance purposes, use the New Relic AWS CloudTrail integration. Tracking error events gives you awareness about API calls and services that have failed, while console logins help you monitor console activity and potential intrusion attempts. New Relic collects this event data so you can display it in a Dashboard or alert on it with NRQL. To gain extended visibility into applications that your code depends on, you can also deploy on-host integrations for commonly used application components, such as MySQL, Apache, and NGINX. In addition, you can create your own custom on-host integration with the New Relic Integrations SDK. 5. Identify issues and roadblocks Once your applications are running in the cloud, they may generate new types of errors that are different from the errors that they generated when running on-premise. You can use New Relic APM and browser monitoring to view error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real-time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. Use the JavaScript errors page to get visibility into real-time user experience: one.newrelic.com > Browser > (select an app) > JS errors: Use the charts on this page to get visibility into the real-time user experience. Then, create a Dashboard that covers a longer period of time and aligns the error and unhandled exception data with your KPIs: one.newrelic.com > Dashboards > Create a dashboard: Use dashboards to align the error and unhandled exception data with your KPIs. Expert tip for alerting on JavaScript errors To get notifications for error spikes that are different from known or common JavaScript errors, use the following NRQL query for browser-monitored: SELECT count(*) FROM JavaScriptError WHERE appName = '<BrowserAppName>' AND errorClass NOT IN ('<ErrorClass1>','<ErrorClass2>') Copy Replace <BrowserAppName> with the browser app name that you want to monitor with this alert. Replace <ErrorClass1> and <ErrorClass2> with the on-premise error class names that you do not want New Relic to alert you about. Set the threshold based on your alerting needs. Using this query, New Relic alerts you every time a JavaScript error occurs when it has an error class that is not normally reported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deploy <em>New</em> <em>Relic</em> Infrastructure",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to assess your migration, identify a list of corporate KPIs (key performance indicators). Using the <em>New</em> <em>Relic</em> platform to measure KPIs helps you eliminate blindspots and see the connections between entities—from your application code, to your <em>cloud</em> infrastructure (including containers running in highly"
      },
      "id": "60445b87196a67bb33960f21"
    },
    {
      "sections": [
        "Create application baselines",
        "1. Identify components",
        "Tip",
        "Example: List of components",
        "2. Determine compatibility",
        "Example: Components matched to New Relic products",
        "3. Deploy monitoring",
        "Deploy APM",
        "Deploy New Relic Infrastructure",
        "Deploy Infrastructure on-host integrations",
        "Create New Relic Synthetics monitors",
        "4. Gather metrics",
        "5. Set up Dashboards",
        "Example: Component performance compared against baselines",
        "Expert tips"
      ],
      "title": "Create application baselines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "878baea2ae1087d64186b1f08b3b4e7c0326fb70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/create-application-baselines/",
      "published_at": "2021-10-12T13:21:28Z",
      "updated_at": "2021-09-14T06:09:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Cloud migrations can take many forms. Some companies choose to port their applications directly from their data center to the cloud (a “Lift and Shift” migration) while others focus on completely re-architecting their applications to take advantage of benefits available only in the cloud. No matter your approach, there are three primary questions you want to answer after your migration: Has my application gotten slower? Is my application less stable than before? Am I losing customers due to either of the previous questions? To answer these questions, start by performing some basic testing to establish a baseline for the performance and availability of your systems. A baseline is a measurement of the current performance and availability of your application, which you then use as a comparison after your migration to validate your business case. In some cases, you may change a baseline when you perform migration acceptance testing. You can also use a baseline as a comparison point during your migration to make sure that you are on track. 1. Identify components Before you begin a cloud migration, identify all the tiers of your entire application stack. List all of the components (applications, services, etc.) that you want to migrate. Segment the application stack as follows: Application (backend/microservices/cron jobs) Dependency services, such as the message queue Database Website Underlying server and infrastructure Tip Make sure that you have access to applications and instances before you start creating application baselines. Engage your application owners, DevOps engineers, and product managers for access. Example: List of components Here is an example of the list of components in an application stack: Component Name Owner Language Stack Accessibility (Internet, Intranet) Operating System Service 1 John Doe Java Internet RHEL 6 Service 2 Maya Wiz .NET Intranet Win2003 R2 RabbitMQ John Doe Java Intranet AIX Website Maya Wiz Classic ASP Internet Win2000 MS SQL Dave Z NA Intranet Win2003 R2 2. Determine compatibility Once you identify the applications that you want to migrate, it is time to verify which application tiers to monitor with the New Relic platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off, as the more you can instrument, the better your baselines. Here are the New Relic products to use for baselining, depending on the components that you identified: APM: Monitor your web apps with APM. See Compatibility and requirements for New Relic agents and products to learn precise compatibility details for each supported language. Infrastructure: Monitor your hosts with infrastructure. See Compatibility and requirements for infrastructure for supported operating systems and environments. You can also instrument other products and services with on-host integrations. Synthetics: Monitor web frontends and APIs with synthetics. Sometimes, you may not be able to instrument your on-premise environment with APM or Infrastructure. For example, maybe your organization's policy forbids installing an agent behind a firewall. In these cases, if the application has a web frontend, use Synthetics, as it offers non-agent monitoring while still providing the ability to establish a baseline. Example: Components matched to New Relic products Match the components that you identified with their corresponding products: Component Name Tier Owner Language Stack Accessibility (Internet/ Intranet) Operating System New Relic Products Service 1 John Doe Java Internet RHEL 6 APM, Infrastructure, Synthetics Service 2 Maya Wiz .NET Intranet Win2003 R2 APM, Infrastructure ActiveMQ John Doe Java Intranet AIX APM, Plugin Website Maya Wiz Classic ASP Internet Win2000 Synthetics MS SQL Dave Z n/a Intranet Win2003 R2 Infrastructure, On-host Integration 3. Deploy monitoring Based on the component-product matches you made, deploy agents or monitors across your architecture: Deploy APM Install the APM agent on your application stack. The steps to install the APM agent are different based on language. Deploy New Relic Infrastructure After reviewing the requirements for infrastructure, follow the instructions to install the infrastructure agent on your hosts: Install for Linux Install for Windows Server Install on AWS Elastic Beanstalk Install with a configuration management tool Deploy Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations. Available integrations include Apache, MySQL, NGINX, and others. Create New Relic Synthetics monitors New Relic Synthetics is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. To get started add a monitor. Tip Make sure to verify that your website URL is accessible from the public network. You may also need to add New Relic IPs to your allow list. 4. Gather metrics After you deploy the agents and monitors, identify which metrics are the most important to your business and use these metrics to define your KPIs. Some recommendations include: Response time: Time taken to respond to a request. Throughput: Number of requests that came in through the application. Requesting queuing (Apache, IIS, NGINX): Duration of time taken for a request to reach your application. Database call duration: Duration of time taken to complete a database call. DB call counts: Number of calls made by application code to the database. Error rate: Percent of errors reported. Apdex score: An industry standard to measure user satisfaction with the response time of web applications and services. DNS setup timing: The time it takes to connect and receive data from DNS. SSL setup timing: The time it takes to establish an SSL connection. You can find some of these metrics in service maps, as well as on APM, and [browser] (/docs/ /new-relic-browser/getting-started/browser-overview-page-website-performance-summary) overview pages. For more detailed information about navigating, interpreting, and using APM, check out these New Relic University’s tutorials: Overview dashboard tour Transactions dashboard Understanding Apdex 5. Set up Dashboards After you define your KPIs, it is easy to visualize them in dashboards. Dashboards provide a single location to view all the data that New Relic products gather. Dashboards data consists of events, and each event has an event type, a timestamp, and key-value attributes. For more information about events, see Data collection and Default events for New Relic products. You can locate your KPIs and business metrics data in New Relic using the data explorer and the NRQL query language. You can also build dashboards to track the performance of those KPIs: Example: Component performance compared against baselines Continuing the examples in this document, the following table illustrates the maturity of your application performance over a period of time based on deployment milestones. Each milestone will serve as a new baseline for your applications: Component Milestone 1 Milestone 2 Milestone N Environment Component Name Response Time SLA Apdex Response Time SLA Apdex Response On-Prem Service 1 1.5 secs 80% 70% 1.5 secs 68% 0.65 1.4 secs Cloud Service 1 0.9 secs 96.8% 95% 0.9 secs 98% 0.99 0.7 secs On-Prem Service 2 0.7 secs 73% 68% 0.7 secs 80% 0.78 0.85 secs Cloud Service 2 0.6 secs 90% 92% 0.6 secs 89% 0.90 0.5 secs After your migration, compare these baselines against your migration acceptance testing baselines. Expert tips If you find that you need data that is not captured by default instrumentation, New Relic makes it easy to capture custom data: APM custom instrumentation Browser custom data Infrastructure custom attributes Custom event data Mobile custom data Synthetics custom attributes You can also learn more about APM custom instrumentation with the New Relic University Custom data tutorial series.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.35364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example: Components matched to <em>New</em> <em>Relic</em> products",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " want to migrate, it is time to verify which application tiers to monitor with the <em>New</em> <em>Relic</em> platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off"
      },
      "id": "6044605c64441f1d15378edf"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide": [
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "JavaScript error rate KPI",
        "HTTP error rate KPI",
        "Time to first byte KPI",
        "Core web vitals: Largest contentful paint (LCP) KPI",
        "Core web vitals: First input delay (FID) KPI",
        "Cumulative layout shift (CLS) KPI",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review Instrumented Pages",
        "Validate Browser URL Grouping",
        "Understand How You Will Segment Your Data",
        "Import the Quality Foundation Dashboard",
        "Capture Current Performance For Each Dashboard Page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to Improve",
        "Improve Targeted KPIs",
        "Improve Page Load Performance",
        "Improve AJAX Response Times",
        "Improve the AJAX Error Rate",
        "Improve Javascript Errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2021-10-12T12:55:15Z",
      "updated_at": "2021-09-18T16:34:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. Desired Outcome This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Key Performance Indicators Quality Foundation measures the following KPIs: JavaScript error rate KPI This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. HTTP error rate KPI HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Time to first byte KPI This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Core web vitals: Largest contentful paint (LCP) KPI Core Web Vitals are part of Google’s Page Experience Metrics. They measure the experience from when a page begins rendering. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Core web vitals: First input delay (FID) KPI This KPI measures the experience from when a page begins rendering. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Cumulative layout shift (CLS) KPI This KPI measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events is at least 2x an average sprint. Establish current state Review Instrumented Pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL Grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand How You Will Segment Your Data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the Quality Foundation Dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture Current Performance For Each Dashboard Page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to Improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve Targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve Page Load Performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX Response Times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX Error Rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve Javascript Errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices going forward: Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization: At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.9312,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Quality foundation <em>implementation</em> <em>guide</em>",
        "sections": "Quality foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " you understand your <em>digital</em> <em>customer</em> <em>experience</em> in a meaningful way. Desired Outcome This <em>implementation</em> <em>guide</em> will help you: Look at <em>customer</em> <em>experience</em> in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "sections": [
        "Improve web uptime",
        "1. Investigate Synthetics checks",
        "2. Create workloads",
        "3. Investigate outages at lowest tier first"
      ],
      "title": "Improve web uptime",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Uptime",
        "Availability"
      ],
      "external_id": "5893b26accc8f1ebcb41ca1ccd7f50f1a2f4f7d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-web-uptime/",
      "published_at": "2021-10-12T12:55:15Z",
      "updated_at": "2021-09-07T09:17:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Steps to follow to improve web uptime: 1. Investigate Synthetics checks Investigate and resolve failed Synthetics checks when they occur. Check multiple locations. Set up an alert to notify you when multiple locations fail. 2. Create workloads Create workloads that correlate synthetic monitors with browser applications, services, and infrastructure. Include a link to the workload in the alert runbook. You can also find the correlated workload for a synthetic using global search. Make sure that alerts are configured for each tier of your workload. This way you can see the health of each of the tiers in one view. This will save you time in troubleshooting. You do not need to create alert notifications for each tier to benefit from this view. 3. Investigate outages at lowest tier first When an outage occurs, start investigating at the lowest tier that is alerting. For instance, if you see that you have an infrastructure issue and a JavaScript issue, investigate infrastructure prior to javascript unless you have a second person or team you can delegate that to. Use the tools that are available to you for troubleshooting: Make sure that distributed tracing is enabled for browser monitoring as well as APM. Use the Browser UI to help you understand what is happening at the end user tier. Use Lookout to help you understand what’s causing flapping or reoccurring issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.13007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>"
      },
      "id": "61372e1728ccbcf13b56a862"
    },
    {
      "sections": [
        "Improve page load performance",
        "Page Load KPI",
        "Cumulative Layout Shift (CLS)",
        "Largest Contentful Paint (LCP)",
        "First Input Delay (FID)"
      ],
      "title": "Improve page load performance",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Core web vitals",
        "Page load",
        "Page render"
      ],
      "external_id": "a6c3e400d5c99451f900a3edee1fa19149b5f82c",
      "image": "https://docs.newrelic.com/static/a73f684466bda769a52da48dc9a4e4cc/d9199/cx_page_load_render_timings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load/",
      "published_at": "2021-10-12T12:54:02Z",
      "updated_at": "2021-09-07T09:17:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user experience, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying to improve. For maximum impact, focus on pages that are frequently accessed but have a lower than accepted score for the 75th percentile of users. Page Load KPI How to improve time to first byte (TTFB): Time to first byte measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. If users in the 75th percentile are experiencing a TTFB of greater than 0.5s for one or more of your pages, you can break timings down further by querying the following attributes in PageView: backendDuration connectionSetupDuration dnsLookupDuration networkDuration Frequently slowness prior to rendering is caused by slowness in the backend, either from third party APIs or backend applications. Synthetics monitoring for third party APIs helps operations and development teams understand when the root cause is outside of their control. Even if you cannot control the code, you can influence the outcome by sharing synthetics results with the third party to help them understand what your customers are experiencing. If the backend applications are owned by you or your team, you can use APM agents, Pixie, or OpenTelemetry to understand and manage performance. To make cross team communication easier, we recommend implementing Service Level Management boundaries. Cumulative Layout Shift (CLS) Cumulative layout shift is a score that indicates how much content shifts once it has already loaded. General tips and tricks for improving CLS: Specify dimensions for stylesheets and let the browser’s default CSS control the aspect ratio. Statically reserve space for ad slots. Avoid ads near the top of the viewport. Avoid inserting new content above existing content. Precompute sufficient space for embeds. Additional resources: Google’s approach to CLS optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. Largest Contentful Paint (LCP) Largest contentful paint measures the difference between the start of page render until the time to paint the largest content element. Common causes for a slow lcp, according to web.dev: Slow server response times Render-blocking JavaScript and CSS Slow resource load times Client-side rendering Use Browser session trace information to understand which of the common causes above factor into the particular page you are trying to optimize. Approaches to improve LCP: Making use of CDNs and paying attention to caching and edge server performance Establishing third party connections early Delaying non-critical Javascript and CSS Additional resources: Google’s approach to LCP optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. First Input Delay (FID) First input delay is the time between when a user first interacts with a page to the time when the browser is able to respond. It’s a field metric that varies based on real user behavior (results vary based on user impatience and action timing) but can be optimized by reducing TBT, total blocking time. To do this, you need to: Break up long blocking tasks. Optimize bloated JavaScript. Look at moving logic server side and/or use web workers to run threads in the background. Use Browser session trace information to understand where your blocking intervals are occurring and for how long they last. Additional resources: Google’s approach to FID optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.08072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user <em>experience</em>, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying"
      },
      "id": "61372e19196a67f4814948d7"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load": [
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "JavaScript error rate KPI",
        "HTTP error rate KPI",
        "Time to first byte KPI",
        "Core web vitals: Largest contentful paint (LCP) KPI",
        "Core web vitals: First input delay (FID) KPI",
        "Cumulative layout shift (CLS) KPI",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review Instrumented Pages",
        "Validate Browser URL Grouping",
        "Understand How You Will Segment Your Data",
        "Import the Quality Foundation Dashboard",
        "Capture Current Performance For Each Dashboard Page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to Improve",
        "Improve Targeted KPIs",
        "Improve Page Load Performance",
        "Improve AJAX Response Times",
        "Improve the AJAX Error Rate",
        "Improve Javascript Errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2021-10-12T12:55:15Z",
      "updated_at": "2021-09-18T16:34:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. Desired Outcome This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Key Performance Indicators Quality Foundation measures the following KPIs: JavaScript error rate KPI This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. HTTP error rate KPI HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Time to first byte KPI This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Core web vitals: Largest contentful paint (LCP) KPI Core Web Vitals are part of Google’s Page Experience Metrics. They measure the experience from when a page begins rendering. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Core web vitals: First input delay (FID) KPI This KPI measures the experience from when a page begins rendering. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Cumulative layout shift (CLS) KPI This KPI measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events is at least 2x an average sprint. Establish current state Review Instrumented Pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL Grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand How You Will Segment Your Data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the Quality Foundation Dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture Current Performance For Each Dashboard Page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to Improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve Targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve Page Load Performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX Response Times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX Error Rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve Javascript Errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices going forward: Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization: At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 408.76456,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Quality foundation <em>implementation</em> <em>guide</em>",
        "sections": "<em>Core</em> <em>web</em> <em>vitals</em>: Largest contentful paint (LCP) KPI",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " and can they find it?) Product and content relevance (Does it have what users care about?) <em>Digital</em> <em>customer</em> <em>experience</em> includes <em>web</em>, mobile, and IoT. The first version of this <em>guide</em> is focused on measuring the end user <em>web</em> <em>experience</em>. Quality Foundation is about creating a standard practice to help"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "sections": [
        "Improve web uptime",
        "1. Investigate Synthetics checks",
        "2. Create workloads",
        "3. Investigate outages at lowest tier first"
      ],
      "title": "Improve web uptime",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Uptime",
        "Availability"
      ],
      "external_id": "5893b26accc8f1ebcb41ca1ccd7f50f1a2f4f7d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-web-uptime/",
      "published_at": "2021-10-12T12:55:15Z",
      "updated_at": "2021-09-07T09:17:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Steps to follow to improve web uptime: 1. Investigate Synthetics checks Investigate and resolve failed Synthetics checks when they occur. Check multiple locations. Set up an alert to notify you when multiple locations fail. 2. Create workloads Create workloads that correlate synthetic monitors with browser applications, services, and infrastructure. Include a link to the workload in the alert runbook. You can also find the correlated workload for a synthetic using global search. Make sure that alerts are configured for each tier of your workload. This way you can see the health of each of the tiers in one view. This will save you time in troubleshooting. You do not need to create alert notifications for each tier to benefit from this view. 3. Investigate outages at lowest tier first When an outage occurs, start investigating at the lowest tier that is alerting. For instance, if you see that you have an infrastructure issue and a JavaScript issue, investigate infrastructure prior to javascript unless you have a second person or team you can delegate that to. Use the tools that are available to you for troubleshooting: Make sure that distributed tracing is enabled for browser monitoring as well as APM. Use the Browser UI to help you understand what is happening at the end user tier. Use Lookout to help you understand what’s causing flapping or reoccurring issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.14606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Improve <em>web</em> uptime",
        "sections": "Improve <em>web</em> uptime",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": "Steps to follow to improve <em>web</em> uptime: 1. Investigate Synthetics checks Investigate and resolve failed Synthetics checks when they occur. Check multiple locations. Set up an alert to notify you when multiple locations fail. 2. Create workloads Create workloads that correlate synthetic monitors"
      },
      "id": "61372e1728ccbcf13b56a862"
    },
    {
      "sections": [
        "Bottom of the funnel analysis implementation guide",
        "Desired outcome",
        "Key performance indicators",
        "Prerequisites",
        "Required knowledge",
        "Required installation and configuration",
        "Establish current state",
        "Identify where the Bottom of the Funnel starts",
        "Ecommerce user journey",
        "Car insurance purchase user journey",
        "Distinguish between Pages and Actions",
        "Create a scripted Synthetics Check for the Bottom of the Funnel",
        "Import the Bottom of the Funnel Dashboard",
        "Capture Current Performance",
        "Improvement process",
        "Plan your work",
        "Advanced topics",
        "Conclusion",
        "Best practices going forward",
        "Value realization"
      ],
      "title": "Bottom of the funnel analysis implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Conversions",
        "Funnel",
        "Bottom of the funnel"
      ],
      "external_id": "d1a470e689225e2241cc6946e36f123491bae202",
      "image": "https://docs.newrelic.com/static/2373669d2bc6f30be8344b42fc79a983/764be/cx-botfa-ecommerce.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-07T09:17:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Desired outcome Increase revenue by resolving issues that appear when a user attempts to complete an action. Key performance indicators Bottom of the Funnel Analysis measures the following KPIs: KPI Description Goal Bottom of the Funnel Success Rate/Conversion Rate The rate of conversion once a user has gone far enough to demonstrate intent to complete an action to actual completion. Examples of this are rate of: Checkout -> Order submission Insurance form review -> submission Completing sign up details -> submission Increase the rate of conversion by addressing errors and latency at the bottom of the funnel Revenue at Risk due to Latency Value of a conversion * number of pages or interactions in the bottom of the funnel that are slower than the industry threshold. Focus on reducing this value by improving page KPIs Revenue at Risk due to Errors Value of a conversion * number of backend errors in the bottom of the funnel interactions Tune this value to make it meaningful by filtering out errors that aren't visible to the end user. Once this is meaningful, focus on reducing it. Create an alert to notify you if it suddenly trends upward. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required installation and configuration Browser Pro installed in relevant pages SPA enabled for single page applications Insights retention for Browser events is at least 2x an average sprint. Establish current state Identify where the Bottom of the Funnel starts The Bottom of the Funnel is focused on the final steps of a user journey where a user has gone far enough to show intent to complete the journey. Some examples: Ecommerce user journey The user journey is simplified so you can focus on where the bottom of the funnel begins - at checkout. Most users entering the checkout phase plan to purchase something. Reducing errors and latency from this point onward is more likely to improve conversions than focusing on any other part of the funnel. Car insurance purchase user journey In the example above, you have the user’s interest in car insurance as they enter information, but you do not know their intent until they see the quote and continue to proceed. Distinguish between Pages and Actions The final steps of a user’s journey is likely to be a mix of full page loads and AJAX calls. You will need to know all pages and Ajax requests for the next step. If you are not sure which requests are running from the page in question, you can run: SELECT count(*) FROM AjaxRequest WHERE pageUrl like ‘%FILTER%’ FACET groupedRequestUrl SINCE 1 DAY AGO Copy Create a scripted Synthetics Check for the Bottom of the Funnel Make sure you have a scripted monitor for each path through the bottom of the funnel. The goal is to make sure your bottom of the funnel services are working around the clock. For example, you may have a checkout flow that calls a different payment API depending on the customer’s payment preferences. Import the Bottom of the Funnel Dashboard Follow the instructions documented in the public GitHub README. Capture Current Performance Follow the GitHub repository README instructions. Use the dashboard from the previous step to understand the bottom of the funnel performance. Create a plan to improve KPIs that don’t meet target values as well as reduce revenue at risk. Improvement process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. For detailed information, see: Improve uptime Improve page load performance Improve AJAX performance Advanced topics Should I apply segmentation? Segmentation (breaking out performance into cohorts, such as region and device type) is a good idea if: Your organization has initiatives tied to addressing a target audience from a particular cohort that you can segment by using either custom attributes or data that is already available in New Relic. You are already familiar with Bottom of the Funnel Analysis and there is a significant enough difference in performance among different cohorts to warrant tracking and/or developer focus. Conclusion Best practices going forward Revisit performance metrics at the end of each sprint. Any time the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your Customer Experience SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation KPIs. Value realization At the end of this process you should: Know your user conversion rate and have addressed errors or performance issues that negatively impact it. Increased revenue for your company. Created, or be on the path to create, a common language with business owners so you are working together; opening new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.80182,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "sections": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your <em>Customer</em> <em>Experience</em> SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation"
      },
      "id": "61372e1964441f16fa42438e"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-web-uptime": [
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "JavaScript error rate KPI",
        "HTTP error rate KPI",
        "Time to first byte KPI",
        "Core web vitals: Largest contentful paint (LCP) KPI",
        "Core web vitals: First input delay (FID) KPI",
        "Cumulative layout shift (CLS) KPI",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review Instrumented Pages",
        "Validate Browser URL Grouping",
        "Understand How You Will Segment Your Data",
        "Import the Quality Foundation Dashboard",
        "Capture Current Performance For Each Dashboard Page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to Improve",
        "Improve Targeted KPIs",
        "Improve Page Load Performance",
        "Improve AJAX Response Times",
        "Improve the AJAX Error Rate",
        "Improve Javascript Errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2021-10-12T12:55:15Z",
      "updated_at": "2021-09-18T16:34:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. Desired Outcome This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Key Performance Indicators Quality Foundation measures the following KPIs: JavaScript error rate KPI This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. HTTP error rate KPI HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Time to first byte KPI This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Core web vitals: Largest contentful paint (LCP) KPI Core Web Vitals are part of Google’s Page Experience Metrics. They measure the experience from when a page begins rendering. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Core web vitals: First input delay (FID) KPI This KPI measures the experience from when a page begins rendering. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Cumulative layout shift (CLS) KPI This KPI measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events is at least 2x an average sprint. Establish current state Review Instrumented Pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL Grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand How You Will Segment Your Data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the Quality Foundation Dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture Current Performance For Each Dashboard Page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to Improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve Targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve Page Load Performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX Response Times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX Error Rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve Javascript Errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices going forward: Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization: At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.3404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Quality foundation <em>implementation</em> <em>guide</em>",
        "sections": "Quality foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " you understand your <em>digital</em> <em>customer</em> <em>experience</em> in a meaningful way. Desired Outcome This <em>implementation</em> <em>guide</em> will help you: Look at <em>customer</em> <em>experience</em> in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "sections": [
        "Bottom of the funnel analysis implementation guide",
        "Desired outcome",
        "Key performance indicators",
        "Prerequisites",
        "Required knowledge",
        "Required installation and configuration",
        "Establish current state",
        "Identify where the Bottom of the Funnel starts",
        "Ecommerce user journey",
        "Car insurance purchase user journey",
        "Distinguish between Pages and Actions",
        "Create a scripted Synthetics Check for the Bottom of the Funnel",
        "Import the Bottom of the Funnel Dashboard",
        "Capture Current Performance",
        "Improvement process",
        "Plan your work",
        "Advanced topics",
        "Conclusion",
        "Best practices going forward",
        "Value realization"
      ],
      "title": "Bottom of the funnel analysis implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Conversions",
        "Funnel",
        "Bottom of the funnel"
      ],
      "external_id": "d1a470e689225e2241cc6946e36f123491bae202",
      "image": "https://docs.newrelic.com/static/2373669d2bc6f30be8344b42fc79a983/764be/cx-botfa-ecommerce.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-07T09:17:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Desired outcome Increase revenue by resolving issues that appear when a user attempts to complete an action. Key performance indicators Bottom of the Funnel Analysis measures the following KPIs: KPI Description Goal Bottom of the Funnel Success Rate/Conversion Rate The rate of conversion once a user has gone far enough to demonstrate intent to complete an action to actual completion. Examples of this are rate of: Checkout -> Order submission Insurance form review -> submission Completing sign up details -> submission Increase the rate of conversion by addressing errors and latency at the bottom of the funnel Revenue at Risk due to Latency Value of a conversion * number of pages or interactions in the bottom of the funnel that are slower than the industry threshold. Focus on reducing this value by improving page KPIs Revenue at Risk due to Errors Value of a conversion * number of backend errors in the bottom of the funnel interactions Tune this value to make it meaningful by filtering out errors that aren't visible to the end user. Once this is meaningful, focus on reducing it. Create an alert to notify you if it suddenly trends upward. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required installation and configuration Browser Pro installed in relevant pages SPA enabled for single page applications Insights retention for Browser events is at least 2x an average sprint. Establish current state Identify where the Bottom of the Funnel starts The Bottom of the Funnel is focused on the final steps of a user journey where a user has gone far enough to show intent to complete the journey. Some examples: Ecommerce user journey The user journey is simplified so you can focus on where the bottom of the funnel begins - at checkout. Most users entering the checkout phase plan to purchase something. Reducing errors and latency from this point onward is more likely to improve conversions than focusing on any other part of the funnel. Car insurance purchase user journey In the example above, you have the user’s interest in car insurance as they enter information, but you do not know their intent until they see the quote and continue to proceed. Distinguish between Pages and Actions The final steps of a user’s journey is likely to be a mix of full page loads and AJAX calls. You will need to know all pages and Ajax requests for the next step. If you are not sure which requests are running from the page in question, you can run: SELECT count(*) FROM AjaxRequest WHERE pageUrl like ‘%FILTER%’ FACET groupedRequestUrl SINCE 1 DAY AGO Copy Create a scripted Synthetics Check for the Bottom of the Funnel Make sure you have a scripted monitor for each path through the bottom of the funnel. The goal is to make sure your bottom of the funnel services are working around the clock. For example, you may have a checkout flow that calls a different payment API depending on the customer’s payment preferences. Import the Bottom of the Funnel Dashboard Follow the instructions documented in the public GitHub README. Capture Current Performance Follow the GitHub repository README instructions. Use the dashboard from the previous step to understand the bottom of the funnel performance. Create a plan to improve KPIs that don’t meet target values as well as reduce revenue at risk. Improvement process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. For detailed information, see: Improve uptime Improve page load performance Improve AJAX performance Advanced topics Should I apply segmentation? Segmentation (breaking out performance into cohorts, such as region and device type) is a good idea if: Your organization has initiatives tied to addressing a target audience from a particular cohort that you can segment by using either custom attributes or data that is already available in New Relic. You are already familiar with Bottom of the Funnel Analysis and there is a significant enough difference in performance among different cohorts to warrant tracking and/or developer focus. Conclusion Best practices going forward Revisit performance metrics at the end of each sprint. Any time the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your Customer Experience SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation KPIs. Value realization At the end of this process you should: Know your user conversion rate and have addressed errors or performance issues that negatively impact it. Increased revenue for your company. Created, or be on the path to create, a common language with business owners so you are working together; opening new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.4458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "sections": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your <em>Customer</em> <em>Experience</em> SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation"
      },
      "id": "61372e1964441f16fa42438e"
    },
    {
      "sections": [
        "Improve page load performance",
        "Page Load KPI",
        "Cumulative Layout Shift (CLS)",
        "Largest Contentful Paint (LCP)",
        "First Input Delay (FID)"
      ],
      "title": "Improve page load performance",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Core web vitals",
        "Page load",
        "Page render"
      ],
      "external_id": "a6c3e400d5c99451f900a3edee1fa19149b5f82c",
      "image": "https://docs.newrelic.com/static/a73f684466bda769a52da48dc9a4e4cc/d9199/cx_page_load_render_timings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load/",
      "published_at": "2021-10-12T12:54:02Z",
      "updated_at": "2021-09-07T09:17:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user experience, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying to improve. For maximum impact, focus on pages that are frequently accessed but have a lower than accepted score for the 75th percentile of users. Page Load KPI How to improve time to first byte (TTFB): Time to first byte measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. If users in the 75th percentile are experiencing a TTFB of greater than 0.5s for one or more of your pages, you can break timings down further by querying the following attributes in PageView: backendDuration connectionSetupDuration dnsLookupDuration networkDuration Frequently slowness prior to rendering is caused by slowness in the backend, either from third party APIs or backend applications. Synthetics monitoring for third party APIs helps operations and development teams understand when the root cause is outside of their control. Even if you cannot control the code, you can influence the outcome by sharing synthetics results with the third party to help them understand what your customers are experiencing. If the backend applications are owned by you or your team, you can use APM agents, Pixie, or OpenTelemetry to understand and manage performance. To make cross team communication easier, we recommend implementing Service Level Management boundaries. Cumulative Layout Shift (CLS) Cumulative layout shift is a score that indicates how much content shifts once it has already loaded. General tips and tricks for improving CLS: Specify dimensions for stylesheets and let the browser’s default CSS control the aspect ratio. Statically reserve space for ad slots. Avoid ads near the top of the viewport. Avoid inserting new content above existing content. Precompute sufficient space for embeds. Additional resources: Google’s approach to CLS optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. Largest Contentful Paint (LCP) Largest contentful paint measures the difference between the start of page render until the time to paint the largest content element. Common causes for a slow lcp, according to web.dev: Slow server response times Render-blocking JavaScript and CSS Slow resource load times Client-side rendering Use Browser session trace information to understand which of the common causes above factor into the particular page you are trying to optimize. Approaches to improve LCP: Making use of CDNs and paying attention to caching and edge server performance Establishing third party connections early Delaying non-critical Javascript and CSS Additional resources: Google’s approach to LCP optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. First Input Delay (FID) First input delay is the time between when a user first interacts with a page to the time when the browser is able to respond. It’s a field metric that varies based on real user behavior (results vary based on user impatience and action timing) but can be optimized by reducing TBT, total blocking time. To do this, you need to: Break up long blocking tasks. Optimize bloated JavaScript. Look at moving logic server side and/or use web workers to run threads in the background. Use Browser session trace information to understand where your blocking intervals are occurring and for how long they last. Additional resources: Google’s approach to FID optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.80185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user <em>experience</em>, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying"
      },
      "id": "61372e19196a67f4814948d7"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide": [
    {
      "sections": [
        "Bottom of the funnel analysis implementation guide",
        "Desired outcome",
        "Key performance indicators",
        "Prerequisites",
        "Required knowledge",
        "Required installation and configuration",
        "Establish current state",
        "Identify where the Bottom of the Funnel starts",
        "Ecommerce user journey",
        "Car insurance purchase user journey",
        "Distinguish between Pages and Actions",
        "Create a scripted Synthetics Check for the Bottom of the Funnel",
        "Import the Bottom of the Funnel Dashboard",
        "Capture Current Performance",
        "Improvement process",
        "Plan your work",
        "Advanced topics",
        "Conclusion",
        "Best practices going forward",
        "Value realization"
      ],
      "title": "Bottom of the funnel analysis implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Conversions",
        "Funnel",
        "Bottom of the funnel"
      ],
      "external_id": "d1a470e689225e2241cc6946e36f123491bae202",
      "image": "https://docs.newrelic.com/static/2373669d2bc6f30be8344b42fc79a983/764be/cx-botfa-ecommerce.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-07T09:17:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Desired outcome Increase revenue by resolving issues that appear when a user attempts to complete an action. Key performance indicators Bottom of the Funnel Analysis measures the following KPIs: KPI Description Goal Bottom of the Funnel Success Rate/Conversion Rate The rate of conversion once a user has gone far enough to demonstrate intent to complete an action to actual completion. Examples of this are rate of: Checkout -> Order submission Insurance form review -> submission Completing sign up details -> submission Increase the rate of conversion by addressing errors and latency at the bottom of the funnel Revenue at Risk due to Latency Value of a conversion * number of pages or interactions in the bottom of the funnel that are slower than the industry threshold. Focus on reducing this value by improving page KPIs Revenue at Risk due to Errors Value of a conversion * number of backend errors in the bottom of the funnel interactions Tune this value to make it meaningful by filtering out errors that aren't visible to the end user. Once this is meaningful, focus on reducing it. Create an alert to notify you if it suddenly trends upward. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required installation and configuration Browser Pro installed in relevant pages SPA enabled for single page applications Insights retention for Browser events is at least 2x an average sprint. Establish current state Identify where the Bottom of the Funnel starts The Bottom of the Funnel is focused on the final steps of a user journey where a user has gone far enough to show intent to complete the journey. Some examples: Ecommerce user journey The user journey is simplified so you can focus on where the bottom of the funnel begins - at checkout. Most users entering the checkout phase plan to purchase something. Reducing errors and latency from this point onward is more likely to improve conversions than focusing on any other part of the funnel. Car insurance purchase user journey In the example above, you have the user’s interest in car insurance as they enter information, but you do not know their intent until they see the quote and continue to proceed. Distinguish between Pages and Actions The final steps of a user’s journey is likely to be a mix of full page loads and AJAX calls. You will need to know all pages and Ajax requests for the next step. If you are not sure which requests are running from the page in question, you can run: SELECT count(*) FROM AjaxRequest WHERE pageUrl like ‘%FILTER%’ FACET groupedRequestUrl SINCE 1 DAY AGO Copy Create a scripted Synthetics Check for the Bottom of the Funnel Make sure you have a scripted monitor for each path through the bottom of the funnel. The goal is to make sure your bottom of the funnel services are working around the clock. For example, you may have a checkout flow that calls a different payment API depending on the customer’s payment preferences. Import the Bottom of the Funnel Dashboard Follow the instructions documented in the public GitHub README. Capture Current Performance Follow the GitHub repository README instructions. Use the dashboard from the previous step to understand the bottom of the funnel performance. Create a plan to improve KPIs that don’t meet target values as well as reduce revenue at risk. Improvement process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. For detailed information, see: Improve uptime Improve page load performance Improve AJAX performance Advanced topics Should I apply segmentation? Segmentation (breaking out performance into cohorts, such as region and device type) is a good idea if: Your organization has initiatives tied to addressing a target audience from a particular cohort that you can segment by using either custom attributes or data that is already available in New Relic. You are already familiar with Bottom of the Funnel Analysis and there is a significant enough difference in performance among different cohorts to warrant tracking and/or developer focus. Conclusion Best practices going forward Revisit performance metrics at the end of each sprint. Any time the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your Customer Experience SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation KPIs. Value realization At the end of this process you should: Know your user conversion rate and have addressed errors or performance issues that negatively impact it. Increased revenue for your company. Created, or be on the path to create, a common language with business owners so you are working together; opening new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 347.37375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "sections": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your <em>Customer</em> <em>Experience</em> SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in <em>Quality</em> Foundation"
      },
      "id": "61372e1964441f16fa42438e"
    },
    {
      "sections": [
        "Improve page load performance",
        "Page Load KPI",
        "Cumulative Layout Shift (CLS)",
        "Largest Contentful Paint (LCP)",
        "First Input Delay (FID)"
      ],
      "title": "Improve page load performance",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Core web vitals",
        "Page load",
        "Page render"
      ],
      "external_id": "a6c3e400d5c99451f900a3edee1fa19149b5f82c",
      "image": "https://docs.newrelic.com/static/a73f684466bda769a52da48dc9a4e4cc/d9199/cx_page_load_render_timings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load/",
      "published_at": "2021-10-12T12:54:02Z",
      "updated_at": "2021-09-07T09:17:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user experience, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying to improve. For maximum impact, focus on pages that are frequently accessed but have a lower than accepted score for the 75th percentile of users. Page Load KPI How to improve time to first byte (TTFB): Time to first byte measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. If users in the 75th percentile are experiencing a TTFB of greater than 0.5s for one or more of your pages, you can break timings down further by querying the following attributes in PageView: backendDuration connectionSetupDuration dnsLookupDuration networkDuration Frequently slowness prior to rendering is caused by slowness in the backend, either from third party APIs or backend applications. Synthetics monitoring for third party APIs helps operations and development teams understand when the root cause is outside of their control. Even if you cannot control the code, you can influence the outcome by sharing synthetics results with the third party to help them understand what your customers are experiencing. If the backend applications are owned by you or your team, you can use APM agents, Pixie, or OpenTelemetry to understand and manage performance. To make cross team communication easier, we recommend implementing Service Level Management boundaries. Cumulative Layout Shift (CLS) Cumulative layout shift is a score that indicates how much content shifts once it has already loaded. General tips and tricks for improving CLS: Specify dimensions for stylesheets and let the browser’s default CSS control the aspect ratio. Statically reserve space for ad slots. Avoid ads near the top of the viewport. Avoid inserting new content above existing content. Precompute sufficient space for embeds. Additional resources: Google’s approach to CLS optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. Largest Contentful Paint (LCP) Largest contentful paint measures the difference between the start of page render until the time to paint the largest content element. Common causes for a slow lcp, according to web.dev: Slow server response times Render-blocking JavaScript and CSS Slow resource load times Client-side rendering Use Browser session trace information to understand which of the common causes above factor into the particular page you are trying to optimize. Approaches to improve LCP: Making use of CDNs and paying attention to caching and edge server performance Establishing third party connections early Delaying non-critical Javascript and CSS Additional resources: Google’s approach to LCP optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. First Input Delay (FID) First input delay is the time between when a user first interacts with a page to the time when the browser is able to respond. It’s a field metric that varies based on real user behavior (results vary based on user impatience and action timing) but can be optimized by reducing TBT, total blocking time. To do this, you need to: Break up long blocking tasks. Optimize bloated JavaScript. Look at moving logic server side and/or use web workers to run threads in the background. Use Browser session trace information to understand where your blocking intervals are occurring and for how long they last. Additional resources: Google’s approach to FID optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 320.46426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user <em>experience</em>, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying"
      },
      "id": "61372e19196a67f4814948d7"
    },
    {
      "sections": [
        "Improve web uptime",
        "1. Investigate Synthetics checks",
        "2. Create workloads",
        "3. Investigate outages at lowest tier first"
      ],
      "title": "Improve web uptime",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Uptime",
        "Availability"
      ],
      "external_id": "5893b26accc8f1ebcb41ca1ccd7f50f1a2f4f7d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-web-uptime/",
      "published_at": "2021-10-12T12:55:15Z",
      "updated_at": "2021-09-07T09:17:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Steps to follow to improve web uptime: 1. Investigate Synthetics checks Investigate and resolve failed Synthetics checks when they occur. Check multiple locations. Set up an alert to notify you when multiple locations fail. 2. Create workloads Create workloads that correlate synthetic monitors with browser applications, services, and infrastructure. Include a link to the workload in the alert runbook. You can also find the correlated workload for a synthetic using global search. Make sure that alerts are configured for each tier of your workload. This way you can see the health of each of the tiers in one view. This will save you time in troubleshooting. You do not need to create alert notifications for each tier to benefit from this view. 3. Investigate outages at lowest tier first When an outage occurs, start investigating at the lowest tier that is alerting. For instance, if you see that you have an infrastructure issue and a JavaScript issue, investigate infrastructure prior to javascript unless you have a second person or team you can delegate that to. Use the tools that are available to you for troubleshooting: Make sure that distributed tracing is enabled for browser monitoring as well as APM. Use the Browser UI to help you understand what is happening at the end user tier. Use Lookout to help you understand what’s causing flapping or reoccurring issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 320.46423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>"
      },
      "id": "61372e1728ccbcf13b56a862"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/index": [
    {
      "sections": [
        "Alert quality management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Incident volume",
        "Incident count KPI",
        "Accumulated incident duration KPI",
        "Mean time to close (MTTC) KPI",
        "Percent under 5 minutes KPI",
        "User engagement",
        "Percentage Acknowledged KPI",
        "Mean time to investigate (MTTI) KPI",
        "Prerequisites",
        "Establish current state of your KPIs",
        "Install and configure the incident event webhook",
        "Install the AQM dashboard",
        "Perform initial AQM orientation and enablement",
        "Accumulate AQM data",
        "Perform second enablement session",
        "Improvement process",
        "Value realization",
        "KPI reference",
        "Incident engagement"
      ],
      "title": "Alert quality management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Alert quality management",
        "Implementation guide"
      ],
      "external_id": "b69abb6b9b6c1257482958e12952dc189aecec2a",
      "image": "https://docs.newrelic.com/static/2be50db00a885e2d8ada51aa391f60d1/748b0/nrAQMIncidentFlow.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide/",
      "published_at": "2021-10-12T12:41:01Z",
      "updated_at": "2021-09-14T20:52:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Teams suffer from alert fatigue when they experience high alert volumes and alerts that are not aligned to business impact. As they start to believe that most alerts are false, they may prioritize easy to resolve alerts over others.  Also, they may close unresolved incidents so they can stay within their SLA targets. The result will be slower incident responses, magnified issue scope, and increased severity when true business impacting issues occur. Alert Quality Management (AQM) focuses on reducing the number of nuisance incidents so that you focus only on alerts with true business impact.  This reduces alert fatigue and ensures that you and your team focus your attention on the right places at the right times. You are a good candidate for AQM if: You have too many alerts. You have alerts that stay open for long time periods. Your alerts are not relevant. Your customers discover your issues before your monitoring tools do. You can't see the value of your observability tool(s). Desired outcome An alert strategy based on measuring business impact will result in faster response times and greater proactive awareness of critical events.  An improved alert signal to noise ratio reduces confusion and improves rapid identification and problem isolation. AQM's overall goal is to ensure that fewer, more valuable, incidents are created, resulting in: Increased uptime and availability Reduced MTTR Decreased alert volume The ability to easily identify alerts that are not valuable, so you can either make them valuable or remove them. The AQM process described in this guide generates the key performance indicators and metrics that you will use to measure progress towards these goals.  The metrics are measured in real time, published in a dashboard, and are used to drive a continuous improvement process that identifies and reduces nuisance alerts and increases user engagement in incident investigation. AQM does not encompass anomaly detection or AIOps, which are designed to detect unknown or unexpected modes of failure.  The two practices (AQM and ML/AI) work hand in hand, they are not mutually exclusive. Key performance indicators You will use the AQM process to collect and measure the following KPIs: Incident volume Incident Count Accumulated incident time Mean Time to Close (MTTC) Percent Under 5 Minutes User Engagement Mean Time to Investigate  (MTTI) % of Incidents Investigated These KPIs will help you to find the noisiest and least valuable alerts so you can improve their value or eliminate them.  You will then use the long term metric trends to show real business impact to management and stakeholders.  Detailed information on each metric follows. Incident volume You should treat incidents (with or without alerts) like a queue of tasks.  Just like a queue, the number of alerts should spend time near zero. Each incident should be a trigger for action to resolve the condition.  If an alert does not result in action, then you should question the value of the alert condition. If you see a constant rate of incidents or specific incidents that are \"always-on\", then you should question why. Are you in a constant state of business impact, or do you simply have a large volume of noise? The alert volume KPIs help you to answer those questions and to measure progress towards a healthy state of high quality alerting. Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the number of low value / nuisance incidents. Best practices: Ensure condition settings are intended to detect real business impact. Ensure condition settings are detecting abnormal behavior. Communicate that the incident details \"Acknowledge\" feature helps measure meaningful and actionable alerts. See Percentage Incident Acknowledge KPI. Report AQM KPIs to all stakeholders. Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the total accumulated minutes of incidents. Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Eliminate alerts that do not result in any remediation actions from the recipients. Improve percent investigated and mean-time-to-investigate KPIs by communicating their importance in improving detection and response times. Report AQM KPIs to all Stakeholders. Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. Goal: Reduce MTTC Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Improve Reliability Engineering skills. Report AQM KPIs to all stakeholders. Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. Goal: Minimize percentage of incidents with short durations Best practices: Ensure that conditions are detecting legitimate deviations from expected behavior. See Baselining and Service Level Management. Ensure that conditions are detecting legitimate deviations that correlate to business impact or impending business impact. User engagement You should measure the value of an incident by the amount of attention it receives.  Engagement in this context is measured by whether or not an incident has been acknowledged. The amount of engagement an individual alert receives is a direct measurement of its value.  More engagement implies a valuable alert, less (or zero) engagement implies a nuisance alert that should be modified or disabled. There is a significant difference between measuring the moment of incident awareness vs. acknowledging the moment resolution activity begins. If you are using an integration with New Relic Alerting, be sure that the \"acknowledge\" event that is sent to New Relic is triggered when resolution activity begins, not when the incident is sent to the external incident management tool.  For more information regarding the standard Incident Management process, see \"Incident Management Process: 5 Steps to Effective Resolution Posted on August 31, 2020 by OnPage Corporation. -- in reference to ITIL4\" Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. Goal: Increase the percentage of incident engagement. Best practices: Educate the DevOps team on when it is appropriate to acknowledge an incident alert. Gamify alert acknowledgement to drive usage. Discourage mass acknowledgement exercises. Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. Goal: Reduce the mean time to investigate Best practices: Work at building incident responder's confidence in alerts. Ensure that valuable alerts are acknowledged. Incentivize response teams to respond quickly to alerts. Prerequisites Before you begin, if you don't have equivalent experience, complete the New Relic University (NRU) Overview Course. Also, make sure you have a basic understanding of: NR1 Alert policy and conditions configuration NR1 incident notification channel webhook configuration NR1 NRQL NR1 alerting best practices NR1 APM & Infrastructure How to baseline data in order to determine anomalies vs. normal behavior. Establish current state of your KPIs As with any continuous improvement process, the first step of AQM is to establish the current state of your KPIs. To do so, perform the following tasks: Install and configure the incident event webhook Install the AQM Dashboard Perform initial AQM orientation and enablement Accumulate AQM data Perform second enablement session Install and configure the incident event webhook The webhook will create New Relic events for each incident as it proceeds through its lifecycle (open, acknowledge, close). To ensure that the AQM process generates accurate and valuable findings, this webhook must be added as a notification channel to every alert policy. The AQM process requires incident, not violation data. This is why you will not be using the default NrAiIncident event, which provides violation data only.  Instead, you will use this webhook to send the required incident data to New Relic. To use the webhook, do the following: Identify your primary production account and each of your accounts that you will be analyzing with the AQM process. Install the incident event webhook into each account that will participate in the AQM process and configure the webhook to report nrAQMIncident events to your primary production account. Assign the webhook as a notification channel to every alert policy in each account. This example shows a webhook notification channel assigned to each alert policy for a New Relic account with multiple sub-accounts. The webhook, AQM dashboard, and detailed installation instructions can be found in the New Relic OMA resource center on GitHub. Install the AQM dashboard The AQM dashboard is the primary asset that drives the AQM process.  You need to install the AQM dashboard into the primary production account you identified in the \"Install and configure incident event webhook\" step you previously performed by doing the following: Download the dashboard definition JSON file from the New Relic OMA resource center GitHub repo. Import the definition into your primary production account. For more details on importing dashboards, see the New Relic Introduction to dashboards documentation Perform initial AQM orientation and enablement During this phase, your incident management team(s) and other stakeholders will learn the goals of the AQM process and the scope of their involvement in it. The most critical portion of this task is educating your team on the importance of acknowledging incident alerts, since that's how the alert's value is determined.  In general, instruct them to follow these guidelines: If you look at an alert and decide to take any sort of further investigative action, acknowledge the alert. If you typically close an alert without doing anything else, do not acknowledge the alert. If the incident alert is always on, do not close or acknowledge it. For further details, see Second Enablement Session. You can use the first session template presentation to communicate this material to your stakeholders. Accumulate AQM data The overall process requires at least two weeks of data before it can proceed.  During this time, you should periodically check the following items: Confirm that incident alert event data is accumulating. Confirm that the webhook is attached to every alert policy. Ensure that incident responders are following the alert acknowledgement guidelines. Perform second enablement session During this phase, you will introduce incident management teams and other stakeholders to the initial AQM data and the ongoing continuous  improvement process you'll be following. The process consists of four activities: Review AQM Dashboard and KPI Trending - Here you and the stakeholders will look at the AQM KPIs and identify their week over week trends.  The team should identify areas where KPIs are not improving and develop strategies to drive improvement. Identify Achievements, Challenges, and Opportunities - Here you and the stakeholders will map the current state of alert quality to business impact, identifying areas where improvement has resulted in better business outcomes and areas where problems are impacting business outcomes. Incident Policy Review - Using the AQM dashboard, you and the stakeholders will identify the noisiest incident policies.  Once identified, those policies should be evaluated as detailed in step 4 below. Alert Policy Recommendations - In this step, you and the stakeholders will review the noisiest policies using the following criteria: Do the alerts have any business impact? Are the policies properly configured? Are they telling us something about the resource that needs to be fixed? Are the policies necessary? (i.e. do they have business impact) Are the thresholds set properly? Technical recommendations - Here, you and the stakeholders will review any technical recommendations, including: Are there application / system problems for engineering to review? Are there poorly constructed policies that need to be fixed? Are there instrumentation gaps? You can use the second session template presentation to keep this part of the AQM process organized. Improvement process This is the ongoing phase of the continuous improvement process where you periodically review your accumulated AQM data and make adjustments as needed to alert policies. You should perform this step once a week until your alert volume is acceptable. You can then perform it less frequently. During this phase you should: Report your KPIs each week to upper management to ensure that the stakeholder teams are appropriately prioritizing the work and to show that progress towards the promised business outcomes are being reached. Record and retain your weekly KPIs  over periods of months to years to establish a baseline and to show the rate of improvement. You should keep in mind that this is a continuous improvment process, you will continue to collect and evaluate the KPIs over long periods of time to ensure you are meeting your AQM goals. Value realization Once the AQM process is established, you will see significant reductions in the volume of alerts while reliability and stability remain the same or improve.  In addition, you should see that your alerts have a clear and unambiguous business impact.  Your AQM KPIs will provide quantifiable proof of these improvements. Once you are firmly on the path to AQM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering.  You can also move to other observability maturity value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform.  These KPIs are also included in the AQM dashboard that can be downloaded from the New Relic OMA resource center GitHub repo. Incident volume Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT count(*) AS 'Incident Count' WHERE current_state='open' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTC (minutes)' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. NRQL: FROM nrAQMIncident SELECT percentage(count(*), WHERE duration <= 5 * 60 * 100) AS '% Under 5min' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Incident engagement Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT filter(count(*), WHERE current_state='acknowledged')/filter(count(*), WHERE current_state='open')*100 AS '% Investigated' WHERE severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTI (minutes)' WHERE current_state='acknowledged' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.45596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Key <em>performance</em> indicators",
        "tags": "<em>Uptime</em>, <em>performance</em>, <em>and</em> <em>reliability</em>",
        "body": ", and <em>Reliability</em> value stream, such as Service Level Management, or <em>Reliability</em> Engineering.  You can also move to other <em>observability</em> <em>maturity</em> value streams, such as <em>Customer</em> <em>Experience</em>. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from"
      },
      "id": "61372f5964441f181342436d"
    },
    {
      "sections": [
        "Service level management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Service response time KPI",
        "Service quality KPI",
        "Service level objective attainment KPI",
        "Service uptime KPI",
        "Prerequisites",
        "Establish current state of your KPIs",
        "Determine in-scope services",
        "Identify service boundaries",
        "Deploy instrumentation",
        "Perform SLM educational workshops",
        "Analyze KPIs and set baseline SLOs",
        "Establish or optimize alerting",
        "Build problem resolution workflows",
        "Execute continuous improvement review",
        "Next steps",
        "Value realization"
      ],
      "title": "Service level management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Service level management",
        "Implementation guide"
      ],
      "external_id": "e3c4da80186b6d33a301db4a15c0b0cff2034131",
      "image": "https://docs.newrelic.com/static/e2478328e46923877c6dd58993aecf5f/d9199/nrSLMServiceMap.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide/",
      "published_at": "2021-10-12T12:21:04Z",
      "updated_at": "2021-09-14T06:11:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview IT Operations is expected to provide services that meet the business’s requirements for performance and reliability. However, many ops teams attempt to measure performace and reliability using legacy methods, like measuring resource consumption. That, in turn, requires that they create complex dashboards of granular metrics which they then try to correlate with application performance and reliability. These complex dashboards require subject matter experts to interpret the results for business stakeholders. Legacy methods create barriers to understanding what a good system state looks like and how bad system states impact the business. Essentially, IT ends up not sharing a common metric vocabulary with the business. This fundamental disconnect will result in the perception that IT is not able to deliver the services that the business requires, with all the implications and impacts that perception carries. Service Level Management (SLM) eliminates that disconnect by better explaining the overall performance of a system in terms that are easily understood by both IT and the business. The intent is to show whether or not the system is meeting its performance and reliability expectations, and if it is trending toward or away from improvement, so proactive steps can be taken. The end goal is that systems are better oriented toward desired business outcomes with IT’s attention focused on issues in areas with the highest business impact. You are a good candidate for SLM if any of the following are true: The business impact of performance and reliability issues are not well understood by all stakeholders. Your MTTx is too high. You are collecting many resource consumption metrics (such as CPU, disk, or memory) or are maintaining many metric correlation rules in order to identify system problems. You can’t see the value of your observability tool(s). Desired outcome Service Level Management’s overall goal is to easily measure and communicate the overall health, performance, and quality of your digital products and services to all stakeholders. By implementing SLM at key output points in your systems, you will have a simpler and more responsive observability practice, tighter alignment with the business, and faster paths to improvement. The SLM process described in this guide will help you to identify the points in your systems where you should measure the key performance metrics of service performance and quality. It will also define and drive a simpler alerting strategy, continuous improvement methodologies, and improved problem resolution workflows. Key performance indicators You will use the SLM process to collect and measure the following KPIs, often referred to as the “Golden Signals”: Service Response Time Service Quality (error rate) Service Level Objective Attainment (Availability) Service Uptime These KPIs directly measure the most important aspects of an IT service, speed and quality, in a way that is easy and intuitive to understand and communicate to technical and non-technical stakeholders. Detailed information on each metric follows. Service response time KPI Service response time measures the amount of time a service requires to process a transaction. It starts when a transaction request is received by the service and ends when the response is sent. Goal: Reduce transaction response time. Best practices: Measure response time at service boundaries. Use continuous improvement processes to drive down response times. Ensure that non-business transactions (i.e. health checks) are not included / measured. Map this KPI back to business impact. Report KPIs to all stakeholders. Service quality KPI Service quality is the number of transactions that result in an unhandled error. Typically, these are transactions whose HTTP response code is greater than or equal to 400. Goal: Reduce the number of unhandled errors. Best practices: Measure error rates at service boundaries. Continually identify and remediate sources of high error volumes. Map this KPI back to business impact. Report KPIs to all stakeholders. Service level objective attainment KPI SLO attainment is the percentage of time a business service is meeting its response time and quality goals. Goal: Improve response time and quality to ensure high SLO attainment. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact. Report KPIs to all stakeholders. Service uptime KPI Service uptime is the percentage of time a service can be reached by at least one client. Typically this is measured using synthetic transactions from representative remote locations. Goal: Use continuous improvement processes to watch uptime metrics and take appropriate steps to ensure uptime meets business requirements. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact Report KPIs to all stakeholders. Prerequisites Before you begin, if you don’t have equivalent experience, you should complete the New Relic University (NRU) Overview Course. You should also have a basic understanding of: New Relic One APM and infrastructure monitoring New Relic One Dashboards and NRQL New Relic One alerting best practices Establish current state of your KPIs As with any continuous improvement process, the first step of SLM is to establish the current state of your KPIs. To do so, you will need to perform the following tasks: Determine in-scope services Identify service boundaries Deploy instrumentation Perform SLM educational workshops Analyze KPIs and set baseline SLOs Establish / Optimize Alerting Build problem resolution workflows Execute continuous improvement review To help illustrate this process, we are going to apply it to an example IT service, an ecommerce site for a cellular telephone provider. Determine in-scope services You should first identify the IT services that are going to be in-scope for the initial iteration of the SLM process. These services should be key to ongoing business operations and as close to your customers as possible. Most commonly, you will be applying the SLM process to an application, since that is the service your customers are expecting you to deliver. SLM can be applied to infrastructure-based services; however, it is a more advanced application of SLM which is applicable to a much smaller set of organizations. If you are considering implementing SLM for infrastructure, you should ensure that the service(s) you are instrumenting are actually the closest to your organization’s end-customer. If your infrastructure is hosting a customer-facing app, then the app should be the target of SLM. Absent anything else, a good methodology for identifying in-scope services is to consult your disaster recovery plan. Typically, the most critical business services are prioritized there. Identify service boundaries Next, you should identify each service’s boundary, which is the service component that is closest to the client sending transaction requests. This should be the application receiving the request from the client, browser, or mobile device, and may also be known as the \"external API.\" Reverse proxies, CDNs, and load balancers are not part of the service boundary. Their service level compliance should be measured via the Uptime KPI (external test requests for connectivity). If your services are using APM, you can identify service boundaries using the service map or dependencies features. A service component is on a boundary if it has no inbound connections. In the example below (from a service map), you can see that the WebPortal is on the boundary. An example of using service maps in New Relic One to identify service boundaries. In contrast, the following screenshot (from the dependencies page) shows that the Inventory Service is not on a boundary since it has incoming connections from the WebPortal. Subsequent examples in this guide will build on the WebPortal service boundary. An example of using the dependencies UI in New Relic One to identify service boundaries. You should understand that the SLM process defines a service boundary as being downstream of any dependencies. The service boundary is the point where all the effects and impacts of dependent services are measured as they contribute to the total response time and quality of the service. By measuring service level compliance at the boundary, you will be able to see the impact that all service components upstream of the boundary have on service delivery. This means that your initial steps into SLM can focus on the services that are closest to your users, yet still capture the contribution of more distant services. As your practice matures, you will be able to identify the next round of upstream services that would benefit from direct SLM instrumentation. In our example, the WebService is downstream of the Fulfillment, Plan, Promo, Login, and Inventory services (among others). By applying SLM at the WebService, we will be seeing the impact of the upstream services on the WebService. Any impactful issues with an upstream service will be reflected in the WebService’s service level KPIs. By instrumenting one service, we are capturing the contribution of five additional services. This greatly simplifies our observability practice. In time, problematic upstream services will self-identify themselves as candidates for direct SLM instrumentation. Deploy instrumentation To collect SLM service response time and transaction success KPIs, you need to deploy instrumentation into the components of your production apps on the service boundary. If you don’t have instrumentation that can do this in production already, then you will need to engage the teams and stakeholders that can help you to get this done. For detailed information on deploying the New Relic instrumentation that can gather this information, see our APM install documentation. The uptime KPIs can be collected using synthetic transactions, which don’t require any instrumentation to be added to the service. If needed, you can start your SLM journey there while waiting for the direct instrumentation to be deployed. The uptime tests should perform a basic, yet realistic, check of the service’s functionality. For detailed information on this capability, see our synthetic monitoring documentation. Perform SLM educational workshops You should share the self-paced New Relic Essentials training course with the appropriate stakeholders so they can understand how the New Relic technology platform will aid in the SLM process. Analyze KPIs and set baseline SLOs The SLM process uses speed and quality as its key performance indicators. In technical terms, speed means response time and quality means error rate. At the end of this phase, you will have created baseline service level objectives for each service in the form of a percentage. For example: “98% of service X’s transactions will be error free and occur in less than 500 milliseconds.” For each in-scope service, you should analyze speed and quality at the service boundary. This will give you an overall understanding of how the entire service and all of its dependencies are performing. As you iterate through the SLM process, you can then identify and prioritize the upstream service components that require direct SLM instrumentation. To analyze KPIs, you should do the following for each service: Identify the volume and 95th percentile response time for each of the service’s transactions over a relatively long period of time, typically between seven days and one month. It is important that you use percentile rather than average, so you can see the entire range of response times, including outliers. If you use averages, you will hide outliers. The following is an example of the initial baseline report. Here you can see the volume, p95 response time, and error volume for the WebPortal and a few other services. The WebPortal’s p95 response time is .36 seconds (or 36 milliseconds), so we have decided to set the SLO target to 0.4 seconds. Example of an initial baseline report measuring volume and 95th percentile response time. Next you should review and identify any non-business transactions, since they should not be included in the SLO attainment calculation. For example, you should not include health check / keep alive transactions and you may not want to include administrative transactions. In the example below, we are looking at some of the transactions from the WebPortal service. We have decided that the about.jsp transaction is a non-business transaction that should not be tracked in our SLO attainment calculation. Example showing transaction breakdowns from the initial baseline report to help identify what to track (or not track) for SLO. Finally, import and edit the SLM template dashboard to exclude non-business transactions. Then use the p95 response time as your baseline response time service level objective. For the example chart, we chose 0.4 seconds as our response time threshold and set our service level objective to 95%. This means that we are expecting 95% of the WebPortal’s business transactions to complete in 0.4 seconds or less and without an error. The red line on the chart shows us our 95% service level objective. Example chart now excluding the non-business transactions. As you can see, there are periods of hours where the app is not meeting its SLOs. If we are going to maintain the 95% target, we would need to identify and fix the service components or dependencies that are causing these problems. Establish or optimize alerting After you have set your service level objectives, you will then configure alerts that will inform you when your SLO attainment has dipped below your goal. These alerts will show you when incidents with a high business impact are occurring. When they are triggered, they should be given a high priority and you should engage the proper teams to start the process of diagnosing the source of the problem. A basic starting point is to configure an alert that triggers when your SLO attainment has dipped under your baseline for more than 10 minutes. For more information, see our documentation on configuring alerts. Build problem resolution workflows As we’ve been discussing, the intent of the SLM process is to identify when business impacting issues occur in your IT services. When this occurs, a diagnostic investigation should be launched. The goal of the investigation is to identify what service element is causing the business impacting issue. SLM tells you that there is a problem with business impact, the diagnostic process helps you to find where the problem is. Typically, your high level diagnostic workflow will start at the service boundary and go as follows: Look at the service’s individual transactions and see which one(s) are departing from their performance and/or response time SLOs. Look at each service component responsible for delivering that transaction until you find the component that is failing. Use in-depth diagnostics to identify the root cause of the problem and then resolve it. Execute continuous improvement review This is an ongoing phase of the SLM process where data is reviewed and adjustments are made as required. Your KPIs should be reported to upper management to ensure that stakeholder teams are appropriately prioritizing work and that you are meeting the SLO goals you’ve set. Periodic KPIs should be recorded and retained over periods of months to years to establish a baseline and to show the rate of improvement. In addition, each time you execute the continuous improvement process, you should: Review each service’s architecture to ensure your instrumentation is deployed at the boundary and that there are no observabilty gaps. Review each service’s transactions to confirm that only business transactions are included in your SLO calculations. Review each service’s SLO and determine if it meets the business’s performance and quality requirements. If it does not, then the SLO should be changed and the appropriate stakeholders notified so they can work to improve performance and quality. Review your SLO attainment and determine if any upstream services should be added to the SLM process. Next steps After you’ve established the SLM process, you should identify other services that would benefit from SLM instrumentation. These may be other front-line services or upstream dependencies of services that are covered by SLOs that have shown themselves to be frequent contributors to SLO attainment failures. As you do this, you should start to measure and report your SLM coverage as a percentage of applications covered by SLOs. For example, you may say that 20% of your apps have established SLOs. As SLM expands into your organization and as its value is seen by management and other stakeholders, you may find that you need a dedicated team to manage the SLM process. The SLM process should also become a primary driver to help you prioritize issue resolution activities. SLO attainment failures are a direct indicator that your IT services are having a negative business impact which is visible to your customers as poor performance and/or unhandled errors. Value realization Once the SLM process is established, you will see a reduction in the effort required to identify business impacting issues, a better ability to communicate with your business stakeholders, and an easier time proving the business’ return on investment in IT services. Your SLM KPIs will provide quantifiable proof of these improvements. In addtion, you should be able to simplify your observability strategy by removing or reducing your dependency on legacy consumption metrics and the logic required to correlate them against your true goal of measuring performance and quality. Once you are firmly on the path to SLM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering. You can also move to other observability maturity value streams, such as Customer Experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.04626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Key <em>performance</em> indicators",
        "tags": "<em>Uptime</em>, <em>performance</em>, <em>and</em> <em>reliability</em>",
        "body": " stream, such as Service Level Management, or <em>Reliability</em> Engineering. You can also move to other <em>observability</em> <em>maturity</em> value streams, such as <em>Customer</em> <em>Experience</em>."
      },
      "id": "61403d0464441f0457424337"
    },
    {
      "sections": [
        "Bottom of the funnel analysis implementation guide",
        "Desired outcome",
        "Key performance indicators",
        "Prerequisites",
        "Required knowledge",
        "Required installation and configuration",
        "Establish current state",
        "Identify where the Bottom of the Funnel starts",
        "Ecommerce user journey",
        "Car insurance purchase user journey",
        "Distinguish between Pages and Actions",
        "Create a scripted Synthetics Check for the Bottom of the Funnel",
        "Import the Bottom of the Funnel Dashboard",
        "Capture Current Performance",
        "Improvement process",
        "Plan your work",
        "Advanced topics",
        "Conclusion",
        "Best practices going forward",
        "Value realization"
      ],
      "title": "Bottom of the funnel analysis implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Conversions",
        "Funnel",
        "Bottom of the funnel"
      ],
      "external_id": "d1a470e689225e2241cc6946e36f123491bae202",
      "image": "https://docs.newrelic.com/static/2373669d2bc6f30be8344b42fc79a983/764be/cx-botfa-ecommerce.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide/",
      "published_at": "2021-10-12T12:55:57Z",
      "updated_at": "2021-09-07T09:17:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Desired outcome Increase revenue by resolving issues that appear when a user attempts to complete an action. Key performance indicators Bottom of the Funnel Analysis measures the following KPIs: KPI Description Goal Bottom of the Funnel Success Rate/Conversion Rate The rate of conversion once a user has gone far enough to demonstrate intent to complete an action to actual completion. Examples of this are rate of: Checkout -> Order submission Insurance form review -> submission Completing sign up details -> submission Increase the rate of conversion by addressing errors and latency at the bottom of the funnel Revenue at Risk due to Latency Value of a conversion * number of pages or interactions in the bottom of the funnel that are slower than the industry threshold. Focus on reducing this value by improving page KPIs Revenue at Risk due to Errors Value of a conversion * number of backend errors in the bottom of the funnel interactions Tune this value to make it meaningful by filtering out errors that aren't visible to the end user. Once this is meaningful, focus on reducing it. Create an alert to notify you if it suddenly trends upward. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required installation and configuration Browser Pro installed in relevant pages SPA enabled for single page applications Insights retention for Browser events is at least 2x an average sprint. Establish current state Identify where the Bottom of the Funnel starts The Bottom of the Funnel is focused on the final steps of a user journey where a user has gone far enough to show intent to complete the journey. Some examples: Ecommerce user journey The user journey is simplified so you can focus on where the bottom of the funnel begins - at checkout. Most users entering the checkout phase plan to purchase something. Reducing errors and latency from this point onward is more likely to improve conversions than focusing on any other part of the funnel. Car insurance purchase user journey In the example above, you have the user’s interest in car insurance as they enter information, but you do not know their intent until they see the quote and continue to proceed. Distinguish between Pages and Actions The final steps of a user’s journey is likely to be a mix of full page loads and AJAX calls. You will need to know all pages and Ajax requests for the next step. If you are not sure which requests are running from the page in question, you can run: SELECT count(*) FROM AjaxRequest WHERE pageUrl like ‘%FILTER%’ FACET groupedRequestUrl SINCE 1 DAY AGO Copy Create a scripted Synthetics Check for the Bottom of the Funnel Make sure you have a scripted monitor for each path through the bottom of the funnel. The goal is to make sure your bottom of the funnel services are working around the clock. For example, you may have a checkout flow that calls a different payment API depending on the customer’s payment preferences. Import the Bottom of the Funnel Dashboard Follow the instructions documented in the public GitHub README. Capture Current Performance Follow the GitHub repository README instructions. Use the dashboard from the previous step to understand the bottom of the funnel performance. Create a plan to improve KPIs that don’t meet target values as well as reduce revenue at risk. Improvement process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. For detailed information, see: Improve uptime Improve page load performance Improve AJAX performance Advanced topics Should I apply segmentation? Segmentation (breaking out performance into cohorts, such as region and device type) is a good idea if: Your organization has initiatives tied to addressing a target audience from a particular cohort that you can segment by using either custom attributes or data that is already available in New Relic. You are already familiar with Bottom of the Funnel Analysis and there is a significant enough difference in performance among different cohorts to warrant tracking and/or developer focus. Conclusion Best practices going forward Revisit performance metrics at the end of each sprint. Any time the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your Customer Experience SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation KPIs. Value realization At the end of this process you should: Know your user conversion rate and have addressed errors or performance issues that negatively impact it. Increased revenue for your company. Created, or be on the path to create, a common language with business owners so you are working together; opening new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.54187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Key <em>performance</em> indicators",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " a different payment API depending on the <em>customer</em>’s payment preferences. Import the Bottom of the Funnel Dashboard Follow the instructions documented in the public GitHub README. Capture Current <em>Performance</em> Follow the GitHub repository README instructions. Use the dashboard from the previous step"
      },
      "id": "61372e1964441f16fa42438e"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/operational-efficiency/sc-implementation-guide": [
    {
      "sections": [
        "Alert quality management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Incident volume",
        "Incident count KPI",
        "Accumulated incident duration KPI",
        "Mean time to close (MTTC) KPI",
        "Percent under 5 minutes KPI",
        "User engagement",
        "Percentage Acknowledged KPI",
        "Mean time to investigate (MTTI) KPI",
        "Prerequisites",
        "Establish current state of your KPIs",
        "Install and configure the incident event webhook",
        "Install the AQM dashboard",
        "Perform initial AQM orientation and enablement",
        "Accumulate AQM data",
        "Perform second enablement session",
        "Improvement process",
        "Value realization",
        "KPI reference",
        "Incident engagement"
      ],
      "title": "Alert quality management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Alert quality management",
        "Implementation guide"
      ],
      "external_id": "b69abb6b9b6c1257482958e12952dc189aecec2a",
      "image": "https://docs.newrelic.com/static/2be50db00a885e2d8ada51aa391f60d1/748b0/nrAQMIncidentFlow.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide/",
      "published_at": "2021-10-12T12:41:01Z",
      "updated_at": "2021-09-14T20:52:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Teams suffer from alert fatigue when they experience high alert volumes and alerts that are not aligned to business impact. As they start to believe that most alerts are false, they may prioritize easy to resolve alerts over others.  Also, they may close unresolved incidents so they can stay within their SLA targets. The result will be slower incident responses, magnified issue scope, and increased severity when true business impacting issues occur. Alert Quality Management (AQM) focuses on reducing the number of nuisance incidents so that you focus only on alerts with true business impact.  This reduces alert fatigue and ensures that you and your team focus your attention on the right places at the right times. You are a good candidate for AQM if: You have too many alerts. You have alerts that stay open for long time periods. Your alerts are not relevant. Your customers discover your issues before your monitoring tools do. You can't see the value of your observability tool(s). Desired outcome An alert strategy based on measuring business impact will result in faster response times and greater proactive awareness of critical events.  An improved alert signal to noise ratio reduces confusion and improves rapid identification and problem isolation. AQM's overall goal is to ensure that fewer, more valuable, incidents are created, resulting in: Increased uptime and availability Reduced MTTR Decreased alert volume The ability to easily identify alerts that are not valuable, so you can either make them valuable or remove them. The AQM process described in this guide generates the key performance indicators and metrics that you will use to measure progress towards these goals.  The metrics are measured in real time, published in a dashboard, and are used to drive a continuous improvement process that identifies and reduces nuisance alerts and increases user engagement in incident investigation. AQM does not encompass anomaly detection or AIOps, which are designed to detect unknown or unexpected modes of failure.  The two practices (AQM and ML/AI) work hand in hand, they are not mutually exclusive. Key performance indicators You will use the AQM process to collect and measure the following KPIs: Incident volume Incident Count Accumulated incident time Mean Time to Close (MTTC) Percent Under 5 Minutes User Engagement Mean Time to Investigate  (MTTI) % of Incidents Investigated These KPIs will help you to find the noisiest and least valuable alerts so you can improve their value or eliminate them.  You will then use the long term metric trends to show real business impact to management and stakeholders.  Detailed information on each metric follows. Incident volume You should treat incidents (with or without alerts) like a queue of tasks.  Just like a queue, the number of alerts should spend time near zero. Each incident should be a trigger for action to resolve the condition.  If an alert does not result in action, then you should question the value of the alert condition. If you see a constant rate of incidents or specific incidents that are \"always-on\", then you should question why. Are you in a constant state of business impact, or do you simply have a large volume of noise? The alert volume KPIs help you to answer those questions and to measure progress towards a healthy state of high quality alerting. Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the number of low value / nuisance incidents. Best practices: Ensure condition settings are intended to detect real business impact. Ensure condition settings are detecting abnormal behavior. Communicate that the incident details \"Acknowledge\" feature helps measure meaningful and actionable alerts. See Percentage Incident Acknowledge KPI. Report AQM KPIs to all stakeholders. Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the total accumulated minutes of incidents. Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Eliminate alerts that do not result in any remediation actions from the recipients. Improve percent investigated and mean-time-to-investigate KPIs by communicating their importance in improving detection and response times. Report AQM KPIs to all Stakeholders. Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. Goal: Reduce MTTC Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Improve Reliability Engineering skills. Report AQM KPIs to all stakeholders. Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. Goal: Minimize percentage of incidents with short durations Best practices: Ensure that conditions are detecting legitimate deviations from expected behavior. See Baselining and Service Level Management. Ensure that conditions are detecting legitimate deviations that correlate to business impact or impending business impact. User engagement You should measure the value of an incident by the amount of attention it receives.  Engagement in this context is measured by whether or not an incident has been acknowledged. The amount of engagement an individual alert receives is a direct measurement of its value.  More engagement implies a valuable alert, less (or zero) engagement implies a nuisance alert that should be modified or disabled. There is a significant difference between measuring the moment of incident awareness vs. acknowledging the moment resolution activity begins. If you are using an integration with New Relic Alerting, be sure that the \"acknowledge\" event that is sent to New Relic is triggered when resolution activity begins, not when the incident is sent to the external incident management tool.  For more information regarding the standard Incident Management process, see \"Incident Management Process: 5 Steps to Effective Resolution Posted on August 31, 2020 by OnPage Corporation. -- in reference to ITIL4\" Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. Goal: Increase the percentage of incident engagement. Best practices: Educate the DevOps team on when it is appropriate to acknowledge an incident alert. Gamify alert acknowledgement to drive usage. Discourage mass acknowledgement exercises. Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. Goal: Reduce the mean time to investigate Best practices: Work at building incident responder's confidence in alerts. Ensure that valuable alerts are acknowledged. Incentivize response teams to respond quickly to alerts. Prerequisites Before you begin, if you don't have equivalent experience, complete the New Relic University (NRU) Overview Course. Also, make sure you have a basic understanding of: NR1 Alert policy and conditions configuration NR1 incident notification channel webhook configuration NR1 NRQL NR1 alerting best practices NR1 APM & Infrastructure How to baseline data in order to determine anomalies vs. normal behavior. Establish current state of your KPIs As with any continuous improvement process, the first step of AQM is to establish the current state of your KPIs. To do so, perform the following tasks: Install and configure the incident event webhook Install the AQM Dashboard Perform initial AQM orientation and enablement Accumulate AQM data Perform second enablement session Install and configure the incident event webhook The webhook will create New Relic events for each incident as it proceeds through its lifecycle (open, acknowledge, close). To ensure that the AQM process generates accurate and valuable findings, this webhook must be added as a notification channel to every alert policy. The AQM process requires incident, not violation data. This is why you will not be using the default NrAiIncident event, which provides violation data only.  Instead, you will use this webhook to send the required incident data to New Relic. To use the webhook, do the following: Identify your primary production account and each of your accounts that you will be analyzing with the AQM process. Install the incident event webhook into each account that will participate in the AQM process and configure the webhook to report nrAQMIncident events to your primary production account. Assign the webhook as a notification channel to every alert policy in each account. This example shows a webhook notification channel assigned to each alert policy for a New Relic account with multiple sub-accounts. The webhook, AQM dashboard, and detailed installation instructions can be found in the New Relic OMA resource center on GitHub. Install the AQM dashboard The AQM dashboard is the primary asset that drives the AQM process.  You need to install the AQM dashboard into the primary production account you identified in the \"Install and configure incident event webhook\" step you previously performed by doing the following: Download the dashboard definition JSON file from the New Relic OMA resource center GitHub repo. Import the definition into your primary production account. For more details on importing dashboards, see the New Relic Introduction to dashboards documentation Perform initial AQM orientation and enablement During this phase, your incident management team(s) and other stakeholders will learn the goals of the AQM process and the scope of their involvement in it. The most critical portion of this task is educating your team on the importance of acknowledging incident alerts, since that's how the alert's value is determined.  In general, instruct them to follow these guidelines: If you look at an alert and decide to take any sort of further investigative action, acknowledge the alert. If you typically close an alert without doing anything else, do not acknowledge the alert. If the incident alert is always on, do not close or acknowledge it. For further details, see Second Enablement Session. You can use the first session template presentation to communicate this material to your stakeholders. Accumulate AQM data The overall process requires at least two weeks of data before it can proceed.  During this time, you should periodically check the following items: Confirm that incident alert event data is accumulating. Confirm that the webhook is attached to every alert policy. Ensure that incident responders are following the alert acknowledgement guidelines. Perform second enablement session During this phase, you will introduce incident management teams and other stakeholders to the initial AQM data and the ongoing continuous  improvement process you'll be following. The process consists of four activities: Review AQM Dashboard and KPI Trending - Here you and the stakeholders will look at the AQM KPIs and identify their week over week trends.  The team should identify areas where KPIs are not improving and develop strategies to drive improvement. Identify Achievements, Challenges, and Opportunities - Here you and the stakeholders will map the current state of alert quality to business impact, identifying areas where improvement has resulted in better business outcomes and areas where problems are impacting business outcomes. Incident Policy Review - Using the AQM dashboard, you and the stakeholders will identify the noisiest incident policies.  Once identified, those policies should be evaluated as detailed in step 4 below. Alert Policy Recommendations - In this step, you and the stakeholders will review the noisiest policies using the following criteria: Do the alerts have any business impact? Are the policies properly configured? Are they telling us something about the resource that needs to be fixed? Are the policies necessary? (i.e. do they have business impact) Are the thresholds set properly? Technical recommendations - Here, you and the stakeholders will review any technical recommendations, including: Are there application / system problems for engineering to review? Are there poorly constructed policies that need to be fixed? Are there instrumentation gaps? You can use the second session template presentation to keep this part of the AQM process organized. Improvement process This is the ongoing phase of the continuous improvement process where you periodically review your accumulated AQM data and make adjustments as needed to alert policies. You should perform this step once a week until your alert volume is acceptable. You can then perform it less frequently. During this phase you should: Report your KPIs each week to upper management to ensure that the stakeholder teams are appropriately prioritizing the work and to show that progress towards the promised business outcomes are being reached. Record and retain your weekly KPIs  over periods of months to years to establish a baseline and to show the rate of improvement. You should keep in mind that this is a continuous improvment process, you will continue to collect and evaluate the KPIs over long periods of time to ensure you are meeting your AQM goals. Value realization Once the AQM process is established, you will see significant reductions in the volume of alerts while reliability and stability remain the same or improve.  In addition, you should see that your alerts have a clear and unambiguous business impact.  Your AQM KPIs will provide quantifiable proof of these improvements. Once you are firmly on the path to AQM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering.  You can also move to other observability maturity value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform.  These KPIs are also included in the AQM dashboard that can be downloaded from the New Relic OMA resource center GitHub repo. Incident volume Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT count(*) AS 'Incident Count' WHERE current_state='open' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTC (minutes)' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. NRQL: FROM nrAQMIncident SELECT percentage(count(*), WHERE duration <= 5 * 60 * 100) AS '% Under 5min' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Incident engagement Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT filter(count(*), WHERE current_state='acknowledged')/filter(count(*), WHERE current_state='open')*100 AS '% Investigated' WHERE severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTI (minutes)' WHERE current_state='acknowledged' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.7463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alert quality management use case <em>implementation</em> <em>guide</em>",
        "sections": "Alert quality management use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": ", and Reliability value stream, such as <em>Service</em> Level Management, or Reliability Engineering.  You can also move to other <em>observability</em> <em>maturity</em> value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from"
      },
      "id": "61372f5964441f181342436d"
    },
    {
      "sections": [
        "Service level management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Service response time KPI",
        "Service quality KPI",
        "Service level objective attainment KPI",
        "Service uptime KPI",
        "Prerequisites",
        "Establish current state of your KPIs",
        "Determine in-scope services",
        "Identify service boundaries",
        "Deploy instrumentation",
        "Perform SLM educational workshops",
        "Analyze KPIs and set baseline SLOs",
        "Establish or optimize alerting",
        "Build problem resolution workflows",
        "Execute continuous improvement review",
        "Next steps",
        "Value realization"
      ],
      "title": "Service level management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Service level management",
        "Implementation guide"
      ],
      "external_id": "e3c4da80186b6d33a301db4a15c0b0cff2034131",
      "image": "https://docs.newrelic.com/static/e2478328e46923877c6dd58993aecf5f/d9199/nrSLMServiceMap.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide/",
      "published_at": "2021-10-12T12:21:04Z",
      "updated_at": "2021-09-14T06:11:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview IT Operations is expected to provide services that meet the business’s requirements for performance and reliability. However, many ops teams attempt to measure performace and reliability using legacy methods, like measuring resource consumption. That, in turn, requires that they create complex dashboards of granular metrics which they then try to correlate with application performance and reliability. These complex dashboards require subject matter experts to interpret the results for business stakeholders. Legacy methods create barriers to understanding what a good system state looks like and how bad system states impact the business. Essentially, IT ends up not sharing a common metric vocabulary with the business. This fundamental disconnect will result in the perception that IT is not able to deliver the services that the business requires, with all the implications and impacts that perception carries. Service Level Management (SLM) eliminates that disconnect by better explaining the overall performance of a system in terms that are easily understood by both IT and the business. The intent is to show whether or not the system is meeting its performance and reliability expectations, and if it is trending toward or away from improvement, so proactive steps can be taken. The end goal is that systems are better oriented toward desired business outcomes with IT’s attention focused on issues in areas with the highest business impact. You are a good candidate for SLM if any of the following are true: The business impact of performance and reliability issues are not well understood by all stakeholders. Your MTTx is too high. You are collecting many resource consumption metrics (such as CPU, disk, or memory) or are maintaining many metric correlation rules in order to identify system problems. You can’t see the value of your observability tool(s). Desired outcome Service Level Management’s overall goal is to easily measure and communicate the overall health, performance, and quality of your digital products and services to all stakeholders. By implementing SLM at key output points in your systems, you will have a simpler and more responsive observability practice, tighter alignment with the business, and faster paths to improvement. The SLM process described in this guide will help you to identify the points in your systems where you should measure the key performance metrics of service performance and quality. It will also define and drive a simpler alerting strategy, continuous improvement methodologies, and improved problem resolution workflows. Key performance indicators You will use the SLM process to collect and measure the following KPIs, often referred to as the “Golden Signals”: Service Response Time Service Quality (error rate) Service Level Objective Attainment (Availability) Service Uptime These KPIs directly measure the most important aspects of an IT service, speed and quality, in a way that is easy and intuitive to understand and communicate to technical and non-technical stakeholders. Detailed information on each metric follows. Service response time KPI Service response time measures the amount of time a service requires to process a transaction. It starts when a transaction request is received by the service and ends when the response is sent. Goal: Reduce transaction response time. Best practices: Measure response time at service boundaries. Use continuous improvement processes to drive down response times. Ensure that non-business transactions (i.e. health checks) are not included / measured. Map this KPI back to business impact. Report KPIs to all stakeholders. Service quality KPI Service quality is the number of transactions that result in an unhandled error. Typically, these are transactions whose HTTP response code is greater than or equal to 400. Goal: Reduce the number of unhandled errors. Best practices: Measure error rates at service boundaries. Continually identify and remediate sources of high error volumes. Map this KPI back to business impact. Report KPIs to all stakeholders. Service level objective attainment KPI SLO attainment is the percentage of time a business service is meeting its response time and quality goals. Goal: Improve response time and quality to ensure high SLO attainment. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact. Report KPIs to all stakeholders. Service uptime KPI Service uptime is the percentage of time a service can be reached by at least one client. Typically this is measured using synthetic transactions from representative remote locations. Goal: Use continuous improvement processes to watch uptime metrics and take appropriate steps to ensure uptime meets business requirements. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact Report KPIs to all stakeholders. Prerequisites Before you begin, if you don’t have equivalent experience, you should complete the New Relic University (NRU) Overview Course. You should also have a basic understanding of: New Relic One APM and infrastructure monitoring New Relic One Dashboards and NRQL New Relic One alerting best practices Establish current state of your KPIs As with any continuous improvement process, the first step of SLM is to establish the current state of your KPIs. To do so, you will need to perform the following tasks: Determine in-scope services Identify service boundaries Deploy instrumentation Perform SLM educational workshops Analyze KPIs and set baseline SLOs Establish / Optimize Alerting Build problem resolution workflows Execute continuous improvement review To help illustrate this process, we are going to apply it to an example IT service, an ecommerce site for a cellular telephone provider. Determine in-scope services You should first identify the IT services that are going to be in-scope for the initial iteration of the SLM process. These services should be key to ongoing business operations and as close to your customers as possible. Most commonly, you will be applying the SLM process to an application, since that is the service your customers are expecting you to deliver. SLM can be applied to infrastructure-based services; however, it is a more advanced application of SLM which is applicable to a much smaller set of organizations. If you are considering implementing SLM for infrastructure, you should ensure that the service(s) you are instrumenting are actually the closest to your organization’s end-customer. If your infrastructure is hosting a customer-facing app, then the app should be the target of SLM. Absent anything else, a good methodology for identifying in-scope services is to consult your disaster recovery plan. Typically, the most critical business services are prioritized there. Identify service boundaries Next, you should identify each service’s boundary, which is the service component that is closest to the client sending transaction requests. This should be the application receiving the request from the client, browser, or mobile device, and may also be known as the \"external API.\" Reverse proxies, CDNs, and load balancers are not part of the service boundary. Their service level compliance should be measured via the Uptime KPI (external test requests for connectivity). If your services are using APM, you can identify service boundaries using the service map or dependencies features. A service component is on a boundary if it has no inbound connections. In the example below (from a service map), you can see that the WebPortal is on the boundary. An example of using service maps in New Relic One to identify service boundaries. In contrast, the following screenshot (from the dependencies page) shows that the Inventory Service is not on a boundary since it has incoming connections from the WebPortal. Subsequent examples in this guide will build on the WebPortal service boundary. An example of using the dependencies UI in New Relic One to identify service boundaries. You should understand that the SLM process defines a service boundary as being downstream of any dependencies. The service boundary is the point where all the effects and impacts of dependent services are measured as they contribute to the total response time and quality of the service. By measuring service level compliance at the boundary, you will be able to see the impact that all service components upstream of the boundary have on service delivery. This means that your initial steps into SLM can focus on the services that are closest to your users, yet still capture the contribution of more distant services. As your practice matures, you will be able to identify the next round of upstream services that would benefit from direct SLM instrumentation. In our example, the WebService is downstream of the Fulfillment, Plan, Promo, Login, and Inventory services (among others). By applying SLM at the WebService, we will be seeing the impact of the upstream services on the WebService. Any impactful issues with an upstream service will be reflected in the WebService’s service level KPIs. By instrumenting one service, we are capturing the contribution of five additional services. This greatly simplifies our observability practice. In time, problematic upstream services will self-identify themselves as candidates for direct SLM instrumentation. Deploy instrumentation To collect SLM service response time and transaction success KPIs, you need to deploy instrumentation into the components of your production apps on the service boundary. If you don’t have instrumentation that can do this in production already, then you will need to engage the teams and stakeholders that can help you to get this done. For detailed information on deploying the New Relic instrumentation that can gather this information, see our APM install documentation. The uptime KPIs can be collected using synthetic transactions, which don’t require any instrumentation to be added to the service. If needed, you can start your SLM journey there while waiting for the direct instrumentation to be deployed. The uptime tests should perform a basic, yet realistic, check of the service’s functionality. For detailed information on this capability, see our synthetic monitoring documentation. Perform SLM educational workshops You should share the self-paced New Relic Essentials training course with the appropriate stakeholders so they can understand how the New Relic technology platform will aid in the SLM process. Analyze KPIs and set baseline SLOs The SLM process uses speed and quality as its key performance indicators. In technical terms, speed means response time and quality means error rate. At the end of this phase, you will have created baseline service level objectives for each service in the form of a percentage. For example: “98% of service X’s transactions will be error free and occur in less than 500 milliseconds.” For each in-scope service, you should analyze speed and quality at the service boundary. This will give you an overall understanding of how the entire service and all of its dependencies are performing. As you iterate through the SLM process, you can then identify and prioritize the upstream service components that require direct SLM instrumentation. To analyze KPIs, you should do the following for each service: Identify the volume and 95th percentile response time for each of the service’s transactions over a relatively long period of time, typically between seven days and one month. It is important that you use percentile rather than average, so you can see the entire range of response times, including outliers. If you use averages, you will hide outliers. The following is an example of the initial baseline report. Here you can see the volume, p95 response time, and error volume for the WebPortal and a few other services. The WebPortal’s p95 response time is .36 seconds (or 36 milliseconds), so we have decided to set the SLO target to 0.4 seconds. Example of an initial baseline report measuring volume and 95th percentile response time. Next you should review and identify any non-business transactions, since they should not be included in the SLO attainment calculation. For example, you should not include health check / keep alive transactions and you may not want to include administrative transactions. In the example below, we are looking at some of the transactions from the WebPortal service. We have decided that the about.jsp transaction is a non-business transaction that should not be tracked in our SLO attainment calculation. Example showing transaction breakdowns from the initial baseline report to help identify what to track (or not track) for SLO. Finally, import and edit the SLM template dashboard to exclude non-business transactions. Then use the p95 response time as your baseline response time service level objective. For the example chart, we chose 0.4 seconds as our response time threshold and set our service level objective to 95%. This means that we are expecting 95% of the WebPortal’s business transactions to complete in 0.4 seconds or less and without an error. The red line on the chart shows us our 95% service level objective. Example chart now excluding the non-business transactions. As you can see, there are periods of hours where the app is not meeting its SLOs. If we are going to maintain the 95% target, we would need to identify and fix the service components or dependencies that are causing these problems. Establish or optimize alerting After you have set your service level objectives, you will then configure alerts that will inform you when your SLO attainment has dipped below your goal. These alerts will show you when incidents with a high business impact are occurring. When they are triggered, they should be given a high priority and you should engage the proper teams to start the process of diagnosing the source of the problem. A basic starting point is to configure an alert that triggers when your SLO attainment has dipped under your baseline for more than 10 minutes. For more information, see our documentation on configuring alerts. Build problem resolution workflows As we’ve been discussing, the intent of the SLM process is to identify when business impacting issues occur in your IT services. When this occurs, a diagnostic investigation should be launched. The goal of the investigation is to identify what service element is causing the business impacting issue. SLM tells you that there is a problem with business impact, the diagnostic process helps you to find where the problem is. Typically, your high level diagnostic workflow will start at the service boundary and go as follows: Look at the service’s individual transactions and see which one(s) are departing from their performance and/or response time SLOs. Look at each service component responsible for delivering that transaction until you find the component that is failing. Use in-depth diagnostics to identify the root cause of the problem and then resolve it. Execute continuous improvement review This is an ongoing phase of the SLM process where data is reviewed and adjustments are made as required. Your KPIs should be reported to upper management to ensure that stakeholder teams are appropriately prioritizing work and that you are meeting the SLO goals you’ve set. Periodic KPIs should be recorded and retained over periods of months to years to establish a baseline and to show the rate of improvement. In addition, each time you execute the continuous improvement process, you should: Review each service’s architecture to ensure your instrumentation is deployed at the boundary and that there are no observabilty gaps. Review each service’s transactions to confirm that only business transactions are included in your SLO calculations. Review each service’s SLO and determine if it meets the business’s performance and quality requirements. If it does not, then the SLO should be changed and the appropriate stakeholders notified so they can work to improve performance and quality. Review your SLO attainment and determine if any upstream services should be added to the SLM process. Next steps After you’ve established the SLM process, you should identify other services that would benefit from SLM instrumentation. These may be other front-line services or upstream dependencies of services that are covered by SLOs that have shown themselves to be frequent contributors to SLO attainment failures. As you do this, you should start to measure and report your SLM coverage as a percentage of applications covered by SLOs. For example, you may say that 20% of your apps have established SLOs. As SLM expands into your organization and as its value is seen by management and other stakeholders, you may find that you need a dedicated team to manage the SLM process. The SLM process should also become a primary driver to help you prioritize issue resolution activities. SLO attainment failures are a direct indicator that your IT services are having a negative business impact which is visible to your customers as poor performance and/or unhandled errors. Value realization Once the SLM process is established, you will see a reduction in the effort required to identify business impacting issues, a better ability to communicate with your business stakeholders, and an easier time proving the business’ return on investment in IT services. Your SLM KPIs will provide quantifiable proof of these improvements. In addtion, you should be able to simplify your observability strategy by removing or reducing your dependency on legacy consumption metrics and the logic required to correlate them against your true goal of measuring performance and quality. Once you are firmly on the path to SLM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering. You can also move to other observability maturity value streams, such as Customer Experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.28586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Service</em> level management use case <em>implementation</em> <em>guide</em>",
        "sections": "<em>Service</em> level management use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " stream, such as <em>Service</em> Level Management, or Reliability Engineering. You can also move to other <em>observability</em> <em>maturity</em> value streams, such as Customer Experience."
      },
      "id": "61403d0464441f0457424337"
    },
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "JavaScript error rate KPI",
        "HTTP error rate KPI",
        "Time to first byte KPI",
        "Core web vitals: Largest contentful paint (LCP) KPI",
        "Core web vitals: First input delay (FID) KPI",
        "Cumulative layout shift (CLS) KPI",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review Instrumented Pages",
        "Validate Browser URL Grouping",
        "Understand How You Will Segment Your Data",
        "Import the Quality Foundation Dashboard",
        "Capture Current Performance For Each Dashboard Page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to Improve",
        "Improve Targeted KPIs",
        "Improve Page Load Performance",
        "Improve AJAX Response Times",
        "Improve the AJAX Error Rate",
        "Improve Javascript Errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2021-10-12T12:55:15Z",
      "updated_at": "2021-09-18T16:34:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. Desired Outcome This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Key Performance Indicators Quality Foundation measures the following KPIs: JavaScript error rate KPI This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. HTTP error rate KPI HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Time to first byte KPI This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Core web vitals: Largest contentful paint (LCP) KPI Core Web Vitals are part of Google’s Page Experience Metrics. They measure the experience from when a page begins rendering. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Core web vitals: First input delay (FID) KPI This KPI measures the experience from when a page begins rendering. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Cumulative layout shift (CLS) KPI This KPI measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events is at least 2x an average sprint. Establish current state Review Instrumented Pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL Grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand How You Will Segment Your Data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the Quality Foundation Dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture Current Performance For Each Dashboard Page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to Improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve Targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve Page Load Performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX Response Times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX Error Rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve Javascript Errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices going forward: Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization: At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.34109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Quality foundation <em>implementation</em> <em>guide</em>",
        "sections": "Quality foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " you understand your digital customer experience in a meaningful way. Desired Outcome This <em>implementation</em> <em>guide</em> will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about"
      },
      "id": "61461531e7b9d25774b6f22d"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide": [
    {
      "sections": [
        "Service level management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Service response time KPI",
        "Service quality KPI",
        "Service level objective attainment KPI",
        "Service uptime KPI",
        "Prerequisites",
        "Establish current state of your KPIs",
        "Determine in-scope services",
        "Identify service boundaries",
        "Deploy instrumentation",
        "Perform SLM educational workshops",
        "Analyze KPIs and set baseline SLOs",
        "Establish or optimize alerting",
        "Build problem resolution workflows",
        "Execute continuous improvement review",
        "Next steps",
        "Value realization"
      ],
      "title": "Service level management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Service level management",
        "Implementation guide"
      ],
      "external_id": "e3c4da80186b6d33a301db4a15c0b0cff2034131",
      "image": "https://docs.newrelic.com/static/e2478328e46923877c6dd58993aecf5f/d9199/nrSLMServiceMap.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide/",
      "published_at": "2021-10-12T12:21:04Z",
      "updated_at": "2021-09-14T06:11:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview IT Operations is expected to provide services that meet the business’s requirements for performance and reliability. However, many ops teams attempt to measure performace and reliability using legacy methods, like measuring resource consumption. That, in turn, requires that they create complex dashboards of granular metrics which they then try to correlate with application performance and reliability. These complex dashboards require subject matter experts to interpret the results for business stakeholders. Legacy methods create barriers to understanding what a good system state looks like and how bad system states impact the business. Essentially, IT ends up not sharing a common metric vocabulary with the business. This fundamental disconnect will result in the perception that IT is not able to deliver the services that the business requires, with all the implications and impacts that perception carries. Service Level Management (SLM) eliminates that disconnect by better explaining the overall performance of a system in terms that are easily understood by both IT and the business. The intent is to show whether or not the system is meeting its performance and reliability expectations, and if it is trending toward or away from improvement, so proactive steps can be taken. The end goal is that systems are better oriented toward desired business outcomes with IT’s attention focused on issues in areas with the highest business impact. You are a good candidate for SLM if any of the following are true: The business impact of performance and reliability issues are not well understood by all stakeholders. Your MTTx is too high. You are collecting many resource consumption metrics (such as CPU, disk, or memory) or are maintaining many metric correlation rules in order to identify system problems. You can’t see the value of your observability tool(s). Desired outcome Service Level Management’s overall goal is to easily measure and communicate the overall health, performance, and quality of your digital products and services to all stakeholders. By implementing SLM at key output points in your systems, you will have a simpler and more responsive observability practice, tighter alignment with the business, and faster paths to improvement. The SLM process described in this guide will help you to identify the points in your systems where you should measure the key performance metrics of service performance and quality. It will also define and drive a simpler alerting strategy, continuous improvement methodologies, and improved problem resolution workflows. Key performance indicators You will use the SLM process to collect and measure the following KPIs, often referred to as the “Golden Signals”: Service Response Time Service Quality (error rate) Service Level Objective Attainment (Availability) Service Uptime These KPIs directly measure the most important aspects of an IT service, speed and quality, in a way that is easy and intuitive to understand and communicate to technical and non-technical stakeholders. Detailed information on each metric follows. Service response time KPI Service response time measures the amount of time a service requires to process a transaction. It starts when a transaction request is received by the service and ends when the response is sent. Goal: Reduce transaction response time. Best practices: Measure response time at service boundaries. Use continuous improvement processes to drive down response times. Ensure that non-business transactions (i.e. health checks) are not included / measured. Map this KPI back to business impact. Report KPIs to all stakeholders. Service quality KPI Service quality is the number of transactions that result in an unhandled error. Typically, these are transactions whose HTTP response code is greater than or equal to 400. Goal: Reduce the number of unhandled errors. Best practices: Measure error rates at service boundaries. Continually identify and remediate sources of high error volumes. Map this KPI back to business impact. Report KPIs to all stakeholders. Service level objective attainment KPI SLO attainment is the percentage of time a business service is meeting its response time and quality goals. Goal: Improve response time and quality to ensure high SLO attainment. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact. Report KPIs to all stakeholders. Service uptime KPI Service uptime is the percentage of time a service can be reached by at least one client. Typically this is measured using synthetic transactions from representative remote locations. Goal: Use continuous improvement processes to watch uptime metrics and take appropriate steps to ensure uptime meets business requirements. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact Report KPIs to all stakeholders. Prerequisites Before you begin, if you don’t have equivalent experience, you should complete the New Relic University (NRU) Overview Course. You should also have a basic understanding of: New Relic One APM and infrastructure monitoring New Relic One Dashboards and NRQL New Relic One alerting best practices Establish current state of your KPIs As with any continuous improvement process, the first step of SLM is to establish the current state of your KPIs. To do so, you will need to perform the following tasks: Determine in-scope services Identify service boundaries Deploy instrumentation Perform SLM educational workshops Analyze KPIs and set baseline SLOs Establish / Optimize Alerting Build problem resolution workflows Execute continuous improvement review To help illustrate this process, we are going to apply it to an example IT service, an ecommerce site for a cellular telephone provider. Determine in-scope services You should first identify the IT services that are going to be in-scope for the initial iteration of the SLM process. These services should be key to ongoing business operations and as close to your customers as possible. Most commonly, you will be applying the SLM process to an application, since that is the service your customers are expecting you to deliver. SLM can be applied to infrastructure-based services; however, it is a more advanced application of SLM which is applicable to a much smaller set of organizations. If you are considering implementing SLM for infrastructure, you should ensure that the service(s) you are instrumenting are actually the closest to your organization’s end-customer. If your infrastructure is hosting a customer-facing app, then the app should be the target of SLM. Absent anything else, a good methodology for identifying in-scope services is to consult your disaster recovery plan. Typically, the most critical business services are prioritized there. Identify service boundaries Next, you should identify each service’s boundary, which is the service component that is closest to the client sending transaction requests. This should be the application receiving the request from the client, browser, or mobile device, and may also be known as the \"external API.\" Reverse proxies, CDNs, and load balancers are not part of the service boundary. Their service level compliance should be measured via the Uptime KPI (external test requests for connectivity). If your services are using APM, you can identify service boundaries using the service map or dependencies features. A service component is on a boundary if it has no inbound connections. In the example below (from a service map), you can see that the WebPortal is on the boundary. An example of using service maps in New Relic One to identify service boundaries. In contrast, the following screenshot (from the dependencies page) shows that the Inventory Service is not on a boundary since it has incoming connections from the WebPortal. Subsequent examples in this guide will build on the WebPortal service boundary. An example of using the dependencies UI in New Relic One to identify service boundaries. You should understand that the SLM process defines a service boundary as being downstream of any dependencies. The service boundary is the point where all the effects and impacts of dependent services are measured as they contribute to the total response time and quality of the service. By measuring service level compliance at the boundary, you will be able to see the impact that all service components upstream of the boundary have on service delivery. This means that your initial steps into SLM can focus on the services that are closest to your users, yet still capture the contribution of more distant services. As your practice matures, you will be able to identify the next round of upstream services that would benefit from direct SLM instrumentation. In our example, the WebService is downstream of the Fulfillment, Plan, Promo, Login, and Inventory services (among others). By applying SLM at the WebService, we will be seeing the impact of the upstream services on the WebService. Any impactful issues with an upstream service will be reflected in the WebService’s service level KPIs. By instrumenting one service, we are capturing the contribution of five additional services. This greatly simplifies our observability practice. In time, problematic upstream services will self-identify themselves as candidates for direct SLM instrumentation. Deploy instrumentation To collect SLM service response time and transaction success KPIs, you need to deploy instrumentation into the components of your production apps on the service boundary. If you don’t have instrumentation that can do this in production already, then you will need to engage the teams and stakeholders that can help you to get this done. For detailed information on deploying the New Relic instrumentation that can gather this information, see our APM install documentation. The uptime KPIs can be collected using synthetic transactions, which don’t require any instrumentation to be added to the service. If needed, you can start your SLM journey there while waiting for the direct instrumentation to be deployed. The uptime tests should perform a basic, yet realistic, check of the service’s functionality. For detailed information on this capability, see our synthetic monitoring documentation. Perform SLM educational workshops You should share the self-paced New Relic Essentials training course with the appropriate stakeholders so they can understand how the New Relic technology platform will aid in the SLM process. Analyze KPIs and set baseline SLOs The SLM process uses speed and quality as its key performance indicators. In technical terms, speed means response time and quality means error rate. At the end of this phase, you will have created baseline service level objectives for each service in the form of a percentage. For example: “98% of service X’s transactions will be error free and occur in less than 500 milliseconds.” For each in-scope service, you should analyze speed and quality at the service boundary. This will give you an overall understanding of how the entire service and all of its dependencies are performing. As you iterate through the SLM process, you can then identify and prioritize the upstream service components that require direct SLM instrumentation. To analyze KPIs, you should do the following for each service: Identify the volume and 95th percentile response time for each of the service’s transactions over a relatively long period of time, typically between seven days and one month. It is important that you use percentile rather than average, so you can see the entire range of response times, including outliers. If you use averages, you will hide outliers. The following is an example of the initial baseline report. Here you can see the volume, p95 response time, and error volume for the WebPortal and a few other services. The WebPortal’s p95 response time is .36 seconds (or 36 milliseconds), so we have decided to set the SLO target to 0.4 seconds. Example of an initial baseline report measuring volume and 95th percentile response time. Next you should review and identify any non-business transactions, since they should not be included in the SLO attainment calculation. For example, you should not include health check / keep alive transactions and you may not want to include administrative transactions. In the example below, we are looking at some of the transactions from the WebPortal service. We have decided that the about.jsp transaction is a non-business transaction that should not be tracked in our SLO attainment calculation. Example showing transaction breakdowns from the initial baseline report to help identify what to track (or not track) for SLO. Finally, import and edit the SLM template dashboard to exclude non-business transactions. Then use the p95 response time as your baseline response time service level objective. For the example chart, we chose 0.4 seconds as our response time threshold and set our service level objective to 95%. This means that we are expecting 95% of the WebPortal’s business transactions to complete in 0.4 seconds or less and without an error. The red line on the chart shows us our 95% service level objective. Example chart now excluding the non-business transactions. As you can see, there are periods of hours where the app is not meeting its SLOs. If we are going to maintain the 95% target, we would need to identify and fix the service components or dependencies that are causing these problems. Establish or optimize alerting After you have set your service level objectives, you will then configure alerts that will inform you when your SLO attainment has dipped below your goal. These alerts will show you when incidents with a high business impact are occurring. When they are triggered, they should be given a high priority and you should engage the proper teams to start the process of diagnosing the source of the problem. A basic starting point is to configure an alert that triggers when your SLO attainment has dipped under your baseline for more than 10 minutes. For more information, see our documentation on configuring alerts. Build problem resolution workflows As we’ve been discussing, the intent of the SLM process is to identify when business impacting issues occur in your IT services. When this occurs, a diagnostic investigation should be launched. The goal of the investigation is to identify what service element is causing the business impacting issue. SLM tells you that there is a problem with business impact, the diagnostic process helps you to find where the problem is. Typically, your high level diagnostic workflow will start at the service boundary and go as follows: Look at the service’s individual transactions and see which one(s) are departing from their performance and/or response time SLOs. Look at each service component responsible for delivering that transaction until you find the component that is failing. Use in-depth diagnostics to identify the root cause of the problem and then resolve it. Execute continuous improvement review This is an ongoing phase of the SLM process where data is reviewed and adjustments are made as required. Your KPIs should be reported to upper management to ensure that stakeholder teams are appropriately prioritizing work and that you are meeting the SLO goals you’ve set. Periodic KPIs should be recorded and retained over periods of months to years to establish a baseline and to show the rate of improvement. In addition, each time you execute the continuous improvement process, you should: Review each service’s architecture to ensure your instrumentation is deployed at the boundary and that there are no observabilty gaps. Review each service’s transactions to confirm that only business transactions are included in your SLO calculations. Review each service’s SLO and determine if it meets the business’s performance and quality requirements. If it does not, then the SLO should be changed and the appropriate stakeholders notified so they can work to improve performance and quality. Review your SLO attainment and determine if any upstream services should be added to the SLM process. Next steps After you’ve established the SLM process, you should identify other services that would benefit from SLM instrumentation. These may be other front-line services or upstream dependencies of services that are covered by SLOs that have shown themselves to be frequent contributors to SLO attainment failures. As you do this, you should start to measure and report your SLM coverage as a percentage of applications covered by SLOs. For example, you may say that 20% of your apps have established SLOs. As SLM expands into your organization and as its value is seen by management and other stakeholders, you may find that you need a dedicated team to manage the SLM process. The SLM process should also become a primary driver to help you prioritize issue resolution activities. SLO attainment failures are a direct indicator that your IT services are having a negative business impact which is visible to your customers as poor performance and/or unhandled errors. Value realization Once the SLM process is established, you will see a reduction in the effort required to identify business impacting issues, a better ability to communicate with your business stakeholders, and an easier time proving the business’ return on investment in IT services. Your SLM KPIs will provide quantifiable proof of these improvements. In addtion, you should be able to simplify your observability strategy by removing or reducing your dependency on legacy consumption metrics and the logic required to correlate them against your true goal of measuring performance and quality. Once you are firmly on the path to SLM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering. You can also move to other observability maturity value streams, such as Customer Experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.81323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Service level <em>management</em> use case <em>implementation</em> <em>guide</em>",
        "sections": "Service level <em>management</em> use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Uptime</em>, <em>performance</em>, <em>and</em> <em>reliability</em>",
        "body": " to identify system problems. You can’t see the value of your <em>observability</em> tool(s). Desired outcome Service Level <em>Management</em>’s overall goal is to easily measure and communicate the overall health, <em>performance</em>, and <em>quality</em> of your digital products and services to all stakeholders. By implementing SLM"
      },
      "id": "61403d0464441f0457424337"
    },
    {
      "sections": [
        "Service characterization use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Business KPI",
        "Service quality",
        "Release frequency",
        "Practitioner KPI",
        "Feature release frequency",
        "Mean time to close",
        "Prerequisites",
        "Establishing current state of your KPIs",
        "Determine your instrumentation needs",
        "Decision matrix",
        "Understand endpoint testing",
        "Improvement process",
        "Config based instrumentation",
        "Create an effective service name",
        "Tip",
        "Override default agent configuration",
        "Isolate service functions",
        "Define custom transaction names",
        "Capture parameters with your transactions",
        "Component measurement",
        "Ensure your frameworks are measured",
        "Track every external service call",
        "Endpoint testing",
        "Value realization",
        "Investments",
        "Training",
        "Development and maintenance",
        "Returns",
        "AQM impact",
        "Service quality improvement",
        "Service delivery improvement"
      ],
      "title": "Service characterization use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Operational efficiency",
        "Service characterization",
        "Implementation guide"
      ],
      "external_id": "6c7ba35514950d573261ef4dbc852f6b3c76433a",
      "image": "https://docs.newrelic.com/static/bd4c9daf746228eed022d0c89454469c/39c09/oma-oe-sc-service-diagram.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/operational-efficiency/sc-implementation-guide/",
      "published_at": "2021-10-12T12:16:04Z",
      "updated_at": "2021-09-19T15:19:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview \"Do I have all the telemetry I need to adequately measure my service?\" The process of onboarding a service for production monitoring tends to start from the end and work its way to the beginning. Typically a completed service is instantiated with agent based monitoring and the team responsible for service delivery needs to read the telemetry coming out of the agent like tea leaves, working their way backward to understand how the service functions by what can be observed. At New Relic, through tens of thousands of observability deployments, we have discovered that the more involved designers, architects, and developers can be in the definition of optimal service delivery measurement, the better. The emergence of the IT aphorism shift left speaks to the need to involve developers more directly in the software lifecycle activities that happen after the development stage is complete. In the case of service observability, we find there is little specific guidance on how developers can meaningfully contribute to production telemetry definitions. This guide is intended to provide practical suggestions for service developers to evaluate the state of your telemetry and suggest paths to improve it. Observability programs that closely link developer expectations with the runtime behavior of production systems are much more effective to diagnose and remediate aberrant conditions. The closer developer connection also produces services that are more robust and performant. You’re a good candidate for service characterization if any of the following are true: Your development teams are disconnected from production observability design. Your production monitoring program suffers from a lag between the introduction of new services/capabilities and their coverage with telemetry and alerting. You need to provide additional business context to your instrumentation for diagnosis and business KPI measurement. You employ a highly customized or proprietary software framework. Your service is under active development. Legacy services, and services built from commercial-off-the-shelf platforms tend to be better served with generic instrumentation options. Desired outcome This guide focuses on the metrics derived from your service’s runtime operation (its code execution) as well as external measurements of execution (through synthetic testing). Service instrumentation planning is the approach used to describe a single service runtime through telemetry. Modern monitoring systems provide deep insight into the technical details of service implementation. The power of distributed trace or bytecode instrumentation allows operations teams to quickly collect detailed service telemetry. Unfortunately, operations teams are often not in the best position to evaluate the quality of the telemetry gathered from the instrumentation. This challenge is compounded by the fact that service delivery teams are asked to implement telemetry collection for the first time in live production systems. Exposing inadequately instrumented services to production users for the purposes of refining that instrumentation creates a period that puts customer satisfaction at risk. This burn-in period often becomes difficult to escape as new features are delivered from code bases without a strong linkage between software delivery and observability programs. Key performance indicators By having your development staff involved in improving your service instrumentation, you should realize observability benefits in the following ways. Better informed development decisions: By detecting areas of volatility or unexpected behavior and addressing them. By understanding what dependencies in your code lack redundancy or robustness, and taking measures to refactor the service. By appreciating how end-user cohorts are employing your software, you can better understand where improvements will have the biggest impact. Improved troubleshooting: More precise and contextually relevant telemetry from your service will allow for more accurate and actionable detection of faults. With better telemetry naming, operations staff can use a common language with developers during incidents, reducing the time to triage and remediate incidents. With these goals in mind, it is important to identify some simple KPIs that help to gauge the ongoing improvements in your software delivery and operations programs. The following outlines some suggested KPIs to consider as you invest in improved instrumentation. Business KPIs are aligned to your overall program objectives and should be consistently measured to demonstrate ongoing program improvement for each service. Practitioner KPIs are used to measure changes in the execution of job functions for those participating in the development and management of services. Business KPI Service quality A metric is required to define how well your service is operating. This will depend upon the needs of your organization and the constraints of the services being monitored. Goal: Improved service quality attainment score over time. Best practices: Create a graphical representation as a trend of Service Quality achievement for defined periods (Monthly / Quarterly). Service Apdex can provide an effective Service specific quality score. (See Apdex: Measure user satisfaction.) A well defined Service Level Management (SLM) approach using SLIs that describe the level of expected operation for service boundaries can be a useful way to establish a single measurement of quality. Release frequency The number of releases for a given service. This should indicate the velocity of the software delivery organization. Often release frequency isn’t immediately comparable between development organizations. Instead, weighting high-value releases or features to bugs can provide an improved comparative context. Goal: Consistency of attainment with consistent or improving Service Quality indicator. Best practices: Can be derived from deployment markers or other events sent to New Relic. Measure directly from code or project management tools such as Jira, BitBucket, GitHub. Consider implementing a collection mechanism to capture release events and store them directly in New Relic. See NR1 CICD Innovation for example JIRA and BitBucket configs. Practitioner KPI Feature release frequency Quantification of the percentage of releases that are directly related to new feature development versus bug fixes or technical debt retirement. The relationship to feature to fix will vary between teams and projects based on the history of the service. Goal: A consistent or improving feature release frequency consistent with the service delivery goals. Best practices: Practitioner feature release frequency is often acquired in the same manner as the broader release frequency business KPI. This metric is then made available to the development team for the service. Mean time to close Average duration of alert-driven incidents in New Relic. See Alert Quality Management Use Case Implementation Guide for more details. Goal: Steady decrease of incident close time for identified services. Best practices: Follow the Alert Quality Management Use Case Implementation Guide, understanding Service behavior through the lens of the alerts defined to help improve service delivery. Prerequisites Before you begin to introduce Service Instrumentation into your development processes, be sure to acquaint yourself with New Relic fundamentals available from New Relic University. In addition to NRU training, review and keep the following documentation resources handy: APM agent install and configuration Instrumentation guides: C-SDK Go Java .NET Node.js PHP Python Ruby OpenTelemetry SDKs Introduction to New Relic synthetic monitoring Establishing current state of your KPIs Determine your instrumentation needs Instrumentation is the process to acquire telemetry from a software system and its associated services for the purpose of describing that software system's runtime behavior and business function. Monitoring systems tend to provide generic capabilities for telemetry acquisition that can be fine tuned to close gaps when monitoring the function of a software system. This use case assumes that your Observability Program has completed the Quality Foundation OMA use case implementation guide and that you have a well considered and deployed telemetry collection architecture for your services. With the possible exception of alert definition, instrumentation offers the most open-ended and customizable activities related to observability. The New Relic One platform provides features to highly customize your use of instrumentation. Because of this, you should carefully consider the amount of time and effort you’re going to put into instrumenting your services. Like all Service Instrumentation assets and dependencies, the introduction of instrumentation will require ongoing oversight and maintenance and therefore is a form of technical debt you will accrue for your project. As you begin the process of instrumentation, you want to continually ask yourself the question: Is the visibility I will gain from this instrumentation worth the cost of implementation and support? Decision matrix As a first step you should evaluate the default instrumentation you obtain from your Observability platform and ask yourself the question: Does the telemetry adequately describe the function and the purpose of my service? For example, think about what your service does. Perhaps it receives an order, needs to validate the order for integrity, conveys that order to a clearinghouse service, and receives a confirmation code that is relayed back to the requestor. This example gives a clear path to break down the function of service and evaluate if we have enough telemetry and context to make informed appraisals of how the service is functioning. Conceptual service that receives and processes http requests. If this conceptual diagram represents the implementation of the service, you will want to know answers to the following questions, at any given moment in time: How many requests do I receive? How many messages and HTTP requests do I send? How many requests are successful? What is the response time for a full request? What is the response time for invocation to a dependency? How much resource should this process take under what number of requests? What are all my points of failure? Most monitoring frameworks for application runtimes will gather telemetry like this as basic functionality. However, sometimes specific implementation of your service will pose a challenge to the generic instrumentation assumptions made by the monitoring software. In this case your Observability platform will need to accommodate your needs and provide an ability to modify a default monitoring configuration. The following table documents some additional situations where you would consider adding additional telemetry or metadata capture through instrumentation. The practices section that follows describes how to close those gaps to ensure your observability platform provides telemetry needed to manage your service. Considerations for instrumentation: Are my base telemetry requirements satisfied? If not, document the gaps and evaluate if they can be closed through custom configuration or additional instrumentation techniques. Can I isolate discrete user stories within the telemetry? If not, use trace capabilities of agents to capture the invocation of a discrete user story with adequate context metadata. Do I have insight into the parameters that are invoking user stories? If not, use custom attributes through agent SDKs to add context to the transactions and spans. Can I measure the major functional components of the software? If not, use instrumentation SDKs to create baseline metrics on a specific functional element of the code. (cache lookups, processing routines, or utility functions). Can I measure the client interactions from my code to external systems? If not, ensure requests and responses are encapsulated by component level tracking. If the client invocation is asynchronous, consider implementing distributed trace features to view the successive processing. Understand endpoint testing Endpoint testing is a simple and practical approach that greatly expedites how to determine the root cause of a given system failure. It allows operations and supporting teams to quickly know there is a real problem, and isolate that problem to a specific service. Modern software systems depend on a number of services to complete their tasks. Historically, the process of monitoring those service endpoints was straightforward. The architecture team would produce a well documented map of dependencies for the operations team. The operations team would dutifully create a check of the itemized endpoints. Today, with continuous delivery processes and small batch changes, new endpoints and dependencies can be created and deployed at a rate that makes it difficult for an operations team to anticipate and proactively define synthetic checks. By giving the service developers greater scope of control to define production services tests during the development phase, you will greatly increase the coverage of endpoint tests for your Observability program. Decision matrix To determine whether to create a synthetic check is straightforward. Generally you will want to know the first occurrence of a failure for a dependency. If you answer “yes” to any of the following questions, consider creating a dedicated synthetic check. Is the end point customer facing? Does the endpoint invoke new dependencies? Is the endpoint on a different network infrastructure? Is the endpoint shared between multiple services? Is the endpoint a content origin supported by a CDN? Improvement process Config based instrumentation Each New Relic agent provides a variety of configuration options. Typically you will define a standard approach to include the agents within infrastructure hosts, application runtimes, and connections to your cloud service providers. Default agent configurations are generic and widely applicable. One of the best ways for developers to influence the applicability of deployment is by overriding the default configuration options for your service instance. The following are default instrumentation options to consider. Create an effective service name Tip New Relic agents provide a variety of mechanisms to define the Service runtime name. Please see the application naming guide to find the implementation details for your runtime environment. The name you give a service provides the namespace (where you will find the agent data). One of the most important strategies New Relic uses to understand the behavior of your services is to aggregate like things together and to use the commonalities derived from aggregation to isolate variance. Modern services are often deployed to multiple contexts to ensure capacity handling or specific functional segmentation. In order to take advantage of the benefits of aggregation, it is very important that your service runtimes are grouping instances with identical operational characteristics. Therefore, when deploying services, pay close attention to the following three criteria to help you name your deployed services: Does my service target a specific audience? Is my service running a different codebase? Is my codebase using a different runtime configuration? If you answer “yes” to any of these questions, consider creating a unique name for your service. Audience criteria Think of the audience as the group of end users or service functions. If your service is split between North American and European deployments, the runtimes in those deployments should be grouped accordingly. For example: newrelic.appname = PORTAL_AMER Copy and newrelic.appname = PORTAL_EMEA Copy This will group the telemetry created by that audience together, allowing you to better understand the contextual similarities of service problems related to a specific user audience. Sometimes the way we deploy applications divides the operational context of a service, such as a portal application with administrative functions. Maybe the admin functions are baked into the general portal codebase, but only one instance in a cluster is handling the portal admin requests. In that case you have a functional audience segmentation opportunity, so you should ensure that it is named appropriately. For example: newrelic.appname = PORTAL_MAIN Copy and newrelic.appname = PORTAL_ADMIN Copy Codebase criteria If you’re running different code versions under the guise of one service, consider segmenting those runtime instances and incorporating version naming as part of your naming scheme. When you group code together as one service name that is executing different service versions, you’re increasing the noise to signal ratio of any metrics you produce. Different code versions might use different amounts of compute resource or process data differently. It becomes very difficult to determine if a service is behaving normally when the signals you get from the metrics are due to different functional implementations. Consider adding a numeric identifier to the service name if you have multiple versions running concurrently. For example: newrelic.appname = PORTAL_MAIN_V112 Copy and newrelic.appname = PORTAL_MAIN_V115 Copy If you employ feature flag framework frameworks like LaunchDarkly or Split, you may have multiple versions of an application or service within a single codebase. Please consult the Isolating Service Functions section to address those conditions. Runtime criteria If an instance of a service is deployed to a system with different runtime constraints, it should be encapsulated in its own telemetry namespace. This can be a deployment to a different datacenter that offers network connectivity advantages to a shared resource, or perhaps the service is running on a separate compute tier with a different memory or thread configuration. These characteristics that affect the code runtime operation can cause different behaviors that lead to different operations behaviors. For example: newrelic.appname = PORTAL_NYC_DC Copy and newrelic.appname = PORTAL_REALLY_BIG_FOOTPRINT Copy Override default agent configuration Tip The New Relic agents provide a variety of options for runtime configuration. Please refer to the agent configuration guide for the options specific to your runtime. Each New Relic APM agent provides a variety of options to modify the default configuration. The most comprehensive and consistent location is the configuration file that accompanies each agent install. However, New Relic agents can also be configured by passing command line parameters directly to the service instance runtime, by using environment variables, or by calling functions within the agent's SDK at runtime. .NET agent configuration options: Using the New Relic .NET SDK API Environment variables Config file options Isolate service functions As the Create an effective service name section indicated, one of the primary objectives of instrumentation is to configure the New Relic agent to group like runtime constraints together as a single named unit. We suggest this because software systems should behave in deterministic ways. For a specific set of inputs, you should get an expected range of measurable outcomes. The degree to which we can comfortably contain these constraints into named service runtime components greatly helps us understand normal behavior and isolate aberrant behavior. Once you have settled on an effective service naming strategy, the next step is to look within the telemetry collected for the service and determine if it suitably isolates the service’s functionality. The implementation pattern we most often encounter is a series of functions being invoked by a web request. The initial receipt and handling of a web request to a service runtime results in the allocation of processing resources. New Relic defines this resource allocation and code execution as a transaction. The New Relic agent is configured with a set of assumptions that create namespaces for transactions as they are detected. Those assumptions differ between the agent language runtime. For example, a good example of how the New Relic Java agent determines the transaction name can be found in the Java agent's transaction naming documentation. However, even after the agent transaction naming protocol has been applied, it may leave you with an unsatisfactory result. By adding additional instrumentation to name the transaction to improve its context, this can greatly improve your understanding of the service’s execution behavior. The goal for transaction naming should be an APM transactions view that provides good segmentation of the services functions in an approach that is easy to understand for a non-developer. New Relic service transaction breakdown view. The transaction breakdown image is a good example of transaction segmentation. It provides detailed tracking of the amount of work being done by each transaction within the broader codebase of the service. It also displays the transaction with a plain user-friendly name that offers some hint of its business context (what the transaction does). As you learn more about naming transactions and including attributes, be sure to make your naming approach accessible for non-technical observers of the data. Transaction breakdown: the transactions in this service seem to be highly weighted to one transaction name with a pretty generic name. Breakdowns like this beg the question: \"Is this a good representation of the work my service does?\" The obtuse transaction breakdown image demonstrates a bad example of transaction name segmentation. In this case we have about 60% of the transaction volume being named OperationHandler/handle. Both the percentage attribution of the transaction volume and the generic nature of the name indicate there might be an overly zealous aggregation of transactions underneath that transaction namespace. A good way to validate your transaction naming approach is to review the distribution of response times for your transaction over a significant period of time in the service web transaction histogram dashboard. The service transaction histogram view shows the count of transactions that fall into each response time bucket. A good naming strategy tends to display a normal distribution. The service transaction image shows a wide range of transaction response rates. Although the bulk of the transactions land in the 0-200 millisecond range, it indicates values ranging from 200-1000 milliseconds. When you have a highly distributed range of responses for a transaction, you should ask yourself: What information do I have during the transaction execution that can help me name this transaction? In many cases, non-normal distributions are a direct result of the parameters being passed to a request, or the work the transaction is being asked to do. It is pretty easy to consider that a service query transaction might take a data range as a parameter. The date range when small might provide a faster lookup time. Therefore, perhaps providing a meaning scheme that is derived from some expected parameter constraints (> 1day, 1-5 days, >5 days) might provide a more meaningful segmentation. Your objective is to create a transaction name that facilitates grouping transactions with the fewest unique characteristics. A more normal distribution of transaction segmentation where individual transactions report more consistent response time attainment with fewer exceptions. The normal distribution image demonstrates more purposefully named transactions within a service. In this case the web transaction response times are more closely grouped, indicating consistent execution characteristics. By ensuring your transaction naming strategy provides a consistent mechanism to group your service’s functions by the types of operations they are performing, you will be able to quickly isolate aberrant behavior, or better understand the root cause of the variations. This will allow you to refactor your application and increase the overall predictability of your service’s functions. Define custom transaction names Tip Consult the New Relic agent API guide for your language agent to review the transaction naming procedure for your runtime. The New Relic agent transaction naming service requires the invocation of a SetName(String name) like API call to the New Relic agent SDK. Each language runtime agent has its own syntax and option for setting the name. For example, to take the value of an http request parameter and use it to name a transaction in the New Relic Java agent, you can use code similar to this: com.newrelic.agent.Agent.LOG.finer(\"[my query handler] Renaming transaction based on an important query parameter\"); com.newrelic.api.agent.NewRelic.setTransactionName(\"Query Handler_\" + (javax.servlet.http.HttpServletRequest)_servletrequest_0).getParameter(\"important_query_parm\")); Copy Please note: There is a maximum capacity to transaction names within New Relic. Your transaction naming strategy will have to trade off a degree of specificity if there are thousands of potential transaction names. When too many transaction names are being reported, New Relic will attempt to create rules to group those transaction names. More details can be found in the agent troubleshooting guide related to metric grouping issues. Should you suspect a metric grouping issue, open a support case with New Relic, and we will be happy to work with you to isolate the cause of the transaction naming issue. Capture parameters with your transactions Tip Consult the New Relic agent custom attributes guide for your agent language to review the metadata enhancement options for attribute customization. The transaction name is a powerful way for you to segment your Service’s functionality so that you can better understand its behavior. This allows you to discretely isolate functionality directly in the New Relic UI. However, there are many occasions when you will want to get some additional context on the function of your Service without resorting to isolating the transaction name. This can be accomplished by introducing attribute capture by your Service. You can add name:value pair attributes to decorate the details of each transaction. The attributes will be available in each transaction event through the APM transaction trace and errors UI, or through direct query of parameters from the NRDB transaction event type. After you select a transaction trace, you can view the custom attributes you have set for your Service’s transaction. Here is an example of the transaction trace details you can see in the APM errors UI. Custom attributes displayed in the APM errors UI. If you have developed a useful transaction name segmentation, you can use the additional context of the attributes to better understand the inputs, cohorts, or segments that led to an unexpected result. In addition to being able to understand the context of your transaction within the APM UI, the introduction of parameters is an extremely useful tool to aggregate and analyze transactions by querying transaction data directly. Custom attributes are added to each transaction, making it easy to isolate and facet on specific conditions. NRQL query expression that uses a custom attribute to facet database call duration. The parameter capture approach can also be used with feature flag systems like Split or LaunchDarkly. In this case, as you are implementing the decision handler for the feature flag, consider capturing the flag context (for example, optimized_version = on) that is being applied to the block of code controlling the version or feature the customer sees. NRQL query that demonstrates the result when the state of a feature flag is captured by a transaction custom attribute. The feature flag state attribute allows us to understand the impact of the code execution path on performance, throughput, and dependency utilization. For example, to take the value of an http request parameter and save it as a custom attribute in the New Relic Java agent, you can use code similar to this: com.newrelic.agent.Agent.LOG.finer(\"[my query handler] Adding an Attribute to transaction based on an important query parameter\"); com.newrelic.api.agent.NewRelic.addCustomParameter(\"ImportantParm\", (javax.servlet.http.HttpServletRequest)_servletrequest_0).getParameter(\"important_query_parm\")); Copy Component measurement The behavior of a specific transaction within the context of a service is a powerful way to segregate functionality and ensure a software system is operating effectively. However, another way to look at the behavior of a software system is to review the detailed component execution model of its implementation. The application framework code components are shared throughout the service, and the ongoing evaluation of component performance can provide an insight into the overall service health. Within New Relic One there are two places we can observe component execution details. The service summary dashboard in APM provides a view of the composite execution of the service broken down by its component parts (for example, garbage collection execution or database calls). This summary dashboard provides a breakdown of major component types within the application. Memcached, External Web Invocations, MySQL and Dirac are all examples of shared code frameworks that the collective transactions of the Service are using to execute their business logic. A similar breakdown is provided on a transaction by transaction basis. This single transaction summary view breaks out the contributing execution time by component. This helps you see the aggregate performance of components within a transaction. Transaction component segments will tend to demonstrate consistent performance behavior, you can use this consistency to detect a change in its fundamental behavior. This can be a good indication of an underlying issue. Resource constraints tend to manifest more obviously within component frameworks than within individual transaction details. This allows you to infer characteristics of dependencies through the common constraints being experienced by all code running within a service. Ensure your frameworks are measured Tip Consult the New Relic agent instrumentation and SDK guides under the language agent for your service runtime to find information about adding metric names to your instrumentation. The syntax for framework instrustrumentation is specific to the language your service is written in, but the general approach is consistent for all. Consider the threads of execution within your Services as an analogy for transactions within New Relic telemetry. Each method or function execution on the stack is an opportunity to add additional instrumentation. In this way New Relic maintains a time-annotated invocation stack for the transaction and uses those method/function start/stop timings to aggregate it into a series of component metrics. A simple Node.js application making a call to a MongoDB. The two major components of the application are the receipt of the request and get/put operations to the MongoDB. If a particular segment of logic is crucial to the function of your Service or transaction, consider wrapping that call with callbacks to the New Relic agent so that the agent can understand that it has entered a discrete code component and can aggregate the time consumed within that component accordingly. By passing a metric name to the callback, you will create a component segment metric for your service and transaction. The metric naming option is specific to the instrumentation language, so be sure to consult the specific language documentation. The New Relic agents allow you to specify a custom metric name for the instrumentation. The metricName will be used to determine the aggregated metric for the component. The following example demonstrates the metricName parameter being passed to a Java agent SDK @Trace annotation. @Weave public abstract class MQOutboundMessageContext implements OutboundTransportMessageContext { @Trace(dispatcher = true, metricName=\"MQTransport\") public void send(final TransportSendListener listener) throws TransportException { try { NewRelic.getAgent().getTracedMethod().setMetricName(\"Message\", \"MQ\", \"Produce\"); MQHelper.processSendMessage(this, NewRelic.getAgent().getTracedMethod()); } catch (Exception e) { NewRelic.getAgent().getLogger().log(Level.FINE, e, \"Unable to set metadata on outgoing MQ message\"); } Weaver.callOriginal(); } } Copy Track every external service call Tip Consult the New Relic agent instrumentation and SDK guides under the language agent for your service runtime to find the details of client library instrumentation. Client instrumentation refers to encapsulating a call from your service to an external resource. Generally, New Relic agents are aware of clients popular for HTTP, gRPC, messaging, and database protocols and will apply the appropriate instrumentation pattern to aggregate calls to those clients as external services. External service dashboard details within New Relic APM. If you have written your own client handler for a protocol, or are using something very new or somewhat niche, the New Relic agent may not recognize the client and record the behavior of the client call. To this end you should verify the external services and databases within APM to represent all expected externalities for your service. Database protocol dashboard details within New Relic APM. It is important to validate that all your services' dependencies are represented here. If you do not see your service dependencies, you will need to introduce new instrumentation to intercept the external call so that your APM agent can track it accordingly. The following example demonstrates wrapping an external call in Node.js for capture by the agent. package main import ( \"net/http\" \"github.com/newrelic/go-agent/v3/newrelic\" ) func currentTransaction() *newrelic.Transaction { return nil } func main() { txn := currentTransaction() client := &http.Client{} request, _ := http.NewRequest(\"GET\", \"http://www.example.com\", nil) segment := newrelic.StartExternalSegment(txn, request) response, _ := client.Do(request) segment.Response = response segment.End() } Copy Examples of other agent API external call tracing: Go ExternalSegment Java ExternalParameters Python external_trace Endpoint testing Endpoint testing provides two benefits to your Service Instrumentation program. Defect detection: By encoding a test for an endpoint that produces a simple true/false result, it allows the operations team to isolate discrete failures to determine if the integrity of service delivery has been compromised. Baselining: Synthetic or machine tests provide a predictable set of conditions that allow you to evaluate the consistency of your service delivery from a control perspective. New Relic’s synthetic monitoring offers the ability to create a variety of testing types by employing an enhanced Selenium JavaScript SDK. Once a Selenium-based test script has been defined, New Relic will manage the location of the script execution as well as its frequency. New Relic synthetics launch dashboard. The synthetic test offers a variety of test options, each with its own focus. For more information see our synthetic monitoring documentation. From the perspective of a Service developer, the monitor type that is most frequently employed is Endpoint availability. This monitor type provides the ability to script http request conditions. These can be as simple as a POST or GET to an accessible API, or involve multiple steps where the Selenium monitoring script successively evaluates requests to ascertain functional integrity of a multi-step process. In practice, developers should consider implementing the simplest possible test to evaluate endpoint availability and integrity. For example, you have just created a new Service endpoint that provides the current exchange rate for a group of currencies. This is a simple GET at an endpoint that returns a JSON object array. Request example: http://example-ip:3000/exchange Response example: [ { \"status\": [ \"quote\" ], \"_id\": \"5b9bf97f61c22f4fb5beb5c9\", \"name\": \"cdn\", \"Created_date\": \"2021-07-12T18:10:07.488Z\", \"__v\": 1 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb2a61c22f4fb5beb5ca\", \"name\": \"usd\", \"Created_date\": \"2021-07-12T18:17:14.224Z\", \"__v\": 0.80 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb3261c22f4fb5beb5cb\", \"name\": \"eur\", \"Created_date\": \"2021-07-12T18:17:22.476Z\", \"__v\": 0.68 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb3761c22f4fb5beb5cc\", \"name\": \"mex\", \"Created_date\": \"2021-07-12T18:17:27.009Z\", \"__v\": 15.97 } ] Copy In order for this service to be considered operational, it needs to respond to requests but also provide the four currency responses. We’re not worried about the content at the moment, just the fact we get four elements back in the array one, for each CDN, USD, EUR and MEX currencies. Using New Relic synthetic monitoring, an API test script could look like the following: /** * This script checks to see if we get the currency data from the endpoint. */ var assert = require('assert'); var myQueryKey = 'secret_key'; var options = { uri: 'http://example_ip:3000/exchange', headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; function callback (err, response, body){ var data = JSON.parse(body); var info = body; if (Array.isArray(data)) { if (data.length !== 4) { assert.fail('Unexpected results in API Call, result was ' + JSON.stringify(data)); } } } $http.get(options, callback); Copy The synthetics script can be directly configured in the New Relic interface, but we highly recommend you maintain your endpoint tests within your source repository system and employ automation. This will help ensure your endpoint testing accompanies the new endpoint dependencies that your Services introduce to production service delivery. Value realization The impact of Service Instrumentation will be directly related to the level of attention you’re willing to invest in overseeing the process. Like the process of monitoring services, your Observability program will benefit through a dedicated team function that thinks critically about its expectations of return for its investment in effort. Here is some guidance to think about the cost of investment for your organization and expectation of benefit. The following section outlines an approach for estimating the investments and returns you should expect by incorporating Service Instrumentation into your Observability practice. Investments Training Ensure all developers are familiar with New Relic agent SDKs and platform capabilities. Cost Model: Dependent on your company's developer FTE model and project estimation. Estimation: Typically a number of hours for a developer to become effective using New Relic instrumentation features. Initial: 16 HRS Training / Exploration Recurring: 4 HRS/Q Review Per developer a yearly investment of 16-40 hours training to develop core skills and maintain skills currency for New Relic platform Development and maintenance The development effort required to implement and maintain instrumentation within a Service project. Cost Model: Dependent on your company's developer FTE model and project estimation. Estimation: This tends to be dependent on the scope of the project and the amount of instrumentation work required. Initial: 8 HRS per developer per service Recurring: 4 HRS/Q Maintenance Per developer a project estimation of 16-32 hours developing and maintaining Service instrumentation Returns AQM impact Alert Quality Management delivers significant benefit to the operations team by ensuring the alert notifications from variant system performance are dealt with swiftly. This improves service delivery and resource allocation during incident remediation. An effective instrumentation practice federated into your observability program will greatly improve your team’s ability to create meaningful alerts. KPIs: Volume: Incident Count Volume: Accumulated Incident Duration Volume: Mean-Time-To-Close (MTTC) User Engagement: Mean Time to Investigate Outcomes: Less alert noise Greater alert and incident responsiveness Less unknown root cause Increased operations productivity Improved service delivery Service quality improvement Improving your service quality will have a direct impact on the key financial metrics for your Service. This will require that you have a well rationalized financial model for your application. Typically this return can be projected by associating a currency value for each percent improvement on a core service quality measure like errors or apdex attainment. As your investment in Service Instrumentation increases, you should see improved attainment on your service quality measures. KPIs: Service Quality (Business KPI) Outcomes: Decreased number of user impacting errors More performant and resilient Service components Service delivery improvement By providing better telemetry from your Service instances, your delivery organization should be able to more quickly detect volatility or downtime and remediate faster. This will lead to better overall service delivery KPIs and decrease episodes of outage or degradation. Cost can be associated with the amount of time it takes to detect, investigate and remediate an incident. This might be related to the value the Service provides your organization that will be lost during an event, or may be related to the general cost to deal with the poorly behaving Service. KPIs: Mean time to detect (MTTD) Mean time to identify (MTTI) Mean time to resolve (MTTR) Outcomes: Decreased time to detect incidents Decreased time to resolve incidents",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.92868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Service characterization use case <em>implementation</em> <em>guide</em>",
        "sections": "Service characterization use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": ". Mean time to close Average duration of <em>alert</em>-driven incidents in New Relic. See <em>Alert</em> <em>Quality</em> <em>Management</em> Use Case <em>Implementation</em> <em>Guide</em> for more details. Goal: Steady decrease of incident close time for identified services. Best practices: Follow the <em>Alert</em> <em>Quality</em> <em>Management</em> Use Case <em>Implementation</em>"
      },
      "id": "6147550428ccbc5d2156a821"
    },
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "JavaScript error rate KPI",
        "HTTP error rate KPI",
        "Time to first byte KPI",
        "Core web vitals: Largest contentful paint (LCP) KPI",
        "Core web vitals: First input delay (FID) KPI",
        "Cumulative layout shift (CLS) KPI",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review Instrumented Pages",
        "Validate Browser URL Grouping",
        "Understand How You Will Segment Your Data",
        "Import the Quality Foundation Dashboard",
        "Capture Current Performance For Each Dashboard Page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to Improve",
        "Improve Targeted KPIs",
        "Improve Page Load Performance",
        "Improve AJAX Response Times",
        "Improve the AJAX Error Rate",
        "Improve Javascript Errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2021-10-12T12:55:15Z",
      "updated_at": "2021-09-18T16:34:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. Desired Outcome This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Key Performance Indicators Quality Foundation measures the following KPIs: JavaScript error rate KPI This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. HTTP error rate KPI HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Time to first byte KPI This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Core web vitals: Largest contentful paint (LCP) KPI Core Web Vitals are part of Google’s Page Experience Metrics. They measure the experience from when a page begins rendering. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Core web vitals: First input delay (FID) KPI This KPI measures the experience from when a page begins rendering. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Cumulative layout shift (CLS) KPI This KPI measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events is at least 2x an average sprint. Establish current state Review Instrumented Pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL Grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand How You Will Segment Your Data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the Quality Foundation Dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture Current Performance For Each Dashboard Page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to Improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve Targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve Page Load Performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX Response Times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX Error Rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve Javascript Errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices going forward: Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization: At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.34108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Quality</em> foundation <em>implementation</em> <em>guide</em>",
        "sections": "<em>Quality</em> foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) <em>Performance</em> (Does it <em>perform</em> well enough to be usable?) Content <em>quality</em> (Does it have what users need"
      },
      "id": "61461531e7b9d25774b6f22d"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide": [
    {
      "sections": [
        "Alert quality management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Incident volume",
        "Incident count KPI",
        "Accumulated incident duration KPI",
        "Mean time to close (MTTC) KPI",
        "Percent under 5 minutes KPI",
        "User engagement",
        "Percentage Acknowledged KPI",
        "Mean time to investigate (MTTI) KPI",
        "Prerequisites",
        "Establish current state of your KPIs",
        "Install and configure the incident event webhook",
        "Install the AQM dashboard",
        "Perform initial AQM orientation and enablement",
        "Accumulate AQM data",
        "Perform second enablement session",
        "Improvement process",
        "Value realization",
        "KPI reference",
        "Incident engagement"
      ],
      "title": "Alert quality management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Alert quality management",
        "Implementation guide"
      ],
      "external_id": "b69abb6b9b6c1257482958e12952dc189aecec2a",
      "image": "https://docs.newrelic.com/static/2be50db00a885e2d8ada51aa391f60d1/748b0/nrAQMIncidentFlow.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide/",
      "published_at": "2021-10-12T12:41:01Z",
      "updated_at": "2021-09-14T20:52:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Teams suffer from alert fatigue when they experience high alert volumes and alerts that are not aligned to business impact. As they start to believe that most alerts are false, they may prioritize easy to resolve alerts over others.  Also, they may close unresolved incidents so they can stay within their SLA targets. The result will be slower incident responses, magnified issue scope, and increased severity when true business impacting issues occur. Alert Quality Management (AQM) focuses on reducing the number of nuisance incidents so that you focus only on alerts with true business impact.  This reduces alert fatigue and ensures that you and your team focus your attention on the right places at the right times. You are a good candidate for AQM if: You have too many alerts. You have alerts that stay open for long time periods. Your alerts are not relevant. Your customers discover your issues before your monitoring tools do. You can't see the value of your observability tool(s). Desired outcome An alert strategy based on measuring business impact will result in faster response times and greater proactive awareness of critical events.  An improved alert signal to noise ratio reduces confusion and improves rapid identification and problem isolation. AQM's overall goal is to ensure that fewer, more valuable, incidents are created, resulting in: Increased uptime and availability Reduced MTTR Decreased alert volume The ability to easily identify alerts that are not valuable, so you can either make them valuable or remove them. The AQM process described in this guide generates the key performance indicators and metrics that you will use to measure progress towards these goals.  The metrics are measured in real time, published in a dashboard, and are used to drive a continuous improvement process that identifies and reduces nuisance alerts and increases user engagement in incident investigation. AQM does not encompass anomaly detection or AIOps, which are designed to detect unknown or unexpected modes of failure.  The two practices (AQM and ML/AI) work hand in hand, they are not mutually exclusive. Key performance indicators You will use the AQM process to collect and measure the following KPIs: Incident volume Incident Count Accumulated incident time Mean Time to Close (MTTC) Percent Under 5 Minutes User Engagement Mean Time to Investigate  (MTTI) % of Incidents Investigated These KPIs will help you to find the noisiest and least valuable alerts so you can improve their value or eliminate them.  You will then use the long term metric trends to show real business impact to management and stakeholders.  Detailed information on each metric follows. Incident volume You should treat incidents (with or without alerts) like a queue of tasks.  Just like a queue, the number of alerts should spend time near zero. Each incident should be a trigger for action to resolve the condition.  If an alert does not result in action, then you should question the value of the alert condition. If you see a constant rate of incidents or specific incidents that are \"always-on\", then you should question why. Are you in a constant state of business impact, or do you simply have a large volume of noise? The alert volume KPIs help you to answer those questions and to measure progress towards a healthy state of high quality alerting. Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the number of low value / nuisance incidents. Best practices: Ensure condition settings are intended to detect real business impact. Ensure condition settings are detecting abnormal behavior. Communicate that the incident details \"Acknowledge\" feature helps measure meaningful and actionable alerts. See Percentage Incident Acknowledge KPI. Report AQM KPIs to all stakeholders. Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the total accumulated minutes of incidents. Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Eliminate alerts that do not result in any remediation actions from the recipients. Improve percent investigated and mean-time-to-investigate KPIs by communicating their importance in improving detection and response times. Report AQM KPIs to all Stakeholders. Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. Goal: Reduce MTTC Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Improve Reliability Engineering skills. Report AQM KPIs to all stakeholders. Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. Goal: Minimize percentage of incidents with short durations Best practices: Ensure that conditions are detecting legitimate deviations from expected behavior. See Baselining and Service Level Management. Ensure that conditions are detecting legitimate deviations that correlate to business impact or impending business impact. User engagement You should measure the value of an incident by the amount of attention it receives.  Engagement in this context is measured by whether or not an incident has been acknowledged. The amount of engagement an individual alert receives is a direct measurement of its value.  More engagement implies a valuable alert, less (or zero) engagement implies a nuisance alert that should be modified or disabled. There is a significant difference between measuring the moment of incident awareness vs. acknowledging the moment resolution activity begins. If you are using an integration with New Relic Alerting, be sure that the \"acknowledge\" event that is sent to New Relic is triggered when resolution activity begins, not when the incident is sent to the external incident management tool.  For more information regarding the standard Incident Management process, see \"Incident Management Process: 5 Steps to Effective Resolution Posted on August 31, 2020 by OnPage Corporation. -- in reference to ITIL4\" Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. Goal: Increase the percentage of incident engagement. Best practices: Educate the DevOps team on when it is appropriate to acknowledge an incident alert. Gamify alert acknowledgement to drive usage. Discourage mass acknowledgement exercises. Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. Goal: Reduce the mean time to investigate Best practices: Work at building incident responder's confidence in alerts. Ensure that valuable alerts are acknowledged. Incentivize response teams to respond quickly to alerts. Prerequisites Before you begin, if you don't have equivalent experience, complete the New Relic University (NRU) Overview Course. Also, make sure you have a basic understanding of: NR1 Alert policy and conditions configuration NR1 incident notification channel webhook configuration NR1 NRQL NR1 alerting best practices NR1 APM & Infrastructure How to baseline data in order to determine anomalies vs. normal behavior. Establish current state of your KPIs As with any continuous improvement process, the first step of AQM is to establish the current state of your KPIs. To do so, perform the following tasks: Install and configure the incident event webhook Install the AQM Dashboard Perform initial AQM orientation and enablement Accumulate AQM data Perform second enablement session Install and configure the incident event webhook The webhook will create New Relic events for each incident as it proceeds through its lifecycle (open, acknowledge, close). To ensure that the AQM process generates accurate and valuable findings, this webhook must be added as a notification channel to every alert policy. The AQM process requires incident, not violation data. This is why you will not be using the default NrAiIncident event, which provides violation data only.  Instead, you will use this webhook to send the required incident data to New Relic. To use the webhook, do the following: Identify your primary production account and each of your accounts that you will be analyzing with the AQM process. Install the incident event webhook into each account that will participate in the AQM process and configure the webhook to report nrAQMIncident events to your primary production account. Assign the webhook as a notification channel to every alert policy in each account. This example shows a webhook notification channel assigned to each alert policy for a New Relic account with multiple sub-accounts. The webhook, AQM dashboard, and detailed installation instructions can be found in the New Relic OMA resource center on GitHub. Install the AQM dashboard The AQM dashboard is the primary asset that drives the AQM process.  You need to install the AQM dashboard into the primary production account you identified in the \"Install and configure incident event webhook\" step you previously performed by doing the following: Download the dashboard definition JSON file from the New Relic OMA resource center GitHub repo. Import the definition into your primary production account. For more details on importing dashboards, see the New Relic Introduction to dashboards documentation Perform initial AQM orientation and enablement During this phase, your incident management team(s) and other stakeholders will learn the goals of the AQM process and the scope of their involvement in it. The most critical portion of this task is educating your team on the importance of acknowledging incident alerts, since that's how the alert's value is determined.  In general, instruct them to follow these guidelines: If you look at an alert and decide to take any sort of further investigative action, acknowledge the alert. If you typically close an alert without doing anything else, do not acknowledge the alert. If the incident alert is always on, do not close or acknowledge it. For further details, see Second Enablement Session. You can use the first session template presentation to communicate this material to your stakeholders. Accumulate AQM data The overall process requires at least two weeks of data before it can proceed.  During this time, you should periodically check the following items: Confirm that incident alert event data is accumulating. Confirm that the webhook is attached to every alert policy. Ensure that incident responders are following the alert acknowledgement guidelines. Perform second enablement session During this phase, you will introduce incident management teams and other stakeholders to the initial AQM data and the ongoing continuous  improvement process you'll be following. The process consists of four activities: Review AQM Dashboard and KPI Trending - Here you and the stakeholders will look at the AQM KPIs and identify their week over week trends.  The team should identify areas where KPIs are not improving and develop strategies to drive improvement. Identify Achievements, Challenges, and Opportunities - Here you and the stakeholders will map the current state of alert quality to business impact, identifying areas where improvement has resulted in better business outcomes and areas where problems are impacting business outcomes. Incident Policy Review - Using the AQM dashboard, you and the stakeholders will identify the noisiest incident policies.  Once identified, those policies should be evaluated as detailed in step 4 below. Alert Policy Recommendations - In this step, you and the stakeholders will review the noisiest policies using the following criteria: Do the alerts have any business impact? Are the policies properly configured? Are they telling us something about the resource that needs to be fixed? Are the policies necessary? (i.e. do they have business impact) Are the thresholds set properly? Technical recommendations - Here, you and the stakeholders will review any technical recommendations, including: Are there application / system problems for engineering to review? Are there poorly constructed policies that need to be fixed? Are there instrumentation gaps? You can use the second session template presentation to keep this part of the AQM process organized. Improvement process This is the ongoing phase of the continuous improvement process where you periodically review your accumulated AQM data and make adjustments as needed to alert policies. You should perform this step once a week until your alert volume is acceptable. You can then perform it less frequently. During this phase you should: Report your KPIs each week to upper management to ensure that the stakeholder teams are appropriately prioritizing the work and to show that progress towards the promised business outcomes are being reached. Record and retain your weekly KPIs  over periods of months to years to establish a baseline and to show the rate of improvement. You should keep in mind that this is a continuous improvment process, you will continue to collect and evaluate the KPIs over long periods of time to ensure you are meeting your AQM goals. Value realization Once the AQM process is established, you will see significant reductions in the volume of alerts while reliability and stability remain the same or improve.  In addition, you should see that your alerts have a clear and unambiguous business impact.  Your AQM KPIs will provide quantifiable proof of these improvements. Once you are firmly on the path to AQM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering.  You can also move to other observability maturity value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform.  These KPIs are also included in the AQM dashboard that can be downloaded from the New Relic OMA resource center GitHub repo. Incident volume Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT count(*) AS 'Incident Count' WHERE current_state='open' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTC (minutes)' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. NRQL: FROM nrAQMIncident SELECT percentage(count(*), WHERE duration <= 5 * 60 * 100) AS '% Under 5min' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Incident engagement Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT filter(count(*), WHERE current_state='acknowledged')/filter(count(*), WHERE current_state='open')*100 AS '% Investigated' WHERE severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTI (minutes)' WHERE current_state='acknowledged' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.04645,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alert quality <em>management</em> use case <em>implementation</em> <em>guide</em>",
        "sections": "Alert quality <em>management</em> use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Uptime</em>, <em>performance</em>, <em>and</em> <em>reliability</em>",
        "body": ", and <em>Reliability</em> value stream, such as <em>Service</em> <em>Level</em> <em>Management</em>, or <em>Reliability</em> Engineering.  You can also move to other <em>observability</em> <em>maturity</em> value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from"
      },
      "id": "61372f5964441f181342436d"
    },
    {
      "sections": [
        "Service characterization use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Business KPI",
        "Service quality",
        "Release frequency",
        "Practitioner KPI",
        "Feature release frequency",
        "Mean time to close",
        "Prerequisites",
        "Establishing current state of your KPIs",
        "Determine your instrumentation needs",
        "Decision matrix",
        "Understand endpoint testing",
        "Improvement process",
        "Config based instrumentation",
        "Create an effective service name",
        "Tip",
        "Override default agent configuration",
        "Isolate service functions",
        "Define custom transaction names",
        "Capture parameters with your transactions",
        "Component measurement",
        "Ensure your frameworks are measured",
        "Track every external service call",
        "Endpoint testing",
        "Value realization",
        "Investments",
        "Training",
        "Development and maintenance",
        "Returns",
        "AQM impact",
        "Service quality improvement",
        "Service delivery improvement"
      ],
      "title": "Service characterization use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Operational efficiency",
        "Service characterization",
        "Implementation guide"
      ],
      "external_id": "6c7ba35514950d573261ef4dbc852f6b3c76433a",
      "image": "https://docs.newrelic.com/static/bd4c9daf746228eed022d0c89454469c/39c09/oma-oe-sc-service-diagram.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/operational-efficiency/sc-implementation-guide/",
      "published_at": "2021-10-12T12:16:04Z",
      "updated_at": "2021-09-19T15:19:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview \"Do I have all the telemetry I need to adequately measure my service?\" The process of onboarding a service for production monitoring tends to start from the end and work its way to the beginning. Typically a completed service is instantiated with agent based monitoring and the team responsible for service delivery needs to read the telemetry coming out of the agent like tea leaves, working their way backward to understand how the service functions by what can be observed. At New Relic, through tens of thousands of observability deployments, we have discovered that the more involved designers, architects, and developers can be in the definition of optimal service delivery measurement, the better. The emergence of the IT aphorism shift left speaks to the need to involve developers more directly in the software lifecycle activities that happen after the development stage is complete. In the case of service observability, we find there is little specific guidance on how developers can meaningfully contribute to production telemetry definitions. This guide is intended to provide practical suggestions for service developers to evaluate the state of your telemetry and suggest paths to improve it. Observability programs that closely link developer expectations with the runtime behavior of production systems are much more effective to diagnose and remediate aberrant conditions. The closer developer connection also produces services that are more robust and performant. You’re a good candidate for service characterization if any of the following are true: Your development teams are disconnected from production observability design. Your production monitoring program suffers from a lag between the introduction of new services/capabilities and their coverage with telemetry and alerting. You need to provide additional business context to your instrumentation for diagnosis and business KPI measurement. You employ a highly customized or proprietary software framework. Your service is under active development. Legacy services, and services built from commercial-off-the-shelf platforms tend to be better served with generic instrumentation options. Desired outcome This guide focuses on the metrics derived from your service’s runtime operation (its code execution) as well as external measurements of execution (through synthetic testing). Service instrumentation planning is the approach used to describe a single service runtime through telemetry. Modern monitoring systems provide deep insight into the technical details of service implementation. The power of distributed trace or bytecode instrumentation allows operations teams to quickly collect detailed service telemetry. Unfortunately, operations teams are often not in the best position to evaluate the quality of the telemetry gathered from the instrumentation. This challenge is compounded by the fact that service delivery teams are asked to implement telemetry collection for the first time in live production systems. Exposing inadequately instrumented services to production users for the purposes of refining that instrumentation creates a period that puts customer satisfaction at risk. This burn-in period often becomes difficult to escape as new features are delivered from code bases without a strong linkage between software delivery and observability programs. Key performance indicators By having your development staff involved in improving your service instrumentation, you should realize observability benefits in the following ways. Better informed development decisions: By detecting areas of volatility or unexpected behavior and addressing them. By understanding what dependencies in your code lack redundancy or robustness, and taking measures to refactor the service. By appreciating how end-user cohorts are employing your software, you can better understand where improvements will have the biggest impact. Improved troubleshooting: More precise and contextually relevant telemetry from your service will allow for more accurate and actionable detection of faults. With better telemetry naming, operations staff can use a common language with developers during incidents, reducing the time to triage and remediate incidents. With these goals in mind, it is important to identify some simple KPIs that help to gauge the ongoing improvements in your software delivery and operations programs. The following outlines some suggested KPIs to consider as you invest in improved instrumentation. Business KPIs are aligned to your overall program objectives and should be consistently measured to demonstrate ongoing program improvement for each service. Practitioner KPIs are used to measure changes in the execution of job functions for those participating in the development and management of services. Business KPI Service quality A metric is required to define how well your service is operating. This will depend upon the needs of your organization and the constraints of the services being monitored. Goal: Improved service quality attainment score over time. Best practices: Create a graphical representation as a trend of Service Quality achievement for defined periods (Monthly / Quarterly). Service Apdex can provide an effective Service specific quality score. (See Apdex: Measure user satisfaction.) A well defined Service Level Management (SLM) approach using SLIs that describe the level of expected operation for service boundaries can be a useful way to establish a single measurement of quality. Release frequency The number of releases for a given service. This should indicate the velocity of the software delivery organization. Often release frequency isn’t immediately comparable between development organizations. Instead, weighting high-value releases or features to bugs can provide an improved comparative context. Goal: Consistency of attainment with consistent or improving Service Quality indicator. Best practices: Can be derived from deployment markers or other events sent to New Relic. Measure directly from code or project management tools such as Jira, BitBucket, GitHub. Consider implementing a collection mechanism to capture release events and store them directly in New Relic. See NR1 CICD Innovation for example JIRA and BitBucket configs. Practitioner KPI Feature release frequency Quantification of the percentage of releases that are directly related to new feature development versus bug fixes or technical debt retirement. The relationship to feature to fix will vary between teams and projects based on the history of the service. Goal: A consistent or improving feature release frequency consistent with the service delivery goals. Best practices: Practitioner feature release frequency is often acquired in the same manner as the broader release frequency business KPI. This metric is then made available to the development team for the service. Mean time to close Average duration of alert-driven incidents in New Relic. See Alert Quality Management Use Case Implementation Guide for more details. Goal: Steady decrease of incident close time for identified services. Best practices: Follow the Alert Quality Management Use Case Implementation Guide, understanding Service behavior through the lens of the alerts defined to help improve service delivery. Prerequisites Before you begin to introduce Service Instrumentation into your development processes, be sure to acquaint yourself with New Relic fundamentals available from New Relic University. In addition to NRU training, review and keep the following documentation resources handy: APM agent install and configuration Instrumentation guides: C-SDK Go Java .NET Node.js PHP Python Ruby OpenTelemetry SDKs Introduction to New Relic synthetic monitoring Establishing current state of your KPIs Determine your instrumentation needs Instrumentation is the process to acquire telemetry from a software system and its associated services for the purpose of describing that software system's runtime behavior and business function. Monitoring systems tend to provide generic capabilities for telemetry acquisition that can be fine tuned to close gaps when monitoring the function of a software system. This use case assumes that your Observability Program has completed the Quality Foundation OMA use case implementation guide and that you have a well considered and deployed telemetry collection architecture for your services. With the possible exception of alert definition, instrumentation offers the most open-ended and customizable activities related to observability. The New Relic One platform provides features to highly customize your use of instrumentation. Because of this, you should carefully consider the amount of time and effort you’re going to put into instrumenting your services. Like all Service Instrumentation assets and dependencies, the introduction of instrumentation will require ongoing oversight and maintenance and therefore is a form of technical debt you will accrue for your project. As you begin the process of instrumentation, you want to continually ask yourself the question: Is the visibility I will gain from this instrumentation worth the cost of implementation and support? Decision matrix As a first step you should evaluate the default instrumentation you obtain from your Observability platform and ask yourself the question: Does the telemetry adequately describe the function and the purpose of my service? For example, think about what your service does. Perhaps it receives an order, needs to validate the order for integrity, conveys that order to a clearinghouse service, and receives a confirmation code that is relayed back to the requestor. This example gives a clear path to break down the function of service and evaluate if we have enough telemetry and context to make informed appraisals of how the service is functioning. Conceptual service that receives and processes http requests. If this conceptual diagram represents the implementation of the service, you will want to know answers to the following questions, at any given moment in time: How many requests do I receive? How many messages and HTTP requests do I send? How many requests are successful? What is the response time for a full request? What is the response time for invocation to a dependency? How much resource should this process take under what number of requests? What are all my points of failure? Most monitoring frameworks for application runtimes will gather telemetry like this as basic functionality. However, sometimes specific implementation of your service will pose a challenge to the generic instrumentation assumptions made by the monitoring software. In this case your Observability platform will need to accommodate your needs and provide an ability to modify a default monitoring configuration. The following table documents some additional situations where you would consider adding additional telemetry or metadata capture through instrumentation. The practices section that follows describes how to close those gaps to ensure your observability platform provides telemetry needed to manage your service. Considerations for instrumentation: Are my base telemetry requirements satisfied? If not, document the gaps and evaluate if they can be closed through custom configuration or additional instrumentation techniques. Can I isolate discrete user stories within the telemetry? If not, use trace capabilities of agents to capture the invocation of a discrete user story with adequate context metadata. Do I have insight into the parameters that are invoking user stories? If not, use custom attributes through agent SDKs to add context to the transactions and spans. Can I measure the major functional components of the software? If not, use instrumentation SDKs to create baseline metrics on a specific functional element of the code. (cache lookups, processing routines, or utility functions). Can I measure the client interactions from my code to external systems? If not, ensure requests and responses are encapsulated by component level tracking. If the client invocation is asynchronous, consider implementing distributed trace features to view the successive processing. Understand endpoint testing Endpoint testing is a simple and practical approach that greatly expedites how to determine the root cause of a given system failure. It allows operations and supporting teams to quickly know there is a real problem, and isolate that problem to a specific service. Modern software systems depend on a number of services to complete their tasks. Historically, the process of monitoring those service endpoints was straightforward. The architecture team would produce a well documented map of dependencies for the operations team. The operations team would dutifully create a check of the itemized endpoints. Today, with continuous delivery processes and small batch changes, new endpoints and dependencies can be created and deployed at a rate that makes it difficult for an operations team to anticipate and proactively define synthetic checks. By giving the service developers greater scope of control to define production services tests during the development phase, you will greatly increase the coverage of endpoint tests for your Observability program. Decision matrix To determine whether to create a synthetic check is straightforward. Generally you will want to know the first occurrence of a failure for a dependency. If you answer “yes” to any of the following questions, consider creating a dedicated synthetic check. Is the end point customer facing? Does the endpoint invoke new dependencies? Is the endpoint on a different network infrastructure? Is the endpoint shared between multiple services? Is the endpoint a content origin supported by a CDN? Improvement process Config based instrumentation Each New Relic agent provides a variety of configuration options. Typically you will define a standard approach to include the agents within infrastructure hosts, application runtimes, and connections to your cloud service providers. Default agent configurations are generic and widely applicable. One of the best ways for developers to influence the applicability of deployment is by overriding the default configuration options for your service instance. The following are default instrumentation options to consider. Create an effective service name Tip New Relic agents provide a variety of mechanisms to define the Service runtime name. Please see the application naming guide to find the implementation details for your runtime environment. The name you give a service provides the namespace (where you will find the agent data). One of the most important strategies New Relic uses to understand the behavior of your services is to aggregate like things together and to use the commonalities derived from aggregation to isolate variance. Modern services are often deployed to multiple contexts to ensure capacity handling or specific functional segmentation. In order to take advantage of the benefits of aggregation, it is very important that your service runtimes are grouping instances with identical operational characteristics. Therefore, when deploying services, pay close attention to the following three criteria to help you name your deployed services: Does my service target a specific audience? Is my service running a different codebase? Is my codebase using a different runtime configuration? If you answer “yes” to any of these questions, consider creating a unique name for your service. Audience criteria Think of the audience as the group of end users or service functions. If your service is split between North American and European deployments, the runtimes in those deployments should be grouped accordingly. For example: newrelic.appname = PORTAL_AMER Copy and newrelic.appname = PORTAL_EMEA Copy This will group the telemetry created by that audience together, allowing you to better understand the contextual similarities of service problems related to a specific user audience. Sometimes the way we deploy applications divides the operational context of a service, such as a portal application with administrative functions. Maybe the admin functions are baked into the general portal codebase, but only one instance in a cluster is handling the portal admin requests. In that case you have a functional audience segmentation opportunity, so you should ensure that it is named appropriately. For example: newrelic.appname = PORTAL_MAIN Copy and newrelic.appname = PORTAL_ADMIN Copy Codebase criteria If you’re running different code versions under the guise of one service, consider segmenting those runtime instances and incorporating version naming as part of your naming scheme. When you group code together as one service name that is executing different service versions, you’re increasing the noise to signal ratio of any metrics you produce. Different code versions might use different amounts of compute resource or process data differently. It becomes very difficult to determine if a service is behaving normally when the signals you get from the metrics are due to different functional implementations. Consider adding a numeric identifier to the service name if you have multiple versions running concurrently. For example: newrelic.appname = PORTAL_MAIN_V112 Copy and newrelic.appname = PORTAL_MAIN_V115 Copy If you employ feature flag framework frameworks like LaunchDarkly or Split, you may have multiple versions of an application or service within a single codebase. Please consult the Isolating Service Functions section to address those conditions. Runtime criteria If an instance of a service is deployed to a system with different runtime constraints, it should be encapsulated in its own telemetry namespace. This can be a deployment to a different datacenter that offers network connectivity advantages to a shared resource, or perhaps the service is running on a separate compute tier with a different memory or thread configuration. These characteristics that affect the code runtime operation can cause different behaviors that lead to different operations behaviors. For example: newrelic.appname = PORTAL_NYC_DC Copy and newrelic.appname = PORTAL_REALLY_BIG_FOOTPRINT Copy Override default agent configuration Tip The New Relic agents provide a variety of options for runtime configuration. Please refer to the agent configuration guide for the options specific to your runtime. Each New Relic APM agent provides a variety of options to modify the default configuration. The most comprehensive and consistent location is the configuration file that accompanies each agent install. However, New Relic agents can also be configured by passing command line parameters directly to the service instance runtime, by using environment variables, or by calling functions within the agent's SDK at runtime. .NET agent configuration options: Using the New Relic .NET SDK API Environment variables Config file options Isolate service functions As the Create an effective service name section indicated, one of the primary objectives of instrumentation is to configure the New Relic agent to group like runtime constraints together as a single named unit. We suggest this because software systems should behave in deterministic ways. For a specific set of inputs, you should get an expected range of measurable outcomes. The degree to which we can comfortably contain these constraints into named service runtime components greatly helps us understand normal behavior and isolate aberrant behavior. Once you have settled on an effective service naming strategy, the next step is to look within the telemetry collected for the service and determine if it suitably isolates the service’s functionality. The implementation pattern we most often encounter is a series of functions being invoked by a web request. The initial receipt and handling of a web request to a service runtime results in the allocation of processing resources. New Relic defines this resource allocation and code execution as a transaction. The New Relic agent is configured with a set of assumptions that create namespaces for transactions as they are detected. Those assumptions differ between the agent language runtime. For example, a good example of how the New Relic Java agent determines the transaction name can be found in the Java agent's transaction naming documentation. However, even after the agent transaction naming protocol has been applied, it may leave you with an unsatisfactory result. By adding additional instrumentation to name the transaction to improve its context, this can greatly improve your understanding of the service’s execution behavior. The goal for transaction naming should be an APM transactions view that provides good segmentation of the services functions in an approach that is easy to understand for a non-developer. New Relic service transaction breakdown view. The transaction breakdown image is a good example of transaction segmentation. It provides detailed tracking of the amount of work being done by each transaction within the broader codebase of the service. It also displays the transaction with a plain user-friendly name that offers some hint of its business context (what the transaction does). As you learn more about naming transactions and including attributes, be sure to make your naming approach accessible for non-technical observers of the data. Transaction breakdown: the transactions in this service seem to be highly weighted to one transaction name with a pretty generic name. Breakdowns like this beg the question: \"Is this a good representation of the work my service does?\" The obtuse transaction breakdown image demonstrates a bad example of transaction name segmentation. In this case we have about 60% of the transaction volume being named OperationHandler/handle. Both the percentage attribution of the transaction volume and the generic nature of the name indicate there might be an overly zealous aggregation of transactions underneath that transaction namespace. A good way to validate your transaction naming approach is to review the distribution of response times for your transaction over a significant period of time in the service web transaction histogram dashboard. The service transaction histogram view shows the count of transactions that fall into each response time bucket. A good naming strategy tends to display a normal distribution. The service transaction image shows a wide range of transaction response rates. Although the bulk of the transactions land in the 0-200 millisecond range, it indicates values ranging from 200-1000 milliseconds. When you have a highly distributed range of responses for a transaction, you should ask yourself: What information do I have during the transaction execution that can help me name this transaction? In many cases, non-normal distributions are a direct result of the parameters being passed to a request, or the work the transaction is being asked to do. It is pretty easy to consider that a service query transaction might take a data range as a parameter. The date range when small might provide a faster lookup time. Therefore, perhaps providing a meaning scheme that is derived from some expected parameter constraints (> 1day, 1-5 days, >5 days) might provide a more meaningful segmentation. Your objective is to create a transaction name that facilitates grouping transactions with the fewest unique characteristics. A more normal distribution of transaction segmentation where individual transactions report more consistent response time attainment with fewer exceptions. The normal distribution image demonstrates more purposefully named transactions within a service. In this case the web transaction response times are more closely grouped, indicating consistent execution characteristics. By ensuring your transaction naming strategy provides a consistent mechanism to group your service’s functions by the types of operations they are performing, you will be able to quickly isolate aberrant behavior, or better understand the root cause of the variations. This will allow you to refactor your application and increase the overall predictability of your service’s functions. Define custom transaction names Tip Consult the New Relic agent API guide for your language agent to review the transaction naming procedure for your runtime. The New Relic agent transaction naming service requires the invocation of a SetName(String name) like API call to the New Relic agent SDK. Each language runtime agent has its own syntax and option for setting the name. For example, to take the value of an http request parameter and use it to name a transaction in the New Relic Java agent, you can use code similar to this: com.newrelic.agent.Agent.LOG.finer(\"[my query handler] Renaming transaction based on an important query parameter\"); com.newrelic.api.agent.NewRelic.setTransactionName(\"Query Handler_\" + (javax.servlet.http.HttpServletRequest)_servletrequest_0).getParameter(\"important_query_parm\")); Copy Please note: There is a maximum capacity to transaction names within New Relic. Your transaction naming strategy will have to trade off a degree of specificity if there are thousands of potential transaction names. When too many transaction names are being reported, New Relic will attempt to create rules to group those transaction names. More details can be found in the agent troubleshooting guide related to metric grouping issues. Should you suspect a metric grouping issue, open a support case with New Relic, and we will be happy to work with you to isolate the cause of the transaction naming issue. Capture parameters with your transactions Tip Consult the New Relic agent custom attributes guide for your agent language to review the metadata enhancement options for attribute customization. The transaction name is a powerful way for you to segment your Service’s functionality so that you can better understand its behavior. This allows you to discretely isolate functionality directly in the New Relic UI. However, there are many occasions when you will want to get some additional context on the function of your Service without resorting to isolating the transaction name. This can be accomplished by introducing attribute capture by your Service. You can add name:value pair attributes to decorate the details of each transaction. The attributes will be available in each transaction event through the APM transaction trace and errors UI, or through direct query of parameters from the NRDB transaction event type. After you select a transaction trace, you can view the custom attributes you have set for your Service’s transaction. Here is an example of the transaction trace details you can see in the APM errors UI. Custom attributes displayed in the APM errors UI. If you have developed a useful transaction name segmentation, you can use the additional context of the attributes to better understand the inputs, cohorts, or segments that led to an unexpected result. In addition to being able to understand the context of your transaction within the APM UI, the introduction of parameters is an extremely useful tool to aggregate and analyze transactions by querying transaction data directly. Custom attributes are added to each transaction, making it easy to isolate and facet on specific conditions. NRQL query expression that uses a custom attribute to facet database call duration. The parameter capture approach can also be used with feature flag systems like Split or LaunchDarkly. In this case, as you are implementing the decision handler for the feature flag, consider capturing the flag context (for example, optimized_version = on) that is being applied to the block of code controlling the version or feature the customer sees. NRQL query that demonstrates the result when the state of a feature flag is captured by a transaction custom attribute. The feature flag state attribute allows us to understand the impact of the code execution path on performance, throughput, and dependency utilization. For example, to take the value of an http request parameter and save it as a custom attribute in the New Relic Java agent, you can use code similar to this: com.newrelic.agent.Agent.LOG.finer(\"[my query handler] Adding an Attribute to transaction based on an important query parameter\"); com.newrelic.api.agent.NewRelic.addCustomParameter(\"ImportantParm\", (javax.servlet.http.HttpServletRequest)_servletrequest_0).getParameter(\"important_query_parm\")); Copy Component measurement The behavior of a specific transaction within the context of a service is a powerful way to segregate functionality and ensure a software system is operating effectively. However, another way to look at the behavior of a software system is to review the detailed component execution model of its implementation. The application framework code components are shared throughout the service, and the ongoing evaluation of component performance can provide an insight into the overall service health. Within New Relic One there are two places we can observe component execution details. The service summary dashboard in APM provides a view of the composite execution of the service broken down by its component parts (for example, garbage collection execution or database calls). This summary dashboard provides a breakdown of major component types within the application. Memcached, External Web Invocations, MySQL and Dirac are all examples of shared code frameworks that the collective transactions of the Service are using to execute their business logic. A similar breakdown is provided on a transaction by transaction basis. This single transaction summary view breaks out the contributing execution time by component. This helps you see the aggregate performance of components within a transaction. Transaction component segments will tend to demonstrate consistent performance behavior, you can use this consistency to detect a change in its fundamental behavior. This can be a good indication of an underlying issue. Resource constraints tend to manifest more obviously within component frameworks than within individual transaction details. This allows you to infer characteristics of dependencies through the common constraints being experienced by all code running within a service. Ensure your frameworks are measured Tip Consult the New Relic agent instrumentation and SDK guides under the language agent for your service runtime to find information about adding metric names to your instrumentation. The syntax for framework instrustrumentation is specific to the language your service is written in, but the general approach is consistent for all. Consider the threads of execution within your Services as an analogy for transactions within New Relic telemetry. Each method or function execution on the stack is an opportunity to add additional instrumentation. In this way New Relic maintains a time-annotated invocation stack for the transaction and uses those method/function start/stop timings to aggregate it into a series of component metrics. A simple Node.js application making a call to a MongoDB. The two major components of the application are the receipt of the request and get/put operations to the MongoDB. If a particular segment of logic is crucial to the function of your Service or transaction, consider wrapping that call with callbacks to the New Relic agent so that the agent can understand that it has entered a discrete code component and can aggregate the time consumed within that component accordingly. By passing a metric name to the callback, you will create a component segment metric for your service and transaction. The metric naming option is specific to the instrumentation language, so be sure to consult the specific language documentation. The New Relic agents allow you to specify a custom metric name for the instrumentation. The metricName will be used to determine the aggregated metric for the component. The following example demonstrates the metricName parameter being passed to a Java agent SDK @Trace annotation. @Weave public abstract class MQOutboundMessageContext implements OutboundTransportMessageContext { @Trace(dispatcher = true, metricName=\"MQTransport\") public void send(final TransportSendListener listener) throws TransportException { try { NewRelic.getAgent().getTracedMethod().setMetricName(\"Message\", \"MQ\", \"Produce\"); MQHelper.processSendMessage(this, NewRelic.getAgent().getTracedMethod()); } catch (Exception e) { NewRelic.getAgent().getLogger().log(Level.FINE, e, \"Unable to set metadata on outgoing MQ message\"); } Weaver.callOriginal(); } } Copy Track every external service call Tip Consult the New Relic agent instrumentation and SDK guides under the language agent for your service runtime to find the details of client library instrumentation. Client instrumentation refers to encapsulating a call from your service to an external resource. Generally, New Relic agents are aware of clients popular for HTTP, gRPC, messaging, and database protocols and will apply the appropriate instrumentation pattern to aggregate calls to those clients as external services. External service dashboard details within New Relic APM. If you have written your own client handler for a protocol, or are using something very new or somewhat niche, the New Relic agent may not recognize the client and record the behavior of the client call. To this end you should verify the external services and databases within APM to represent all expected externalities for your service. Database protocol dashboard details within New Relic APM. It is important to validate that all your services' dependencies are represented here. If you do not see your service dependencies, you will need to introduce new instrumentation to intercept the external call so that your APM agent can track it accordingly. The following example demonstrates wrapping an external call in Node.js for capture by the agent. package main import ( \"net/http\" \"github.com/newrelic/go-agent/v3/newrelic\" ) func currentTransaction() *newrelic.Transaction { return nil } func main() { txn := currentTransaction() client := &http.Client{} request, _ := http.NewRequest(\"GET\", \"http://www.example.com\", nil) segment := newrelic.StartExternalSegment(txn, request) response, _ := client.Do(request) segment.Response = response segment.End() } Copy Examples of other agent API external call tracing: Go ExternalSegment Java ExternalParameters Python external_trace Endpoint testing Endpoint testing provides two benefits to your Service Instrumentation program. Defect detection: By encoding a test for an endpoint that produces a simple true/false result, it allows the operations team to isolate discrete failures to determine if the integrity of service delivery has been compromised. Baselining: Synthetic or machine tests provide a predictable set of conditions that allow you to evaluate the consistency of your service delivery from a control perspective. New Relic’s synthetic monitoring offers the ability to create a variety of testing types by employing an enhanced Selenium JavaScript SDK. Once a Selenium-based test script has been defined, New Relic will manage the location of the script execution as well as its frequency. New Relic synthetics launch dashboard. The synthetic test offers a variety of test options, each with its own focus. For more information see our synthetic monitoring documentation. From the perspective of a Service developer, the monitor type that is most frequently employed is Endpoint availability. This monitor type provides the ability to script http request conditions. These can be as simple as a POST or GET to an accessible API, or involve multiple steps where the Selenium monitoring script successively evaluates requests to ascertain functional integrity of a multi-step process. In practice, developers should consider implementing the simplest possible test to evaluate endpoint availability and integrity. For example, you have just created a new Service endpoint that provides the current exchange rate for a group of currencies. This is a simple GET at an endpoint that returns a JSON object array. Request example: http://example-ip:3000/exchange Response example: [ { \"status\": [ \"quote\" ], \"_id\": \"5b9bf97f61c22f4fb5beb5c9\", \"name\": \"cdn\", \"Created_date\": \"2021-07-12T18:10:07.488Z\", \"__v\": 1 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb2a61c22f4fb5beb5ca\", \"name\": \"usd\", \"Created_date\": \"2021-07-12T18:17:14.224Z\", \"__v\": 0.80 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb3261c22f4fb5beb5cb\", \"name\": \"eur\", \"Created_date\": \"2021-07-12T18:17:22.476Z\", \"__v\": 0.68 }, { \"status\": [ \"quote\" ], \"_id\": \"5b9bfb3761c22f4fb5beb5cc\", \"name\": \"mex\", \"Created_date\": \"2021-07-12T18:17:27.009Z\", \"__v\": 15.97 } ] Copy In order for this service to be considered operational, it needs to respond to requests but also provide the four currency responses. We’re not worried about the content at the moment, just the fact we get four elements back in the array one, for each CDN, USD, EUR and MEX currencies. Using New Relic synthetic monitoring, an API test script could look like the following: /** * This script checks to see if we get the currency data from the endpoint. */ var assert = require('assert'); var myQueryKey = 'secret_key'; var options = { uri: 'http://example_ip:3000/exchange', headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; function callback (err, response, body){ var data = JSON.parse(body); var info = body; if (Array.isArray(data)) { if (data.length !== 4) { assert.fail('Unexpected results in API Call, result was ' + JSON.stringify(data)); } } } $http.get(options, callback); Copy The synthetics script can be directly configured in the New Relic interface, but we highly recommend you maintain your endpoint tests within your source repository system and employ automation. This will help ensure your endpoint testing accompanies the new endpoint dependencies that your Services introduce to production service delivery. Value realization The impact of Service Instrumentation will be directly related to the level of attention you’re willing to invest in overseeing the process. Like the process of monitoring services, your Observability program will benefit through a dedicated team function that thinks critically about its expectations of return for its investment in effort. Here is some guidance to think about the cost of investment for your organization and expectation of benefit. The following section outlines an approach for estimating the investments and returns you should expect by incorporating Service Instrumentation into your Observability practice. Investments Training Ensure all developers are familiar with New Relic agent SDKs and platform capabilities. Cost Model: Dependent on your company's developer FTE model and project estimation. Estimation: Typically a number of hours for a developer to become effective using New Relic instrumentation features. Initial: 16 HRS Training / Exploration Recurring: 4 HRS/Q Review Per developer a yearly investment of 16-40 hours training to develop core skills and maintain skills currency for New Relic platform Development and maintenance The development effort required to implement and maintain instrumentation within a Service project. Cost Model: Dependent on your company's developer FTE model and project estimation. Estimation: This tends to be dependent on the scope of the project and the amount of instrumentation work required. Initial: 8 HRS per developer per service Recurring: 4 HRS/Q Maintenance Per developer a project estimation of 16-32 hours developing and maintaining Service instrumentation Returns AQM impact Alert Quality Management delivers significant benefit to the operations team by ensuring the alert notifications from variant system performance are dealt with swiftly. This improves service delivery and resource allocation during incident remediation. An effective instrumentation practice federated into your observability program will greatly improve your team’s ability to create meaningful alerts. KPIs: Volume: Incident Count Volume: Accumulated Incident Duration Volume: Mean-Time-To-Close (MTTC) User Engagement: Mean Time to Investigate Outcomes: Less alert noise Greater alert and incident responsiveness Less unknown root cause Increased operations productivity Improved service delivery Service quality improvement Improving your service quality will have a direct impact on the key financial metrics for your Service. This will require that you have a well rationalized financial model for your application. Typically this return can be projected by associating a currency value for each percent improvement on a core service quality measure like errors or apdex attainment. As your investment in Service Instrumentation increases, you should see improved attainment on your service quality measures. KPIs: Service Quality (Business KPI) Outcomes: Decreased number of user impacting errors More performant and resilient Service components Service delivery improvement By providing better telemetry from your Service instances, your delivery organization should be able to more quickly detect volatility or downtime and remediate faster. This will lead to better overall service delivery KPIs and decrease episodes of outage or degradation. Cost can be associated with the amount of time it takes to detect, investigate and remediate an incident. This might be related to the value the Service provides your organization that will be lost during an event, or may be related to the general cost to deal with the poorly behaving Service. KPIs: Mean time to detect (MTTD) Mean time to identify (MTTI) Mean time to resolve (MTTR) Outcomes: Decreased time to detect incidents Decreased time to resolve incidents",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.50436,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Service</em> characterization use case <em>implementation</em> <em>guide</em>",
        "sections": "<em>Service</em> characterization use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " is complete. In the case of <em>service</em> <em>observability</em>, we find there is little specific guidance on how developers can meaningfully contribute to production telemetry definitions. This <em>guide</em> is intended to provide practical suggestions for <em>service</em> developers to evaluate the state of your telemetry and suggest"
      },
      "id": "6147550428ccbc5d2156a821"
    },
    {
      "sections": [
        "Improve page load performance",
        "Page Load KPI",
        "Cumulative Layout Shift (CLS)",
        "Largest Contentful Paint (LCP)",
        "First Input Delay (FID)"
      ],
      "title": "Improve page load performance",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Core web vitals",
        "Page load",
        "Page render"
      ],
      "external_id": "a6c3e400d5c99451f900a3edee1fa19149b5f82c",
      "image": "https://docs.newrelic.com/static/a73f684466bda769a52da48dc9a4e4cc/d9199/cx_page_load_render_timings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load/",
      "published_at": "2021-10-12T12:54:02Z",
      "updated_at": "2021-09-07T09:17:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user experience, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying to improve. For maximum impact, focus on pages that are frequently accessed but have a lower than accepted score for the 75th percentile of users. Page Load KPI How to improve time to first byte (TTFB): Time to first byte measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. If users in the 75th percentile are experiencing a TTFB of greater than 0.5s for one or more of your pages, you can break timings down further by querying the following attributes in PageView: backendDuration connectionSetupDuration dnsLookupDuration networkDuration Frequently slowness prior to rendering is caused by slowness in the backend, either from third party APIs or backend applications. Synthetics monitoring for third party APIs helps operations and development teams understand when the root cause is outside of their control. Even if you cannot control the code, you can influence the outcome by sharing synthetics results with the third party to help them understand what your customers are experiencing. If the backend applications are owned by you or your team, you can use APM agents, Pixie, or OpenTelemetry to understand and manage performance. To make cross team communication easier, we recommend implementing Service Level Management boundaries. Cumulative Layout Shift (CLS) Cumulative layout shift is a score that indicates how much content shifts once it has already loaded. General tips and tricks for improving CLS: Specify dimensions for stylesheets and let the browser’s default CSS control the aspect ratio. Statically reserve space for ad slots. Avoid ads near the top of the viewport. Avoid inserting new content above existing content. Precompute sufficient space for embeds. Additional resources: Google’s approach to CLS optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. Largest Contentful Paint (LCP) Largest contentful paint measures the difference between the start of page render until the time to paint the largest content element. Common causes for a slow lcp, according to web.dev: Slow server response times Render-blocking JavaScript and CSS Slow resource load times Client-side rendering Use Browser session trace information to understand which of the common causes above factor into the particular page you are trying to optimize. Approaches to improve LCP: Making use of CDNs and paying attention to caching and edge server performance Establishing third party connections early Delaying non-critical Javascript and CSS Additional resources: Google’s approach to LCP optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. First Input Delay (FID) First input delay is the time between when a user first interacts with a page to the time when the browser is able to respond. It’s a field metric that varies based on real user behavior (results vary based on user impatience and action timing) but can be optimized by reducing TBT, total blocking time. To do this, you need to: Break up long blocking tasks. Optimize bloated JavaScript. Look at moving logic server side and/or use web workers to run threads in the background. Use Browser session trace information to understand where your blocking intervals are occurring and for how long they last. Additional resources: Google’s approach to FID optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.86205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Improve page load <em>performance</em>",
        "sections": "Improve page load <em>performance</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " and manage <em>performance</em>. To make cross team communication easier, we recommend implementing <em>Service</em> <em>Level</em> <em>Management</em> boundaries. Cumulative Layout Shift (CLS) Cumulative layout shift is a score that indicates how much content shifts once it has already loaded. General tips and tricks for improving CLS"
      },
      "id": "61372e19196a67f4814948d7"
    }
  ]
}