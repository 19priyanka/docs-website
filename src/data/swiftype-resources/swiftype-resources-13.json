{
  "/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan": [
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-09-20T23:24:40Z",
      "updated_at": "2021-08-08T23:13:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as February 19, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to New Relic Full Stack Observability Pro or Enterprise Products, you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the New Relic Full Stack Observability Pro or Enterprise Products. If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make New Relic Full Stack Observability Standard and Telemetry Data Platform available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users (Full Stack Observability), New Relic provides an updated support plan commitment. By subscribing to New Relic One Users (Full Stack Observability), you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the New Relic One - Standard User (Full Stack Observability Standard) Product, you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie, is subject to their own terms of service. For clarity, such other platforms do not form part of the New Relic One offering and New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.6756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One <em>usage</em> <em>plan</em> descriptions",
        "sections": "New Relic One <em>usage</em> <em>plan</em> descriptions",
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing <em>plan</em>. For an explanation of how that <em>plan</em> works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The <em>Usage</em> <em>Plan</em> applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    },
    {
      "sections": [
        "Security policy",
        "New Relic Security Policy",
        "1. Purpose",
        "2. Security Overview",
        "3.Security Certifications",
        "4. Data Control and Encryption",
        "5. Facilities",
        "6. Employee Access, Screening and Controls.",
        "7. Security Incident and Data Breach Response",
        "8. Network and Systems Security",
        "9. Authentication and Access Management",
        "10. Vulnerability Management",
        "11. System Access and Logging",
        "12. Disaster Recovery and Data Backup",
        "13. Copies and Removal",
        "14. Third Party Vendor Management",
        "15. Disclosure by Law",
        "16. Updates"
      ],
      "title": "Security policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "291509f6b521ca34ac9d49039518e7da8b883518",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/",
      "published_at": "2021-09-20T19:36:40Z",
      "updated_at": "2021-09-20T19:36:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Updated 16 September 2021. The below Security Policy applies only to customers with an existing New Relic agreement in place that explicitly references this Security Policy applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic Security Policy 1. Purpose This Policy describes New Relic's security program and the technical and organizational security controls to protect New Relic’s systems as shown in New Relic’s third-party audits and certifications. New Relic may update this Policy from time to time, and such updates will not materially reduce the overall protections set forth in this Policy. The then-current terms of this Policy are available at https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/. 2. Security Overview 2.1. New Relic maintains a comprehensive Information Protection Program to manage information security within New Relic that includes administrative, technical, and physical safeguards designed to protect the confidentiality, integrity, and availability of Customer Data and that is appropriate to the nature, size, and complexity of New Relic's business operations. New Relic’s Information Protection Program includes: 2.1.1. executive review, support and accountability for all security related policies and practices; 2.1.2. formal written policies and procedures that are designed to protect against the loss, theft, or other unauthorized access or alteration of Customer Data, meet or exceed applicable industry standards, outlines a definition of information security and its overall objectives, include defined information security roles and responsibilities, a framework for setting control objectives and controls, a formal and effective risk mitigation program and a service provider security management program; 2.1.3. periodic risk assessments, including internal audits and/or independent 3rd party audits, to measure the effectiveness and appropriateness of controls for all systems processing Customer Data; 2.1.4. in-depth review of security incidents, including effective determination of root cause and corrective action; formal, industry-recognized controls frameworks based on an external audit standard; 2.1.5. employee screening and access management; and 2.1.6. comprehensive security testing, vulnerability identification, and mitigation methodology that consists of a variety of independent approaches that, when combined, are designed to maximize coverage for a diverse set of attack vectors. 2.2. New Relic's Chief Information Security Officer (CISO) leads New Relic's Information Security Program and develops, reviews, and approves, with appropriate stakeholders, New Relic's security policies and procedures. New Relic has appointed data protection officer(s) as described in New Relic’s Privacy Notices who are consulted as necessary under applicable laws. 2.3. Information security objectives, approach, scope, importance, goals, and principles for the organization’s security program are formally identified, communicated throughout the organization to users in a form that is relevant, accessible, and understandable to the intended reader; and supported by a controls framework that considers legislative, regulatory, contractual requirements, and other policy-related requirements. 2.4. New Relic will maintain written policies and procedures to review, test, and approve (as appropriate) changes affecting New Relic infrastructure and systems that process Customer Data including, but not limited to, peer reviews prior to introducing new code into production. New Relic will establish acceptance criteria for new information systems, upgrades, and new versions and will carry out suitable tests of the system(s) during development and prior to acceptance. Any changes or updates will not materially decrease the security of the systems. 3.Security Certifications 3.1. New Relic regularly tests, assesses, and evaluates its security measures for protecting Customer Data using industry-recognized standards and uses independent third-party auditors to verify such controls. 3.2. New Relic agrees to provide Customer, upon request, with applicable certifications or reports about New Relic systems. All information exchanged in connection with the audit activities described in this section is deemed to be the Confidential Information of New Relic. 3.3. Additional information about New Relic’s security certifications are available on New Relic’s Security Guide. 4. Data Control and Encryption 4.1. The Service and related features are designed to provide Customer with control over Customer’s data sources and Customer’s environments that are monitored and sending data to New Relic. 4.2. New Relic will have established methods to: (i) enable Customer to use encyrption on Customer Data in transit, and (ii) securely hash passwords in storage following industry standard practices (e.g. scrypt) as described in the Documentation. Server certificate-based authentication is used as part of the TLS encryption with a trusted certificate authority. 4.3. New Relic receives and processes data in accordance with the Agreement and the Services as described in the Documentation. New Relic permits customers to delete personal data in accordance with applicable privacy laws as further described in the Documentation. In the event of error in personal data sent in Customer Data Customers may request personal data deletion and re-send data that is accurate. 4.4. Additional information for Customer data control and encryption, including encryption of data at rest, is available on New Relic’s Security Guide. 5. Facilities 5.1. All physical locations that process Customer Data are co-locations and third party data centers. All physical locations have security measures in place that are designed to prevent unauthorized physical access to data processing facilities and unlawful access, modification, or destruction of Customer Data. 5.2. New Relic will seek assurances (e.g., in the form of an independent 3rd party audit report such as the SOC 2 Type 2, ISO 27001, and vendor security evaluations) from its data processing facilities vendors that store or process Customer Data: 5.2.1. secure its data process facilities in an access-controlled location and have protections in place to prevent unauthorized access, damage, and interference; 5.2.2 employ physical security appropriate to the classification of the assets and information being managed which may include card key access, security cameras, and solid wall construction for all exterior walls; 5.2.3 limit and screen all entrants, which may include measures such as on-site security guard, badge reader, electronic lock, or a monitored closed caption television (CCTV); and 5.2.4 maintain relevant access logs. 5.3. Additional information about New Relic’s third party data centers are available on New Relic’s Security Guide. 6. Employee Access, Screening and Controls. New Relic will have and maintain policies and practices that include, at a minimum, the following controls and safeguards applied to New Relic employees and contractors who may access Customer Data: 6.1. For U.S. New Relic employees and subject to applicable law, a criminal background screening of each of its new employees to whom it gives access to Customer Data at the federal, state, and county levels. For non-U.S. New Relic employees, New Relic will use commercially reasonable efforts to meet the same criteria as established for U.S.-based New Relic employees, subject to general business practices in the respective country and in compliance with applicable local law requirements; 6.2. All New Relic employees with access to Customer Data will undergo adequate training, such as annual security awareness training, in the care, protection and handling of Customer Data, and will align with the privacy and security measures set out in this Addendum by following the guidance provided in their welcome package, which includes New Relic’s security policies and a security acknowledgement; 6.3. A disciplinary policy and process, to be used when New Relic employees violate New Relic security or privacy policies or access Customer Data without prior authorization; 6.4. Administrative or remote access to New Relic systems that process Customer Data will align with industry standard practices, including multi-factor authentication; 6.5. Restricted access to New Relic proprietary source code to prevent unauthorized access; 6.6. Controls designed to ensure that only those New Relic employees with an actual need-to-know will have access to New Relic systems including, but not limited to, the use of a formal access management process for the request, review, approval, and provisioning; 6.7. Controls designed to ensure that New Relic employees are granted access to New Relic systems based on least-privilege principles; and 6.8. Revoke access to New Relic employees no longer requiring access. 7. Security Incident and Data Breach Response 7.1. New Relic will take appropriate physical, technical, and administrative security measures that are commercially reasonable and consistent with industry standards to prevent a Data Breach, and as required by any applicable law or regulation. Without limiting the foregoing, New Relic will implement security measures at least as stringent as those set out in this Addendum. New Relic will designate a senior representative to provide incident briefings, as needed in case of a Data Breach, and to respond to reasonable requests by Customer pertaining to privacy and data security issues within a commercially reasonable time frame. 7.2. New Relic will: 7.2.1. Notify Customer without undue delay if New Relic becomes aware of a Data Breach; 7.2.2. Maintain a security incident response plan, including procedures and means to respond in a manner consistent with industry standards; 7.2.3. Reasonably cooperate with Customer to investigate and remediate a Data Breach and mitigate any further risk to the Customer Data, or risk to data subjects and/or Customer’s reputation or brand; 7.2.4. Provide reasonable assistance to Customer at New Relic’s sole cost and expense; and 7.2.5. Make commercially reasonable efforts to preserve evidence and reasonably cooperate with Customer and legal authorities (as applicable and legally permissible) during an investigation of a Data Breach. 8. Network and Systems Security 8.1. All extranet connectivity by New Relic personnel to systems processing Customer Data will be through secure remote connections. 8.2. Network segments connected to the Internet will be protected by secure access control mechanisms, such as a firewall configured to secure all devices behind it and properly addresses security concerns according to industry standard practices. 8.3. New Relic will have industry standard measures in place to actively monitor its systems and help detect a potential hostile attack, such as Network Intrusion Detection (NID) or Host Intrusion Detection (HID)/Prevention. 8.4. Applications, ports, services, and similar access points installed on a computer or network facility, which are not specifically required for business functionality, will be disabled or removed. 8.5. New Relic maintains configuration standards for authorized operating systems and software for systems that support processing of Customer Data. New Relic will establish and follow server configuration guidelines and processes for preventing unauthorized access to Customer Data. New Relic maintains secure images or templates for systems based on the organization’s approved configuration standards. 8.6. Development, test, and operational environments will be logically separated to reduce the risks of unauthorized access or changes to the operational system. 8.7. New Relic network architecture will be designed to limit site access and restrict the availability of information systems that are considered to be vulnerable to attack. 8.8. New Relic provides appropriate TLS certificates when users access and view Customer Data in the Service. New Relic’s software for sending Customer Data to New Relic will encrypt Customer Data in transit by default. 9. Authentication and Access Management If you subscribe to the requisite New Relic One Service, New Relic will provide industry standard authentication and access controls to protect Customer Data, including industry standard authentication methods utilized to help prevent unauthorized access to the Service. New Relic’s access control methods will clearly state the rules and rights for each user or group of users including applications and information sharing and will include a process for granting and removing access to all information systems processing Customer Data. A record of all privileges allocated will be maintained pursuant to the requirements herein. 9.1. In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic shall (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed. 10. Vulnerability Management New Relic will have and maintain the following vulnerability management processes for all devices used to connect to the New Relic network and Services. 10.1. New Relic will align to industry standard practices for build out, minimization of services and secure configuration, in accordance with, industry-recognized minimum security baselines for the New Relic platform and subcontractor systems connected to the New Relic platform in relation to the provision of the Services. 10.2. New Relic will employ industry-recognized standards and tools to conduct frequent infrastructure vulnerability scanning to test New Relic’s network and infrastructure and application penetration testing to test the New Relic Services. New Relic applies “Medium”, “High” and “Critical” security patches for all components in production and development environments as soon as commercially possible in accordance with its vulnerability management protocol, and consistent with industry standard practices and standards; 10.3. New Relic will have processes in place designed to ensure adherence to industry standard security development practices for development and testing for all code, APIs, and applications deployed and implemented in support of the Service; 10.4. New Relic will have and maintain solutions to identify and prevent malicious attackers or code from accessing or compromising Customer Data or systems that process Customer Data. These include, but are not limited to, software that identifies and removes malware and detects attempted intrusions. New Relic will have a security event and incident monitoring system and supporting processes to notify appropriate personnel in response to threats. 11. System Access and Logging 11.1. Access to New Relic’s systems will not be granted to employees of New Relic unless they have been uniquely identified and have sufficient credentials. 11.2. Access to New Relic’s systems will be logged and retained for no less than 6 months to assist in investigations and access control monitoring, including, but not limited to, end user access and activities, and information security events. 11.3. New Relic agrees to provide Customer the capability to access log records relating to Customer Accounts and the New Relic systems that process Customer Data in the event of a Data Breach or if required in connection with a law enforcement request. 12. Disaster Recovery and Data Backup 12.1. New Relic will have plans designed to respond to loss of services, which are tested and reviewed at least annually. This plan will include documented policies and procedures to restore service in the event of a service failure. 12.2. New Relic will establish and follow backup and restore procedures for Customer Data. 12.3. New Relic business continuity plan identifies critical systems. Annual disaster recovery tests are performed to check and restore customer data in the event of an incident. 12.4. New Relic will provide Customer with redacted copies of its plan(s) and evidence of tests/reviews upon request, but not more frequently than once annually, and subject to confidentiality requirements. 12.5. Additional information for Customer Data control and encryption are available on New Relic’s Security Guide. 13. Copies and Removal 13.1. In addition to any obligations of New Relic in the Agreement, upon expiration or termination of the Agreement for any reason: (a) New Relic will, and will cause its personnel, to cease all access and use of any Customer Data, and (b) New Relic will delete all copies of Customer Data within ninety (90) days. 13.2. New Relic will maintain a process of ensuring secure destruction and deletion of all Customer Data, when reasonably requested by Customer or as otherwise provided in the Agreement. The process will include industry standard processes so that: (i) Customer Data cannot be practicably read or reconstructed, and (ii) the systems that store Customer Data are securely erased and/or decommissioned disks are destroyed. 14. Third Party Vendor Management New Relic may use third party vendors to provide the Services. New Relic performs a security risk-based assessment of prospective vendors before working with them to validate they meet New Relic’s security and business continuity standards, including the type of access and classification of data being accessed (if any), controls necessary to protect data, and legal/regulatory requirements. New Relic enters into written agreements with its vendors that process Customer Data which include confidentiality, privacy, and security obligations that provide an appropriate level of protection for Customer Data that these vendors may process for New Relic to maintain the security posture in this Policy, including following industry security standards. 15. Disclosure by Law In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic will (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed. New Relic publishes its law enforcement requests report on New Relic’s Security Guide. 16. Updates As New Relic releases new products, services, functionality, and features, New Relic may update this Policy to account for such products, services, functionality, and features. For additional information, see our security guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.49797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " time to time, and such updates will not materially reduce the overall protections set forth in this Policy. The then-current terms of this Policy are available at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;referenced-policies&#x2F;security-policy&#x2F;. 2. Security Overview 2.1. New Relic"
      },
      "id": "603ea3dbe7b9d22b802a0802"
    },
    {
      "sections": [
        "Security guide",
        "Tip",
        "Security Program",
        "Security Domains",
        "Security Certifications",
        "Data Control, Facilities, and Encryption",
        "Law Enforcement Request Report"
      ],
      "title": "Security guide",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "356f0d11ffcb62208a743a0a7c127f5f6da9c940",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-guide/",
      "published_at": "2021-09-20T19:45:30Z",
      "updated_at": "2021-09-19T15:21:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Last updated September 17, 2021. This is supplement to our security policy and serves as a guide to New Relic’s description of its Services, functionalities, and features. Tip We may update the URLs in this document without notice. Security Program New Relic follows \"privacy by design\" principles as described here: https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Security Domains New Relic’s policies and procedures cover industry-recognized security domains such as Endpoint Protection; Portable Media Security; Mobile Device Security; Wireless Security; Configuration Management; Vulnerability Management; Network Protection; Transmission Protection; Password Management; Access Control, Audit Logging & Monitoring; Education, Training, and Awareness; Third Party Assurance; Incident Management; Business Continuity and Disaster Recover; Risk Management; Data Protection & Privacy; and Service Management Systems. Security Certifications New Relic audits its Services against industry standards as described at https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/. Data Control, Facilities, and Encryption New Relic's customers can send data to New Relic's APIs by (1) using New Relic's software, (2) using vendor-neutral software that is managed and maintained by a third-party such as via OpenTelemetry instrumentation provided by opentelemetry.io, or (3) from third-party systems that customer's manage and/or control. New Relic's customers can use New Relic's Services such as NerdGraph to filter out and drop data. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph/. New Relic's customers can adjust their data retention periods as appropriate for their needs. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-retention/#adjust-retention. New Relic Logs obfuscates numbers that match known patterns, such as bank card and social security numbers as described here: https://docs.newrelic.com/docs/logs/log-management/get-started/new-relics-log-management-security-privacy/. New Relic honors requests to delete personal data in accordance with applicable privacy laws. Please see https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Customers may use New Relic's APIs to query data, such as NerdGraph described here, and New Relic Services to export the data to other cloud providers. Customers can configure its log forwarder [https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/] before sending infrastructure logs to New Relic. For New Relic Customers in New Relic US, FedRAMP and HIPAA-enabled environments, Customer Data is replicated to the off-site backup system via Amazon Simple Storage Service (S3). Category of Customer Description FedRAMP HIPAA-enabled US Gen Pop EU Gen Pop Data is stored in Amazon Web Services (“AWS”). Limited Data is stored in IBM Data for New Relic Incident Intelligence is stored in Google Cloud New Relic regularly tests, assess, and evaluates its measures to ensure the security of processing using industry-recognized standards and uses independent third-party auditors as provided below: Annual SOC 2 Type 2 Annual FedRAMP assessment by an independent third-party pursuant to NIST 800-53 rev 4 Moderate authorization. Annual HITRUST-validated assessment by an independent third-party *Pursuing CY2021 Q4 ISO 27001 *Pursuing CY2021 TISAX *Pursuing CY2021 The Services that operate on Amazon Web Services (“AWS”) are protected by the security and environmental controls of AWS. Detailed information about AWS security is available at https://aws.amazon.com/security/ and http://aws.amazon.com/security/sharing-the-security-responsibility/. Data encryption at rest utilizes FIPS 140-2 compliant encryption methodology. For AWS SOC Reports, please see https://aws.amazon.com/compliance/soc-faqs/. The Services that operate on Google Cloud Platform (\"GCP\") are protected by the security and environmental controls of GCP. Detailed information about GCP security is available at https://cloud.google.com/docs/tutorials#security. For GCP reports, please see https://cloud.google.com/security/compliance/. IBM Deft Zayo QTS Law Enforcement Request Report New Relic has not to date received any request for customer data from a law enforcement or other government agency (including under any national security process), and has not made any corresponding disclosures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.1987,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " *Pursuing CY2021 The Services that operate on Amazon Web Services (“AWS”) are protected by the security and environmental controls of AWS. Detailed <em>information</em> about AWS security is available at https:&#x2F;&#x2F;aws.amazon.com&#x2F;security&#x2F; and http:&#x2F;&#x2F;aws.amazon.com&#x2F;security&#x2F;sharing-the-security-responsibility"
      },
      "id": "6147558128ccbc973a56a863"
    }
  ],
  "/docs/licenses/product-or-service-licenses/miscellaneous/help-center-documentation-licenses": [
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.02902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.24722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.6104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic APM <em>licenses</em>",
        "sections": "New Relic APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;new-relic-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-20T22:59:29Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.48225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-09-20T23:00:20Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright © 2016 Segment.io, Inc. CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.48225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.69038,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-09-20T22:59:29Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.4824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-09-20T23:00:20Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright © 2016 Segment.io, Inc. CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.48225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.69037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-09-20T22:59:29Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.4824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-20T22:59:29Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.48225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.69037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/apm-agent-sdk-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/c-sdk-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Resource Provider licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Resource Provider licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "24ced9cf2b1386e7b34fc9d3d79fc31a5e17acdd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-resource-provider-licenses/",
      "published_at": "2021-09-21T05:53:44Z",
      "updated_at": "2021-03-13T02:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Resource Provider. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License JSON.NET MIT MoreLinq Apache 2.0 Polly New BSD StackExchange.Redis MIT",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.0633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Resource Provider <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Resource Provider <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Microsoft Azure Portal Resource Provider. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License JSON.NET MIT MoreLinq Apache 2.0 Polly <em>New</em> BSD StackExchange.Redis MIT"
      },
      "id": "6044e80664441fc6a3378eec"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/java-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Resource Provider licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Resource Provider licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "24ced9cf2b1386e7b34fc9d3d79fc31a5e17acdd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-resource-provider-licenses/",
      "published_at": "2021-09-21T05:53:44Z",
      "updated_at": "2021-03-13T02:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Resource Provider. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License JSON.NET MIT MoreLinq Apache 2.0 Polly New BSD StackExchange.Redis MIT",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.0633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Resource Provider <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Resource Provider <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Microsoft Azure Portal Resource Provider. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License JSON.NET MIT MoreLinq Apache 2.0 Polly <em>New</em> BSD StackExchange.Redis MIT"
      },
      "id": "6044e80664441fc6a3378eec"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-resource-provider-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses": [
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Resource Provider licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Resource Provider licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "24ced9cf2b1386e7b34fc9d3d79fc31a5e17acdd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-resource-provider-licenses/",
      "published_at": "2021-09-21T05:53:44Z",
      "updated_at": "2021-03-13T02:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Resource Provider. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License JSON.NET MIT MoreLinq Apache 2.0 Polly New BSD StackExchange.Redis MIT",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.0633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Resource Provider <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Resource Provider <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Microsoft Azure Portal Resource Provider. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License JSON.NET MIT MoreLinq Apache 2.0 Polly <em>New</em> BSD StackExchange.Redis MIT"
      },
      "id": "6044e80664441fc6a3378eec"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/nodejs-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/php-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/ruby-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.42079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-20T20:37:29Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.20015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-20T14:50:42Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.06448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/browser-agent-licenses": [
    {
      "sections": [
        "New Relic Browser licenses",
        "UI tier"
      ],
      "title": "New Relic Browser licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Browser"
      ],
      "external_id": "b308c950e31570ee201237a88bfb8891da10a23c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-browser/new-relic-browser-licenses/",
      "published_at": "2021-09-20T16:56:30Z",
      "updated_at": "2021-03-16T04:45:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Browser. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. UI tier Library License DataStax Cassandra Java Driver Apache 2.0 d3 BSD Finagle Apache 2.0 gulp-rename MIT Jackson Apache 2.0 nee ISC nscala-time Apache 2.0 photocopy ISC Rapture Apache 2.0 React Apache 2.0 require.dir MIT Scrooge Apache 2.0 slf4j MIT snappy-java Apache 2.0 TwitterServer Apache 2.0 Typesafe Config Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.64224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>Browser</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>Browser</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Browser</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. UI tier Library License DataStax"
      },
      "id": "603ece91e7b9d2c9d02a07c2"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.02896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.24722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/new-relic-browser-licenses": [
    {
      "sections": [
        "Browser agent licenses"
      ],
      "title": "Browser agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Browser"
      ],
      "external_id": "9fac9d2d566767575f22d9458e49410063a83406",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-browser/browser-agent-licenses/",
      "published_at": "2021-09-21T06:09:47Z",
      "updated_at": "2021-03-16T04:45:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Browser agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Browserify MIT Episodes Apache 2.0 Lo-Dash MIT TraceKit MIT",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.25337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> agent <em>licenses</em>",
        "sections": "<em>Browser</em> agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Browser</em> agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Browserify MIT Episodes Apache 2.0 Lo-Dash MIT TraceKit MIT"
      },
      "id": "603eb41ce7b9d298012a080a"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.02896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.24722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-edition": [
    {
      "sections": [
        "Developer Program Resources"
      ],
      "title": "Developer Program Resources",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Developer edition"
      ],
      "external_id": "8a2f08905c7dcd10e50e975783ca3cf0071324c0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-program-resources/",
      "published_at": "2021-09-20T14:31:40Z",
      "updated_at": "2021-03-13T03:24:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer, you are eligible to participate in New Relic’s Developer Program. Additional information and resources are available at New Relic’s Developer Program site. By downloading, accessing, or using the developer resources (including the CLI), you agree that usage of the developer resources is pursuant to the New Relic Developers Terms and Conditions and that you have the authority to bind your organization. Such terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not use these developer resources. If your use of the New Relic developer resources are covered under a separate agreement, the above does not apply to you.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.5864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Developer</em> Program Resources",
        "sections": "<em>Developer</em> Program Resources",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer, you are eligible to participate in <em>New</em> <em>Relic</em>’s <em>Developer</em> Program. Additional information and resources are available at <em>New</em> <em>Relic</em>’s <em>Developer</em> Program site. By downloading, accessing, or using the <em>developer</em> resources (including the CLI), you agree that usage of the <em>developer</em> resources"
      },
      "id": "6044e7bb196a676d20960f4d"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.6903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.74174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-program-resources": [
    {
      "sections": [
        "Developer edition",
        "Terms"
      ],
      "title": "Developer edition",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Developer edition"
      ],
      "external_id": "60bc94afd677817a7b7fd7dd471c537090a9f711",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-edition/",
      "published_at": "2021-09-21T05:34:21Z",
      "updated_at": "2021-03-13T02:26:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All new accounts (outside Japan) created on or after July 30, 2020 are on the New Relic One pricing plan and have the newer New Relic One user model as described here. If (i) your account was created prior to July 30, 2020; or (ii) you are a current New Relic K.K. customer (Japan): in addition to the New Relic Pre-release policy, use of the Developer Edition of New Relic to the extent it is available is also subject to the following terms: Terms Non-production use only Up to $500 per month in total product usage across the New Relic platform Up to 2 users",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.58421,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Developer</em> <em>edition</em>",
        "sections": "<em>Developer</em> <em>edition</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " to the <em>New</em> <em>Relic</em> Pre-release policy, use of the <em>Developer</em> <em>Edition</em> of <em>New</em> <em>Relic</em> to the extent it is available is also subject to the following terms: Terms Non-production use only Up to $500 per month in total <em>product</em> usage across the <em>New</em> <em>Relic</em> platform Up to 2 users"
      },
      "id": "604506b9e7b9d22d115799c8"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.6903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.74174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-infrastructure/new-relic-infrastructure-licenses": [
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.02895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.24722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.6104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses": [
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.02895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.24722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.6104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.69545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logs</em> plugin <em>licenses</em>",
        "sections": "<em>Logs</em> plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " used for <em>New</em> <em>Relic</em> <em>Logs</em>, see <em>Logs</em> <em>licenses</em>. Plugins for <em>Logs</em> The following <em>licenses</em> are for the plugins used to connects your <em>log</em> data with <em>New</em> <em>Relic</em> <em>Logs</em>. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 <em>New</em> <em>Relic</em>, Inc. Fluentd Library License Copyright Fluentd Apache"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.69029,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.11952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses": [
    {
      "sections": [
        "Logs licenses",
        "Logs"
      ],
      "title": "Logs licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "229757bf0e3d8f3518533b11a059b9e4516e4699",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses/",
      "published_at": "2021-09-20T18:21:12Z",
      "updated_at": "2021-03-16T04:46:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for the New Relic Logs plugins, see Logs plugin licenses. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-plugin-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal Fuzzy-search ISC Copyright © 2016, Wouter Rutgers Immer MIT Copyright © 2017 Michel Weststrate Lodash MIT Copyright © JS Foundation and other contributors Lodash.debounce MIT Copyright © JS Foundation and other contributors Moment MIT Copyright © JS Foundation and other contributors Node-sass MIT Copyright © 2013-2016 Andrew Nesbitt Prop-types MIT Copyright © 2013-present, Facebook, Inc. React MIT Copyright © Facebook, Inc. and its affiliates. React-dom MIT Copyright © Facebook, Inc. and its affiliates. React-highlight-words MIT Copyright © 2015 Treasure Data React-json-view MIT Copyright © 2015 Mac Gainor React-popper MIT Copyright © 2018 React Popper authors React-redux MIT Copyright © 2015-present Dan Abramov React-select MIT Copyright © 2018 Jed Watson React-tooltip MIT Copyright © 2015 Wang Zixiao Redux MIT Copyright © 2015-present Dan Abramov Redux-logger MIT Copyright © 2016 Eugene Rodionov Redux-saga MIT Copyright © 2015 Yassine Elouafi Reselect MIT Copyright © 2015-2018 Reselect Contributors Shortid MIT Copyright © Dylan Greene Snyk Apache License 2.0 Copyright © 2015 Snyk Ltd. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.74126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logs</em> <em>licenses</em>",
        "sections": "<em>Logs</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Logs</em> plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea57b28ccbce04ceba77a"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.69029,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.11952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "iOS SDK for mobile monitoring licenses"
      ],
      "title": "iOS SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "71d2df4a922b6728230da4b4e8241f2d458ea66c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/ios-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:46Z",
      "updated_at": "2021-07-22T01:04:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the iOS SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apple Reachability Apple Reachability JSON++ MIT mod-pbxproj BSD-3 PLCrashReporter MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.98662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "iOS SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the iOS SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Apple"
      },
      "id": "60450cfde7b9d2c9eb5799c3"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-09-20T22:59:29Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.54861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.74174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/ios-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.74823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-09-20T22:59:29Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.54861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.74174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one": [
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.69028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.74174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.11952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-plugins/plugins-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.75436,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs <em>plugin</em> <em>licenses</em>",
        "sections": "Logs <em>plugin</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs <em>plugins</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Logs licenses",
        "Logs"
      ],
      "title": "Logs licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "229757bf0e3d8f3518533b11a059b9e4516e4699",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses/",
      "published_at": "2021-09-20T18:21:12Z",
      "updated_at": "2021-03-16T04:46:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for the New Relic Logs plugins, see Logs plugin licenses. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-plugin-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal Fuzzy-search ISC Copyright © 2016, Wouter Rutgers Immer MIT Copyright © 2017 Michel Weststrate Lodash MIT Copyright © JS Foundation and other contributors Lodash.debounce MIT Copyright © JS Foundation and other contributors Moment MIT Copyright © JS Foundation and other contributors Node-sass MIT Copyright © 2013-2016 Andrew Nesbitt Prop-types MIT Copyright © 2013-present, Facebook, Inc. React MIT Copyright © Facebook, Inc. and its affiliates. React-dom MIT Copyright © Facebook, Inc. and its affiliates. React-highlight-words MIT Copyright © 2015 Treasure Data React-json-view MIT Copyright © 2015 Mac Gainor React-popper MIT Copyright © 2018 React Popper authors React-redux MIT Copyright © 2015-present Dan Abramov React-select MIT Copyright © 2018 Jed Watson React-tooltip MIT Copyright © 2015 Wang Zixiao Redux MIT Copyright © 2015-present Dan Abramov Redux-logger MIT Copyright © 2016 Eugene Rodionov Redux-saga MIT Copyright © 2015 Yassine Elouafi Reselect MIT Copyright © 2015-2018 Reselect Contributors Shortid MIT Copyright © Dylan Greene Snyk Apache License 2.0 Copyright © 2015 Snyk Ltd. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.19675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs <em>licenses</em>",
        "sections": "Logs <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " used for the <em>New</em> <em>Relic</em> Logs <em>plugins</em>, see Logs <em>plugin</em> <em>licenses</em>. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-<em>plugin</em>-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal"
      },
      "id": "603ea57b28ccbce04ceba77a"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.69028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-synthetics/new-relic-synthetics-licenses": [
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-20T14:33:45Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.69026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-20T18:22:26Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.74174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-20T21:26:03Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.11952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.94743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring <em>agent</em>. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure <em>agent</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.08429,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.9503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET <em>agent</em> connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.34985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "59255e4b759113c33c56c041bc7376f06de7fe45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:41Z",
      "updated_at": "2021-09-01T04:08:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.33582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "f8ebd94136bca8ad2279d6f1170f3f6848a51ebc",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-09-20T14:38:18Z",
      "updated_at": "2021-08-27T07:09:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.72235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.34985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "59255e4b759113c33c56c041bc7376f06de7fe45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:41Z",
      "updated_at": "2021-09-01T04:08:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.33582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b4e0747855dd10d05a7ead1d4504beba3f218723",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-09-20T14:34:21Z",
      "updated_at": "2021-08-26T05:33:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.61,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-go": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.9662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.28557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream <em>for</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.27118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-nodejs": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.94711,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream <em>for</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.95026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-php": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.94696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.08386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream <em>for</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.95024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-python": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.94696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.08386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream <em>for</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.95024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-ruby": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.9468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.08371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream <em>for</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.95023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:42Z",
      "updated_at": "2021-09-01T04:15:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the log data from the FileTarget output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.34976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "f8ebd94136bca8ad2279d6f1170f3f6848a51ebc",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-09-20T14:38:18Z",
      "updated_at": "2021-08-27T07:09:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.72226,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b4e0747855dd10d05a7ead1d4504beba3f218723",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-09-20T14:34:21Z",
      "updated_at": "2021-08-26T05:33:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.60992,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all": [
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "59255e4b759113c33c56c041bc7376f06de7fe45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all/",
      "published_at": "2021-09-20T14:42:41Z",
      "updated_at": "2021-09-01T04:08:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.3357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "f8ebd94136bca8ad2279d6f1170f3f6848a51ebc",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-09-20T14:38:18Z",
      "updated_at": "2021-08-27T07:09:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.72223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b4e0747855dd10d05a7ead1d4504beba3f218723",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-09-20T14:34:21Z",
      "updated_at": "2021-08-26T05:33:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.6099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-firelens-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.38693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.75092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.38693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.75092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-logs-s3": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.38666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.75067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.4712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 390.63248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.71442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.96147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/enable-log-management-new-relic": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.3864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.75043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47119,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluent-bit-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.3864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.75043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47119,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluentd-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.3861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.75018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent": [
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.75018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-09-21T08:18:37Z",
      "updated_at": "2021-08-26T21:24:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, you'll need: A New Relic license key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key. Configure with the New Relic license key: output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, you&#x27;ll need: A <em>New</em> <em>Relic</em> license key Logstash 6.6 or higher Logstash requires Java 8"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.38586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.74994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/kubernetes-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.38586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.74994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.3856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.7497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.3856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-09-21T07:37:07Z",
      "updated_at": "2021-08-26T21:25:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, you'll need: A New Relic license key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Add a snippet to your vector.toml file (located in /etc/vector by default), replacing YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-09-21T08:18:37Z",
      "updated_at": "2021-08-26T21:24:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, you'll need: A New Relic license key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key. Configure with the New Relic license key: output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, you&#x27;ll need: A <em>New</em> <em>Relic</em> license key Logstash 6.6 or higher Logstash requires Java 8"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.3853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.74948,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-09-21T08:18:37Z",
      "updated_at": "2021-08-26T21:24:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, you'll need: A New Relic license key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key. Configure with the New Relic license key: output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.47015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, you&#x27;ll need: A <em>New</em> <em>Relic</em> license key Logstash 6.6 or higher Logstash requires Java 8"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/index": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 72.18765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "Forward your <em>logs</em> using the infrastructure agent",
        "tags": "<em>Logs</em>",
        "body": "You can forward your <em>logs</em> to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 69.98525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Stream <em>logs</em> using Kinesis Data Firehose",
        "tags": "<em>Logs</em>",
        "body": "&#x2F;firehose&#x2F;v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View <em>log</em> data If everything is configured correctly and your data is being collected, you should see data <em>logs</em> in both of these places: New Relic <em>Logs</em> UI New Relic"
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "NerdGraph tutorial: Managing data partition rules",
        "Data partition rule schema",
        "Example query of data partitions rules",
        "Create data partitions rules",
        "Update data partitions rules",
        "Delete data partitions rules"
      ],
      "title": "NerdGraph tutorial:  Managing data partition rules",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples",
        "Logs"
      ],
      "external_id": "b2a64a1935bf04aadfa82cf15ec7544eb40dcc99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/examples/nerdgraph-data-partition-rules-tutorial/",
      "published_at": "2021-09-20T19:42:41Z",
      "updated_at": "2021-09-20T19:42:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic’s NerdGraph GraphQL explorer to query and manage your data partition rules. This document includes: The data partition rule schema An example query of data partition rules How to create a data partition rule How to update a data partition rule How to delete a data partition rule Data partition rule schema Here's the complete list of possible data partition rule fields: Fields Description id Unique data partition rule identifier. targetDataPartition The name of the data partition. description A description of what this data partition rule represents. matchingCriteria The matching criteria for this data partition rule. Once the rule is enables, logs matching this criteria will be routed to the specified data partition. retentionPolicy The retention policy of the data partition data. createdAt The date and time the rule was created. createdBy The user who created the rule. updatedAt The date and time the rule was last changed. updatedBy The user who last updated the rule. enabled Whether or not this data partition rule is enabled. deleted Whether or not this data partition rule has been deleted. Deleting a data partition rule does not delete the already routed logs. Example query of data partitions rules This NerdGraph API request example gets all of the data partition rules for a given account. In this example, only a few fields are requested. { actor { account(id: 123456) { logConfigurations { dataPartitionRules { id targetDataPartition description matchingCriteria { attributeName matchingOperator matchingExpression } } } } } } Copy Create data partitions rules This example creates a new data partition rule. Before creating the rule, please be sure to check the article organize data with partitions. mutation { logConfigurationsCreateDataPartitionRule( accountId: 1123456, rule: { targetDataPartition: \"Log_aNewDataPartitionRule\", description: \"Example data partition rule\", matchingCriteria: { attributeName: \"attribute\", matchingMethod: LIKE, matchingExpression: \"'%example%'\" }, retentionPolicy: STANDARD, enabled: true }) { rule { id targetDataPartition description } errors { message type } } } Copy Update data partitions rules This example updates the data partition rule with the given id \"123\". The fields that can be updated are description, matchingCriteria, and enabled. All of them are optional so you just need to use the ones you want to update. mutation { logConfigurationsUpdateDataPartitionRule( accountId: 1123456, rule: { id: \"123\", description: \"Example data partition rule\", matchingCriteria: { attributeName: \"attribute\", matchingMethod: LIKE, matchingExpression: \"'%example%'\" }, enabled: true }) { rule { id targetDataPartition description } errors { message type } } } Copy Delete data partitions rules This example deletes a data partition rule. Deleting a data partition rule doesn't delete the already persisted data. This data is retained for a given period of time defined by the retention policy field. mutation { logConfigurationsDeleteDataPartitionRule(id: \"1111\", accountId: 123456) { errors { message type } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 69.84198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Logs</em>",
        "body": " <em>logs</em>. Example query of data partitions rules This NerdGraph API request example gets all of the data partition rules for a given account. In this example, only a few fields are requested. { actor { account(id: 123456) { <em>log</em>Configurations { dataPartitionRules { id targetDataPartition description"
      },
      "id": "60dedc7a196a674f914ea040"
    }
  ],
  "/docs/logs/log-management/get-started/get-started-log-management": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.00955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "Forward your <em>logs</em> using the infrastructure agent",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " To enable <em>log</em> forwarding through the infrastructure agent: If you haven&#x27;t already, create a New Relic account. It&#x27;s free, forever. <em>Start</em> by verifying the system requirements needed for configuring <em>Logs</em>. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "New Relic's log management security and privacy",
        "Automatic obfuscation",
        "Customize your security settings"
      ],
      "title": "New Relic's log management security and privacy",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Get started"
      ],
      "external_id": "ea5a441833677e4e7e60dfca315a3a410a7c9309",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/get-started/new-relics-log-management-security-privacy/",
      "published_at": "2021-09-21T08:15:11Z",
      "updated_at": "2021-03-16T09:26:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With log management you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in API calls or log forwarder configuration. All data for the logs service is then reported to New Relic over HTTPS. This document describes additional security considerations for your logging data. For more information about New Relic's security measures: See our security and privacy documentation. Visit the New Relic security website. Read this blog post that explains how you can use our log management tools to gain visibility into some of the most severe threats to modern digital businesses. Automatic obfuscation The log management service automatically masks number patterns that appear to be for items such as credit cards or Social Security numbers. All integers, including spaces and hyphens that may be used as delimiters, are replaced with a string of Xes. Numbers that appear to be a credit card (thirteen to sixteen digits) are obfuscated as XXXXXXXXXXXXXXXX. For example: Numbers with hyphens, such as 4111-1111-1111-1111 Numbers with spaces, such as 4111 1111 1111 1111 Numbers with thirteen (Visa), fourteen (Diner's Club), fifteen (American Express, JCB), or sixteen digits (Visa, Mastercard, Discover, JCB), such as 4111111111111111 Nine-digit numbers with hyphens that appear to be Social Security numbers, such as 123-45-6789, are obfuscated as XXXXXXXXX. Nine-digit numbers with spaces, such as 123 45 6789, or hyphens in a different pattern, such as 12-345-67-89, are not automatically obfuscated. If you need to opt out of automatic obfuscation, get support at support.newrelic.com. Customize your security settings The data you send to New Relic, including any additional filtering, is controlled by the configuration of the log forwarder you use, such as FluentD. Because you control what customer data is logged, be sure to follow your organization's security guidelines to mask, obfuscate, or prevent sending any sensitive data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.15178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic&#x27;s <em>log</em> <em>management</em> security and privacy",
        "sections": "New Relic&#x27;s <em>log</em> <em>management</em> security and privacy",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "With <em>log</em> <em>management</em> you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in API calls or <em>log</em> forwarder configuration. All data for the <em>logs</em> service"
      },
      "id": "603ea3dc64441f0bc14e884f"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.79897,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Stream <em>logs</em> using Kinesis Data Firehose",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable <em>log</em> <em>management</em>, follow the troubleshooting procedures."
      },
      "id": "603e96be64441f41584e8858"
    }
  ],
  "/docs/logs/log-management/get-started/new-relics-log-management-security-privacy": [
    {
      "sections": [
        "Get started with log management",
        "Find problems faster, reduce context switching",
        "Bring in your logging data",
        "View your logging data in New Relic"
      ],
      "title": "Get started with log management",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Get started"
      ],
      "external_id": "77761091d3c83970c78e92210970ade2a7441df9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/get-started/get-started-log-management/",
      "published_at": "2021-09-21T08:15:13Z",
      "updated_at": "2021-08-02T09:45:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As applications move towards the cloud, microservices architecture is becoming more dispersed, making the ability to monitor logs essential. New Relic offers a fast, scalable log management platform so you can connect your logs with the rest of your telemetry and infrastructure data in a single place. Our log management solution provides deeper visibility into application and infrastructure performance data (events and errors) to reduce mean-time-to-resolve (MTTR) and quickly troubleshoot production incidents. It does this by providing super-fast searching capabilities, alerts, and co-location of application, infrastructure, and log data, while visualizing everything from a single place. Find problems faster, reduce context switching Log management provides a way to connect your log data with the rest of your application and infrastructure data, allowing you to get to the root cause of problems quickly, without losing context switching between tools. Log management features include: Instantly search through your logs. Visualize your log data directly from the Logs UI. Use logging data to create custom charts, dashboards, and alerts. Troubleshoot performance issues without switching between tools. Bring in your logging data You can bring your log data into New Relic using a compatible log forwarding plugin, or with OpenTelemetry. Forward your logs using our Infrastructure agent or our Kubernetes plugin. Use our plugins for well-known log forwarders, like Fluentd, Fluent Bit, and Logstash. Stream or ship your logs from Amazon using AWS Lambda or Kinesis. Send your logs data using the Logs API. Once log management is enabled, you can also connect your logs with your APM agent, Kubernetes clusters, or distributed tracing to get additional contextual logging data with our logs in context extensions. View your logging data in New Relic You can explore your logging data in the UI or by API: Logs UI at one.newrelic.com Logs UI for EU region data center if applicable: one.eu.newrelic.com You can also query the Log data type. For example, use NRQL to run: SELECT * FROM Log Copy For more information about query options in New Relic, see Query your data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.16794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>log</em> <em>management</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ", and Logstash. Stream or ship your <em>logs</em> from Amazon using AWS Lambda or Kinesis. Send your <em>logs</em> data using the <em>Logs</em> API. Once <em>log</em> <em>management</em> is enabled, you can also connect your <em>logs</em> with your APM agent, Kubernetes clusters, or distributed tracing to <em>get</em> additional contextual logging data with our"
      },
      "id": "603ea62ee7b9d249432a07e2"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.00945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "Forward your <em>logs</em> using the infrastructure agent",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " To enable <em>log</em> forwarding through the infrastructure agent: If you haven&#x27;t already, create a New Relic account. It&#x27;s free, forever. <em>Start</em> by verifying the system requirements needed for configuring <em>Logs</em>. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.79887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Stream <em>logs</em> using Kinesis Data Firehose",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable <em>log</em> <em>management</em>, follow the troubleshooting procedures."
      },
      "id": "603e96be64441f41584e8858"
    }
  ],
  "/docs/logs/log-management/log-api/introduction-log-api": [
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-09-21T07:53:41Z",
      "updated_at": "2021-08-26T21:31:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid New Relic license key for the account you want to send logs to Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_LICENSE_KEY with your New Relic license key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_LICENSE_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing `YOUR_LICENSE_KEY with your New Relic license key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_LICENSE_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic license key: template NRFormat { template(\"YOUR_LICENSE_KEY <${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.30286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "We offer a wide range of solutions to get your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b4e0747855dd10d05a7ead1d4504beba3f218723",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-09-20T14:34:21Z",
      "updated_at": "2021-08-26T05:33:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.99211,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: Configure <em>logs</em> in context",
        "sections": "C SDK: Configure <em>logs</em> in context",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": "<em>Logs</em> in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> <em>API</em>. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.63258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "Forward your <em>logs</em> using the infrastructure agent",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": "You can forward your <em>logs</em> to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/logs/log-management/log-api/log-event-data": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-09-21T08:22:43Z",
      "updated_at": "2021-08-21T17:14:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.74892,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if available) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.3919,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic": [
    {
      "sections": [
        "Introduction to the Log API",
        "Compatibility and requirements",
        "HTTP setup",
        "HTTP headers",
        "HTTP query parameters",
        "JSON body",
        "Simplified JSON body message",
        "Detailed JSON body message",
        "Limits and restricted characters",
        "Caution",
        "Important",
        "Rate limit violations",
        "HTTP requests per minute",
        "JSON bytes per minute",
        "Log payload format",
        "JSON message attributes",
        "Common block attributes",
        "Logs block attributes",
        "JSON message attribute parsing",
        "Log JSON example",
        "Log POST example",
        "Example of stored common block attributes:",
        "Example of stored logs block attributes example:",
        "HTTP endpoint",
        "Find log data",
        "What's next?"
      ],
      "title": "Introduction to the Log API",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "198ebbf54f4a13fdf2f5b0f19d8cc8677afd09a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/introduction-log-api/",
      "published_at": "2021-09-21T07:34:45Z",
      "updated_at": "2021-08-26T21:30:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If our logging solutions don't meet your needs, you can use our Log API to send log data directly to New Relic's Log management via an HTTP endpoint. Want to try out our Log API? Create a New Relic account for free! No credit card required. Compatibility and requirements Requirements include: A New Relic license key For payload details, see limits and restricted characters. HTTP setup To send log data to your New Relic account: Get your New Relic license key. Generate the JSON message using the required headers and body fields. Ensure you're providing an Api-Key or License-Key via headers or query parameters Submit the JSON message to the HTTP endpoint in a POST request. Generate some traffic and wait a few minutes, then check your account for data. HTTP headers When creating your HTTP headers, use these guidelines: Header Supported values Content-Type Required application/json json application/gzip gzip Api-Key Required A New Relic license key. You can also send this via query parameter. You can also use an Insights insert key but the license key is preferred. Gzipped JSON formatting is accepted. If sending compressed JSON, please include the Content-Type: application/json and Content-Encoding: gzip headers. HTTP query parameters The license key can also be passed as a query string parameter. This can be useful when sending logs from cloud-based sources that don't allow custom HTTP request headers. Query parameter Value Api-Key Your license key. Use this key whenever you send a header. You can also use an Insights insert key but the license key is preferred. JSON body You can send your JSON message using either a simplified or detailed set of attributes: Simplified JSON body message When using the simplified format to create your JSON message, send a single JSON object with the following: Field Value type Format Required Notes \"timestamp\" Integer Either milliseconds or seconds since epoch No If the field is not specific as millisecond or seconds since epoch, the message will be timestamped using the ingest time \"message\" String any string No This is the main log message field that is searched by default \"logtype\" String any string No Primary field for identifying logs and matching parsing rules other_fields (must not contain white space) String any string No These will become attributes of the log message Note: Log management does not support white space in attribute names Detailed JSON body message When using the detailed format to create your body, it must be a JSON array containing one or more JSON objects, each of which with the following format: Field Value type Format Required Notes \"common\" Object See common. No Any attributes that are common to all log messages \"logs\" Array See logs. Yes Array with the log entries Limits and restricted characters Caution Avoid calling our API from within the code of a customer-facing application. This can cause performance issues or block your application if response time is slow. If you need to do it this way, call our API asynchronously to avoid these performance issues. Restrictions on logs sent to the Log API: Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Important Payloads with timestamps older than 48 hours may be dropped. Rate limits on logs sent to the Log API: Maximum rate for HTTP requests sent to the Log API: 300,000 requests per minute Maximum rate of uncompressed Log JSON bytes sent to the Log API: 10 GB per minute Rate limit violations Exceeding rate limits affects how the Log API behaves. Follow these instructions if this happens. HTTP requests per minute When the maximum request rate limit is exceeded for an account, the New Relic Log API returns a 429 response for the remainder of the minute. This response includes a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. JSON bytes per minute When the maximum Log JSON byte limit is exceeded for an account, the New Relic Log API returns a 429 response for the remainder of the minute. This response includes a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, try to reduce the amount of log data you are sending, or spread it out over a larger period of time. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Log payload format We accept any valid JSON payload. The payload must encoded as UTF-8. Important Log management does not support white space in attribute names. For example, {\"Sample Attribute\": \"Value\"} would cause errors. JSON message attributes Common block attributes This is a block containing attributes that will be common to all log entries in logs: Field Value type Format Required Notes \"timestamp\" Integer Milliseconds or seconds since epoch No Message timestamp default to ingest time \"attributes\" Object JSON No This sub-object contains all other attributes of the message Logs block attributes This is an array containing log entries with the following format: Field Value type Format Required Notes \"timestamp\" Integer Milliseconds or seconds since epoch No Message timestamp default to ingest time \"attributes\" Object JSON No This sub-object contains all other attributes of the message \"message\" String (any string) Yes This is the main log message field that is searched by default \"log\" String (any string) No We will rewrite this string as the field message on ingest \"LOG\" String (any string) No We will rewrite this string as the field message on ingest \"MESSAGE\" String (any string) No We will rewrite this string as the field message on ingest JSON message attribute parsing This will attempt to parse any message attribute as JSON. If the message attribute is JSON, it will be parsed and the resultant JSON attributes will be added to the event. If the message attribute is not JSON, it is left as is. For example, the event: { \"timestamp\": 1562767499238, \"message\": \"{\\\"service-name\\\": \\\"login-service\\\", \\\"user\\\": {\\\"id\\\": 123, \\\"name\\\": \\\"alice\\\"}}\" } Copy Will be treated as: { \"timestamp\": 1562767499238, \"message\": \"{\\\"service-name\\\": \\\"my-service\\\", \\\"user\\\": {\\\"id\\\": 123, \\\"name\\\": \\\"alice\\\"}}\", \"service-name\": \"my-service\", \"user\": { \"id\": 123, \"name\": \"alice\" } } Copy Important Log management does not support white space in attribute names. For example, {\"Sample Attribute\": \"Value\"} would cause errors. Log JSON example Attributes may be scalar JSON types like string and number, but may also be compound (or nested) objects. Compound attributes will have their leaf attributes stored with flattened names. For instance, a compound user attribute in a log entry's attributes: \"attributes\": { \"action\": \"login\", \"user\": { \"id\": 123, \"name\": \"alice\" } } Copy will result in the following attributes being stored with the log event: Attribute Value \"action\" \"login\" \"user.id\" 123 \"user.name\" \"alice\" Log POST example Log POST message example: POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: <YOUR_LICENSE_KEY> Accept: */* Content-Length: 319 [{ \"common\": { \"attributes\": { \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } }, \"logs\": [{ \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged in\" },{ \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged out\", \"attributes\": { \"auditId\": 123 } }] }] Copy The above POST message would result in the following log messages being stored in Log management: Example of stored common block attributes: Attribute Value \"logtype\" \"accesslogs\" \"service\" \"login-service\" \"hostname\" \"login.example.com\" Example of stored logs block attributes example: Attribute Value \"timestamp\" 1550086450124 \"message\" \"User 'xyz' logged out\" \"auditId\" 123 HTTP endpoint Once configured, your JSON data can be sent to the following endpoint in a POST request: United States (US) endpoint: https://log-api.newrelic.com/log/v1 Copy European Union (EU) endpoint: https://log-api.eu.newrelic.com/log/v1 Copy Here's an example of a JSON POST request: POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: <YOUR_LICENSE_KEY> Accept: */* Content-Length: 133 { \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Find log data For where to find data sent via the Log API (including from integrations that use that API), see Find log data. What's next? Now that you've enabled Log management, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards, charts, or alerts. If no data appears after you enable Log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.30202,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Log</em> <em>API</em>",
        "sections": "Introduction to the <em>Log</em> <em>API</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " (including from integrations that use that <em>API</em>), see Find <em>log</em> data. What&#x27;s next? Now that you&#x27;ve enabled <em>Log</em> <em>management</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>"
      },
      "id": "603ea832196a6726e7a83da1"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b4e0747855dd10d05a7ead1d4504beba3f218723",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-09-20T14:34:21Z",
      "updated_at": "2021-08-26T05:33:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.9921,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: Configure <em>logs</em> in context",
        "sections": "C SDK: Configure <em>logs</em> in context",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": "<em>Logs</em> in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> <em>API</em>. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.63249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "Forward your <em>logs</em> using the infrastructure agent",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": "You can forward your <em>logs</em> to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/logs/log-management/troubleshooting/find-issues-cause-or-impact-surrounding-logs": [
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.15775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Stream <em>logs</em> using Kinesis Data Firehose",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable <em>log</em> <em>management</em>, follow the <em>troubleshooting</em> procedures."
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.97104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "<em>Troubleshoot</em> <em>log</em> forwarding",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " like this: SELECT * FROM <em>Log</em> Copy <em>Troubleshoot</em> <em>log</em> forwarding Important Fluent Bit&#x27;s tail plugin does not support network drives. If no data appears after you enable <em>log</em> <em>management</em>, follow standard <em>troubleshooting</em> procedures. No data appears when tailing a file The <em>log</em> forwarding feature requires"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-09-21T08:18:35Z",
      "updated_at": "2021-08-26T21:29:57Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarding plugin. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response is a success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error parsing JSON payload Copy Checking for data Try querying the Log data type. For example, you can use the NRQL query builder to look at everything in the Log eventType. If no data appears in the query builder, then no data will appear in the Logs UI. SELECT * FROM Log Copy For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.68552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em>, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> <em>troubleshooting</em> Comments Access to data See Factors affecting access to features"
      },
      "id": "6044181d64441f9138378f05"
    }
  ],
  "/docs/logs/log-management/troubleshooting/json-message-not-parsed": [
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.15775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Stream <em>logs</em> using Kinesis Data Firehose",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable <em>log</em> <em>management</em>, follow the <em>troubleshooting</em> procedures."
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.97104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "<em>Troubleshoot</em> <em>log</em> forwarding",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " like this: SELECT * FROM <em>Log</em> Copy <em>Troubleshoot</em> <em>log</em> forwarding Important Fluent Bit&#x27;s tail plugin does not support network drives. If no data appears after you enable <em>log</em> <em>management</em>, follow standard <em>troubleshooting</em> procedures. No data appears when tailing a file The <em>log</em> forwarding feature requires"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-09-21T08:18:35Z",
      "updated_at": "2021-08-26T21:29:57Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarding plugin. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response is a success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error parsing JSON payload Copy Checking for data Try querying the Log data type. For example, you can use the NRQL query builder to look at everything in the Log eventType. If no data appears in the query builder, then no data will appear in the Logs UI. SELECT * FROM Log Copy For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.68552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em>, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> <em>troubleshooting</em> Comments Access to data See Factors affecting access to features"
      },
      "id": "6044181d64441f9138378f05"
    }
  ],
  "/docs/logs/log-management/troubleshooting/log-message-truncated": [
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.15764,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Stream <em>logs</em> using Kinesis Data Firehose",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable <em>log</em> <em>management</em>, follow the <em>troubleshooting</em> procedures."
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.97092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "<em>Troubleshoot</em> <em>log</em> forwarding",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " like this: SELECT * FROM <em>Log</em> Copy <em>Troubleshoot</em> <em>log</em> forwarding Important Fluent Bit&#x27;s tail plugin does not support network drives. If no data appears after you enable <em>log</em> <em>management</em>, follow standard <em>troubleshooting</em> procedures. No data appears when tailing a file The <em>log</em> forwarding feature requires"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-09-21T08:18:35Z",
      "updated_at": "2021-08-26T21:29:57Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarding plugin. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response is a success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error parsing JSON payload Copy Checking for data Try querying the Log data type. For example, you can use the NRQL query builder to look at everything in the Log eventType. If no data appears in the query builder, then no data will appear in the Logs UI. SELECT * FROM Log Copy For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.68552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em>, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> <em>troubleshooting</em> Comments Access to data See Factors affecting access to features"
      },
      "id": "6044181d64441f9138378f05"
    }
  ],
  "/docs/logs/log-management/troubleshooting/no-log-data-appears-ui": [
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.15764,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Stream <em>logs</em> using Kinesis Data Firehose",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable <em>log</em> <em>management</em>, follow the <em>troubleshooting</em> procedures."
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.97092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "<em>Troubleshoot</em> <em>log</em> forwarding",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " like this: SELECT * FROM <em>Log</em> Copy <em>Troubleshoot</em> <em>log</em> forwarding Important Fluent Bit&#x27;s tail plugin does not support network drives. If no data appears after you enable <em>log</em> <em>management</em>, follow standard <em>troubleshooting</em> procedures. No data appears when tailing a file The <em>log</em> forwarding feature requires"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "21fbe5d33e7949880f546958d658a1f86de212ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/new-relic-logs/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-20T16:07:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the message field, it's not automatically parsed and is not being stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not a valid JSON, it won't be parsed. Instead it will be stored as a string and truncated if it exceeds the character limit. The content is a valid JSON but \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem: send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.6873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>"
      },
      "id": "60441865e7b9d2b0b05799c1"
    }
  ],
  "/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail": [
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-20T19:23:47Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.15753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Stream <em>logs</em> using Kinesis Data Firehose",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable <em>log</em> <em>management</em>, follow the <em>troubleshooting</em> procedures."
      },
      "id": "603e96be64441f41584e8858"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-21T08:04:56Z",
      "updated_at": "2021-09-21T08:04:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.9708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the infrastructure agent",
        "sections": "<em>Troubleshoot</em> <em>log</em> forwarding",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": " like this: SELECT * FROM <em>Log</em> Copy <em>Troubleshoot</em> <em>log</em> forwarding Important Fluent Bit&#x27;s tail plugin does not support network drives. If no data appears after you enable <em>log</em> <em>management</em>, follow standard <em>troubleshooting</em> procedures. No data appears when tailing a file The <em>log</em> forwarding feature requires"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-09-21T08:18:35Z",
      "updated_at": "2021-08-26T21:29:57Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarding plugin. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response is a success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error parsing JSON payload Copy Checking for data Try querying the Log data type. For example, you can use the NRQL query builder to look at everything in the Log eventType. If no data appears in the query builder, then no data will appear in the Logs UI. SELECT * FROM Log Copy For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.68549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em>, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> <em>troubleshooting</em> Comments Access to data See Factors affecting access to features"
      },
      "id": "6044181d64441f9138378f05"
    }
  ],
  "/docs/logs/log-management/ui-data/built-log-parsing-rulesets": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-09-21T08:22:43Z",
      "updated_at": "2021-08-21T17:14:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.74887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.3922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if available) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39189,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/data-partitions": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-09-21T08:22:43Z",
      "updated_at": "2021-08-21T17:14:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.74887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.3922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if available) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/drop-data-drop-filter-rules": [
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.3922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if available) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-09-20T16:07:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. Each log's summary in the Logs UI provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Log queries in New Relic are based on the Lucene query language, and any Lucene function listed in this document is supported. (If a Lucene function is not listed, we do not support it.) For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> <em>UI</em> in New Relic One to quickly search through your <em>log</em> <em>data</em> in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. Each <em>log</em>&#x27;s summary in the <em>Logs</em> <em>UI</em> provides query options to add, exclude"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-09-21T08:22:43Z",
      "updated_at": "2021-08-21T17:14:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.74887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.3922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if available) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/long-logs-blobs": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-09-21T08:22:43Z",
      "updated_at": "2021-08-21T17:14:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.74884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.3922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if available) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/parsing": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-09-21T08:22:43Z",
      "updated_at": "2021-08-21T17:14:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.74884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.3922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if available) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-09-20T16:07:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. Each log's summary in the Logs UI provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Log queries in New Relic are based on the Lucene query language, and any Lucene function listed in this document is supported. (If a Lucene function is not listed, we do not support it.) For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> <em>UI</em> in New Relic One to quickly search through your <em>log</em> <em>data</em> in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. Each <em>log</em>&#x27;s summary in the <em>Logs</em> <em>UI</em> provides query options to add, exclude"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/ui-data/query-syntax-logs": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-09-21T08:22:43Z",
      "updated_at": "2021-08-21T17:14:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.74884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:08:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if available) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/use-logs-ui": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-09-21T08:22:43Z",
      "updated_at": "2021-08-21T17:14:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.74884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-20T16:06:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-09-20T16:07:03Z",
      "updated_at": "2021-08-02T13:07:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. Each log's summary in the Logs UI provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Log queries in New Relic are based on the Lucene query language, and any Lucene function listed in this document is supported. (If a Lucene function is not listed, we do not support it.) For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> <em>UI</em> in New Relic One to quickly search through your <em>log</em> <em>data</em> in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. Each <em>log</em>&#x27;s summary in the <em>Logs</em> <em>UI</em> provides query options to add, exclude"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui": [
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-20T16:09:16Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.97983,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s <em>Android</em> <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: <em>Android</em> 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-20T16:10:31Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.07498,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-09-20T20:38:32Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.88489,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for authentication. <em>Android</em> <em>app</em> users will also see a notification message. Important The authentication email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app": [
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-09-20T16:07:04Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.97974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Android</em> <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-20T16:10:31Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.07498,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-09-20T20:38:32Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.88489,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for authentication. <em>Android</em> <em>app</em> users will also see a notification message. Important The authentication email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps": [
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-20T16:10:31Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.07492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-20T16:09:16Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.06921,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ", additional installation or user <em>authentication</em> steps may be required. View <em>New</em> <em>Relic</em> data To view details of your <em>apps</em> monitored by <em>New</em> <em>Relic</em>, select a product from the <em>app</em>&#x27;s main menu. See below for details on how to use specific features of the <em>app</em>: <em>New</em> <em>Relic</em> product details The <em>New</em> <em>Relic</em> Android <em>app</em>"
      },
      "id": "604415e0196a67ff23960f46"
    },
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-09-20T16:07:04Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.06915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Android</em> <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> Android <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, <em>Alerts</em>, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices": [
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-09-20T16:08:14Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.07445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " channel to the <em>alert</em> policy. View <em>alert</em> incident details The notification automatically appears on your device&#x27;s lock screen. To start the <em>New</em> <em>Relic</em> <em>app</em>: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the <em>New</em> <em>Relic</em> <em>app</em>&#x27;s <em>Alerts</em> menu, select"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-20T16:10:31Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.07492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-20T16:09:16Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.06921,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ", additional installation or user <em>authentication</em> steps may be required. View <em>New</em> <em>Relic</em> data To view details of your <em>apps</em> monitored by <em>New</em> <em>Relic</em>, select a product from the <em>app</em>&#x27;s main menu. See below for details on how to use specific features of the <em>app</em>: <em>New</em> <em>Relic</em> product details The <em>New</em> <em>Relic</em> Android <em>app</em>"
      },
      "id": "604415e0196a67ff23960f46"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication": [
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-09-20T16:08:14Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.07445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " channel to the <em>alert</em> policy. View <em>alert</em> incident details The notification automatically appears on your device&#x27;s lock screen. To start the <em>New</em> <em>Relic</em> <em>app</em>: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the <em>New</em> <em>Relic</em> <em>app</em>&#x27;s <em>Alerts</em> menu, select"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-20T16:10:31Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.07484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-20T16:09:16Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.06915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ", additional installation or user <em>authentication</em> steps may be required. View <em>New</em> <em>Relic</em> data To view details of your <em>apps</em> monitored by <em>New</em> <em>Relic</em>, select a product from the <em>app</em>&#x27;s main menu. See below for details on how to use specific features of the <em>app</em>: <em>New</em> <em>Relic</em> product details The <em>New</em> <em>Relic</em> Android <em>app</em>"
      },
      "id": "604415e0196a67ff23960f46"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app": [
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-20T16:10:31Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 367.21185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> to <em>iOS</em> <em>mobile</em> <em>app</em>",
        "sections": "<em>Introduction</em> to <em>iOS</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s <em>i</em>Phone and <em>i</em>Pad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> <em>iOS</em> <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s <em>iOS</em> <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-09-20T16:08:14Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.96373,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ": Android From your Android device&#x27;s Settings, select <em>Apps</em>, then select the <em>New</em> <em>Relic</em> <em>app</em>. Select Uninstall. Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em>. <em>iOS</em> From your <em>iOS</em> home screen, tap and hold the <em>New</em> <em>Relic</em> icon until it shakes. To delete the <em>app</em>, select the X icon. Continue"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-20T16:09:16Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.14142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> to <em>New</em> <em>Relic</em> Android <em>app</em>",
        "sections": "<em>Install</em> <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s Android <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app": [
    {
      "sections": [
        "Install the New Relic iOS mobile app",
        "Compatibility and requirements",
        "Installation"
      ],
      "title": "Install the New Relic iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "a33650792e7ba24040db9a65d8d7fbb25c341d18",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app/",
      "published_at": "2021-09-20T16:11:40Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the New Relic iPhone and iPad apps, and links to more detailed information. Compatibility and requirements The New Relic iOS app allows you to view your New Relic applications, Infrastructure data, plugins you have installed from Plugin Central, key transactions, Synthetics monitors, and alerts from an Apple iPhone or iPad. Product requirements include: iOS 7 or higher iPhone users: iPhone 4S or higher iPad users: iPad 2 or higher You can also use an iPod touch, although resolution may be different. Installation You can install the New Relic app from the App Store or learn more from the New Relic website. Follow standard procedures to install any iOS app, and then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or authentication steps may be required. For more information, see User settings and authentication.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.59091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>New</em> <em>Relic</em> <em>iOS</em> <em>mobile</em> <em>app</em>",
        "sections": "<em>Install</em> the <em>New</em> <em>Relic</em> <em>iOS</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the <em>New</em> <em>Relic</em> <em>i</em>Phone and <em>i</em>Pad <em>apps</em>, and links to more detailed information. Compatibility and requirements The <em>New</em> <em>Relic</em> <em>iOS</em> <em>app</em> allows you to view your <em>New</em> <em>Relic</em> applications"
      },
      "id": "60441616196a67b070960f2b"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-09-20T16:08:14Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.96373,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ": Android From your Android device&#x27;s Settings, select <em>Apps</em>, then select the <em>New</em> <em>Relic</em> <em>app</em>. Select Uninstall. Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em>. <em>iOS</em> From your <em>iOS</em> home screen, tap and hold the <em>New</em> <em>Relic</em> icon until it shakes. To delete the <em>app</em>, select the X icon. Continue"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-20T16:09:16Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.14136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> to <em>New</em> <em>Relic</em> Android <em>app</em>",
        "sections": "<em>Install</em> <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s Android <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/tvos-app/introduction-apple-tv-app": [
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-20T16:10:31Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.07478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-20T16:09:16Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.06909,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> Android <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s Android <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    },
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-09-20T16:07:04Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.06903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> Android <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    }
  ],
  "/docs/mobile-crash-rest-api-v1": [
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Important",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-20T19:44:39Z",
      "updated_at": "2021-09-20T19:44:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. Important The AWS CloudWatch Metric Streams integration is not currently FedRAMP compliant. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. To enable FedRAMP compliance for Infinite Tracing, you would create a new FedRAMP compliant trace observer from the New Relic Edge app.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.61163,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Mobile</em> monitoring agents",
        "body": "-<em>api</em>.newrelic.com&#x2F;trace&#x2F;<em>v1</em> endpoint with https:&#x2F;&#x2F;gov-trace-<em>api</em>.newrelic.com&#x2F;trace&#x2F;<em>v1</em>. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and <em>mobile</em> agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. To enable FedRAMP compliance for Infinite Tracing, you would create a new FedRAMP compliant trace observer from the New Relic Edge app."
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Working with the New Relic REST API (v1) (deprecated)",
        "Important"
      ],
      "title": "Working with the New Relic REST API (v1) (deprecated)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v1 deprecated",
        "New Relic REST API v1"
      ],
      "external_id": "9cb0f38eb95a8757624ddb63298ff9a32e1176e7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v1-deprecated/new-relic-rest-api-v1/working-new-relic-rest-api-v1-deprecated/",
      "published_at": "2021-09-20T20:25:32Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Currently New Relic supports two versions of the REST API. Version 1 is deprecated and has been replaced with the newer v2. No termination date has been announced. However, no further development or modifications are being made to v1. Important Start new projects by referring to Getting started with API v2 and the New Relic REST API v2 examples. Also, begin migrating your v1 scripts to their v2 equivalent. To use the REST API v1 in any way, your API key is required. Then, from the command line, you can use: curl -gH \"x-api-key:REPLACE_WITH_YOUR_API_KEY\" 'ENDPOINT_URL' Copy OR wget -qO- --header \"x-api-key:REPLACE_WITH_YOUR_API_KEY\" 'ENDPOINT_URL' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.7674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Working with the New Relic <em>REST</em> <em>API</em> (<em>v1</em>) (deprecated)",
        "sections": "Working with the New Relic <em>REST</em> <em>API</em> (<em>v1</em>) (deprecated)",
        "tags": "<em>REST</em> <em>API</em> <em>v1</em> deprecated",
        "body": "Currently New Relic supports two versions of the <em>REST</em> <em>API</em>. Version <em>1</em> is deprecated and has been replaced with the newer <em>v</em>2. No termination date has been announced. However, no further development or modifications are being made to <em>v1</em>. Important Start new projects by referring to Getting started"
      },
      "id": "6043ff97e7b9d20358579a0d"
    },
    {
      "sections": [
        "Legacy New Relic OpenTelemetry Exporters",
        "Important",
        "New Relic Language Exporters",
        "New Relic Exporter for the OpenTelemetry Collector",
        "Endpoint configuration for New Relic exporters",
        "US endpoints",
        "EU region endpoints",
        "Tip"
      ],
      "title": "Legacy New Relic OpenTelemetry Exporters",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "0bcf5013d05814a9a0c8017b8c91a1770c7b8394",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-legacy-new-relic-exporters/",
      "published_at": "2021-09-20T19:20:09Z",
      "updated_at": "2021-09-20T19:20:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic published a number of exporters that are used to send OpenTelemetry data over New Relic's proprietary protocol. These exporters are being deprecated in favor of sending data to New Relic using the OpenTelemetry protocol. Important The exporters are listed here for reference. To migrate off these exporters, follow our quick start guide. New Relic Language Exporters As mentioned above, our language-specific exporters are being deprecated. These exporters allowed applications to export OpenTelemetry data directly to New Relic. The New Relic OTLP endpoint makes this strategy obsolete since it allows applications to export data to New Relic's proprietary endpoints. The exporters and their maintenance status are as follows: Go: To be archived soon Java: Archived Python: Archived .NET: To be archived soon New Relic Exporter for the OpenTelemetry Collector If you deployed your own collector with a New Relic exporter, we'll continue to support this exporter at least until the native OTLP ingest is beyond pre-release. We encourage you to migrate to the OTLP exporter in your collector. If you need help with that see our quick start guide. If you still need information about the New Relic Exporter, see the opentelemetry-collector-contrib repository. The OpenTelemetry Collector with New Relic Exporter example demonstrates what such a setup might look like. Endpoint configuration for New Relic exporters You can change the New Relic endpoints where you send your data. US endpoints By default, New Relic OpenTelemetry exporters send data to these US data centers: Spans: https://trace-api.newrelic.com/trace/v1 Metrics: https://metric-api.newrelic.com/metric/v1 Logs: https://log-api.newrelic.com/log/v1 You may need to override these default endpoints to send data to the EU region or to use Infinite Tracing. EU region endpoints To send telemetry data to New Relic’s endpoints in the EU region, use the following: Tip These URLs don't apply to Infinite Tracing. Spans: https://trace-api.eu.newrelic.com/trace/v1 Metrics: https://metric-api.eu.newrelic.com/metric/v1 Logs: https://log-api.eu.newrelic.com/log/v1",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.94177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " endpoints By default, New Relic OpenTelemetry exporters send data to these US data centers: Spans: https:&#x2F;&#x2F;trace-<em>api</em>.newrelic.com&#x2F;trace&#x2F;<em>v1</em> Metrics: https:&#x2F;&#x2F;metric-<em>api</em>.newrelic.com&#x2F;metric&#x2F;<em>v1</em> Logs: https:&#x2F;&#x2F;log-<em>api</em>.newrelic.com&#x2F;log&#x2F;<em>v1</em> You may need to override these default endpoints to send data to the EU"
      },
      "id": "60f6b9b928ccbc930b4b111c"
    }
  ],
  "/docs/mobile-monitoring/index": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 535.6014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map page, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-20T16:10:31Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.4775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> app",
        "sections": "<em>Mobile</em> <em>monitoring</em>",
        "tags": "<em>Mobile</em> apps",
        "body": " sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. <em>Mobile</em> <em>monitoring</em> If you have a <em>mobile</em> application and have installed <em>mobile</em> <em>monitoring</em>, you can <em>monitor</em> its performance directly from your iPhone"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Remove applications from New Relic",
        "Before attempting to remove an app",
        "Remove an application from New Relic",
        "APM applications",
        "Browser",
        "Mobile",
        "Troubleshooting",
        "You lack permissions",
        "You have not waited long enough",
        "Not all agents are disabled",
        "You have problems removing your PHP app",
        "You don't know where the app's data is coming from",
        "Browser data is still reporting",
        "For more help"
      ],
      "title": "Remove applications from New Relic",
      "type": "docs",
      "tags": [
        "APM",
        "Maintenance"
      ],
      "external_id": "f457af939892708a477895093f97b65d08ff015a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/new-relic-apm/maintenance/remove-applications-new-relic/",
      "published_at": "2021-09-20T19:22:08Z",
      "updated_at": "2021-09-20T19:22:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applications are automatically removed from New Relic after 93 days without sending data to our platform. You can also remove an application using the UI, once it has stopped sending data. Key metrics will continue to be available via the New Relic REST API, with the application name remaining reserved. For more information, see Inactive apps in New Relic One and our data retention guidelines. Before attempting to remove an app Before attempting to remove an app monitored by New Relic APM, browser monitoring, or mobile monitoring from the UI, keep in mind: You can downgrade your account to pay less or make it entirely free. The ability to remove an app from the UI may be dependent on permissions. If an agent is still sending data from an app, you cannot remove that app. Remove an application from New Relic Before you can remove an application monitored by New Relic APM, browser monitoring, or mobile monitoring, the app must first stop reporting data. Do this by disabling the agent (explained below) or by uninstalling the agent completely. APM applications Disable an APM agent using these instructions: C SDK: Do a quick recompile and deploy. For example, surround your instrumentation in #ifdef, and set the value of YOURNAMESPACE_NEWRELIC_ENABLED with your build system. Go: Set Enabled to false. Java: Set agent_enabled to false. .NET: Set Newrelic.AgentEnabled to false. Node.js: Set agent_enabled to false. PHP: Remove or disable both the newrelic.so and newrelic-daemon components. Set newrelic.enabled to false. Python: Set monitor_mode to false. Ruby: Set agent_enabled to false. Restart the application server and wait up to ten minutes. Verify the color-coded health status for the app has turned to gray and is no longer reporting data. To remove the APM application from the UI (and any associated apps in browser monitoring), you have a few options: Delete the app from the UI. Go to one.newrelic.com > APM > (select an app/service) > Settings > Application, and click the Delete application button. Use NerdGraph to delete an entity. If you've done the above and are still seeing that app in the UI, you can use NerdGraph to delete the relevant entities. For how to find entity IDs, see Entities. Browser If you've used the copy/paste method to install the browser agent, remove the JavaScript snippet from your application's pages. After 93 days, that app will be removed from the UI. If you want to remove it sooner than that, you have several options: Delete an associated APM app. If your browser app is linked to an APM application, deleting the APM application also removes the browser application. See the instructions for deleting an APM app. Delete it from the UI. Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings, and click the Delete application button. Use NerdGraph to delete an entity. If you've done the above and are still seeing that app in the UI, you can use NerdGraph to delete the relevant entities. For how to find entity IDs, see Entities. Mobile Remove all references/dependencies to New Relic's mobile monitoring SDK/frameworks, then rebuild the application. For more information, see the iOS and Android install docs. After 93 days, the app will be removed from the UI. If you want to remove it sooner than that, you have several options: Remove it using the UI. Go to one.newrelic.com > Mobile > (select an app) > Settings > Application, and click Delete application. Use NerdGraph to delete an entity. If you've done the above and are still seeing that app in the UI, you can use NerdGraph to delete the relevant entities. For how to find entity IDs, see Entities. Troubleshooting If you have problems removing an app, here are some possible causes and suggested solutions: You lack permissions If you don't have relevant permissions, you won't be able to remove an application. You have not waited long enough All app data must stop reporting to New Relic before you can remove that entity from New Relic. In most cases, this takes between 10-15 minutes. In rare cases, it can take a few minutes longer. Not all agents are disabled If you have multiple agents reporting data under the same UI name, then you must make sure you disable or uninstall all of the agents associated with that entity. You have problems removing your PHP app If you have a PHP app and aren't able to remove it from the UI, possible causes include: You have not disabled both components of the PHP agent. You must stop or uninstall both newrelic.so and newrelic-daemon in order to be able to remove a PHP app. For more information, see New Relic daemon processes. You have set up per-directory monitoring of your PHP app, and unexpected PHP data is reporting as the default PHP application in the New Relic UI. To fix this, change the default app name in the PHP agent config. You don't know where the app's data is coming from If you don't know where an app's data is coming from, it may be because the app's name has been changed. When an app name is changed in the UI, it does not change the underlying app name being reported; it only changes how the app name appears in the UI. To see if there is a difference between the reported name and the displayed name: From one.newrelic.com, select APM, then select an application. Scroll down to Settings and select Application. Compare the name in the Application alias field to the name in the Your application still reports as message directly beneath it. To get host information about an app you are not familiar with: From one.newrelic.com, select APM, then select an application. From the summary view, review the Servers list. Once you have identified where app data is coming from, you can remove the app from New Relic. Browser data is still reporting To remove an app from New Relic, all data must have stopped reporting, including browser monitoring data. To verify that you have disabled or uninstalled the APM agent associated with the app: Ensure that browser monitoring is disabled. If your browser monitoring script is inserted by the APM agent, turn it off from inside the UI, in the agent's config file, or in both. If you copied and pasted the monitoring JavaScript snippet in certain pages, remove that JavaScript snippet manually. Ensure all caches have been cleared that the application uses, such as host caches, CDNs, or anything else that caches built pages. Optional: To see a count of how many page views report from each domain, use this NRQL query: SELECT count(*) FROM PageView WHERE appName = 'YOUR_BROWSER_APP_NAME' FACET domain Copy If these steps don't resolve the issue, it is likely due to an end-user's browser cache that hasn't yet cleared. Wait until those caches clear. If your app has internal users, you may be able to identify the users and clear those caches. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 379.46268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Mobile</em>",
        "body": " reserved. For more information, see Inactive apps in New Relic One and our data retention guidelines. Before attempting to remove an app Before attempting to remove an app monitored by New Relic APM, browser <em>monitoring</em>, or <em>mobile</em> <em>monitoring</em> from the UI, keep in mind: You can downgrade your account"
      },
      "id": "603ebbef28ccbc48d1eba78d"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/crash-analysis-group-filter-your-crashes": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.59976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "Important The <em>mobile</em> Maps <em>UI</em> is deprecated since December 22, 2020. Service maps are available in New Relic One&#x27;s left navigation for each <em>mobile</em> entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-20T16:14:59Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.59306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-20T16:13:55Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.57884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.5997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "Important The <em>mobile</em> Maps <em>UI</em> is deprecated since December 22, 2020. Service maps are available in New Relic One&#x27;s left navigation for each <em>mobile</em> entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-20T16:14:59Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.59305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-20T16:13:55Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.57884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.5997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "Important The <em>mobile</em> Maps <em>UI</em> is deprecated since December 22, 2020. Service maps are available in New Relic One&#x27;s left navigation for each <em>mobile</em> entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-20T16:14:59Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.59305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-20T16:13:55Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.57884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-occurrences": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.59964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "Important The <em>mobile</em> Maps <em>UI</em> is deprecated since December 22, 2020. Service maps are available in New Relic One&#x27;s left navigation for each <em>mobile</em> entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-20T16:14:59Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.59305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-20T16:13:55Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.57884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.59964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "Important The <em>mobile</em> Maps <em>UI</em> is deprecated since December 22, 2020. Service maps are available in New Relic One&#x27;s left navigation for each <em>mobile</em> entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-20T16:14:59Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.59305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Handled exceptions: Analyze trends, prevent crashes",
        "Handled exceptions workflow",
        "Exception percentage charts",
        "Exception percentage charts example",
        "Groups and filters",
        "Groups and filters example",
        "Top five exception locations",
        "Top five exception locations example",
        "Query builder links",
        "Exception locations table",
        "Exception locations table example"
      ],
      "title": "Handled exceptions: Analyze trends, prevent crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "d325744648613b771d7dd39de3f1448fe8a54ab9",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes/",
      "published_at": "2021-09-20T16:12:47Z",
      "updated_at": "2021-07-21T21:33:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Handled exceptions help you identify significant factors contributing to poor mobile application experience, and use filterable data to find a resolution more quickly. You can also use the handled exceptions API to customize the data you send, and use NRQL to query and share the data. Handled exceptions workflow To get the most out of the Handled exceptions UI, use this basic workflow: Go to one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions. Use any of New Relic's standard page functions to drill down into detailed information; for example, zoom into any area of a chart. Look for obvious or general trends in the Users affected and Sessions affected percentage charts. Adjust the types of exceptions shown by using groups and filters. Optional: Query or share the chart data. Look for similar patterns where exceptions appear in stack traces with the Top 5 exception locations table. To view stack trace thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Exception percentage charts Start with the Users affected and Sessions affected percentage charts to see at a glance whether there are any unexpected spikes, dips, or patterns with exceptions in general. (If the Users affected chart is empty, there were no user sessions during the selected time period.) For example: Are there any spikes near a recent version release? Is there a time period when the percentage of users has been affected significantly by the exception? Are there uneventful periods? To examine data in greater detail: Below any chart, select Expand chart. Exception percentage charts example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: The percentage charts help you quickly see any unexpected spikes, dips, or patterns with exceptions in general. Groups and filters Use the groups and filters to examine attributes for crashes, devices, locations, or other custom attributes in more detail. You can select a group, then filter to specific data. For example: Group the list by exception location (default), cause, app build or version, devices, connections, or other custom attributes. This lets you discover patterns in your exceptions to determine the root cause. Use the time picker to adjust the currently selected time period. Filter by a specific Version or by one or more attribute Filter, such as appVersion, exceptionLocationMethod, lastInteraction, or any of the longer list of standard and custom attributes. The currently selected filters appear at the top of the UI page. You can close them, add other filters, or select other groups and filters. Groups and filters example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: Group the data by attributes that matter to the most to you, then select one or more filters to help pinpoint specific causes behind the exceptions. Top five exception locations Use the Top 5 exception locations table to find or sort patterns in the type of exception you selected from the groups and filters. This includes: Recurring locations in the stack trace Mobile app version Number of occurrences Number of users affected during the selected time period For example, you can group by Exception Message, filter to timeout message, then select individual timeout locations from the table to review the stack trace thread and details about each occurrence. To filter or group by other attributes, use the table's search window, or select any of the available filters. For example, filter by type of occurrence, device, a specific location, or any custom attributes. To look for other historical patterns, change the selected time period. Top five exception locations example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: This example shows the Expand chart button and links to the query builder, where you can query, create dashboards, and share the handled exceptions data. Query builder links Handled exceptions charts use default attributes for mobile events (including MobileHandledException), along with any custom attributes you have added to this event type. When you mouse over the charts, direct links appear below them. These links to the query builder allow you to analyze your mobile app data even deeper. View query link: View the NRQL query used to calculate the chart data. View in query builder link: View the chart, and share it with others. Exception locations table The Exception locations table supplements the charts. It lists where the top five handled exceptions appear in their stack trace thread, and links them to relevant details. Each row helps you find answers to questions such as: How many of this exception occurred within the selected time period? Does a specific app version have a higher (or lower) number of users affected? Which exception has the fewest number of occurrences? You can change the sort order or filter options to focus on just the types of exceptions that matter the most to you and your teams. To view additional thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. Exception locations table example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: To continue to the handled exception's Occurrences page, select any row on the table.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.54523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "sections": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " exceptions workflow To get the most out of the Handled exceptions <em>UI</em>, use this basic workflow: Go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select an app) &gt; Exceptions &gt; Handled exceptions. Use any of New Relic&#x27;s standard page functions to drill down into detailed information; for example, zoom into any area"
      },
      "id": "604505ae28ccbc783e2c6085"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/investigate-mobile-app-crash-report": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.5996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "Important The <em>mobile</em> Maps <em>UI</em> is deprecated since December 22, 2020. Service maps are available in New Relic One&#x27;s left navigation for each <em>mobile</em> entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-20T16:14:59Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.59305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-20T16:13:55Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.57884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.5996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "Important The <em>mobile</em> Maps <em>UI</em> is deprecated since December 22, 2020. Service maps are available in New Relic One&#x27;s left navigation for each <em>mobile</em> entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-20T16:13:55Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.57884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    },
    {
      "sections": [
        "Handled exceptions: Analyze trends, prevent crashes",
        "Handled exceptions workflow",
        "Exception percentage charts",
        "Exception percentage charts example",
        "Groups and filters",
        "Groups and filters example",
        "Top five exception locations",
        "Top five exception locations example",
        "Query builder links",
        "Exception locations table",
        "Exception locations table example"
      ],
      "title": "Handled exceptions: Analyze trends, prevent crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "d325744648613b771d7dd39de3f1448fe8a54ab9",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes/",
      "published_at": "2021-09-20T16:12:47Z",
      "updated_at": "2021-07-21T21:33:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Handled exceptions help you identify significant factors contributing to poor mobile application experience, and use filterable data to find a resolution more quickly. You can also use the handled exceptions API to customize the data you send, and use NRQL to query and share the data. Handled exceptions workflow To get the most out of the Handled exceptions UI, use this basic workflow: Go to one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions. Use any of New Relic's standard page functions to drill down into detailed information; for example, zoom into any area of a chart. Look for obvious or general trends in the Users affected and Sessions affected percentage charts. Adjust the types of exceptions shown by using groups and filters. Optional: Query or share the chart data. Look for similar patterns where exceptions appear in stack traces with the Top 5 exception locations table. To view stack trace thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Exception percentage charts Start with the Users affected and Sessions affected percentage charts to see at a glance whether there are any unexpected spikes, dips, or patterns with exceptions in general. (If the Users affected chart is empty, there were no user sessions during the selected time period.) For example: Are there any spikes near a recent version release? Is there a time period when the percentage of users has been affected significantly by the exception? Are there uneventful periods? To examine data in greater detail: Below any chart, select Expand chart. Exception percentage charts example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: The percentage charts help you quickly see any unexpected spikes, dips, or patterns with exceptions in general. Groups and filters Use the groups and filters to examine attributes for crashes, devices, locations, or other custom attributes in more detail. You can select a group, then filter to specific data. For example: Group the list by exception location (default), cause, app build or version, devices, connections, or other custom attributes. This lets you discover patterns in your exceptions to determine the root cause. Use the time picker to adjust the currently selected time period. Filter by a specific Version or by one or more attribute Filter, such as appVersion, exceptionLocationMethod, lastInteraction, or any of the longer list of standard and custom attributes. The currently selected filters appear at the top of the UI page. You can close them, add other filters, or select other groups and filters. Groups and filters example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: Group the data by attributes that matter to the most to you, then select one or more filters to help pinpoint specific causes behind the exceptions. Top five exception locations Use the Top 5 exception locations table to find or sort patterns in the type of exception you selected from the groups and filters. This includes: Recurring locations in the stack trace Mobile app version Number of occurrences Number of users affected during the selected time period For example, you can group by Exception Message, filter to timeout message, then select individual timeout locations from the table to review the stack trace thread and details about each occurrence. To filter or group by other attributes, use the table's search window, or select any of the available filters. For example, filter by type of occurrence, device, a specific location, or any custom attributes. To look for other historical patterns, change the selected time period. Top five exception locations example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: This example shows the Expand chart button and links to the query builder, where you can query, create dashboards, and share the handled exceptions data. Query builder links Handled exceptions charts use default attributes for mobile events (including MobileHandledException), along with any custom attributes you have added to this event type. When you mouse over the charts, direct links appear below them. These links to the query builder allow you to analyze your mobile app data even deeper. View query link: View the NRQL query used to calculate the chart data. View in query builder link: View the chart, and share it with others. Exception locations table The Exception locations table supplements the charts. It lists where the top five handled exceptions appear in their stack trace thread, and links them to relevant details. Each row helps you find answers to questions such as: How many of this exception occurred within the selected time period? Does a specific app version have a higher (or lower) number of users affected? Which exception has the fewest number of occurrences? You can change the sort order or filter options to focus on just the types of exceptions that matter the most to you and your teams. To view additional thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. Exception locations table example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: To continue to the handled exception's Occurrences page, select any row on the table.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.54521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "sections": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " exceptions workflow To get the most out of the Handled exceptions <em>UI</em>, use this basic workflow: Go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select an app) &gt; Exceptions &gt; Handled exceptions. Use any of New Relic&#x27;s standard page functions to drill down into detailed information; for example, zoom into any area"
      },
      "id": "604505ae28ccbc783e2c6085"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/alerts-page-mobile-apps": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-20T16:17:27Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.38574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-20T16:18:45Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.68755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-20T16:18:44Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-20T16:17:27Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.38574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-20T16:18:45Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.68755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-20T16:18:44Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/interactions-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-20T16:17:27Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.38573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-20T16:18:45Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.68755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-20T16:18:44Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index": [
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-20T16:18:45Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.68755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-20T16:18:44Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-09-20T16:17:28Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.6582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-20T16:17:27Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.38573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-20T16:18:45Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.68755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-20T16:18:44Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-monitoring-email-notifications": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-20T16:17:27Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.38571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-20T16:18:45Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.68753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-20T16:18:44Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-20T16:17:27Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.38571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-20T16:18:45Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.68753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-09-20T16:17:28Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-20T16:17:27Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.3857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-20T16:18:44Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-09-20T16:17:28Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.65819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/analyze-network-requests-using-mobilerequest-event-data": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.21454,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "Important",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "https://docs.newrelic.com/static/44339db3414bda429d69b74258ab64e8/8c557/screen-http-requests-details_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-09-21T01:22:03Z",
      "updated_at": "2021-07-09T12:28:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): Here is an example of a selected HTTP request for an app monitored with mobile. To view details for the transaction, select App server drill-down. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View the related app's transaction Important This feature is not available when the related app has distributed tracing enabled. To view the related app's transaction: Select App server drill-down, then view the Transactions page for the app associated with this HTTP request. To return to the HTTP requests page, select your browser's Back function. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.60217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-09-21T01:22:03Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.60205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP errors: <em>Network</em> failure analysis",
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors <em>page</em> helps you to better understand HTTP errors and <em>network</em> failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors <em>page</em> to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/carriers-page": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.21445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "Important",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "https://docs.newrelic.com/static/44339db3414bda429d69b74258ab64e8/8c557/screen-http-requests-details_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-09-21T01:22:03Z",
      "updated_at": "2021-07-09T12:28:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): Here is an example of a selected HTTP request for an app monitored with mobile. To view details for the transaction, select App server drill-down. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View the related app's transaction Important This feature is not available when the related app has distributed tracing enabled. To view the related app's transaction: Select App server drill-down, then view the Transactions page for the app associated with this HTTP request. To return to the HTTP requests page, select your browser's Back function. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.60217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-09-21T01:22:03Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.60205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP errors: <em>Network</em> failure analysis",
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors <em>page</em> helps you to better understand HTTP errors and <em>network</em> failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors <em>page</em> to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/connection-types-page": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-20T20:38:31Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.21445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "Important",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "https://docs.newrelic.com/static/44339db3414bda429d69b74258ab64e8/8c557/screen-http-requests-details_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-09-21T01:22:03Z",
      "updated_at": "2021-07-09T12:28:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): Here is an example of a selected HTTP request for an app monitored with mobile. To view details for the transaction, select App server drill-down. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View the related app's transaction Important This feature is not available when the related app has distributed tracing enabled. To view the related app's transaction: Select App server drill-down, then view the Transactions page for the app associated with this HTTP request. To return to the HTTP requests page, select your browser's Back function. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.60217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-09-21T01:22:03Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.60205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP errors: <em>Network</em> failure analysis",
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors <em>page</em> helps you to better understand HTTP errors and <em>network</em> failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors <em>page</em> to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    }
  ]
}