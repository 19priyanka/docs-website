{
  "/docs/infrastructure/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration": [
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations",
        "Configure nri-prometheus-latest.yaml",
        "Example configuration file",
        "Key names and definitions",
        "Configure objects in target key",
        "Kubernetes port and endpoint path",
        "Example: Labels for Kubernetes port and path",
        "Services and Endpoints scrape behaviour",
        "Reload the configuration",
        "Docker: Run previous config file"
      ],
      "title": "Configure Prometheus OpenMetrics integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "12be9e8bb8c03ca3f0eed948d0bc6e863b60efef",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations/",
      "published_at": "2021-10-24T16:20:38Z",
      "updated_at": "2021-09-07T23:50:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Unless otherwise noted, configuration options for your Prometheus OpenMetrics integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: Configure your New Relic license key as an environment variable named LICENSE_KEY. This provides a more secure environment, as New Relic can load your environment variable from a mutual TLS authentication secret. Configure nri-prometheus-latest.yaml The nri-prometheus-latest.yaml manifest file includes the nri-prometheus-cfg map showing an example configuration. Use the manifest file to configure the following parameters. Example configuration file The following is an example configuration file that you can save and modify to fit your needs. For more information, see the documentation about mutual TLS authentication and translating PromQL to NRQL. # The name of your cluster. It's important to match other New Relic products to relate the data. cluster_name: \"<YOUR_CLUSTER_NAME>\" # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true # standalone: true # How often the integration should run. Defaults to 30s. # scrape_duration: \"30s\" # The HTTP client timeout when fetching data from targets. Defaults to 5s. # scrape_timeout: \"5s\" # How old must the entries used for calculating the counters delta be # before the telemetry emitter expires them. Defaults to 5m. # telemetry_emitter_delta_expiration_age: \"5m\" # How often must the telemetry emitter check for expired delta entries. # Defaults to 5m. # telemetry_emitter_delta_expiration_check_interval: \"5m\" # Wether the integration should run in verbose mode or not. Defaults to false. verbose: false # Whether the integration should run in audit mode or not. Defaults to false. # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent. # It does not include verbose mode. This can lead to a high log volume, use with care. audit: false # Wether the integration should skip TLS verification or not. Defaults to false. insecure_skip_verify: false # The label used to identify scrapable targets. Defaults to \"prometheus.io/scrape\". scrape_enabled_label: \"prometheus.io/scrape\" # scrape_services Allows to enable scraping the service and not the endpoints behind. # When endpoints are scraped this is no longer needed scrape_services: true # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does. # Please notice that depending on the number of endpoints behind a service the load can increase considerably scrape_endpoints: false # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true. require_scrape_enabled_label_for_nodes: true # Number of worker threads used for scraping targets. # For large clusters with many (>400) targets, slowly increase until scrape # time falls between the desired `scrape_duration`. # Increasing this value too much will result in huge memory consumption if too # many metrics are being scraped. # Default: 4 # worker_threads: 4 # Maximum number of metrics to keep in memory until a report is triggered. # Changing this value is not recommended unless instructed by the New Relic support team. # max_stored_metrics: 10000 # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms. # Changing this value is not recommended unless instructed by the New Relic support team. # min_emitter_harvest_period: 200ms # targets: # - description: Secure etcd example # urls: [\"https://192.168.3.1:2379\", \"https://192.168.3.2:2379\", \"https://192.168.3.3:2379\"] # tls_config: # ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" # cert_file_path: \"/etc/etcd/etcd-client.crt\" # key_file_path: \"/etc/etcd/etcd-client.key\" # Proxy to be used by the emitters when submitting metrics. It should be # in the format [scheme]://[domain]:[port]. # The emitter is the component in charge of sending the scraped metrics. # This proxy won't be used when scraping metrics from the targets. # By default it's empty, meaning that no proxy will be used. # emitter_proxy: \"http://localhost:8888\" # Certificate to add to the root CA that the emitter will use when # verifying server certificates. # If left empty, TLS uses the host's root CA set. # emitter_ca_file: \"/path/to/cert/server.pem\" # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account # having limited privileges. Defaults to false. # disable_autodiscovery: false # Whether the emitter should skip TLS verification when submitting data. # Defaults to false. # emitter_insecure_skip_verify: false # Histogram support is based on New Relic's guidelines for higher # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md. # To better support visualization of this data, percentiles are calculated # based on the histogram metrics and sent to New Relic. # By default, the following percentiles are calculated: 50, 95 and 99. # # percentiles: # - 50 # - 95 # - 99 # transformations: # - description: \"General processing rules\" # rename_attributes: # - metric_prefix: \"\" # attributes: # container_name: \"containerName\" # pod_name: \"podName\" # namespace: \"namespaceName\" # node: \"nodeName\" # container: \"containerName\" # pod: \"podName\" # deployment: \"deploymentName\" # ignore_metrics: # # Ignore all the metrics except the ones listed below. # # This is a list that complements the data retrieved by the New # # Relic Kubernetes Integration, that's why Pods and containers are # # not included, because they are already collected by the # # Kubernetes Integration. # - except: # - kube_hpa_ # - kube_daemonset_ # - kube_statefulset_ # - kube_endpoint_ # - kube_service_ # - kube_limitrange # - kube_node_ # - kube_poddisruptionbudget_ # - kube_resourcequota # - nr_stats # copy_attributes: # # Copy all the labels from the timeseries with metric name # # `kube_hpa_labels` into every timeseries with a metric name that # # starts with `kube_hpa_` only if they share the same `namespace` # # and `hpa` labels. # - from_metric: \"kube_hpa_labels\" # to_metrics: \"kube_hpa_\" # match_by: # - namespace # - hpa # - from_metric: \"kube_daemonset_labels\" # to_metrics: \"kube_daemonset_\" # match_by: # - namespace # - daemonset # - from_metric: \"kube_statefulset_labels\" # to_metrics: \"kube_statefulset_\" # match_by: # - namespace # - statefulset # - from_metric: \"kube_endpoint_labels\" # to_metrics: \"kube_endpoint_\" # match_by: # - namespace # - endpoint # - from_metric: \"kube_service_labels\" # to_metrics: \"kube_service_\" # match_by: # - namespace # - service # - from_metric: \"kube_node_labels\" # to_metrics: \"kube_node_\" # match_by: # - namespace # - node # integration definition files required to map metrics to entities # definition_files_path: /etc/newrelic-infra/definition-files Copy Key names and definitions Here are some key names and definitions for your Prometheus OpenMetrics config file. Key name Description cluster_name Required. The name of the cluster. This value will be included as the clusterName attribute for all metrics. verbose Stringified boolean. true (default): Logs debugging information. false: Only logs error messages. targets Configuration of static endpoints to be scraped by the integration. It contains a list of objects. For more information about this structure, see the documentation about target configuration. scrape_enabled_label Kubernetes String. The integration will check if the Kubernetes pod and service are annotated or have a label with this value to decide if it has to be scraped. This is particularly useful when you want to limit the amount of data by ignoring metrics or including specific metrics that are sent to New Relic. Since by default we use the same label Prometheus uses to discover targets that can be scraped, most exporters that you install automatically set this label. To keep a fine-grained control on the targets you want the integration to scrape, you can set this option to some other value (such as newrelic/scrape) and then add the annotation or label newrelic/scrape: \"true\" to your Kubernetes objects. If both are set, annotations take precedence over labels. Default: \"prometheus.io/scrape\" scrape_duration How often should the scraper run. To lower memory usage, increase this value. To raise memory usage, decrease this value. The impact on memory usage is due to distributing target fetching over the scrape interval to avoid querying (and buffering) all the data at once. Default is 30s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. scrape_timeout The HTTP client timeout when fetching data from endpoints. Default: 5s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. worker_threads Number of worker threads used for scraping targets. Can be increased on environments with a high number of targets or targets with high latency, but might increase memory consumption. Default: 4. It is not recommended to use more than 10. require_scrape_enabled_label_for_nodes Kubernetes Whether or not Kubernetes nodes need labels to be scraped. Default: true. percentiles Histogram support is based on New Relic's guidelines for higher level metrics abstractions. To better support visualization of this data, percentiles are calculated based on the histogram metrics and sent to New Relic. Valid values include 50, 95, and 99. emitter_proxy Proxy used by the integration when submitting metrics: [scheme]://[domain]:[port] This proxy won't be used when fetching metrics from the targets. By default this is empty, and no proxy will be used. emitter_ca_file Certificate to add to the root CA that the emitter will use when verifying server certificates. If left empty, TLS uses the host's root CA set. emitter_insecure_skip_verify Whether the emitter should skip TLS verification when submitting data. Default: false. disable_autodiscovery Set to true in order to disable autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account having limited privileges. Default: false. Configure objects in target key If you want the target key in the configuration file to contain one or more objects, use the following structure in the YAML list: Key name Description description A description for the URLs in this target. urls A list of strings with the URLs to be scraped. tls_config Authentication configuration used to send requests. It supports TLS and Mutual TLS. For more information, see the documentation about mutual TLS authentication. Kubernetes port and endpoint path New Relic's Prometheus OpenMetrics integration automatically discovers which targets to scrape. To specify the port and endpoint path to be used when constructing the target, you can use the prometheus.io/port and prometheus.io/path annotations or label in your Kubernetes pods and services. Annotations take precedence over labels. If prometheus.io/port is not present, the integration will try to scrape each port or ContainerPort defined for the service. If prometheus.io/path is not present, the integration will default to /metrics. If a service is not running on the default /my-metrics-path path, add a label to the pod prometheus.io/path=my-metrics-path. If the path to the metrics endpoint is more complex and cannot be a valid label value (for example, foo/bar), use annotations instead. Example: Labels for Kubernetes port and path In this example, you have a deployment in your cluster, and the pods expose Prometheus metrics on port 8080 and in the path my-metrics. In the PodSpec metadata of the deployment manifest, set the labels prometheus.io/port: \"8080\" and prometheus.io/path: \"my-metrics\". When the integration tries to retrieve the metrics from your pods, it will send a request to http://<pod-ip>:8080/my-metrics. apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment spec: replicas: 2 selector: matchLabels: app: my-app template: metadata: labels: app: my-app prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" prometheus.io/path: \"my-metrics\" Copy Services and Endpoints scrape behaviour By default, services are scraped directly instead of the underlying endpoints since scrape_services is set to true and scrape_endpoints to false. In order to change this behaviour set scrape_endpoints to true configuring Prometheus OpenMetrics integrations to scrape the underlying endpoints, as Prometheus server natively does, instead of directly the services. Please notice that depending on the number of endpoints behind the services in the cluster the load and the data ingested can increase considerably, monitor and, if needed, increase resource requirements. Moreover, even if it is possible to set both scrape_services and scrape_endpoints to true to assure retrocompatibility, it would lead to duplicate data. Reload the configuration The Prometheus OpenMetrics integration does not automatically reload the configuration when you make changes to the configuration file. Docker: To reload the configuration, restart the container running the integration: docker restart nri-prometheus Copy Kubernetes: To reload the configuration, restart the integration. Recommendation: Scale the deployment down to zero replicas, and then scale it back to one replica: kubectl scale deployment nri-prometheus --replicas=0 kubectl scale deployment nri-prometheus --replicas=1 Copy Docker: Run previous config file Docker: To run the integration with the previous configuration file: Copy the content and save it to a config.yaml file. From within the same directory, run the command: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e CLUSTER_NAME=\"YOUR_CLUSTER_NAME\" \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:latest --configfile=/config.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.90753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "Unless otherwise noted, configuration options for your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: <em>Configure</em> your New Relic license key"
      },
      "id": "603e830964441f85a04e8877"
    },
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations in large Kubernetes environments",
        "Configure the integration for large environments"
      ],
      "title": "Configure Prometheus OpenMetrics integrations in large  Kubernetes environments",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "84e7d3b803e614a6362e0246a58b48e3209094ad",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations-large-kubernetes-environments/",
      "published_at": "2021-10-24T16:12:26Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of metrics exposed by each target. For example, a Prometheus OpenMetrics integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30 seconds, consumes 2.5CPU and 700MB of RAM. Configure the integration for large environments To estimate the size of the environment you are monitoring, run the following query to see how many targets are being scraped: SELECT latest(nr_stats_targets) FROM Metric where clusterName=’clusterName’ SINCE 30 MINUTES AGO TIMESERIES Copy In huge environments with hundreds of targets to be scraped, the latency on the /metrics endpoints must be below 1 second. Run this query to check the latency of the different targets. This query retrieves the data exposed by the Prometheus OpenMetrics integration, and shows the time required to fetch each endpoint. SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=’clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy In order to keep the time needed to scrape all the targets below 30 seconds, use the following configurations: Targets Configuration Targets < 400, with 1000 metrics each No modification is required. CPU ranges roughly between 0.1 and 1.5 cores, and the memory required should be no more than 256MB. 400 < targets < 1000, with 1000 metrics each The number of workers should be increased to 6-8. CPU ranges roughly between 1.5 and 3.5 cores, and the memory required is around 100MB. Targets > 1000, with 1000 metrics each The number of workers should be increased to 10 or more. CPU is over 3.5 cores, and the memory required is around 1GB or more.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.6634,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large  Kubernetes environments",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large Kubernetes environments",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of <em>metrics</em> exposed by each target. For example, a <em>Prometheus</em> <em>OpenMetrics</em> integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30"
      },
      "id": "603e9b3b196a676cd0a83d81"
    },
    {
      "sections": [
        "Add mutual TLS to Prometheus endpoints",
        "Add secret to config file"
      ],
      "title": "Add mutual TLS to Prometheus endpoints",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "707c96de26f106ddeaea4e18d5b71290170fea90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/add-mutual-tls-prometheus-endpoints/",
      "published_at": "2021-10-24T17:38:21Z",
      "updated_at": "2021-03-13T03:34:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure mutual TLS authentication when needed for the endpoints in your Prometheus OpenMetrics integration with New Relic. Add tls_config to your configuration file for Docker or Kubernetes, as explained in this example. Add secret to config file Recommendation: Put the CA bundle, key, and cert files in a secret, and include them in the Prometheus OpenMetrics integration's container. Mutual TLS authentication is limited to a static list of URLs. To configure endpoints that require MTLS authentication, follow this example: targets: - description: \"Secure etcd example\" urls: [\"https://123.456.7.1:2379\", \"https://123.456.7.2:2379\"] tls_config: ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" cert_file_path: \"/etc/etcd/etcd-client.crt\" key_file_path: \"/etc/etcd/etcd-client.key\" transformations: ... Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.56999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add mutual TLS to <em>Prometheus</em> endpoints",
        "sections": "Add mutual TLS to <em>Prometheus</em> endpoints",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "You can <em>configure</em> mutual TLS authentication when needed for the endpoints in your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic. Add tls_config to your configuration file for Docker or Kubernetes, as explained in this example. Add secret to config file Recommendation: Put the CA bundle, key"
      },
      "id": "6044e621196a67efb9960f37"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/install-configure-remote-write/prometheus-remote-write-integration": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 3823.23,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics or <em>remote</em> <em>write</em> <em>integration</em>?",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "This page provides an overview of New Relic&#x27;s <em>Prometheus</em> <em>integration</em> options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. <em>Prometheus</em> OpenMetrics or <em>remote</em> <em>write</em> <em>integration</em>? We currently offer two"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "image": "https://docs.newrelic.com/static/d2a9c929c7541b67b6fe4c87844fc01b/ae694/prometheus_grafana_dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2020/08/create-grafana-dashboards-prometheus-data-stored-new-relic/",
      "sections": [
        "Create Grafana dashboards with Prometheus data stored in New Relic",
        "Step 1: Get data flowing into New Relic with the Prometheus remote write integration",
        "Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic"
      ],
      "published_at": "2021-10-19T05:58:32Z",
      "title": "Create Grafana dashboards with Prometheus data stored in New Relic",
      "updated_at": "2021-10-19T05:58:32Z",
      "type": "docs",
      "external_id": "da09ab47a2ac806ad3ed1fa67e3a02dd54394383",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’ve teamed up with Grafana Labs so you can use our platform as a data source for Prometheus metrics and see them in your existing dashboards, seamlessly tapping into the reliability, scale, and security provided by New Relic. Follow the steps below or use this more detailed walkthrough to send Prometheus data to New Relic, so that Grafana can populate your existing Prometheus-specific dashboards with that data. This process requires Prometheus version 2.15.0 or higher and Grafana version 6.7.0 or higher. You’ll also need to sign up for New Relic. Here's an example of how these Grafana dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to Instrument Everything – US or Instrument Everything – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get your remote_write URL. For more information on how to set up the Prometheus remote write integration, check out our docs. Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic For more information on how to configure New Relic as a Prometheus data source for Grafana, check out our docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 3008.52,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create Grafana dashboards with <em>Prometheus</em> data stored in New Relic",
        "sections": "Step 1: Get data flowing into New Relic with the <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em>",
        "body": " dashboards with <em>Prometheus</em> data look in our new dark mode. Step 1: Get data flowing into New Relic with the <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em> Go to Instrument Everything – US or Instrument Everything – EU, then click the <em>Prometheus</em> tile. You can also go to the <em>Prometheus</em> <em>remote</em> <em>write</em> setup page to get"
      },
      "id": "60445821e7b9d23b585799e4"
    },
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-18T15:27:07Z",
      "updated_at": "2021-07-22T05:51:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1812.5546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics or <em>remote</em> <em>write</em> <em>integration</em>?",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "This page provides an overview of New Relic&#x27;s <em>Prometheus</em> <em>integration</em> options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. <em>Prometheus</em> OpenMetrics or <em>remote</em> <em>write</em> <em>integration</em>? We currently offer two"
      },
      "id": "603ea41964441f0d824e8874"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/install-configure-remote-write/remote-write-errors-error-messages": [
    {
      "sections": [
        "Set up your Prometheus remote write integration",
        "Set up the integration",
        "Map Prometheus and New Relic metric types",
        "Override metric type mappings",
        "Set allow or deny lists for sent metrics",
        "Customize remote write behavior",
        "X-License Key",
        "prometheus_server URL parameter",
        "Optimize throughput and memory consumption",
        "Troubleshoot error messages",
        "Remove the integration"
      ],
      "title": "Set up your Prometheus remote write integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "e2a503880e8e1c38284434d5829fad3f48dc7abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration/",
      "published_at": "2021-10-24T16:26:26Z",
      "updated_at": "2021-09-08T01:33:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can get Prometheus data flowing in New Relic with just a few simple steps. This page covers basic setup for the remote write integration, as well as a few common troubleshooting topics. For information on integrating Prometheus servers in a high availability (HA) configuration, see our Prometheus high availability documentation. Set up the integration Go to the Prometheus remote write setup launcher in New Relic One, then complete these steps. Add Prometheus data Enter a name for the Prometheus server to be connected and your remote_write URL. Important: The name you enter for the server will create an attribute on your data. It will also be the name that identifies which Prometheus server is sending data to New Relic. Add a new remote_write URL to your Prometheus YML file. Add this information under global_config in the file, at the same indentation level as the global section. Use the following syntax: remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=YOUR_DATA_SOURCE_NAME bearer_token:YOUR_LICENSE_KEY Copy OR remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?X-License-Key=YOUR_LICENSE_KEY&prometheus_server=YOUR_DATA_SOURCE_NAME Copy European Union accounts: If you're connecting from the EU, use the following URL: https://metric-api.eu.newrelic.com/prometheus/v1/write Copy Kubernetes and Helm remote write integrations: Add the remote write URL to your Helm values.yaml file. Replace remoteWrite: [] with two lines similar to the following example. Be sure to use your remote write URL and use indentation that matches the rest of the file: remoteWrite: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=YOUR_DATA_SOURCE_NAME bearer_token:YOUR_LICENSE_KEY Copy Restart your Prometheus server. View your data in the New Relic UI. For example, use the remote write dashboard we automatically create when you set up your integration. Map Prometheus and New Relic metric types The Prometheus remote write protocol does not include metric type information or other helpful metric metadata when sending metrics to New Relic. Because the remote write protocol doesn't include this information, New Relic infers the metric type based on Prometheus naming conventions. Metrics not following these naming conventions may not be mapped correctly. New Relic maps Prometheus metrics types into New Relic metric types based on Prometheus metric naming conventions as follows: metricName_bucket is stored as a New Relic count metric type. metricName_count is stored as a New Relic count metric type. metricName_total is stored as a New Relic count metric type. metricName_sum is stored as a New Relic summary metric type. Everything else is stored as a New Relic gauge metric type. Override metric type mappings If you have metrics that don't follow Prometheus naming conventions, you can configure remote-write to tag the metric with a newrelic_metric_type label that indicates the metric type. This label is stripped when received by New Relic. Example: You have a counter metric named my_counter, which does not have our naming convention suffix of _bucket, _count or _total. In this situation, your metric would be identified as a gauge rather than a counter. To correct this, add the following relabel configuration to your prometheus.yml: - url: https://metric-api.newrelic.com/prometheus/v1/write?X-License-Key=... write_relabel_configs: - source_labels: [__name__] regex: ^my_counter$ target_label: newrelic_metric_type replacement: \"counter\" action: replace Copy This rule matches any metric with the name my_counter and adds a newrelic_metric_type label that identifies it as a counter. You can use the following (case sensitive) values as the replacement value: counter gauge summary When a newrelic_metric_type label is present on a metric received and set to one of the valid values, New Relic will assign the indicated type to the metric (and strip the label) before downstream consumption in the data pipeline. If you have multiple metrics that don't follow the above naming conventions, you can add multiple rules with each rule matching different source labels. Set allow or deny lists for sent metrics If you need greater control over the data you send to New Relic, you can send a subset of your metrics. To do this, configure remote-write with the write_relabel_configs parameter with a subparameter action value of keep or deny. In this example, you'll only send the metrics that match the regular expression. Unmatched metrics won't be sent. Alternatively, you can use action: drop to drop all of the metrics that match the regular expression. - url: https://metric-api.newrelic.com/prometheus/v1/write?X-License-Key=... write_relabel_configs: - source_labels: [__name__] regex: \"coredns_(.*)|etcd_(.*)\" action: keep Copy This Kubernetes example uses this Helm chart's values.yaml file. If you're using a different Helm chart, please check its remoteWrite documentation (for example, some Helm files use camelcase writeRelabelConfigs instead). remoteWrite: - url: https://metric-api.newrelic.com/prometheus/v1/write?X-License-Key=... write_relabel_configs: - source_labels: [__name__] regex: \"coredns_(.*)|etcd_(.*)\" action: keep Copy Customize remote write behavior You can customize the following parameters if you are writing to more than one account in New Relic or are connecting more than one Prometheus data source to the same account in New Relic. For more information, see the docs on remote write tuning. X-License Key Your account's license key is not an API key. The license key is used for authentication and to identify which account to write data into. If you are configuring Prometheus to write into different New Relic accounts, use a different key on each remote write URL. prometheus_server URL parameter The prometheus_server parameter is a label or attribute used to add to stats that are written to NRDB. Use this same label when configuring your Grafana data source to limit results to just those from a particular prometheus_server. Optimize throughput and memory consumption Remote write increases the total memory consumption of your Prometheus servers. If you're experiencing issues we recommend the following: Increase max_samples_per_send for higher throughput workloads, along a proportional increase in capacity. If memory consumption is still a problem, try limiting the number of max_shards per server. Troubleshoot error messages If you receive an integration error message from New Relic or error messages in your Prometheus server logs after restarting your Prometheus server, review our remote write troubleshooting documentation. This includes fixing common errors, such as missing or incorrect characters, bad requests, request entity too large, and rate limit errors. Remove the integration When you remove the Prometheus remote write integration, this stops new data from flowing, but it will not purge or remove any historical data. To remove the integration, remove the configuration code snippet from your Prometheus YML file, then restart the server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.08275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up your <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em>",
        "sections": "Set up your <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": "_server=YOUR_DATA_SOURCE_NAME Copy European Union accounts: If you&#x27;re connecting from the EU, use the following URL: https:&#x2F;&#x2F;metric-api.eu.newrelic.com&#x2F;<em>prometheus</em>&#x2F;v1&#x2F;<em>write</em> Copy Kubernetes and Helm <em>remote</em> <em>write</em> <em>integrations</em>: Add the <em>remote</em> <em>write</em> URL to your Helm values.yaml file. Replace <em>remoteWrite</em>: [] with two"
      },
      "id": "603e94de196a674e6ca83def"
    },
    {
      "sections": [
        "Drop data using Prometheus remote write",
        "Tip",
        "Drop entire metric data points from remote write integration",
        "Example",
        "Drop specific labels or attributes from data points",
        "Prometheus or NerdGraph?",
        "Considerations for the Prometheus config file method",
        "Considerations the NerdGraph method",
        "Learn more"
      ],
      "title": "Drop data using Prometheus remote write",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "f3e07dd4f6bbdb65881f13035af5af172c5409e7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure/remote-write-drop-data/",
      "published_at": "2021-10-24T16:14:03Z",
      "updated_at": "2021-07-09T08:33:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can drop data you don't want to keep by changing the remote_write section of the YAML config file. Tip You can also drop remote write data using NerdGraph. For more information, see Drop data using NerdGraph. Drop entire metric data points from remote write integration If a target is sending a noisy metric that you don't want sent to New Relic, you can specify that New Relic should drop that data. Example Let's say you don't want to receive data for the metric node_memory_active_bytes from an instance running at localhost:9100. Using the write_relabel_config entry shown below, you can target the metric name using the __name__ label in combination with the instance name. remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=macbook-server-cluster bearer_token: <redacted> write_relabel_configs: - source_labels: ['__name__', 'instance'] regex: 'node_memory_active_bytes;localhost:9100' action: 'drop' Copy This tells Prometheus that you want to do some action against metrics with these labels. To limit which metrics with these labels are affected, you must include some value for regex. By default this value is set to .* and it will include all metrics. In this case, it will drop all metric data points coming out of Prometheus via remote write. Drop specific labels or attributes from data points If a target is sending specific labels or attributes you're not interested in receiving, you can drop these from the metrics you receive. Example Let's say one of your targets is sending a bunch of extra attributes you're not interested in receiving. These might include things like high cardinality attributes such as unique machine identifiers, JVM IDs, or similar. In this case, you need to change both the remote_write and the scrape_configs section of the YAML file. The result will look something like this: remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=macbook-server-cluster bearer_token: <redacted> write_relabel_configs: - regex: 'extraLabelToRemove.*' action: 'labeldrop' ... scrape_configs: # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config. - job_name: 'node' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9100'] labels: group: 'production' keepLabelName1: 'please-keep-me' extraLabelToRemove: 'please-remove-me' extraLabelToRemove1: 'please-remove-me' extraLabelToRemove2: 'please-remove-me' extraLabelToRemove4: 'please-remove-me' extraLabelToRemove3: 'please-remove-me' extraLabelToRemove5: 'please-remove-me' Copy Prometheus or NerdGraph? There are advantages to both dropping data using the method described on this page and using NerdGraph. This section is intended to help you figure out which method is better for your specific needs and preferences. Considerations for the Prometheus config file method With this method, your dropped data never leaves the associated Prometheus instance. This is a valuable feature if bytes transferred is a cost consideration on the app hosting side. However, this method may be less appealing than the NerdGraph option due to the following considerations: Maintained via config yaml files that need to be loaded onto each Prometheus instance (or via a shared storage mechanism) Requires access to Prometheus server, meaning that either: The server needs to be restarted Served must be be accessed at port with path /-/reload (assuming the server has lifecycle management enabled as described here in the Prometheus configuration docs. Considerations the NerdGraph method NerdGraph is a great option if you want to manage all your data dropping in a single place. It can also be updated easily via the API and requires no restart or interaction with Prometheus. However, this method applies rules to all incoming data points. This means that you should set up your rules with careful consideration using WHERE filtering. For more information, see Drop data using NerdGraph. Learn more Send Prometheus metric data to New Relic Prometheus High Availability (HA)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.20503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop data using <em>Prometheus</em> <em>remote</em> <em>write</em>",
        "sections": "Drop data using <em>Prometheus</em> <em>remote</em> <em>write</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": " target the metric name using the __name__ label in combination with the instance name. <em>remote_write</em>: - url: https:&#x2F;&#x2F;metric-api.newrelic.com&#x2F;<em>prometheus</em>&#x2F;v1&#x2F;<em>write</em>?<em>prometheus</em>_server=macbook-server-cluster bearer_token: &lt;redacted&gt; <em>write</em>_relabel_configs: - source_labels: [&#x27;__name__&#x27;, &#x27;instance&#x27;] regex"
      },
      "id": "60e809e4e7b9d298bafc1035"
    },
    {
      "sections": [
        "Prometheus High Availability (HA)",
        "Tip",
        "External labels",
        "Prometheus Operator",
        "Standalone Prometheus"
      ],
      "title": "Prometheus High Availability (HA)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "3c0fddd6e878f30f8ba4c132f537b88cd47f2eba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure/prometheus-high-availability-ha/",
      "published_at": "2021-10-24T17:29:20Z",
      "updated_at": "2021-03-13T02:41:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are using our Prometheus remote write integration in a high-availability (HA) configuration, you need to make sure your Prometheus servers aren't sending multiple copies of the same metrics to New Relic. This document describes how you can configure your remote write integration so that New Relic does not keep duplicated metrics. Tip For information on standard Prometheus remote write integration without using a high-availability configuration, see Set up your Prometheus remote write integration. External labels New Relic requires two external labels to deduplicate data from replicas in a high-availability configuration: Label name Description Example value prometheus A label whose value identifies the name of a high-availability cluster or group of Prometheus servers. monitoring-cluster prometheus_replica A label whose value identifies the unique replica sending this data. replica-1 The remaining sections explain how labels work with Prometheus Operator and standalone Prometheus. Prometheus Operator These external labels are added by default if you use Prometheus Operator version 0.19.0 (or higher). This applies whether you use Prometheus Operator directly or via the helm chart. The operator sets the value of the prometheus label (the one identifying a cluster) as <prometheus deployment namespace>/<prometheus deployment name>. For example, if your namespace for the Prometheus deployment is monitoring and the name of the deployment is prometheus-cluster1, the value is monitoring/prometheus-cluster1. The operator sets the value of the prometheus_replica label as the name of the pod for each replica. This follows the format replica-<replica number>, where the number is the ordinal of that replica (for example, the first replica is named replica-1). Tip If you still see duplicate copies of replica data, make sure you do not have replicaExternalLabelName or prometheusExternalLabelName in your Prometheus spec or chart configuration because these overrides change the label name. Standalone Prometheus When deploying a Prometheus server directly, you need to add the external labels to the configuration file. Here are two different example configurations for replicas within the same high-availability cluster: Replica 1 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-1 Copy Replica 2 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-2 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.10246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Prometheus</em> High Availability (HA)",
        "sections": "<em>Prometheus</em> High Availability (HA)",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": "If you are using our <em>Prometheus</em> <em>remote</em> <em>write</em> integration in a high-availability (HA) configuration, you need to make sure your <em>Prometheus</em> servers aren&#x27;t sending multiple copies of the same metrics to New Relic. This document describes how you can <em>configure</em> your <em>remote</em> <em>write</em> integration so that New"
      },
      "id": "6044e621196a67b846960f6b"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration": [
    {
      "sections": [
        "Remote write errors and error messages",
        "Common errors and issues",
        "Configuration errors",
        "400: bad request error",
        "413: request entity too large error",
        "429: rate limit error",
        "Investigate error messages"
      ],
      "title": "Remote write errors and error messages",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "0d190be5dc4fd91ce6bbcef7343d01f75670ca51",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-remote-write/remote-write-errors-error-messages/",
      "published_at": "2021-10-24T17:50:22Z",
      "updated_at": "2021-08-08T19:27:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This resource contains information about common errors and error messages that may alert you to issues with data visibility and availability, as well as information about how to respond. Common errors and issues If you receive an integration error message from New Relic or error messages in your Prometheus server logs after restarting your Prometheus server, there are several actions you can take to troubleshoot and get data flowing properly. Below are a few tips regarding common issues and error messages. For specific information on how to query NrIntegrationError events, see Investigate error messages below. Configuration errors Missing or incorrect characters in the remote write URL in the config file (for example the endpoint, license key, or prometheus_server name) or incorrect placement of the information in the file will result in the Prometheus server not starting, remote write not working properly, or errors appearing in Prometheus server logs. 400: bad request error If no data appears with a bad request error, check your configuration file to confirm that the placement of the remote write information is correct, and that there are no missing or incorrect characters. 413: request entity too large error This means you have sent a request in which one or more fields, or the entire payload, has exceeded our limits. 429: rate limit error This means you have hit a rate limit on the amount of data being sent at one time (for example cardinality or data points per minute). You can troubleshoot by reducing the amount of Prometheus or general metric data you are sending, or by requesting a rate-limit increase. Investigate error messages You can investigate error messages in New Relic by doing either or both of the following. Run a NRQL query of the NrIntegrationError event and examine the message attribute. Investigate individual errors in time to see when and where they occur and any simultaneously occurring issues, and perform targeted troubleshooting based on what you find out. For example: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' TIMESERIES Copy If you’ve validated that you can send data successfully but are unable to query it, you may be running into other kinds of limits, like the inspected count limit. This may manifest itself as an error message during the integration process that says: Unable to retrieve data for Prometheus data source <name>.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.9631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Remote</em> <em>write</em> errors <em>and</em> error messages",
        "sections": "<em>Remote</em> <em>write</em> errors <em>and</em> error messages",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": " error messages below. Configuration errors Missing or incorrect characters in the <em>remote</em> <em>write</em> URL in the config file (for example the endpoint, license key, or <em>prometheus</em>_server name) or incorrect placement of the information in the file will result in the <em>Prometheus</em> server not starting, <em>remote</em> <em>write</em>"
      },
      "id": "6044e65d196a67914a960f6b"
    },
    {
      "sections": [
        "Drop data using Prometheus remote write",
        "Tip",
        "Drop entire metric data points from remote write integration",
        "Example",
        "Drop specific labels or attributes from data points",
        "Prometheus or NerdGraph?",
        "Considerations for the Prometheus config file method",
        "Considerations the NerdGraph method",
        "Learn more"
      ],
      "title": "Drop data using Prometheus remote write",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "f3e07dd4f6bbdb65881f13035af5af172c5409e7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure/remote-write-drop-data/",
      "published_at": "2021-10-24T16:14:03Z",
      "updated_at": "2021-07-09T08:33:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can drop data you don't want to keep by changing the remote_write section of the YAML config file. Tip You can also drop remote write data using NerdGraph. For more information, see Drop data using NerdGraph. Drop entire metric data points from remote write integration If a target is sending a noisy metric that you don't want sent to New Relic, you can specify that New Relic should drop that data. Example Let's say you don't want to receive data for the metric node_memory_active_bytes from an instance running at localhost:9100. Using the write_relabel_config entry shown below, you can target the metric name using the __name__ label in combination with the instance name. remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=macbook-server-cluster bearer_token: <redacted> write_relabel_configs: - source_labels: ['__name__', 'instance'] regex: 'node_memory_active_bytes;localhost:9100' action: 'drop' Copy This tells Prometheus that you want to do some action against metrics with these labels. To limit which metrics with these labels are affected, you must include some value for regex. By default this value is set to .* and it will include all metrics. In this case, it will drop all metric data points coming out of Prometheus via remote write. Drop specific labels or attributes from data points If a target is sending specific labels or attributes you're not interested in receiving, you can drop these from the metrics you receive. Example Let's say one of your targets is sending a bunch of extra attributes you're not interested in receiving. These might include things like high cardinality attributes such as unique machine identifiers, JVM IDs, or similar. In this case, you need to change both the remote_write and the scrape_configs section of the YAML file. The result will look something like this: remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=macbook-server-cluster bearer_token: <redacted> write_relabel_configs: - regex: 'extraLabelToRemove.*' action: 'labeldrop' ... scrape_configs: # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config. - job_name: 'node' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9100'] labels: group: 'production' keepLabelName1: 'please-keep-me' extraLabelToRemove: 'please-remove-me' extraLabelToRemove1: 'please-remove-me' extraLabelToRemove2: 'please-remove-me' extraLabelToRemove4: 'please-remove-me' extraLabelToRemove3: 'please-remove-me' extraLabelToRemove5: 'please-remove-me' Copy Prometheus or NerdGraph? There are advantages to both dropping data using the method described on this page and using NerdGraph. This section is intended to help you figure out which method is better for your specific needs and preferences. Considerations for the Prometheus config file method With this method, your dropped data never leaves the associated Prometheus instance. This is a valuable feature if bytes transferred is a cost consideration on the app hosting side. However, this method may be less appealing than the NerdGraph option due to the following considerations: Maintained via config yaml files that need to be loaded onto each Prometheus instance (or via a shared storage mechanism) Requires access to Prometheus server, meaning that either: The server needs to be restarted Served must be be accessed at port with path /-/reload (assuming the server has lifecycle management enabled as described here in the Prometheus configuration docs. Considerations the NerdGraph method NerdGraph is a great option if you want to manage all your data dropping in a single place. It can also be updated easily via the API and requires no restart or interaction with Prometheus. However, this method applies rules to all incoming data points. This means that you should set up your rules with careful consideration using WHERE filtering. For more information, see Drop data using NerdGraph. Learn more Send Prometheus metric data to New Relic Prometheus High Availability (HA)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.20503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop data using <em>Prometheus</em> <em>remote</em> <em>write</em>",
        "sections": "Drop data using <em>Prometheus</em> <em>remote</em> <em>write</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": " target the metric name using the __name__ label in combination with the instance name. <em>remote_write</em>: - url: https:&#x2F;&#x2F;metric-api.newrelic.com&#x2F;<em>prometheus</em>&#x2F;v1&#x2F;<em>write</em>?<em>prometheus</em>_server=macbook-server-cluster bearer_token: &lt;redacted&gt; <em>write</em>_relabel_configs: - source_labels: [&#x27;__name__&#x27;, &#x27;instance&#x27;] regex"
      },
      "id": "60e809e4e7b9d298bafc1035"
    },
    {
      "sections": [
        "Prometheus High Availability (HA)",
        "Tip",
        "External labels",
        "Prometheus Operator",
        "Standalone Prometheus"
      ],
      "title": "Prometheus High Availability (HA)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "3c0fddd6e878f30f8ba4c132f537b88cd47f2eba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure/prometheus-high-availability-ha/",
      "published_at": "2021-10-24T17:29:20Z",
      "updated_at": "2021-03-13T02:41:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are using our Prometheus remote write integration in a high-availability (HA) configuration, you need to make sure your Prometheus servers aren't sending multiple copies of the same metrics to New Relic. This document describes how you can configure your remote write integration so that New Relic does not keep duplicated metrics. Tip For information on standard Prometheus remote write integration without using a high-availability configuration, see Set up your Prometheus remote write integration. External labels New Relic requires two external labels to deduplicate data from replicas in a high-availability configuration: Label name Description Example value prometheus A label whose value identifies the name of a high-availability cluster or group of Prometheus servers. monitoring-cluster prometheus_replica A label whose value identifies the unique replica sending this data. replica-1 The remaining sections explain how labels work with Prometheus Operator and standalone Prometheus. Prometheus Operator These external labels are added by default if you use Prometheus Operator version 0.19.0 (or higher). This applies whether you use Prometheus Operator directly or via the helm chart. The operator sets the value of the prometheus label (the one identifying a cluster) as <prometheus deployment namespace>/<prometheus deployment name>. For example, if your namespace for the Prometheus deployment is monitoring and the name of the deployment is prometheus-cluster1, the value is monitoring/prometheus-cluster1. The operator sets the value of the prometheus_replica label as the name of the pod for each replica. This follows the format replica-<replica number>, where the number is the ordinal of that replica (for example, the first replica is named replica-1). Tip If you still see duplicate copies of replica data, make sure you do not have replicaExternalLabelName or prometheusExternalLabelName in your Prometheus spec or chart configuration because these overrides change the label name. Standalone Prometheus When deploying a Prometheus server directly, you need to add the external labels to the configuration file. Here are two different example configurations for replicas within the same high-availability cluster: Replica 1 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-1 Copy Replica 2 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-2 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.10246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Prometheus</em> High Availability (HA)",
        "sections": "<em>Prometheus</em> High Availability (HA)",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": "If you are using our <em>Prometheus</em> <em>remote</em> <em>write</em> integration in a high-availability (HA) configuration, you need to make sure your <em>Prometheus</em> servers aren&#x27;t sending multiple copies of the same metrics to New Relic. This document describes how you can <em>configure</em> your <em>remote</em> <em>write</em> integration so that New"
      },
      "id": "6044e621196a67b846960f6b"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/troubleshooting/debug-issues-data-sent-metric-api-prometheus-integration": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our <em>Prometheus</em> <em>integrations</em>: You can use Grafana or other query tools via New Relic&#x27;s <em>Prometheus</em>&#x27; API. You benefit from more"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "3c8907d358e49c8dde5cab6dfa386deb5407d335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-08-08T19:29:48Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.71554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "sections": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": ". If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for <em>Prometheus</em> OpenMetrics <em>integrations</em>, New Relic will apply rate limits to your account and create an associated NrIntegrationError event."
      },
      "id": "6045054528ccbc2c342c606b"
    },
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-10-24T16:31:50Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.196396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.1506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our <em>Prometheus</em> <em>integrations</em>: You can use Grafana or other query tools via New Relic&#x27;s <em>Prometheus</em>&#x27; API. You benefit from more"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "3c8907d358e49c8dde5cab6dfa386deb5407d335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-08-08T19:29:48Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.71554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "sections": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": ". If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for <em>Prometheus</em> OpenMetrics <em>integrations</em>, New Relic will apply rate limits to your account and create an associated NrIntegrationError event."
      },
      "id": "6045054528ccbc2c342c606b"
    },
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-10-24T16:31:50Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.196396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/troubleshooting/get-logs-prometheus-integration": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.1506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our <em>Prometheus</em> <em>integrations</em>: You can use Grafana or other query tools via New Relic&#x27;s <em>Prometheus</em>&#x27; API. You benefit from more"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "3c8907d358e49c8dde5cab6dfa386deb5407d335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-08-08T19:29:48Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.71554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "sections": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": ". If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for <em>Prometheus</em> OpenMetrics <em>integrations</em>, New Relic will apply rate limits to your account and create an associated NrIntegrationError event."
      },
      "id": "6045054528ccbc2c342c606b"
    },
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-10-24T16:31:50Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.196396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/troubleshooting/get-scraper-metrics-prometheus-integration": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our <em>Prometheus</em> <em>integrations</em>: You can use Grafana or other query tools via New Relic&#x27;s <em>Prometheus</em>&#x27; API. You benefit from more"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "3c8907d358e49c8dde5cab6dfa386deb5407d335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-08-08T19:29:48Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.71553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "sections": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": ". If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for <em>Prometheus</em> OpenMetrics <em>integrations</em>, New Relic will apply rate limits to your account and create an associated NrIntegrationError event."
      },
      "id": "6045054528ccbc2c342c606b"
    },
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-10-24T16:31:50Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.196396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our <em>Prometheus</em> <em>integrations</em>: You can use Grafana or other query tools via New Relic&#x27;s <em>Prometheus</em>&#x27; API. You benefit from more"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "3c8907d358e49c8dde5cab6dfa386deb5407d335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-08-08T19:29:48Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.71553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "sections": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": ". If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for <em>Prometheus</em> OpenMetrics <em>integrations</em>, New Relic will apply rate limits to your account and create an associated NrIntegrationError event."
      },
      "id": "6045054528ccbc2c342c606b"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-10-24T16:26:26Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.23965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our <em>Prometheus</em> <em>integrations</em>: You can use Grafana or other query tools via New Relic&#x27;s <em>Prometheus</em>&#x27; API. You benefit from more"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-10-24T16:31:50Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.196396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-10-24T16:26:26Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.23965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our <em>Prometheus</em> <em>integrations</em>: You can use Grafana or other query tools via New Relic&#x27;s <em>Prometheus</em>&#x27; API. You benefit from more"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "3c8907d358e49c8dde5cab6dfa386deb5407d335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-08-08T19:29:48Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.71553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "sections": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": ". If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for <em>Prometheus</em> OpenMetrics <em>integrations</em>, New Relic will apply rate limits to your account and create an associated NrIntegrationError event."
      },
      "id": "6045054528ccbc2c342c606b"
    },
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-10-24T16:31:50Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.196396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/troubleshooting/sparse-data-missing-metrics-data-gaps": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our <em>Prometheus</em> <em>integrations</em>: You can use Grafana or other query tools via New Relic&#x27;s <em>Prometheus</em>&#x27; API. You benefit from more"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "3c8907d358e49c8dde5cab6dfa386deb5407d335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-08-08T19:29:48Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.71553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "sections": "Rate limit errors (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": ". If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for <em>Prometheus</em> OpenMetrics <em>integrations</em>, New Relic will apply rate limits to your account and create an associated NrIntegrationError event."
      },
      "id": "6045054528ccbc2c342c606b"
    },
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-10-24T16:31:50Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.196396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/view-query-data/supported-promql-features": [
    {
      "sections": [
        "Translate PromQL queries to NRQL",
        "Tip",
        "Prometheus and New Relic metric types",
        "Mapping between NRQL and our PromQL-style queries",
        "PromQL-style query example",
        "NRQL query example",
        "Filter examples",
        "PromQL-style to NRQL query examples",
        "For more help"
      ],
      "title": "Translate PromQL queries to NRQL",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "fcf45fb8fb49f9d22f74574c2e7032533377e584",
      "image": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql/images/PROMQL-query-2.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql/",
      "published_at": "2021-10-24T16:03:13Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Do you have a PromQL query you’d like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style query language to explore your Prometheus OpenMetrics integration data along with other data sent to New Relic. Tip To run PromQL-style queries in New Relic One, go to the query builder advanced PromQL-style mode. Prometheus and New Relic metric types The different metric types supported by Prometheus and New Relic are related to each other: New Relic Prometheus Description Count Counter The Prometheus counter is a cumulative sum while the New Relic count is a delta sum. For example, if you see 2 requests in the first reporting period and 3 requests in the second reporting period. The Prometheus counter will report 2 and then 5, while the New Relic count will report 2 and then 3. Gauge Gauge A Prometheus gauge is similar to a New Relic gauge. Multiple counts Histogram Prometheus automatically maps a histogram to a set of counters. In New Relic, these counters should be changed to deltas and reported as counts. Gauges and counts Summary Prometheus represents a Summary with a given basename as the following time series: a basename_sum a basename_count and 0 or more of basename{quantile=\".xx\"...} metrics New Relic maps the _sum as a Summary, the _count as a Counter, and each quantile metric as a Gauge. Summary (No equivalent in Prometheus) New Relic has a distinct metric type called a summary that is different than the Prometheus summary. It is designed for reporting aggregated discrete events so that you can query the count, sum, min, max, and average values. Mapping between NRQL and our PromQL-style queries Tip To see how New Relic translates PromQL-style queries to NRQL, write a query in the query builder PromQL-style tab, then switch to the NRQL tab. This table shows the mapping between NRQL and our PromQL-style queries when exploring data. For more contextual information, see the examples. Description Mapping between NRQL and PromQL-style queries Search for attributes: Explore the attributes on the container_memory_usage_bytes metric. PromQL: container_memory_usage_bytes Copy NRQL: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy Find attribute's value: Explore the current value of the container_memory_usage_bytes metric for unique id attributes. PromQL: sum(container_memory_usage_bytes) by (id) Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy Visualize the attribute's value: Chart the value of the container_memory_usage_bytes metric with the given id attribute value. PromQL: container_memory_usage_bytes{id=\"/\"} Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = '/' TIMESERIES Copy PromQL-style query example 1. Start your query. When exploring your data for a particular metric in PromQL, such as memory by container usage in bytes, you can start with a query such as: container_memory_usage_bytes Copy This will chart all the unique metric timeseries for the input metric. 2. Filter the query results. Looking at the data, you can add more query parameters to filter down the number of metric timeseries. For example, if you only want timeseries where the id is /, the PromQL-style query will be: container_memory_usage_bytes{id=\"/\"} Copy PromQL-style example: To filter the data, run this PromQL-style query: container_memory_usage_bytes { id=\"/\"}. NRQL query example 1. Query available metrics. To explore your data, start by looking at all the available metrics. Use the following NRQL query: FROM Metric SELECT uniques(metricName) Copy 2. Find unique attributes. Once you have found the metric you want to review, such as container_memory_usage_bytes, you can find the unique attributes with the following query: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy The results will show each available attribute key and the value type (string, boolean, or number). 3. Aggregate and chart the metrics. To chart metrics using NRQL, you first need an aggregation function. For example, you can use latest for gauges, sum for counts, and average for summaries. As the following chart shows, all the unique timeseries are aggregated into one unique timeseries by default: one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes'. 4. View metrics by ID. To view the unique metric timeseries with various id values, run the following query: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT latest(container_memory_usage_bytes) FACET id. 5. Add the selected ID to the query. Next you can select an id value and put it in the NRQL where clause. FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = \"/\" timeseries Copy one.newrelic.com > Query your data: This example shows the data displayed after running From Metric select latest(container_memory_usage_bytes) where id = \"/\" timeseries. Filter examples Both our PromQL-style query language and NRQL provide syntax to filter down the number of unique metric timeseries. PromQL-style uses brackets to filter. NRQL uses a WHERE clause. Here are some example queries: Description PromQL-style and NRQL queries Select data with specific values. PromQL: go_memstats_heap_alloc_bytes{job=\"apiserver\", instance=\"1234\"}) Copy NRQL: To only select data with specific values in NRQL, use the WHERE clause with =. In this example, all data must have the selected value for job and handler. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE job = 'apiserver' AND instance = '1234' TIMESERIES Copy Select data with multiple values. PromQL: go_memstats_heap_alloc_bytes{environment=~\"staging|testing|development\",method!=\"GET\"} Copy NRQL: In NRQL use the in clause to select multiple values for an attribute and the != sign to select all values but the one listed. In this example, the environment can be staging, testing, or development, and the method cannot be GET. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE environment IN ('staging', 'testing', 'development') AND method != 'GET' TIMESERIES Copy Select data using partial string values. PromQL: go_memstats_heap_alloc_bytes{job=~\"api.*\"} Copy NRQL: In NRQL use the LIKE clause to match part of a string value. In this example, all data will be returned where the job attributes start with api. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHEREe job LIKE 'api%' TIMESERIES Copy PromQL-style to NRQL query examples You can simulate the following PromQL-style queries with NRQL queries: Description PromQL-style and NRQL queries Measure the per second rate over the last minute of the http_request_total metric. PromQL: sum(rate(http_requests_total[1m])) Copy NRQL: FROM Metric SELECT rate(sum(http_request_total), 1 second) TIMESERIES 1 minute Copy Chart the difference of the two metrics, then divide by 1024. PromQL: (instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 Copy NRQL: FROM Metric SELECT (latest(instance_memory_limit_bytes) - latest(instance_memory_usage_bytes)) / 1024 TIMESERIES Copy Provide the summed rate per 30-second interval by each handler. PromQL: sum(rate(http_requests_total[30s])) by (handler) Copy NRQL: FROM Metric SELECT rate(sum(http_requests_total), 30 seconds) FACET handler TIMESERIES Copy Chart the difference in the two metrics where the instance is named foo and the fstype is either ext4 or xfs. PromQL: (node_filesystem_free_bytes{instance='foo',fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{instance='foo',fstype=~\"ext4|xfs\"}) Copy NRQL: FROM Metric SELECT latest(node_filesystem_free_bytes) / latest(node_filesystem_size_bytes) WHERE instance = 'foo' AND fstype IN ('ext4', 'xfs') Copy For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.60559,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Translate PromQL <em>queries</em> to NRQL",
        "sections": "<em>Prometheus</em> <em>and</em> New Relic metric types",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Do you have a PromQL <em>query</em> you’d like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style <em>query</em> language to explore your <em>Prometheus</em> OpenMetrics integration <em>data</em> along with other <em>data</em> sent to New"
      },
      "id": "603ead4528ccbcbecfeba77b"
    },
    {
      "sections": [
        "View and query your Prometheus data",
        "Default attributes for the OpenMetrics integration",
        "Default attributes for the remote write integration",
        "NRQL query examples",
        "Get metric names",
        "Get the attributes for a metric",
        "Get the values for an attribute in OpenMetrics",
        "Build the query",
        "Get metric values",
        "Get a chart of the metric",
        "Query counter metrics (deltas)",
        "View connected Redis clients per pod with OpenMetrics",
        "Docker: View average memory free for scraped endpoints",
        "Kubernetes: View average memory usage for pods in a deployment",
        "View data in New Relic",
        "Create histograms and summaries"
      ],
      "title": "View and query your Prometheus data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "91a0388492ae73a9ddb8a1701b639a6b6a71822a",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/view-query-your-prometheus-data/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-03-16T04:13:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To query and visualize the metrics collected for your Prometheus OpenMetrics or remote write integration with New Relic, you can use NRQL. You can also translate your PromQL-style queries to NRQL using either Grafana or the query builder. All metrics for Docker and Kubernetes are stored in the Metric type. Default attributes for the OpenMetrics integration By default, the following attributes will be added to all metrics for Docker and Kubernetes integrations: Default attributes (all integrations) Description clusterName The name of the cluster provided in the scraper configuration. integrationName The name of this integration (nri-prometheus). integrationVersion The version of the integration; for example, 0.2.0. metricName The name of the metric itself. nrMetricType The type of the New Relic Metric type; for example, Gauges. promMetricType The metric type of the Prometheus metric scrapedEndpoint The URL of the endpoint is being scraped. Kubernetes: If the scraper is running in Kubernetes, New Relic also adds the following attributes to all the metrics: Additional Kubernetes attributes Description deploymentName Name of the deployment, if scraping a pod. label The Kubernetes labels of the object being scraped, prefixed by \"label\". namespaceName Name of the namespace. nodeName Name of the node where the pod being scraped is running, if applicable. podName Name of the pod being scraped, if applicable. serviceName Name of the service being scraped, if applicable Default attributes for the remote write integration By default, the following attributes will be added to Prometheus remote write metrics: Default attributes (all integrations) Description prometheus_server A user supplied label specified as a Prometheus remote write URL parameter. The value supplied should be unique as it is intended to differentiate between source Prometheus servers at query time. Unspecified by default. newrelic.source The name of the New Relic ingest point (prometheusAPI). instrumentation.provider prometheus instrumentation.name remote-write instrumentation.source A user supplied identifier for the source of the Prometheus data that matches the value of prometheus_server. instrumentation.version Used to identify the version of the remote write API; for example, 0.0.1. NRQL query examples When you build queries, be aware that there is no linking between the metrics, entities, and attributes. Use the following NRQL queries to find out which metrics are available and which attributes are present on these metrics: Get metric names To get all metric names for OpenMetrics: FROM Metric SELECT uniques(metricName) Copy To get metric names for a remote write integration: FROM Metric SELECT uniques(metricName) WHERE instrumentation.provider='prometheus' AND instrumentation.name='remote-write' Copy To get metric names for a remote write integration from a single Prometheus source: FROM Metric SELECT uniques(metricName) WHERE instrumentation.provider='prometheus' AND instrumentation.name='remote-write' AND instrumentation.source='<ds>' Copy To get metric names for a specific OpenMetrics endpoint: FROM Metric SELECT uniques(metricName) WHERE scrapedEndpoint='<ep>' Copy To get metric names for a specific OpenMetrics cluster, namespace, or pod: FROM Metric SELECT uniques(metricName) WHERE clusterName='<cn>' Copy FROM Metric SELECT uniques(metricName) WHERE namespaceName='<ns>' Copy FROM Metric SELECT uniques(metricName) WHERE podName='<pod>' Copy Get the attributes for a metric To get all attributes for the selected metric: FROM Metric SELECT keyset() WHERE metricName='<mn>' Copy Get the values for an attribute in OpenMetrics The autocomplete will show all values of the attribute, regardless of the pod. To determine the attribute values for a specific pod: FROM Metric SELECT uniques(<attribute>) WHERE metricName='<mn>' AND podName='<pod>' Copy Build the query Using metric name and attributes, you can query your data. For more information about facets, time series, and time selection, see the NRQL documentation. To build PromQL-style queries, see our docs. Get metric values To get raw metric values: FROM Metric SELECT <metricName> WHERE <attribute>='<value>' Copy Get a chart of the metric To get a chart of the metric with an aggregator of average, min, max, or sum: FROM Metric SELECT <aggregator>(<metricname>) WHERE <attribute>='<value>' TIMESERIES Copy Query counter metrics (deltas) Currently the integration calculates the deltas for counter metrics. This is why queries on counter metrics will show the deltas of the counter instead of the absolute value of the counter. View connected Redis clients per pod with OpenMetrics Docker: This example assumes you are scraping Redis exporters. To view the number of connected Redis clients per endpoint in a cluster: FROM Metric SELECT latest(redis_connected_clients) WHERE clusterName='my-cluster' FACET scrapedEndpoint TIMESERIES Copy Kubernetes: This example assumes that you have Redis pods with the Redis exporter installed. To view the number of connected Redis clients per pod in the default namespace: FROM Metric SELECT latest(redis_connected_clients) WHERE namespaceName='default' FACET podName TIMESERIES Copy Docker: View average memory free for scraped endpoints This example assumes you are scraping node exporters for Docker and want to use OpenMetrics. To view average memory free for all scraped endpoints in a cluster: FROM Metric SELECT average(node_memory_MemFree_bytes) WHERE clusterName='my-cluster' Copy Kubernetes: View average memory usage for pods in a deployment To view average memory usage for all pods in a Kubernetes deployment using OpenMetrics: FROM Metric SELECT average(container_memory_usage_bytes) WHERE deploymentName='my-app-deployment' AND namespaceName='default' Copy View data in New Relic When you query the data, you can view the results in the New Relic UI. You can also visualize the data as charts, histograms, etc. To view the NRQL query results for your Prometheus integration's data: Go to one.newrelic.com > Query your data. For more information, see New Relic's query builder documentation. Create histograms and summaries With remote write or version 1.2.0 or higher of the Prometheus OpenMetrics integration, you can create histograms and percentiles (summaries) of your data. The OpenMetrics data is based on New Relic's guidelines in GitHub for higher level metric abstractions, while the remote write data closely matches the schema of the original Prometheus data. Data presentation Comments Histograms A bucket <basename>_bucket{le=\"42\"} will be sent as this: For OpenMetrics: <basename>_buckets For remote write: <basename>_bucket The dimension will be this: For OpenMetrics: {histogram.bucket.upperBound=\"42\"} For remote write: {histogram.bucket.le=\"42\"} Percentiles Quantiles (summaries) are transformed into percentiles. A metric <basename>{quantile=\"0.3\"} will be sent to New Relic as <basename>.percentiles. The dimension will be this: {percentile=\"30\"} NRQL has two functions that work on remote write ingested PromQL: bucketPercentile() and histogram(). The links include query examples.These two functions don't work on OpenMetrics ingested buckets. To better support visualization of histograms, percentiles are calculated based on the histogram metrics and sent to New Relic. To configure the calculated percentiles for OpenMetrics, use the percentiles configuration option.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.60542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>View</em> <em>and</em> <em>query</em> your <em>Prometheus</em> <em>data</em>",
        "sections": "<em>View</em> <em>and</em> <em>query</em> your <em>Prometheus</em> <em>data</em>",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " identifier for the source of the <em>Prometheus</em> <em>data</em> that matches the value of <em>prometheus</em>_server. instrumentation.version Used to identify the version of the remote write API; for example, 0.0.1. NRQL <em>query</em> examples When you build queries, be aware that there is no linking between the metrics, entities"
      },
      "id": "603eb04be7b9d20f9d2a07eb"
    },
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric <em>data</em> to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " de-duplicate <em>data</em> from HA-pairs on ingest. Reminders: You will need to manage your <em>Prometheus</em> servers. You can reduce your storage retention. Fewer <em>query</em> loads to the server. Recommendations: Evaluate your observability needs to manage your <em>data</em> volumes better: The scrape interval is the biggest"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/view-query-data/translate-promql-queries-nrql": [
    {
      "sections": [
        "Supported PromQL Features",
        "Important",
        "Supported features",
        "Aggregation operators and functions",
        "Arithmetic binary operators",
        "Logical operators",
        "Date/time functions",
        "Mathematical functions",
        "Rate-like functions",
        "Predictive functions",
        "Time-series selectors",
        "PromQL troubleshooting",
        "Metric types",
        "Limits",
        "Range vector selectors (sliding windows and smoothing behavior)",
        "Query range and data scraping intervals"
      ],
      "title": "Supported PromQL Features",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "d4a93b9db3bfe5639ed01968b6e55a8e0aaa9389",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/supported-promql-features/",
      "published_at": "2021-10-24T15:57:15Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic supports PromQL-style queries, and our query builder offers a PromQL-style query mode that translates PromQL syntax queries into the closest NRQL approximation. Although the method of approximation means that a handful of edge cases are not fully supported, it provides coverage for an overwhelming majority of queries, supporting over 99.5% of queries across the 7.8 million top Grafana dashboard downloads. Read on to learn about how we work with PromQL queries, as well as differences between standard PromQL and our PromQL-like query language we want you to be aware of. Important For general information about Prometheus queries and operators, see the Prometheus.io documentation. Supported features We support the following aggregation, arithmetic, mathematical, and rate-like functions. As we continue to expand support for Prometheus and PromQL, this list will be updated. Aggregation operators and functions Aggregation operators: avg() count() min() max() quantile() stddev() stdvar() sum() topk() Aggregation functions: histogram_quantile() <aggregation>_over_time() functions: avg_over_time count_over_time min_over_time max_over_time quantile_over_time stdev_over_time stvar_over_time sum_over_time Arithmetic binary operators + (addition) - (subtraction) * (multiplication) / (division) % (percent) ^ (power/exponents) Logical operators and or Date/time functions day_of_month() day_of_week() days_in_month() hour() minute() month() time() timestamp() year() Mathematical functions abs() ceil() clamp_max() clamp_min() exp() floor() ln() log10() log2() round() sqrt() Rate-like functions delta() deriv() idelta() increase() irate() rate() Predictive functions predict_linear Time-series selectors We offer support for PromQL time-series selectors including the following: instant vector selectors range series selectors offset modifier Important We only support offset queries if every vector in the query has the same offset value. PromQL troubleshooting This section describes differences in behavior between PromQL and our PromQL-style query behavior and how to work with and around these differences. This is particularly relevant if you want to use advanced queries and our PromQL-style mode in the query builder. Metric types Prometheus recommendations note that you should only use some functions, like delta(), on gauges, and only use others like rate() and increase() on counters, but queries in Prometheus still work most of the time even if they don’t follow those instructions. However, because NRDB converts PromQL-style accumulating counters to delta counters, our implementation is unforgiving when using these functions on the wrong data type and will produce different or incorrect answers. For this reason, it's best to follow all Prometheus recommendations when working with our PromQL-style queries, even if you don't follow these recommendations in Prometheus. Limits In order to ensure the stability and performance of our system for all users, we place some limits on what queries can be run. In all cases, we enforce a limit of 366 steps in range queries. We also default to only returning 100 timeseries from queries by default. If you want to see more (or fewer), you need to explicitly add a topk() to your query. (Note that the topk() implementation in our PromQL-style query is different from that of Prometheus.) We limit the total memory a query can use. This means that requests for large numbers of time steps or large numbers of time series may be rejected, particularly if they are combined with an aggregation like unique count or quantile which require significantly more memory to compute than simple arithmetic aggregations. Range vector selectors (sliding windows and smoothing behavior) We provide support for sliding window timeseries aggregations. For more information, see our NRQL syntax, clauses, and functions resource and our sliding windows deep dive. For information on translating between NRQL and our PromQL-style language, see Translate PromQL queries to NRQL. Query range and data scraping intervals The range of your query in PromQL must be larger than the duration of the step size of the query to avoid the error \"TIMESERIES bucket size is larger than the current time window\". We inspect data up to one minute old when servicing instant queries. If your scrape interval is greater than 1 minute, some queries may result in No data found. Avoid this by sending data at least once per minute. If the timeseries unit for your NRQL query is less than the scrape interval for your application, some periods will lack data, and the resulting graph may be jagged or contain peaks and valleys. In general, set the step size to your scrape interval, or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.6061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Query</em> range <em>and</em> <em>data</em> scraping intervals",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " with and around these differences. This is particularly relevant if you want to use advanced queries and our PromQL-style mode in the <em>query</em> builder. Metric types <em>Prometheus</em> recommendations note that you should only use some functions, like delta(), on gauges, and only use others like rate() and increase"
      },
      "id": "603e9523e7b9d292ec2a07ce"
    },
    {
      "sections": [
        "View and query your Prometheus data",
        "Default attributes for the OpenMetrics integration",
        "Default attributes for the remote write integration",
        "NRQL query examples",
        "Get metric names",
        "Get the attributes for a metric",
        "Get the values for an attribute in OpenMetrics",
        "Build the query",
        "Get metric values",
        "Get a chart of the metric",
        "Query counter metrics (deltas)",
        "View connected Redis clients per pod with OpenMetrics",
        "Docker: View average memory free for scraped endpoints",
        "Kubernetes: View average memory usage for pods in a deployment",
        "View data in New Relic",
        "Create histograms and summaries"
      ],
      "title": "View and query your Prometheus data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "91a0388492ae73a9ddb8a1701b639a6b6a71822a",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/view-query-your-prometheus-data/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-03-16T04:13:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To query and visualize the metrics collected for your Prometheus OpenMetrics or remote write integration with New Relic, you can use NRQL. You can also translate your PromQL-style queries to NRQL using either Grafana or the query builder. All metrics for Docker and Kubernetes are stored in the Metric type. Default attributes for the OpenMetrics integration By default, the following attributes will be added to all metrics for Docker and Kubernetes integrations: Default attributes (all integrations) Description clusterName The name of the cluster provided in the scraper configuration. integrationName The name of this integration (nri-prometheus). integrationVersion The version of the integration; for example, 0.2.0. metricName The name of the metric itself. nrMetricType The type of the New Relic Metric type; for example, Gauges. promMetricType The metric type of the Prometheus metric scrapedEndpoint The URL of the endpoint is being scraped. Kubernetes: If the scraper is running in Kubernetes, New Relic also adds the following attributes to all the metrics: Additional Kubernetes attributes Description deploymentName Name of the deployment, if scraping a pod. label The Kubernetes labels of the object being scraped, prefixed by \"label\". namespaceName Name of the namespace. nodeName Name of the node where the pod being scraped is running, if applicable. podName Name of the pod being scraped, if applicable. serviceName Name of the service being scraped, if applicable Default attributes for the remote write integration By default, the following attributes will be added to Prometheus remote write metrics: Default attributes (all integrations) Description prometheus_server A user supplied label specified as a Prometheus remote write URL parameter. The value supplied should be unique as it is intended to differentiate between source Prometheus servers at query time. Unspecified by default. newrelic.source The name of the New Relic ingest point (prometheusAPI). instrumentation.provider prometheus instrumentation.name remote-write instrumentation.source A user supplied identifier for the source of the Prometheus data that matches the value of prometheus_server. instrumentation.version Used to identify the version of the remote write API; for example, 0.0.1. NRQL query examples When you build queries, be aware that there is no linking between the metrics, entities, and attributes. Use the following NRQL queries to find out which metrics are available and which attributes are present on these metrics: Get metric names To get all metric names for OpenMetrics: FROM Metric SELECT uniques(metricName) Copy To get metric names for a remote write integration: FROM Metric SELECT uniques(metricName) WHERE instrumentation.provider='prometheus' AND instrumentation.name='remote-write' Copy To get metric names for a remote write integration from a single Prometheus source: FROM Metric SELECT uniques(metricName) WHERE instrumentation.provider='prometheus' AND instrumentation.name='remote-write' AND instrumentation.source='<ds>' Copy To get metric names for a specific OpenMetrics endpoint: FROM Metric SELECT uniques(metricName) WHERE scrapedEndpoint='<ep>' Copy To get metric names for a specific OpenMetrics cluster, namespace, or pod: FROM Metric SELECT uniques(metricName) WHERE clusterName='<cn>' Copy FROM Metric SELECT uniques(metricName) WHERE namespaceName='<ns>' Copy FROM Metric SELECT uniques(metricName) WHERE podName='<pod>' Copy Get the attributes for a metric To get all attributes for the selected metric: FROM Metric SELECT keyset() WHERE metricName='<mn>' Copy Get the values for an attribute in OpenMetrics The autocomplete will show all values of the attribute, regardless of the pod. To determine the attribute values for a specific pod: FROM Metric SELECT uniques(<attribute>) WHERE metricName='<mn>' AND podName='<pod>' Copy Build the query Using metric name and attributes, you can query your data. For more information about facets, time series, and time selection, see the NRQL documentation. To build PromQL-style queries, see our docs. Get metric values To get raw metric values: FROM Metric SELECT <metricName> WHERE <attribute>='<value>' Copy Get a chart of the metric To get a chart of the metric with an aggregator of average, min, max, or sum: FROM Metric SELECT <aggregator>(<metricname>) WHERE <attribute>='<value>' TIMESERIES Copy Query counter metrics (deltas) Currently the integration calculates the deltas for counter metrics. This is why queries on counter metrics will show the deltas of the counter instead of the absolute value of the counter. View connected Redis clients per pod with OpenMetrics Docker: This example assumes you are scraping Redis exporters. To view the number of connected Redis clients per endpoint in a cluster: FROM Metric SELECT latest(redis_connected_clients) WHERE clusterName='my-cluster' FACET scrapedEndpoint TIMESERIES Copy Kubernetes: This example assumes that you have Redis pods with the Redis exporter installed. To view the number of connected Redis clients per pod in the default namespace: FROM Metric SELECT latest(redis_connected_clients) WHERE namespaceName='default' FACET podName TIMESERIES Copy Docker: View average memory free for scraped endpoints This example assumes you are scraping node exporters for Docker and want to use OpenMetrics. To view average memory free for all scraped endpoints in a cluster: FROM Metric SELECT average(node_memory_MemFree_bytes) WHERE clusterName='my-cluster' Copy Kubernetes: View average memory usage for pods in a deployment To view average memory usage for all pods in a Kubernetes deployment using OpenMetrics: FROM Metric SELECT average(container_memory_usage_bytes) WHERE deploymentName='my-app-deployment' AND namespaceName='default' Copy View data in New Relic When you query the data, you can view the results in the New Relic UI. You can also visualize the data as charts, histograms, etc. To view the NRQL query results for your Prometheus integration's data: Go to one.newrelic.com > Query your data. For more information, see New Relic's query builder documentation. Create histograms and summaries With remote write or version 1.2.0 or higher of the Prometheus OpenMetrics integration, you can create histograms and percentiles (summaries) of your data. The OpenMetrics data is based on New Relic's guidelines in GitHub for higher level metric abstractions, while the remote write data closely matches the schema of the original Prometheus data. Data presentation Comments Histograms A bucket <basename>_bucket{le=\"42\"} will be sent as this: For OpenMetrics: <basename>_buckets For remote write: <basename>_bucket The dimension will be this: For OpenMetrics: {histogram.bucket.upperBound=\"42\"} For remote write: {histogram.bucket.le=\"42\"} Percentiles Quantiles (summaries) are transformed into percentiles. A metric <basename>{quantile=\"0.3\"} will be sent to New Relic as <basename>.percentiles. The dimension will be this: {percentile=\"30\"} NRQL has two functions that work on remote write ingested PromQL: bucketPercentile() and histogram(). The links include query examples.These two functions don't work on OpenMetrics ingested buckets. To better support visualization of histograms, percentiles are calculated based on the histogram metrics and sent to New Relic. To configure the calculated percentiles for OpenMetrics, use the percentiles configuration option.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.60542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>View</em> <em>and</em> <em>query</em> your <em>Prometheus</em> <em>data</em>",
        "sections": "<em>View</em> <em>and</em> <em>query</em> your <em>Prometheus</em> <em>data</em>",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " identifier for the source of the <em>Prometheus</em> <em>data</em> that matches the value of <em>prometheus</em>_server. instrumentation.version Used to identify the version of the remote write API; for example, 0.0.1. NRQL <em>query</em> examples When you build queries, be aware that there is no linking between the metrics, entities"
      },
      "id": "603eb04be7b9d20f9d2a07eb"
    },
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric <em>data</em> to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " de-duplicate <em>data</em> from HA-pairs on ingest. Reminders: You will need to manage your <em>Prometheus</em> servers. You can reduce your storage retention. Fewer <em>query</em> loads to the server. Recommendations: Evaluate your observability needs to manage your <em>data</em> volumes better: The scrape interval is the biggest"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    }
  ],
  "/docs/infrastructure/prometheus-integrations/view-query-data/view-query-your-prometheus-data": [
    {
      "sections": [
        "Supported PromQL Features",
        "Important",
        "Supported features",
        "Aggregation operators and functions",
        "Arithmetic binary operators",
        "Logical operators",
        "Date/time functions",
        "Mathematical functions",
        "Rate-like functions",
        "Predictive functions",
        "Time-series selectors",
        "PromQL troubleshooting",
        "Metric types",
        "Limits",
        "Range vector selectors (sliding windows and smoothing behavior)",
        "Query range and data scraping intervals"
      ],
      "title": "Supported PromQL Features",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "d4a93b9db3bfe5639ed01968b6e55a8e0aaa9389",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/supported-promql-features/",
      "published_at": "2021-10-24T15:57:15Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic supports PromQL-style queries, and our query builder offers a PromQL-style query mode that translates PromQL syntax queries into the closest NRQL approximation. Although the method of approximation means that a handful of edge cases are not fully supported, it provides coverage for an overwhelming majority of queries, supporting over 99.5% of queries across the 7.8 million top Grafana dashboard downloads. Read on to learn about how we work with PromQL queries, as well as differences between standard PromQL and our PromQL-like query language we want you to be aware of. Important For general information about Prometheus queries and operators, see the Prometheus.io documentation. Supported features We support the following aggregation, arithmetic, mathematical, and rate-like functions. As we continue to expand support for Prometheus and PromQL, this list will be updated. Aggregation operators and functions Aggregation operators: avg() count() min() max() quantile() stddev() stdvar() sum() topk() Aggregation functions: histogram_quantile() <aggregation>_over_time() functions: avg_over_time count_over_time min_over_time max_over_time quantile_over_time stdev_over_time stvar_over_time sum_over_time Arithmetic binary operators + (addition) - (subtraction) * (multiplication) / (division) % (percent) ^ (power/exponents) Logical operators and or Date/time functions day_of_month() day_of_week() days_in_month() hour() minute() month() time() timestamp() year() Mathematical functions abs() ceil() clamp_max() clamp_min() exp() floor() ln() log10() log2() round() sqrt() Rate-like functions delta() deriv() idelta() increase() irate() rate() Predictive functions predict_linear Time-series selectors We offer support for PromQL time-series selectors including the following: instant vector selectors range series selectors offset modifier Important We only support offset queries if every vector in the query has the same offset value. PromQL troubleshooting This section describes differences in behavior between PromQL and our PromQL-style query behavior and how to work with and around these differences. This is particularly relevant if you want to use advanced queries and our PromQL-style mode in the query builder. Metric types Prometheus recommendations note that you should only use some functions, like delta(), on gauges, and only use others like rate() and increase() on counters, but queries in Prometheus still work most of the time even if they don’t follow those instructions. However, because NRDB converts PromQL-style accumulating counters to delta counters, our implementation is unforgiving when using these functions on the wrong data type and will produce different or incorrect answers. For this reason, it's best to follow all Prometheus recommendations when working with our PromQL-style queries, even if you don't follow these recommendations in Prometheus. Limits In order to ensure the stability and performance of our system for all users, we place some limits on what queries can be run. In all cases, we enforce a limit of 366 steps in range queries. We also default to only returning 100 timeseries from queries by default. If you want to see more (or fewer), you need to explicitly add a topk() to your query. (Note that the topk() implementation in our PromQL-style query is different from that of Prometheus.) We limit the total memory a query can use. This means that requests for large numbers of time steps or large numbers of time series may be rejected, particularly if they are combined with an aggregation like unique count or quantile which require significantly more memory to compute than simple arithmetic aggregations. Range vector selectors (sliding windows and smoothing behavior) We provide support for sliding window timeseries aggregations. For more information, see our NRQL syntax, clauses, and functions resource and our sliding windows deep dive. For information on translating between NRQL and our PromQL-style language, see Translate PromQL queries to NRQL. Query range and data scraping intervals The range of your query in PromQL must be larger than the duration of the step size of the query to avoid the error \"TIMESERIES bucket size is larger than the current time window\". We inspect data up to one minute old when servicing instant queries. If your scrape interval is greater than 1 minute, some queries may result in No data found. Avoid this by sending data at least once per minute. If the timeseries unit for your NRQL query is less than the scrape interval for your application, some periods will lack data, and the resulting graph may be jagged or contain peaks and valleys. In general, set the step size to your scrape interval, or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.60608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Query</em> range <em>and</em> <em>data</em> scraping intervals",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " with and around these differences. This is particularly relevant if you want to use advanced queries and our PromQL-style mode in the <em>query</em> builder. Metric types <em>Prometheus</em> recommendations note that you should only use some functions, like delta(), on gauges, and only use others like rate() and increase"
      },
      "id": "603e9523e7b9d292ec2a07ce"
    },
    {
      "sections": [
        "Translate PromQL queries to NRQL",
        "Tip",
        "Prometheus and New Relic metric types",
        "Mapping between NRQL and our PromQL-style queries",
        "PromQL-style query example",
        "NRQL query example",
        "Filter examples",
        "PromQL-style to NRQL query examples",
        "For more help"
      ],
      "title": "Translate PromQL queries to NRQL",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "fcf45fb8fb49f9d22f74574c2e7032533377e584",
      "image": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql/images/PROMQL-query-2.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql/",
      "published_at": "2021-10-24T16:03:13Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Do you have a PromQL query you’d like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style query language to explore your Prometheus OpenMetrics integration data along with other data sent to New Relic. Tip To run PromQL-style queries in New Relic One, go to the query builder advanced PromQL-style mode. Prometheus and New Relic metric types The different metric types supported by Prometheus and New Relic are related to each other: New Relic Prometheus Description Count Counter The Prometheus counter is a cumulative sum while the New Relic count is a delta sum. For example, if you see 2 requests in the first reporting period and 3 requests in the second reporting period. The Prometheus counter will report 2 and then 5, while the New Relic count will report 2 and then 3. Gauge Gauge A Prometheus gauge is similar to a New Relic gauge. Multiple counts Histogram Prometheus automatically maps a histogram to a set of counters. In New Relic, these counters should be changed to deltas and reported as counts. Gauges and counts Summary Prometheus represents a Summary with a given basename as the following time series: a basename_sum a basename_count and 0 or more of basename{quantile=\".xx\"...} metrics New Relic maps the _sum as a Summary, the _count as a Counter, and each quantile metric as a Gauge. Summary (No equivalent in Prometheus) New Relic has a distinct metric type called a summary that is different than the Prometheus summary. It is designed for reporting aggregated discrete events so that you can query the count, sum, min, max, and average values. Mapping between NRQL and our PromQL-style queries Tip To see how New Relic translates PromQL-style queries to NRQL, write a query in the query builder PromQL-style tab, then switch to the NRQL tab. This table shows the mapping between NRQL and our PromQL-style queries when exploring data. For more contextual information, see the examples. Description Mapping between NRQL and PromQL-style queries Search for attributes: Explore the attributes on the container_memory_usage_bytes metric. PromQL: container_memory_usage_bytes Copy NRQL: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy Find attribute's value: Explore the current value of the container_memory_usage_bytes metric for unique id attributes. PromQL: sum(container_memory_usage_bytes) by (id) Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy Visualize the attribute's value: Chart the value of the container_memory_usage_bytes metric with the given id attribute value. PromQL: container_memory_usage_bytes{id=\"/\"} Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = '/' TIMESERIES Copy PromQL-style query example 1. Start your query. When exploring your data for a particular metric in PromQL, such as memory by container usage in bytes, you can start with a query such as: container_memory_usage_bytes Copy This will chart all the unique metric timeseries for the input metric. 2. Filter the query results. Looking at the data, you can add more query parameters to filter down the number of metric timeseries. For example, if you only want timeseries where the id is /, the PromQL-style query will be: container_memory_usage_bytes{id=\"/\"} Copy PromQL-style example: To filter the data, run this PromQL-style query: container_memory_usage_bytes { id=\"/\"}. NRQL query example 1. Query available metrics. To explore your data, start by looking at all the available metrics. Use the following NRQL query: FROM Metric SELECT uniques(metricName) Copy 2. Find unique attributes. Once you have found the metric you want to review, such as container_memory_usage_bytes, you can find the unique attributes with the following query: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy The results will show each available attribute key and the value type (string, boolean, or number). 3. Aggregate and chart the metrics. To chart metrics using NRQL, you first need an aggregation function. For example, you can use latest for gauges, sum for counts, and average for summaries. As the following chart shows, all the unique timeseries are aggregated into one unique timeseries by default: one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes'. 4. View metrics by ID. To view the unique metric timeseries with various id values, run the following query: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT latest(container_memory_usage_bytes) FACET id. 5. Add the selected ID to the query. Next you can select an id value and put it in the NRQL where clause. FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = \"/\" timeseries Copy one.newrelic.com > Query your data: This example shows the data displayed after running From Metric select latest(container_memory_usage_bytes) where id = \"/\" timeseries. Filter examples Both our PromQL-style query language and NRQL provide syntax to filter down the number of unique metric timeseries. PromQL-style uses brackets to filter. NRQL uses a WHERE clause. Here are some example queries: Description PromQL-style and NRQL queries Select data with specific values. PromQL: go_memstats_heap_alloc_bytes{job=\"apiserver\", instance=\"1234\"}) Copy NRQL: To only select data with specific values in NRQL, use the WHERE clause with =. In this example, all data must have the selected value for job and handler. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE job = 'apiserver' AND instance = '1234' TIMESERIES Copy Select data with multiple values. PromQL: go_memstats_heap_alloc_bytes{environment=~\"staging|testing|development\",method!=\"GET\"} Copy NRQL: In NRQL use the in clause to select multiple values for an attribute and the != sign to select all values but the one listed. In this example, the environment can be staging, testing, or development, and the method cannot be GET. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE environment IN ('staging', 'testing', 'development') AND method != 'GET' TIMESERIES Copy Select data using partial string values. PromQL: go_memstats_heap_alloc_bytes{job=~\"api.*\"} Copy NRQL: In NRQL use the LIKE clause to match part of a string value. In this example, all data will be returned where the job attributes start with api. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHEREe job LIKE 'api%' TIMESERIES Copy PromQL-style to NRQL query examples You can simulate the following PromQL-style queries with NRQL queries: Description PromQL-style and NRQL queries Measure the per second rate over the last minute of the http_request_total metric. PromQL: sum(rate(http_requests_total[1m])) Copy NRQL: FROM Metric SELECT rate(sum(http_request_total), 1 second) TIMESERIES 1 minute Copy Chart the difference of the two metrics, then divide by 1024. PromQL: (instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 Copy NRQL: FROM Metric SELECT (latest(instance_memory_limit_bytes) - latest(instance_memory_usage_bytes)) / 1024 TIMESERIES Copy Provide the summed rate per 30-second interval by each handler. PromQL: sum(rate(http_requests_total[30s])) by (handler) Copy NRQL: FROM Metric SELECT rate(sum(http_requests_total), 30 seconds) FACET handler TIMESERIES Copy Chart the difference in the two metrics where the instance is named foo and the fstype is either ext4 or xfs. PromQL: (node_filesystem_free_bytes{instance='foo',fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{instance='foo',fstype=~\"ext4|xfs\"}) Copy NRQL: FROM Metric SELECT latest(node_filesystem_free_bytes) / latest(node_filesystem_size_bytes) WHERE instance = 'foo' AND fstype IN ('ext4', 'xfs') Copy For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.60559,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Translate PromQL <em>queries</em> to NRQL",
        "sections": "<em>Prometheus</em> <em>and</em> New Relic metric types",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Do you have a PromQL <em>query</em> you’d like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style <em>query</em> language to explore your <em>Prometheus</em> OpenMetrics integration <em>data</em> along with other <em>data</em> sent to New"
      },
      "id": "603ead4528ccbcbecfeba77b"
    },
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Prometheus OpenMetrics integration for Kubernetes or Docker",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "aaeaf025175ef14ba33549b5a315caab72c929d0",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-10-24T16:09:51Z",
      "updated_at": "2021-10-24T02:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Examine the benefits, reminders, and recommendations for each option below. Prometheus remote write integration Benefits: Easy access to your combined metrics in New Relic if you already have Prometheus servers. Access only takes one line of yaml in your Prometheus configuration. Access your metrics through both New Relic and Prometheus without making additional adjustments in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Reminders: You will need to manage your Prometheus servers. You can reduce your storage retention. Fewer query loads to the server. Recommendations: Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more New Relic accounts or sub-accounts to manage rate limits. Prometheus OpenMetrics integration for Kubernetes or Docker Benefits: Best for an alternative to Prometheus servers Store all your metrics directly in New Relic No need to manage any Prometheus servers yourself. No need for local storage. Reminders: Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. New Relic's database can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.15012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric <em>data</em> to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics <em>integrations</em>",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": " de-duplicate <em>data</em> from HA-pairs on ingest. Reminders: You will need to manage your <em>Prometheus</em> servers. You can reduce your storage retention. Fewer <em>query</em> loads to the server. Recommendations: Evaluate your observability needs to manage your <em>data</em> volumes better: The scrape interval is the biggest"
      },
      "id": "6174c75c28ccbcbd0cc6bde8"
    }
  ],
  "/docs/instrumentation-editor-instrument-net-ui": [
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "bd62b563a23cb35cc2aabc7f1f44e3dcacbce3cf",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/introduction-new-relic/",
      "published_at": "2021-10-24T01:44:12Z",
      "updated_at": "2021-10-24T01:44:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will setup many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in New Relic One, no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic integrations. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. As a full user you get access to our entire set of observability tools in New Relic One: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.00476,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "New Relic is an observability platform that helps you build better software. You can bring in data <em>from</em> any digital source so that you can fully understand your system and how to improve it. With New Relic, you can: Bring all your data together: <em>Instrument</em> everything and import data <em>from</em> across"
      },
      "id": "6043ad0764441f5a06378ecd"
    },
    {
      "sections": [
        "Introduction to New Relic for .NET",
        "Support for both .NET Framework and .NET Core",
        "Install the agent on Windows with our guided install",
        "Install the agent",
        "Tip",
        "Configure the agent",
        "Extend your instrumentation",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for .NET",
      "type": "docs",
      "tags": [
        "Agents",
        "NET agent",
        "Getting started"
      ],
      "external_id": "a19f931fc6b91fa9a3ff3e1b73886901259ca8a9",
      "image": "https://docs.newrelic.com/static/23d1cfe6da584e6ebb01f6a40080b06e/c1b63/net_overview.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/net-agent/getting-started/introduction-new-relic-net/",
      "published_at": "2021-10-23T18:00:24Z",
      "updated_at": "2021-10-23T17:58:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With our .NET agent for application performance monitoring, you can: Use APM to get a high-level overview of your app, to see code-level details like transaction traces, database queries, and errors, and to track activity across a large distributed system. Get proactive notifications from alerts to ensure your app is up and running smoothly. Use the query builder to query your data and create custom dashboards with that data. Install infrastructure monitoring to view the performance of your app's host environment. Support for both .NET Framework and .NET Core New Relic's .NET agent supports both .NET Framework and .NET Core, and it works with all .NET compatible languages, such as VB.NET, C#, and CLI. The agent's support for .NET Core takes advantage of the compatibility, speed, expanded API features, and cross-platform capabilities of Microsoft's .NET Core. The agent does not support Microsoft .NET Core versions earlier than 2.0. With New Relic's support for .NET, you can monitor your apps in dynamic or distributed environments, such as: Cloud-managed server VM images On-host VM servers Microsoft Azure App Services Self-hosted Windows and Linux systems Amazon AWS EC2 VMs Install the agent on Windows with our guided install Our guided install creates a customized CLI command for your environment that downloads and installs the .NET agent for Windows IIS applications. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install In addition to the .NET agent, you can use this to install our infrastructure agent to discover other applications, infrastructure, and log sources running in your environment and recommend which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Install the agent Before you install the .NET agent, create your New Relic account. Then, review the requirements for .NET Framework or the requirements for .NET Core. When you are ready to install, use our launcher, or see the install instructions appropriate for your operating system: Windows or Linux. Add .NET data Tip To stay up-to-date with new features and bug fixes, see the .NET agent release notes. After you install the agent and wait a few minutes for your app to generate traffic, data will appear in the APM Summary page. If no data appears, or if you encounter other problems, see New Relic's .NET agent troubleshooting procedures. one.newrelic.com > APM > (select an app) > Summary: After installing the .NET agent, you will see a summary of your app's performance on the Summary page. Configure the agent The most important part of agent configuration is to give your app a descriptive name. New Relic uses this app name to aggregate metrics when you have multiple apps or hosts. The agent also includes a variety of configuration options to further customize your installation. Extend your instrumentation After installing the .NET agent, extend the agent's instrumentation with one or more of these methods: Instrumentation options Details Browser instrumentation Integrate the .NET agent with browser monitoring to gain visibility into end-user activity. ASP.NET apps (.NET Framework only): Use any of the available options to install the browser agent. ASP.NET Core apps (targeting .NET Core or .NET Framework): Use either the API method or the copy/paste method to inject the browser agent into your webpages. Custom instrumentation Instrument transactions not captured as part of New Relic's automatic framework instrumentation. Agent API See the .NET agent API guide to learn how to customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom attributes Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Distributed tracing Enable distributed tracing to understand activity across a complex, distributed system that uses many services and microservices. Open source telemetry Explore these tools: OpenTelemetry exporter and .NET Telemetry SDK. Check the source code The .NET agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.47958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for .<em>NET</em>",
        "sections": "Introduction to New Relic for .<em>NET</em>",
        "tags": "<em>NET</em> agent",
        "body": " of the available options to install the browser agent. ASP.<em>NET</em> Core apps (targeting .<em>NET</em> Core or .<em>NET</em> Framework): Use either the API method or the copy&#x2F;paste method to inject the browser agent into your webpages. Custom <em>instrumentation</em> <em>Instrument</em> transactions not captured as part of New Relic"
      },
      "id": "61744d37e7b9d2d02813ddf8"
    },
    {
      "sections": [
        "Troubleshooting: Missing entities in service maps",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "Troubleshooting: Missing entities in service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "44f9c026ad8e1c9d6ba02bd1ec2f2deecbc26832",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/troubleshooting-missing-entities-service-maps/",
      "published_at": "2021-10-24T12:02:27Z",
      "updated_at": "2021-10-24T01:50:44Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When using service maps, you can't view the full set of entities or the relationships between entities that you expect to see. Solution Make sure that the entities are being monitored with an agent. If you have a mix of agents with some having distributed tracing turned on and some having it turned off, you will not see the relations between those agents. The solution for this scenario is to run all agents either with distributed tracing turned on (preferred) or turn it off for all agents. If this does not remedy the issue, the service you're trying to view may require manual instrumentation. When you view applications and services that we automatically instrument in service maps, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some of these services or applications are missing from service maps. Tip Some browser apps are exceptions to this, and may be missing because: Relationships for copy and paste browser agents are not detected. Only the relationships for injected browser agents is shown (the app the agent is injected into). Call relationships (for example, AJAX calling to other apps) are not displayed. If services or apps are missing, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.1264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " <em>instrumentation</em>. When you view applications and services that we automatically <em>instrument</em> in service maps, you&#x27;ll usually see complete and detailed data for those nodes in the distributed tracing <em>UI</em>. However, you may notice that some of these services or applications are missing <em>from</em> service maps. Tip Some"
      },
      "id": "603eb369196a67b4aaa83d8d"
    }
  ],
  "/docs/kubernetes-pixie/auto-telemetry-pixie/auto-telemetry-pixie-data-model": [
    {
      "sections": [
        "Auto-telemetry with Pixie for instant Kubernetes observability",
        "Quickly start observing and debugging Kubernetes clusters",
        "Important",
        "Explore your cluster",
        "Tip",
        "Investigate usage spikes with Flamegraph",
        "Debug live"
      ],
      "title": "Auto-telemetry with Pixie for instant Kubernetes observability",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "1dc7474aedbf84c51593c152fc39fda0a46b4f48",
      "image": "https://docs.newrelic.com/static/1e793128e5d6019bbebd8123dbf943ab/c1b63/service-graph.png",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/get-started-auto-telemetry-pixie/",
      "published_at": "2021-10-24T23:31:41Z",
      "updated_at": "2021-10-24T02:52:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When we say auto-telemetry, we’re not talking about cars — we're talking about instant baseline visibility into your Kubernetes clusters. With the New Relic One integration with Pixie, you get similar data to traditional language agents, but without manually instrumenting your code or redeploying your application. Pixie auto-telemetry is powered by eBPF, a virtual machine-like construct that enables Pixie to seamlessly collect fine-grained telemetry data — service-level metrics, unsampled requests, and more. With one install command, you get deeper insight into your Kubernetes clusters and workloads. No language agents required. Live debugging with Pixie shows a service graph listing the namespaces and the node that are available on the current cluster. Simply put, Auto-telemetry with Pixie offers the quickest option for getting observability into your Kubernetes services. Quickly start observing and debugging Kubernetes clusters Our Pixie integration gives you the best of both worlds: Pixie’s fast and simple Kubernetes observability coupled with New Relic One’s incident correlation, intelligent alerting, and long-term retention. You’ll get visibility into HTTP services using golden signals, HTTP transactions, database transactions, distributed tracing, and JVM metrics. You can operate, debug, and scale your Kubernetes clusters based on the information you learn about how your clusters and services are running. Using the New Relic Explorer, you can see key metrics and events at every level, starting with the cluster, and diving down into namespaces, deployments, and pods. You can quickly spot anomalous behavior, and where it’s happening. And then dive deeper using embedded visualizations of your Pixie data. Quickly identify hot spots with Flamegraph. On the Live debugging with Pixie tab, answer questions like what SQL requests your app is making or which services are talking to each other. Important Auto-Telemetry with Pixie leverages Community Cloud with Pixie, a separate platform from New Relic One. Use of Community Cloud with Pixie is subject to separate terms of service. Explore your cluster Access the Pixie UI via New Relic's Live debugging with Pixie area of your Kubernetes clusters. The cluster explorer provides a quick overview of the nodes in your cluster, including CPU, memory, and storage, as well as the status of each pod (healthy, warning, or critical). You can also find out what services are running in each container, their latency, throughput, and error rate. For more information about using the cluster explorer, see Navigate the Kubernetes cluster explorer. Note that you cannot log directly into the Pixie UI unless you have created a separate Pixie login. Tip Containers might be listed for up to four hours after they get decommissioned. You can query the Pixie data in New Relic One and create dashboards for at-a-glance monitoring. Find the data model and sample queries here. Investigate usage spikes with Flamegraph Debugging is orders of magnitude easier when you can quickly see what your application is doing. Flamegraph, a Pixie always-on visualization, requires no instrumentation, redeploying, or recompiling. It works for compiled languages like Go, C+, Rust, to name a few. And at a glance, Flamegraph tells you what functions your application is spending time on and where you have hot spots. Flamegraph is especially useful for hierarchical resource use, like disk usage and CPU utilization. For more information on how to read Flamegraph, see the Pixie documentation. Debug live On the Live debugging with Pixie tab, run PxL scripts — scripts written in Pixie's PxL language — to view live data captured through eBPF. Select the script drop-down and then select a script to run in the tab. (For best results, select a time range that is recent in the time picker.) Scripts enable you to debug: Traffic in multiple formats: HTTP and HTTPs (including encrypted), DNS, Postgres, MySQL, Cassandra, Redis (currently supporting SQL and HTTP in beta). Learn more: Request tracing tutorial. Database request performance. Learn more: Database Query Profiling tutorial. Service maps to learn which services are talking to each other. Learn more: Service Performance tutorial. Network traffic maps to learn which nodes are talking to each other. Learn more: Network Monitoring tutorial. Monitor resource usage by Node and Pod. Learn more: Infra health tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 712.22363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> for instant <em>Kubernetes</em> observability",
        "sections": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> for instant <em>Kubernetes</em> observability",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": " your application. <em>Pixie</em> <em>auto</em>-<em>telemetry</em> is powered by <em>eBPF</em>, a virtual machine-like construct that enables <em>Pixie</em> to seamlessly collect fine-grained <em>telemetry</em> data — <em>service</em>-level metrics, unsampled requests, and more. With one install command, you get deeper insight into your <em>Kubernetes</em> clusters"
      },
      "id": "6174ca7364441f0e385fdea5"
    },
    {
      "sections": [
        "Install Auto-telemetry with Pixie",
        "General prerequisites for using Pixie",
        "Setup steps depend on your account status",
        "Install from the beginning of the guided install process",
        "Install from the Configure the HELM command/manifest (yaml) file",
        "Important",
        "Helm method",
        "manifest method",
        "If you link the wrong Pixie and New Relic account"
      ],
      "title": "Install Auto-telemetry with Pixie",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "bb957763e579e39ef2bbeafeebc46ab3a111bca2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/install-auto-telemetry-pixie/",
      "published_at": "2021-10-24T23:30:47Z",
      "updated_at": "2021-10-24T02:51:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To get up and running with Auto-telemetry with Pixie, you start with our guided installation. The guided installation deploys Pixie with New Relic's Kubernetes integration on your cluster. You don't need to do any further configuration or installation to start using Pixie. If you want to install Auto-telemetry with Pixie on multiple clusters, re-run the guided install for each additional cluster. General prerequisites for using Pixie You must be a New Relic full platform user. Other user-related requirements: Users on our New Relic One user model must be assigned to a group that has a role with Pixie-related capabilities. Users on our original user model cannot be Restricted. Review this Pixie data security overview for actions to take to secure your data. Make sure you have sufficient memory: Pixie requires 2Gb of memory per node in your cluster. Review the other Pixie technical requirements. Setup steps depend on your account status Use the following table to find out where to start installing Auto-telemetry with Pixie. Where you start the installation depends on whether you already have a New Relic or Pixie account, or both. New Relic Pixie Next steps Start the guided install at the beginning of the process. If you already have both types of accounts, and used the same email address for each of them, click the New Relic icon in the Pixie UI. This brings you to the Configure the HELM command/manifest (yaml) file section of the guided installation. Then, follow the steps. If you're using different email addresses in Pixie and New Relic, create a new account for either Pixie or New Relic to match email addresses across both products. You can also contact New Relic support to manually link your existing New Relic account with your Pixie account. If you follow a link to New Relic from the Pixie UI and do not have a New Relic account, you must first create one. Click the New Relic icon in the Pixie UI, and follow the steps to create a New Relic account. When you do so, your Pixie account is linked to it. Then, continue the guided install process with these steps. Sign up for a free New Relic account. Then, start the guided install at the beginning of the process. Install from the beginning of the guided install process Open our New Relic One guided install. Select the account you want to use for the guided install, and click Continue. Note: if you have a single account, you won't see this option. Select Kubernetes and then continue with step one in the next section. Install from the Configure the HELM command/manifest (yaml) file If you arrived in the guided installation process by following a link from Pixie or from within New Relic, your steps begin here. Select the account and cluster for the install. If needed, select a namespace. Important Currently, Pixie performs best on clusters with up to 100 nodes (exceeding 100 nodes can lead to excessive memory usage and scripts failing to run). Friendly reminder: autoscaling can quickly drive up your node numbers. Click Continue. Select the data you want to gather, observe, and debug, and click Continue. On the Choose install method page, select either Helm or manifest. Helm method Run the provided Helm command on your command line. If you're concerned about the amount of Pixie data you'll ingest, check out strategies for reducing ingest. Helm installs a bundle containing the New Relic infrastructure agent, an integration to gather Prometheus metrics and Kubernetes events, and the Pixie integration. The deployment takes a few minutes to complete. To see the status of the install to the cluster, run kubectl get pods -n newrelic. For general information about installing a Kubernetes integration, see this Helm install info. manifest method Run the provided command in your console, and insert the path to your downloaded manifest. If you're running your Kubernetes cluster in the cloud, see the additional steps in the Kubernetes docs. Click Continue to open the Listening for data page. When you get the message, See your data, click Kubernetes Cluster Explorer to see your cluster. Auto-telemetry with Pixie might restart after installation. This is caused by the auto update feature. If you link the wrong Pixie and New Relic account Contact support to unlink a Pixie account from your New Relic account. Be aware that if you unlink a Pixie account that was created automatically through the guided install, you'll lose access to that Pixie account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 513.55707,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "sections": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": "To get up and running with <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>, you start with our guided installation. The guided installation deploys <em>Pixie</em> with New Relic&#x27;s <em>Kubernetes</em> integration on your cluster. You don&#x27;t need to do any further configuration or installation to start using <em>Pixie</em>. If you want to install"
      },
      "id": "6174ca14e7b9d26ba513cd12"
    },
    {
      "sections": [
        "Auto-telemetry with Pixie data and security",
        "Control who has access to Pixie data",
        "Manage auto-update and two-way communication",
        "Helm option",
        "newrelic-manifest.yaml option"
      ],
      "title": "Auto-telemetry with Pixie data and security",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry data",
        "Service monitoring",
        "Kubernetes",
        "eBPF",
        "Pixie data"
      ],
      "external_id": "acec5042b8735d73fa255829401e8708bd6d0595",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/pixie-data-security-overview/",
      "published_at": "2021-10-24T23:32:39Z",
      "updated_at": "2021-10-24T02:51:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Auto-telemetry with Pixie is New Relic One's integration of Community Cloud for Pixie, a managed version of Pixie open source software. Auto-telemetry with Pixie therefore benefits from Pixie's approach to keeping data secure. The data that Pixie collects is stored entirely within your Kubernetes cluster. This data does not persist outside of your environment, and will never be stored by Community Cloud for Pixie. This means that your sensitive data remains within your environment and control. Community Cloud for Pixie makes queries directly to your Kubernetes cluster to access the data. In order for the query results to be shown in the Community Cloud for Pixie UI, CLI, and API, the data is sent to the client from your cluster using a reverse proxy. Community Cloud for Pixie’s reverse proxy is designed to ensure: Data is ephemeral. It only passes through the Community Cloud for Pixie's cloud proxy in transit. This ensures data locality. Data is encrypted while in transit. Only you are able to read your data. New Relic One fetches and stores data that related to an application's performance. With Auto-telemetry with Pixie, a predefined subset of data persists outside of your cluster. This data is stored in our database, in your selected region. This data persists in order to give you long-term storage, alerting, correlation with additional data, and the ability to use advanced New Relic platform capabilities, such as anomaly detection. The persisted performance metrics include, but are not limited to: Golden metrics (throughput, latency, error rate) for HTTP-based services HTTP transaction data Database transaction data (for MySQL & PostgreSQL) Distributed tracing JVM metrics The data you view on the Live debugging tab comes through Community Cloud for Pixie, and is therefore potentially sensitive. It is not stored by New Relic and is ephemeral and queryable for less than 24 hours. Control who has access to Pixie data If you want to manage which members of your organization can view Pixie data in New Relic One, as well as install and delete Pixie links, you can create a custom role. Note that this option is available only to Enterprise and Pro level customers. For more information, see New Relic's user model. Manage auto-update and two-way communication Pixie maintains an active two-way communication channel from your host system to Community Cloud with Pixie at withpixie.ai. Pixie uses this communication channel to query data, push updates, and retrieve metadata and health checks about Pixie and your Kubernetes cluster. By default, Pixie queries withpixie.ai to check if new updates have been pushed and then automatically installs them if they’re present. To disable auto updates, you must set a flag prior to the install process using either Helm or in the newrelic-manifest.yaml file. To disable automatic updates, choose one: Helm option Add --set pixie-chart.disableAutoUpdate=true to your Helm command. newrelic-manifest.yaml option in your newrelic-manifest.yaml file under the pl-cluster-config section, add PL_DISABLE_AUTO_UPDATE: \"true\" to the data directive. Example: --- apiVersion: v1 data: PL_CUSTOM_ANNOTATIONS: \"\" PL_CUSTOM_LABELS: \"\" PL_DISABLE_AUTO_UPDATE: \"true\" PL_ETCD_OPERATOR_ENABLED: \"false\" PL_MD_ETCD_SERVER: \"https://etcd.newrelic.svc:2379\" PX_MEMORY_LIMIT: \"\" kind: ConfigMap metadata: annotations: creationTimestamp: null labels: name: pl-cluster-config namespace: newrelic --- Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 433.2984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data and security",
        "sections": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data and security",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em> data",
        "body": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> is New Relic One&#x27;s integration of Community Cloud for <em>Pixie</em>, a managed version of <em>Pixie</em> open source software. <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> therefore benefits from <em>Pixie</em>&#x27;s approach to keeping data secure. The data that <em>Pixie</em> collects is stored entirely within your <em>Kubernetes</em>"
      },
      "id": "6174ca40e7b9d203d413d744"
    }
  ],
  "/docs/kubernetes-pixie/auto-telemetry-pixie/get-started-auto-telemetry-pixie": [
    {
      "sections": [
        "Install Auto-telemetry with Pixie",
        "General prerequisites for using Pixie",
        "Setup steps depend on your account status",
        "Install from the beginning of the guided install process",
        "Install from the Configure the HELM command/manifest (yaml) file",
        "Important",
        "Helm method",
        "manifest method",
        "If you link the wrong Pixie and New Relic account"
      ],
      "title": "Install Auto-telemetry with Pixie",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "bb957763e579e39ef2bbeafeebc46ab3a111bca2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/install-auto-telemetry-pixie/",
      "published_at": "2021-10-24T23:30:47Z",
      "updated_at": "2021-10-24T02:51:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To get up and running with Auto-telemetry with Pixie, you start with our guided installation. The guided installation deploys Pixie with New Relic's Kubernetes integration on your cluster. You don't need to do any further configuration or installation to start using Pixie. If you want to install Auto-telemetry with Pixie on multiple clusters, re-run the guided install for each additional cluster. General prerequisites for using Pixie You must be a New Relic full platform user. Other user-related requirements: Users on our New Relic One user model must be assigned to a group that has a role with Pixie-related capabilities. Users on our original user model cannot be Restricted. Review this Pixie data security overview for actions to take to secure your data. Make sure you have sufficient memory: Pixie requires 2Gb of memory per node in your cluster. Review the other Pixie technical requirements. Setup steps depend on your account status Use the following table to find out where to start installing Auto-telemetry with Pixie. Where you start the installation depends on whether you already have a New Relic or Pixie account, or both. New Relic Pixie Next steps Start the guided install at the beginning of the process. If you already have both types of accounts, and used the same email address for each of them, click the New Relic icon in the Pixie UI. This brings you to the Configure the HELM command/manifest (yaml) file section of the guided installation. Then, follow the steps. If you're using different email addresses in Pixie and New Relic, create a new account for either Pixie or New Relic to match email addresses across both products. You can also contact New Relic support to manually link your existing New Relic account with your Pixie account. If you follow a link to New Relic from the Pixie UI and do not have a New Relic account, you must first create one. Click the New Relic icon in the Pixie UI, and follow the steps to create a New Relic account. When you do so, your Pixie account is linked to it. Then, continue the guided install process with these steps. Sign up for a free New Relic account. Then, start the guided install at the beginning of the process. Install from the beginning of the guided install process Open our New Relic One guided install. Select the account you want to use for the guided install, and click Continue. Note: if you have a single account, you won't see this option. Select Kubernetes and then continue with step one in the next section. Install from the Configure the HELM command/manifest (yaml) file If you arrived in the guided installation process by following a link from Pixie or from within New Relic, your steps begin here. Select the account and cluster for the install. If needed, select a namespace. Important Currently, Pixie performs best on clusters with up to 100 nodes (exceeding 100 nodes can lead to excessive memory usage and scripts failing to run). Friendly reminder: autoscaling can quickly drive up your node numbers. Click Continue. Select the data you want to gather, observe, and debug, and click Continue. On the Choose install method page, select either Helm or manifest. Helm method Run the provided Helm command on your command line. If you're concerned about the amount of Pixie data you'll ingest, check out strategies for reducing ingest. Helm installs a bundle containing the New Relic infrastructure agent, an integration to gather Prometheus metrics and Kubernetes events, and the Pixie integration. The deployment takes a few minutes to complete. To see the status of the install to the cluster, run kubectl get pods -n newrelic. For general information about installing a Kubernetes integration, see this Helm install info. manifest method Run the provided command in your console, and insert the path to your downloaded manifest. If you're running your Kubernetes cluster in the cloud, see the additional steps in the Kubernetes docs. Click Continue to open the Listening for data page. When you get the message, See your data, click Kubernetes Cluster Explorer to see your cluster. Auto-telemetry with Pixie might restart after installation. This is caused by the auto update feature. If you link the wrong Pixie and New Relic account Contact support to unlink a Pixie account from your New Relic account. Be aware that if you unlink a Pixie account that was created automatically through the guided install, you'll lose access to that Pixie account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 513.55707,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "sections": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": "To get up and running with <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>, you start with our guided installation. The guided installation deploys <em>Pixie</em> with New Relic&#x27;s <em>Kubernetes</em> integration on your cluster. You don&#x27;t need to do any further configuration or installation to start using <em>Pixie</em>. If you want to install"
      },
      "id": "6174ca14e7b9d26ba513cd12"
    },
    {
      "sections": [
        "Auto-telemetry with Pixie data and security",
        "Control who has access to Pixie data",
        "Manage auto-update and two-way communication",
        "Helm option",
        "newrelic-manifest.yaml option"
      ],
      "title": "Auto-telemetry with Pixie data and security",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry data",
        "Service monitoring",
        "Kubernetes",
        "eBPF",
        "Pixie data"
      ],
      "external_id": "acec5042b8735d73fa255829401e8708bd6d0595",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/pixie-data-security-overview/",
      "published_at": "2021-10-24T23:32:39Z",
      "updated_at": "2021-10-24T02:51:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Auto-telemetry with Pixie is New Relic One's integration of Community Cloud for Pixie, a managed version of Pixie open source software. Auto-telemetry with Pixie therefore benefits from Pixie's approach to keeping data secure. The data that Pixie collects is stored entirely within your Kubernetes cluster. This data does not persist outside of your environment, and will never be stored by Community Cloud for Pixie. This means that your sensitive data remains within your environment and control. Community Cloud for Pixie makes queries directly to your Kubernetes cluster to access the data. In order for the query results to be shown in the Community Cloud for Pixie UI, CLI, and API, the data is sent to the client from your cluster using a reverse proxy. Community Cloud for Pixie’s reverse proxy is designed to ensure: Data is ephemeral. It only passes through the Community Cloud for Pixie's cloud proxy in transit. This ensures data locality. Data is encrypted while in transit. Only you are able to read your data. New Relic One fetches and stores data that related to an application's performance. With Auto-telemetry with Pixie, a predefined subset of data persists outside of your cluster. This data is stored in our database, in your selected region. This data persists in order to give you long-term storage, alerting, correlation with additional data, and the ability to use advanced New Relic platform capabilities, such as anomaly detection. The persisted performance metrics include, but are not limited to: Golden metrics (throughput, latency, error rate) for HTTP-based services HTTP transaction data Database transaction data (for MySQL & PostgreSQL) Distributed tracing JVM metrics The data you view on the Live debugging tab comes through Community Cloud for Pixie, and is therefore potentially sensitive. It is not stored by New Relic and is ephemeral and queryable for less than 24 hours. Control who has access to Pixie data If you want to manage which members of your organization can view Pixie data in New Relic One, as well as install and delete Pixie links, you can create a custom role. Note that this option is available only to Enterprise and Pro level customers. For more information, see New Relic's user model. Manage auto-update and two-way communication Pixie maintains an active two-way communication channel from your host system to Community Cloud with Pixie at withpixie.ai. Pixie uses this communication channel to query data, push updates, and retrieve metadata and health checks about Pixie and your Kubernetes cluster. By default, Pixie queries withpixie.ai to check if new updates have been pushed and then automatically installs them if they’re present. To disable auto updates, you must set a flag prior to the install process using either Helm or in the newrelic-manifest.yaml file. To disable automatic updates, choose one: Helm option Add --set pixie-chart.disableAutoUpdate=true to your Helm command. newrelic-manifest.yaml option in your newrelic-manifest.yaml file under the pl-cluster-config section, add PL_DISABLE_AUTO_UPDATE: \"true\" to the data directive. Example: --- apiVersion: v1 data: PL_CUSTOM_ANNOTATIONS: \"\" PL_CUSTOM_LABELS: \"\" PL_DISABLE_AUTO_UPDATE: \"true\" PL_ETCD_OPERATOR_ENABLED: \"false\" PL_MD_ETCD_SERVER: \"https://etcd.newrelic.svc:2379\" PX_MEMORY_LIMIT: \"\" kind: ConfigMap metadata: annotations: creationTimestamp: null labels: name: pl-cluster-config namespace: newrelic --- Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 433.2984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data and security",
        "sections": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data and security",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em> data",
        "body": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> is New Relic One&#x27;s integration of Community Cloud for <em>Pixie</em>, a managed version of <em>Pixie</em> open source software. <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> therefore benefits from <em>Pixie</em>&#x27;s approach to keeping data secure. The data that <em>Pixie</em> collects is stored entirely within your <em>Kubernetes</em>"
      },
      "id": "6174ca40e7b9d203d413d744"
    },
    {
      "sections": [
        "Install Auto-telemetry with Pixie",
        "General prerequisites for using Pixie",
        "Setup steps depend on your account status",
        "Install from the beginning of the guided install process",
        "Install from the Configure the HELM command/manifest (yaml) file",
        "Important",
        "Helm method",
        "manifest method",
        "If you link the wrong Pixie and New Relic account",
        "Reduce ingest during install with Helm"
      ],
      "title": "Install Auto-telemetry with Pixie",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "0950cfd46d2665325c85ef2acc22f1a84933743c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/auto-telemetry-pixie/install-auto-telemetry-pixie/",
      "published_at": "2021-10-18T12:40:36Z",
      "updated_at": "2021-09-27T15:20:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To get up and running with Auto-telemetry with Pixie, you start with our guided installation. The guided installation deploys Pixie with New Relic's Kubernetes integration on your cluster. You don't need to do any further configuration or installation to start using Pixie. If you want to install Auto-telemetry with Pixie on multiple clusters, re-run the guided install for each additional cluster. General prerequisites for using Pixie You must be a New Relic full platform user. Other user-related requirements: Users on our New Relic One user model must be assigned to a group that has a role with Pixie-related capabilities. Users on our original user model cannot be Restricted. Review this Pixie data security overview for actions to take to secure your data. Make sure you have sufficient memory: Pixie requires 2Gb of memory per node in your cluster. Review the other Pixie technical requirements. Setup steps depend on your account status Use the following table to find out where to start installing Auto-telemetry with Pixie. Where you start the installation depends on whether you already have a New Relic or Pixie account, or both. New Relic Pixie Next steps Start the guided install at the beginning of the process. If you already have both types of accounts, and used the same email address for each of them, click the New Relic icon in the Pixie UI. This brings you to the Configure the HELM command/manifest (yaml) file section of the guided installation. Then, follow the steps. If you're using different email addresses in Pixie and New Relic, create a new account for either Pixie or New Relic to match email addresses across both products. You can also contact New Relic support to manually link your existing New Relic account with your Pixie account. If you follow a link to New Relic from the Pixie UI and do not have a New Relic account, you must first create one. Click the New Relic icon in the Pixie UI, and follow the steps to create a New Relic account. When you do so, your Pixie account is linked to it. Then, continue the guided install process with these steps. Sign up for a free New Relic account. Then, start the guided install at the beginning of the process. Install from the beginning of the guided install process Open our New Relic One guided install. Select the account you want to use for the guided install, and click Continue. Note: if you have a single account, you won't see this option. Select Kubernetes and then continue with step one in the next section. Install from the Configure the HELM command/manifest (yaml) file If you arrived in the guided installation process by following a link from Pixie or from within New Relic, your steps begin here. Select the account and cluster for the install. If needed, select a namespace. Important Currently, Pixie performs best on clusters with up to 100 nodes (exceeding 100 nodes can lead to excessive memory usage and scripts failing to run). Friendly reminder: autoscaling can quickly drive up your node numbers. Click Continue. Select the data you want to gather, observe, and debug, and click Continue. On the Choose install method page, select either Helm or manifest. Helm method Run the provided Helm command on your command line. If you're concerned about the amount of Pixie data you'll ingest, find some parameters for reducing ingest below. Helm installs a bundle containing the New Relic infrastructure agent, an integration to gather Prometheus metrics and Kubernetes events, and the Pixie integration. The deployment takes a few minutes to complete. To see the status of the install to the cluster, run kubectl get pods -n newrelic. For general information about installing a Kubernetes integration, see this Helm install info. manifest method Run the provided command in your console, and insert the path to your downloaded manifest. If you're running your Kubernetes cluster in the cloud, see the additional steps in the Kubernetes docs. Click Continue to open the Listening for data page. When you get the message, See your data, click Kubernetes Cluster Explorer to see your cluster. Auto-telemetry with Pixie might restart after installation. This is caused by the auto update feature. If you link the wrong Pixie and New Relic account Contact support to unlink a Pixie account from your New Relic account. Be aware that if you unlink a Pixie account that was created automatically through the guided install, you'll lose access to that Pixie account. Reduce ingest during install with Helm If you want to reduce the amount of Pixie data that New Relic ingests, you can add the following parameters to your Helm chart during installation. Note that the data still exists in Pixie: excludeNamespacesRegex - use to identify the namespaces that you want to exclude from sending observability data to New Relic. If empty, data for all namespaces is sent to New Relic. Example: --set newrelic-pixie.excludeNamespacesRegex=\"examplenamespace-1|examplenamespace-2\" excludePodsRegex - use to identify pods across all namespaces that you want to exclude from sending observability data to New Relic. If empty, data for all pods (except those in excluded namespaces) is sent to New Relic. Example: --set newrelic-pixie.excludePodsRegex=\"examplepod-1|examplepod-2\" Learn more about the available parameters for the newrelic-pixie Helm chart here.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.2703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "sections": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": "To get up and running with <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>, you start with our guided installation. The guided installation deploys <em>Pixie</em> with New Relic&#x27;s <em>Kubernetes</em> integration on your cluster. You don&#x27;t need to do any further configuration or installation to start using <em>Pixie</em>. If you want to install"
      },
      "id": "614754c628ccbc38d556a84c"
    }
  ],
  "/docs/kubernetes-pixie/auto-telemetry-pixie/install-auto-telemetry-pixie": [
    {
      "sections": [
        "Auto-telemetry with Pixie for instant Kubernetes observability",
        "Quickly start observing and debugging Kubernetes clusters",
        "Important",
        "Explore your cluster",
        "Tip",
        "Investigate usage spikes with Flamegraph",
        "Debug live"
      ],
      "title": "Auto-telemetry with Pixie for instant Kubernetes observability",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "1dc7474aedbf84c51593c152fc39fda0a46b4f48",
      "image": "https://docs.newrelic.com/static/1e793128e5d6019bbebd8123dbf943ab/c1b63/service-graph.png",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/get-started-auto-telemetry-pixie/",
      "published_at": "2021-10-24T23:31:41Z",
      "updated_at": "2021-10-24T02:52:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When we say auto-telemetry, we’re not talking about cars — we're talking about instant baseline visibility into your Kubernetes clusters. With the New Relic One integration with Pixie, you get similar data to traditional language agents, but without manually instrumenting your code or redeploying your application. Pixie auto-telemetry is powered by eBPF, a virtual machine-like construct that enables Pixie to seamlessly collect fine-grained telemetry data — service-level metrics, unsampled requests, and more. With one install command, you get deeper insight into your Kubernetes clusters and workloads. No language agents required. Live debugging with Pixie shows a service graph listing the namespaces and the node that are available on the current cluster. Simply put, Auto-telemetry with Pixie offers the quickest option for getting observability into your Kubernetes services. Quickly start observing and debugging Kubernetes clusters Our Pixie integration gives you the best of both worlds: Pixie’s fast and simple Kubernetes observability coupled with New Relic One’s incident correlation, intelligent alerting, and long-term retention. You’ll get visibility into HTTP services using golden signals, HTTP transactions, database transactions, distributed tracing, and JVM metrics. You can operate, debug, and scale your Kubernetes clusters based on the information you learn about how your clusters and services are running. Using the New Relic Explorer, you can see key metrics and events at every level, starting with the cluster, and diving down into namespaces, deployments, and pods. You can quickly spot anomalous behavior, and where it’s happening. And then dive deeper using embedded visualizations of your Pixie data. Quickly identify hot spots with Flamegraph. On the Live debugging with Pixie tab, answer questions like what SQL requests your app is making or which services are talking to each other. Important Auto-Telemetry with Pixie leverages Community Cloud with Pixie, a separate platform from New Relic One. Use of Community Cloud with Pixie is subject to separate terms of service. Explore your cluster Access the Pixie UI via New Relic's Live debugging with Pixie area of your Kubernetes clusters. The cluster explorer provides a quick overview of the nodes in your cluster, including CPU, memory, and storage, as well as the status of each pod (healthy, warning, or critical). You can also find out what services are running in each container, their latency, throughput, and error rate. For more information about using the cluster explorer, see Navigate the Kubernetes cluster explorer. Note that you cannot log directly into the Pixie UI unless you have created a separate Pixie login. Tip Containers might be listed for up to four hours after they get decommissioned. You can query the Pixie data in New Relic One and create dashboards for at-a-glance monitoring. Find the data model and sample queries here. Investigate usage spikes with Flamegraph Debugging is orders of magnitude easier when you can quickly see what your application is doing. Flamegraph, a Pixie always-on visualization, requires no instrumentation, redeploying, or recompiling. It works for compiled languages like Go, C+, Rust, to name a few. And at a glance, Flamegraph tells you what functions your application is spending time on and where you have hot spots. Flamegraph is especially useful for hierarchical resource use, like disk usage and CPU utilization. For more information on how to read Flamegraph, see the Pixie documentation. Debug live On the Live debugging with Pixie tab, run PxL scripts — scripts written in Pixie's PxL language — to view live data captured through eBPF. Select the script drop-down and then select a script to run in the tab. (For best results, select a time range that is recent in the time picker.) Scripts enable you to debug: Traffic in multiple formats: HTTP and HTTPs (including encrypted), DNS, Postgres, MySQL, Cassandra, Redis (currently supporting SQL and HTTP in beta). Learn more: Request tracing tutorial. Database request performance. Learn more: Database Query Profiling tutorial. Service maps to learn which services are talking to each other. Learn more: Service Performance tutorial. Network traffic maps to learn which nodes are talking to each other. Learn more: Network Monitoring tutorial. Monitor resource usage by Node and Pod. Learn more: Infra health tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 712.2231,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> for instant <em>Kubernetes</em> observability",
        "sections": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> for instant <em>Kubernetes</em> observability",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": " your application. <em>Pixie</em> <em>auto</em>-<em>telemetry</em> is powered by <em>eBPF</em>, a virtual machine-like construct that enables <em>Pixie</em> to seamlessly collect fine-grained <em>telemetry</em> data — <em>service</em>-level metrics, unsampled requests, and more. With one install command, you get deeper insight into your <em>Kubernetes</em> clusters"
      },
      "id": "6174ca7364441f0e385fdea5"
    },
    {
      "sections": [
        "Auto-telemetry with Pixie data and security",
        "Control who has access to Pixie data",
        "Manage auto-update and two-way communication",
        "Helm option",
        "newrelic-manifest.yaml option"
      ],
      "title": "Auto-telemetry with Pixie data and security",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry data",
        "Service monitoring",
        "Kubernetes",
        "eBPF",
        "Pixie data"
      ],
      "external_id": "acec5042b8735d73fa255829401e8708bd6d0595",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/pixie-data-security-overview/",
      "published_at": "2021-10-24T23:32:39Z",
      "updated_at": "2021-10-24T02:51:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Auto-telemetry with Pixie is New Relic One's integration of Community Cloud for Pixie, a managed version of Pixie open source software. Auto-telemetry with Pixie therefore benefits from Pixie's approach to keeping data secure. The data that Pixie collects is stored entirely within your Kubernetes cluster. This data does not persist outside of your environment, and will never be stored by Community Cloud for Pixie. This means that your sensitive data remains within your environment and control. Community Cloud for Pixie makes queries directly to your Kubernetes cluster to access the data. In order for the query results to be shown in the Community Cloud for Pixie UI, CLI, and API, the data is sent to the client from your cluster using a reverse proxy. Community Cloud for Pixie’s reverse proxy is designed to ensure: Data is ephemeral. It only passes through the Community Cloud for Pixie's cloud proxy in transit. This ensures data locality. Data is encrypted while in transit. Only you are able to read your data. New Relic One fetches and stores data that related to an application's performance. With Auto-telemetry with Pixie, a predefined subset of data persists outside of your cluster. This data is stored in our database, in your selected region. This data persists in order to give you long-term storage, alerting, correlation with additional data, and the ability to use advanced New Relic platform capabilities, such as anomaly detection. The persisted performance metrics include, but are not limited to: Golden metrics (throughput, latency, error rate) for HTTP-based services HTTP transaction data Database transaction data (for MySQL & PostgreSQL) Distributed tracing JVM metrics The data you view on the Live debugging tab comes through Community Cloud for Pixie, and is therefore potentially sensitive. It is not stored by New Relic and is ephemeral and queryable for less than 24 hours. Control who has access to Pixie data If you want to manage which members of your organization can view Pixie data in New Relic One, as well as install and delete Pixie links, you can create a custom role. Note that this option is available only to Enterprise and Pro level customers. For more information, see New Relic's user model. Manage auto-update and two-way communication Pixie maintains an active two-way communication channel from your host system to Community Cloud with Pixie at withpixie.ai. Pixie uses this communication channel to query data, push updates, and retrieve metadata and health checks about Pixie and your Kubernetes cluster. By default, Pixie queries withpixie.ai to check if new updates have been pushed and then automatically installs them if they’re present. To disable auto updates, you must set a flag prior to the install process using either Helm or in the newrelic-manifest.yaml file. To disable automatic updates, choose one: Helm option Add --set pixie-chart.disableAutoUpdate=true to your Helm command. newrelic-manifest.yaml option in your newrelic-manifest.yaml file under the pl-cluster-config section, add PL_DISABLE_AUTO_UPDATE: \"true\" to the data directive. Example: --- apiVersion: v1 data: PL_CUSTOM_ANNOTATIONS: \"\" PL_CUSTOM_LABELS: \"\" PL_DISABLE_AUTO_UPDATE: \"true\" PL_ETCD_OPERATOR_ENABLED: \"false\" PL_MD_ETCD_SERVER: \"https://etcd.newrelic.svc:2379\" PX_MEMORY_LIMIT: \"\" kind: ConfigMap metadata: annotations: creationTimestamp: null labels: name: pl-cluster-config namespace: newrelic --- Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 433.2981,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data and security",
        "sections": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data and security",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em> data",
        "body": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> is New Relic One&#x27;s integration of Community Cloud for <em>Pixie</em>, a managed version of <em>Pixie</em> open source software. <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> therefore benefits from <em>Pixie</em>&#x27;s approach to keeping data secure. The data that <em>Pixie</em> collects is stored entirely within your <em>Kubernetes</em>"
      },
      "id": "6174ca40e7b9d203d413d744"
    },
    {
      "sections": [
        "Manage your Auto-telemetry with Pixie data ingest",
        "Exclude namespaces and pods",
        "Use Kubernetes features to collect selected data"
      ],
      "title": "Manage your Auto-telemetry with Pixie data ingest",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Kubernetes pods",
        "Kubernetes",
        "manage Pixie data"
      ],
      "external_id": "2d4fe0c707ac63c7625317cb20a544bc5f0e03d8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/manage-pixie-data/",
      "published_at": "2021-10-24T23:32:39Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You have options for the type and the amount of data you ingest when you install Auto-telemetry with Pixie. During install, use Helm to reduce or exclude data, either by excluding specific namespaces or pods, or by collecting data for only the nodes you want. Exclude namespaces and pods If you want to reduce the amount of Pixie data that New Relic ingests, you can exclude namespaces or pods by adding the following parameters to your Helm chart during installation. Note that the data still exists in Pixie: excludeNamespacesRegex - use to identify the namespaces that you want to exclude from sending observability data to New Relic. If empty, data for all namespaces is sent to New Relic. For example: --set newrelic-pixie.excludeNamespacesRegex=\"examplenamespace-1|examplenamespace-2\" Copy excludePodsRegex - use to identify pods across all namespaces that you want to exclude from sending observability data to New Relic. If empty, data for all pods (except those in excluded namespaces) is sent to New Relic. For example: --set newrelic-pixie.excludePodsRegex=\"examplepod-1|examplepod-2\" Copy These two configuration options provide additional control over the Metric and Span data sent to New Relic from Pixie. For example, if you wanted to configure the newrelic-pixie integration to exclude all namespaces except for px-sock-shop and kafka-demo, append the following config parameter to your Helm install or Helm upgrade command. --set newrelic-pixie.excludeNamespacesRegex=\"default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator\" Copy Or, if you wanted to exclude pods running in a non-excluded namespace, you could add another configuration parameter to your Helm install or Helm upgrade. Instead of matching exact names, you can use a simple regex to match pod names related to load testing, just as an example. --set newrelic-pixie.excludePodsRegex=\"load-test.*|loadgen.*\" Copy If you're performing a brand new install, you'll need to append excludeNamespacesRegex and excludePodsRegex to the helm upgrade --install command provided by New Relic's guided install: kubectl apply -f https://raw.githubusercontent.com/pixie-labs/pixie/main/k8s/operator/crd/base/px.dev_viziers.yaml && \\ kubectl apply -f https://raw.githubusercontent.com/pixie-labs/pixie/main/k8s/operator/helm/crds/olm_crd.yaml && \\ helm repo add newrelic https://helm-charts.newrelic.com && helm repo update && \\ kubectl create namespace newrelic ; helm upgrade --install newrelic-bundle newrelic/nri-bundle \\ --set global.licenseKey=<NR LICENSE KEY> \\ --set global.cluster=pixie-auto-telemetry \\ --namespace=newrelic \\ --set newrelic-infrastructure.privileged=true \\ --set ksm.enabled=true \\ --set prometheus.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true \\ --set newrelic-pixie.enabled=true \\ --set newrelic-pixie.apiKey=<PIXIE API KEY> \\ --set pixie-chart.enabled=true \\ --set pixie-chart.deployKey=<PIXIE DEPLOY KEY> \\ --set pixie-chart.clusterName=pixie-auto-telemetry \\ --set newrelic-pixie.excludeNamespacesRegex=\"default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator\" \\ --set newrelic-pixie.excludePodsRegex=\"load-test.*|loadgen.*\" Copy If you're just upgrading an existing install, then this is a much simpler approach: helm upgrade newrelic-bundle newrelic/nri-bundle --reuse-values -n newrelic --set newrelic-pixie.excludeNamespacesRegex=\"default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator Copy Learn more about the available parameters for the newrelic-pixie Helm chart here. Use Kubernetes features to collect selected data When you deploy Auto-telemetry with Pixie, you're actually enabling the Auto-telemetry with Pixie Helm chart, as well as other New Relic components included in the New Relic infrastructure bundle. The Pixie Edge Module (PEM) pods are deployed to the cluster as a Kubernetes DaemonSet. This means that by default, a pod is scheduled to every cluster node and is responsible for collecting all of the observability metrics for that node. In Kubernetes, you can assign pods to a specific subset of cluster nodes using nodeSelectors, taints/tolerations, and node affinity/anti-affinity. That way, you'll only collect metrics for the nodes you choose, instead of every node. This is helpful if you only want to deploy Auto-telemetry with Pixie to five of your ten cluster nodes, for example. Maybe the designated five nodes are responsible for high-priority workloads, or perhaps you're running both Linux and Windows nodes in your cluster and only want to deploy on the Linux nodes, since Windows nodes are not currently supported. You can now assign pods to a subset of nodes by providing an additional option to the guided installation command. This option passes an escaped JSON string to the Auto-telemetry with Pixie chart, which enables a nodeSelector that only schedules the PEM DaemonSet on nodes with the label pixie=allowed. --set pixie-chart.patches.vizier-pem='\\{\\\"spec\\\"\\: \\{\\\"template\\\"\\: \\{\\\"spec\\\"\\: \\{ \\\"nodeSelector\\\"\\: \\{\\\"pixie\\\"\\: \\\"allowed\\\" \\}\\}\\}\\}\\}' Copy If you're using a values file, common with Helm, then this is what that would look like in the nri-bundle values.yaml: pixie-chart: enabled: true patches: vizier-pem: '{\"spec\": {\"template\": {\"spec\": { \"nodeSelector\": {\"pixie\": \"allowed\" }}}}}' Copy This approach gives you a multitude of configuration options; you just need to stick with the standard Kubernetes spec.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.64758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data ingest",
        "sections": "Manage your <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data ingest",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": " for the newrelic-<em>pixie</em> Helm chart here. Use <em>Kubernetes</em> features to collect selected data When you deploy <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>, you&#x27;re actually enabling the <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> Helm chart, as well as other New Relic components included in the New Relic infrastructure bundle. The <em>Pixie</em> Edge Module (PEM"
      },
      "id": "6174cb5b64441f9af45fe035"
    }
  ],
  "/docs/kubernetes-pixie/auto-telemetry-pixie/manage-pixie-data": [
    {
      "sections": [
        "Auto-telemetry with Pixie for instant Kubernetes observability",
        "Quickly start observing and debugging Kubernetes clusters",
        "Important",
        "Explore your cluster",
        "Tip",
        "Investigate usage spikes with Flamegraph",
        "Debug live"
      ],
      "title": "Auto-telemetry with Pixie for instant Kubernetes observability",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "1dc7474aedbf84c51593c152fc39fda0a46b4f48",
      "image": "https://docs.newrelic.com/static/1e793128e5d6019bbebd8123dbf943ab/c1b63/service-graph.png",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/get-started-auto-telemetry-pixie/",
      "published_at": "2021-10-24T23:31:41Z",
      "updated_at": "2021-10-24T02:52:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When we say auto-telemetry, we’re not talking about cars — we're talking about instant baseline visibility into your Kubernetes clusters. With the New Relic One integration with Pixie, you get similar data to traditional language agents, but without manually instrumenting your code or redeploying your application. Pixie auto-telemetry is powered by eBPF, a virtual machine-like construct that enables Pixie to seamlessly collect fine-grained telemetry data — service-level metrics, unsampled requests, and more. With one install command, you get deeper insight into your Kubernetes clusters and workloads. No language agents required. Live debugging with Pixie shows a service graph listing the namespaces and the node that are available on the current cluster. Simply put, Auto-telemetry with Pixie offers the quickest option for getting observability into your Kubernetes services. Quickly start observing and debugging Kubernetes clusters Our Pixie integration gives you the best of both worlds: Pixie’s fast and simple Kubernetes observability coupled with New Relic One’s incident correlation, intelligent alerting, and long-term retention. You’ll get visibility into HTTP services using golden signals, HTTP transactions, database transactions, distributed tracing, and JVM metrics. You can operate, debug, and scale your Kubernetes clusters based on the information you learn about how your clusters and services are running. Using the New Relic Explorer, you can see key metrics and events at every level, starting with the cluster, and diving down into namespaces, deployments, and pods. You can quickly spot anomalous behavior, and where it’s happening. And then dive deeper using embedded visualizations of your Pixie data. Quickly identify hot spots with Flamegraph. On the Live debugging with Pixie tab, answer questions like what SQL requests your app is making or which services are talking to each other. Important Auto-Telemetry with Pixie leverages Community Cloud with Pixie, a separate platform from New Relic One. Use of Community Cloud with Pixie is subject to separate terms of service. Explore your cluster Access the Pixie UI via New Relic's Live debugging with Pixie area of your Kubernetes clusters. The cluster explorer provides a quick overview of the nodes in your cluster, including CPU, memory, and storage, as well as the status of each pod (healthy, warning, or critical). You can also find out what services are running in each container, their latency, throughput, and error rate. For more information about using the cluster explorer, see Navigate the Kubernetes cluster explorer. Note that you cannot log directly into the Pixie UI unless you have created a separate Pixie login. Tip Containers might be listed for up to four hours after they get decommissioned. You can query the Pixie data in New Relic One and create dashboards for at-a-glance monitoring. Find the data model and sample queries here. Investigate usage spikes with Flamegraph Debugging is orders of magnitude easier when you can quickly see what your application is doing. Flamegraph, a Pixie always-on visualization, requires no instrumentation, redeploying, or recompiling. It works for compiled languages like Go, C+, Rust, to name a few. And at a glance, Flamegraph tells you what functions your application is spending time on and where you have hot spots. Flamegraph is especially useful for hierarchical resource use, like disk usage and CPU utilization. For more information on how to read Flamegraph, see the Pixie documentation. Debug live On the Live debugging with Pixie tab, run PxL scripts — scripts written in Pixie's PxL language — to view live data captured through eBPF. Select the script drop-down and then select a script to run in the tab. (For best results, select a time range that is recent in the time picker.) Scripts enable you to debug: Traffic in multiple formats: HTTP and HTTPs (including encrypted), DNS, Postgres, MySQL, Cassandra, Redis (currently supporting SQL and HTTP in beta). Learn more: Request tracing tutorial. Database request performance. Learn more: Database Query Profiling tutorial. Service maps to learn which services are talking to each other. Learn more: Service Performance tutorial. Network traffic maps to learn which nodes are talking to each other. Learn more: Network Monitoring tutorial. Monitor resource usage by Node and Pod. Learn more: Infra health tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.1366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> for instant <em>Kubernetes</em> observability",
        "sections": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> for instant <em>Kubernetes</em> observability",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": "When we say <em>auto</em>-<em>telemetry</em>, we’re not talking about cars — we&#x27;re talking about instant baseline visibility into your <em>Kubernetes</em> clusters. With the New Relic One integration with <em>Pixie</em>, you get similar <em>data</em> to traditional language agents, but without manually instrumenting your code or redeploying"
      },
      "id": "6174ca7364441f0e385fdea5"
    },
    {
      "sections": [
        "Install Auto-telemetry with Pixie",
        "General prerequisites for using Pixie",
        "Setup steps depend on your account status",
        "Install from the beginning of the guided install process",
        "Install from the Configure the HELM command/manifest (yaml) file",
        "Important",
        "Helm method",
        "manifest method",
        "If you link the wrong Pixie and New Relic account"
      ],
      "title": "Install Auto-telemetry with Pixie",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "bb957763e579e39ef2bbeafeebc46ab3a111bca2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/install-auto-telemetry-pixie/",
      "published_at": "2021-10-24T23:30:47Z",
      "updated_at": "2021-10-24T02:51:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To get up and running with Auto-telemetry with Pixie, you start with our guided installation. The guided installation deploys Pixie with New Relic's Kubernetes integration on your cluster. You don't need to do any further configuration or installation to start using Pixie. If you want to install Auto-telemetry with Pixie on multiple clusters, re-run the guided install for each additional cluster. General prerequisites for using Pixie You must be a New Relic full platform user. Other user-related requirements: Users on our New Relic One user model must be assigned to a group that has a role with Pixie-related capabilities. Users on our original user model cannot be Restricted. Review this Pixie data security overview for actions to take to secure your data. Make sure you have sufficient memory: Pixie requires 2Gb of memory per node in your cluster. Review the other Pixie technical requirements. Setup steps depend on your account status Use the following table to find out where to start installing Auto-telemetry with Pixie. Where you start the installation depends on whether you already have a New Relic or Pixie account, or both. New Relic Pixie Next steps Start the guided install at the beginning of the process. If you already have both types of accounts, and used the same email address for each of them, click the New Relic icon in the Pixie UI. This brings you to the Configure the HELM command/manifest (yaml) file section of the guided installation. Then, follow the steps. If you're using different email addresses in Pixie and New Relic, create a new account for either Pixie or New Relic to match email addresses across both products. You can also contact New Relic support to manually link your existing New Relic account with your Pixie account. If you follow a link to New Relic from the Pixie UI and do not have a New Relic account, you must first create one. Click the New Relic icon in the Pixie UI, and follow the steps to create a New Relic account. When you do so, your Pixie account is linked to it. Then, continue the guided install process with these steps. Sign up for a free New Relic account. Then, start the guided install at the beginning of the process. Install from the beginning of the guided install process Open our New Relic One guided install. Select the account you want to use for the guided install, and click Continue. Note: if you have a single account, you won't see this option. Select Kubernetes and then continue with step one in the next section. Install from the Configure the HELM command/manifest (yaml) file If you arrived in the guided installation process by following a link from Pixie or from within New Relic, your steps begin here. Select the account and cluster for the install. If needed, select a namespace. Important Currently, Pixie performs best on clusters with up to 100 nodes (exceeding 100 nodes can lead to excessive memory usage and scripts failing to run). Friendly reminder: autoscaling can quickly drive up your node numbers. Click Continue. Select the data you want to gather, observe, and debug, and click Continue. On the Choose install method page, select either Helm or manifest. Helm method Run the provided Helm command on your command line. If you're concerned about the amount of Pixie data you'll ingest, check out strategies for reducing ingest. Helm installs a bundle containing the New Relic infrastructure agent, an integration to gather Prometheus metrics and Kubernetes events, and the Pixie integration. The deployment takes a few minutes to complete. To see the status of the install to the cluster, run kubectl get pods -n newrelic. For general information about installing a Kubernetes integration, see this Helm install info. manifest method Run the provided command in your console, and insert the path to your downloaded manifest. If you're running your Kubernetes cluster in the cloud, see the additional steps in the Kubernetes docs. Click Continue to open the Listening for data page. When you get the message, See your data, click Kubernetes Cluster Explorer to see your cluster. Auto-telemetry with Pixie might restart after installation. This is caused by the auto update feature. If you link the wrong Pixie and New Relic account Contact support to unlink a Pixie account from your New Relic account. Be aware that if you unlink a Pixie account that was created automatically through the guided install, you'll lose access to that Pixie account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.1117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "sections": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": " the additional steps in the <em>Kubernetes</em> docs. Click Continue to open the Listening for <em>data</em> page. When you get the message, See your <em>data</em>, click <em>Kubernetes</em> Cluster Explorer to see your cluster. <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> might restart after installation. This is caused by the <em>auto</em> update feature"
      },
      "id": "6174ca14e7b9d26ba513cd12"
    },
    {
      "sections": [
        "Auto-telemetry with Pixie data and security",
        "Control who has access to Pixie data",
        "Manage auto-update and two-way communication",
        "Helm option",
        "newrelic-manifest.yaml option"
      ],
      "title": "Auto-telemetry with Pixie data and security",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry data",
        "Service monitoring",
        "Kubernetes",
        "eBPF",
        "Pixie data"
      ],
      "external_id": "acec5042b8735d73fa255829401e8708bd6d0595",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/pixie-data-security-overview/",
      "published_at": "2021-10-24T23:32:39Z",
      "updated_at": "2021-10-24T02:51:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Auto-telemetry with Pixie is New Relic One's integration of Community Cloud for Pixie, a managed version of Pixie open source software. Auto-telemetry with Pixie therefore benefits from Pixie's approach to keeping data secure. The data that Pixie collects is stored entirely within your Kubernetes cluster. This data does not persist outside of your environment, and will never be stored by Community Cloud for Pixie. This means that your sensitive data remains within your environment and control. Community Cloud for Pixie makes queries directly to your Kubernetes cluster to access the data. In order for the query results to be shown in the Community Cloud for Pixie UI, CLI, and API, the data is sent to the client from your cluster using a reverse proxy. Community Cloud for Pixie’s reverse proxy is designed to ensure: Data is ephemeral. It only passes through the Community Cloud for Pixie's cloud proxy in transit. This ensures data locality. Data is encrypted while in transit. Only you are able to read your data. New Relic One fetches and stores data that related to an application's performance. With Auto-telemetry with Pixie, a predefined subset of data persists outside of your cluster. This data is stored in our database, in your selected region. This data persists in order to give you long-term storage, alerting, correlation with additional data, and the ability to use advanced New Relic platform capabilities, such as anomaly detection. The persisted performance metrics include, but are not limited to: Golden metrics (throughput, latency, error rate) for HTTP-based services HTTP transaction data Database transaction data (for MySQL & PostgreSQL) Distributed tracing JVM metrics The data you view on the Live debugging tab comes through Community Cloud for Pixie, and is therefore potentially sensitive. It is not stored by New Relic and is ephemeral and queryable for less than 24 hours. Control who has access to Pixie data If you want to manage which members of your organization can view Pixie data in New Relic One, as well as install and delete Pixie links, you can create a custom role. Note that this option is available only to Enterprise and Pro level customers. For more information, see New Relic's user model. Manage auto-update and two-way communication Pixie maintains an active two-way communication channel from your host system to Community Cloud with Pixie at withpixie.ai. Pixie uses this communication channel to query data, push updates, and retrieve metadata and health checks about Pixie and your Kubernetes cluster. By default, Pixie queries withpixie.ai to check if new updates have been pushed and then automatically installs them if they’re present. To disable auto updates, you must set a flag prior to the install process using either Helm or in the newrelic-manifest.yaml file. To disable automatic updates, choose one: Helm option Add --set pixie-chart.disableAutoUpdate=true to your Helm command. newrelic-manifest.yaml option in your newrelic-manifest.yaml file under the pl-cluster-config section, add PL_DISABLE_AUTO_UPDATE: \"true\" to the data directive. Example: --- apiVersion: v1 data: PL_CUSTOM_ANNOTATIONS: \"\" PL_CUSTOM_LABELS: \"\" PL_DISABLE_AUTO_UPDATE: \"true\" PL_ETCD_OPERATOR_ENABLED: \"false\" PL_MD_ETCD_SERVER: \"https://etcd.newrelic.svc:2379\" PX_MEMORY_LIMIT: \"\" kind: ConfigMap metadata: annotations: creationTimestamp: null labels: name: pl-cluster-config namespace: newrelic --- Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.86038,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> <em>data</em> and security",
        "sections": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> <em>data</em> and security",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em> <em>data</em>",
        "body": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> is New Relic One&#x27;s integration of Community Cloud for <em>Pixie</em>, a managed version of <em>Pixie</em> open source software. <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> therefore benefits from <em>Pixie</em>&#x27;s approach to keeping <em>data</em> secure. The <em>data</em> that <em>Pixie</em> collects is stored entirely within your <em>Kubernetes</em>"
      },
      "id": "6174ca40e7b9d203d413d744"
    }
  ],
  "/docs/kubernetes-pixie/auto-telemetry-pixie/pixie-data-security-overview": [
    {
      "sections": [
        "Auto-telemetry with Pixie for instant Kubernetes observability",
        "Quickly start observing and debugging Kubernetes clusters",
        "Important",
        "Explore your cluster",
        "Tip",
        "Investigate usage spikes with Flamegraph",
        "Debug live"
      ],
      "title": "Auto-telemetry with Pixie for instant Kubernetes observability",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "1dc7474aedbf84c51593c152fc39fda0a46b4f48",
      "image": "https://docs.newrelic.com/static/1e793128e5d6019bbebd8123dbf943ab/c1b63/service-graph.png",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/get-started-auto-telemetry-pixie/",
      "published_at": "2021-10-24T23:31:41Z",
      "updated_at": "2021-10-24T02:52:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When we say auto-telemetry, we’re not talking about cars — we're talking about instant baseline visibility into your Kubernetes clusters. With the New Relic One integration with Pixie, you get similar data to traditional language agents, but without manually instrumenting your code or redeploying your application. Pixie auto-telemetry is powered by eBPF, a virtual machine-like construct that enables Pixie to seamlessly collect fine-grained telemetry data — service-level metrics, unsampled requests, and more. With one install command, you get deeper insight into your Kubernetes clusters and workloads. No language agents required. Live debugging with Pixie shows a service graph listing the namespaces and the node that are available on the current cluster. Simply put, Auto-telemetry with Pixie offers the quickest option for getting observability into your Kubernetes services. Quickly start observing and debugging Kubernetes clusters Our Pixie integration gives you the best of both worlds: Pixie’s fast and simple Kubernetes observability coupled with New Relic One’s incident correlation, intelligent alerting, and long-term retention. You’ll get visibility into HTTP services using golden signals, HTTP transactions, database transactions, distributed tracing, and JVM metrics. You can operate, debug, and scale your Kubernetes clusters based on the information you learn about how your clusters and services are running. Using the New Relic Explorer, you can see key metrics and events at every level, starting with the cluster, and diving down into namespaces, deployments, and pods. You can quickly spot anomalous behavior, and where it’s happening. And then dive deeper using embedded visualizations of your Pixie data. Quickly identify hot spots with Flamegraph. On the Live debugging with Pixie tab, answer questions like what SQL requests your app is making or which services are talking to each other. Important Auto-Telemetry with Pixie leverages Community Cloud with Pixie, a separate platform from New Relic One. Use of Community Cloud with Pixie is subject to separate terms of service. Explore your cluster Access the Pixie UI via New Relic's Live debugging with Pixie area of your Kubernetes clusters. The cluster explorer provides a quick overview of the nodes in your cluster, including CPU, memory, and storage, as well as the status of each pod (healthy, warning, or critical). You can also find out what services are running in each container, their latency, throughput, and error rate. For more information about using the cluster explorer, see Navigate the Kubernetes cluster explorer. Note that you cannot log directly into the Pixie UI unless you have created a separate Pixie login. Tip Containers might be listed for up to four hours after they get decommissioned. You can query the Pixie data in New Relic One and create dashboards for at-a-glance monitoring. Find the data model and sample queries here. Investigate usage spikes with Flamegraph Debugging is orders of magnitude easier when you can quickly see what your application is doing. Flamegraph, a Pixie always-on visualization, requires no instrumentation, redeploying, or recompiling. It works for compiled languages like Go, C+, Rust, to name a few. And at a glance, Flamegraph tells you what functions your application is spending time on and where you have hot spots. Flamegraph is especially useful for hierarchical resource use, like disk usage and CPU utilization. For more information on how to read Flamegraph, see the Pixie documentation. Debug live On the Live debugging with Pixie tab, run PxL scripts — scripts written in Pixie's PxL language — to view live data captured through eBPF. Select the script drop-down and then select a script to run in the tab. (For best results, select a time range that is recent in the time picker.) Scripts enable you to debug: Traffic in multiple formats: HTTP and HTTPs (including encrypted), DNS, Postgres, MySQL, Cassandra, Redis (currently supporting SQL and HTTP in beta). Learn more: Request tracing tutorial. Database request performance. Learn more: Database Query Profiling tutorial. Service maps to learn which services are talking to each other. Learn more: Service Performance tutorial. Network traffic maps to learn which nodes are talking to each other. Learn more: Network Monitoring tutorial. Monitor resource usage by Node and Pod. Learn more: Infra health tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 507.26172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> for instant <em>Kubernetes</em> observability",
        "sections": "<em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> for instant <em>Kubernetes</em> observability",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": " your application. <em>Pixie</em> <em>auto</em>-<em>telemetry</em> is powered by <em>eBPF</em>, a virtual machine-like construct that enables <em>Pixie</em> to seamlessly collect fine-grained <em>telemetry</em> <em>data</em> — <em>service</em>-level metrics, unsampled requests, and more. With one install command, you get deeper insight into your <em>Kubernetes</em> clusters"
      },
      "id": "6174ca7364441f0e385fdea5"
    },
    {
      "sections": [
        "Install Auto-telemetry with Pixie",
        "General prerequisites for using Pixie",
        "Setup steps depend on your account status",
        "Install from the beginning of the guided install process",
        "Install from the Configure the HELM command/manifest (yaml) file",
        "Important",
        "Helm method",
        "manifest method",
        "If you link the wrong Pixie and New Relic account"
      ],
      "title": "Install Auto-telemetry with Pixie",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "bb957763e579e39ef2bbeafeebc46ab3a111bca2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/install-auto-telemetry-pixie/",
      "published_at": "2021-10-24T23:30:47Z",
      "updated_at": "2021-10-24T02:51:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To get up and running with Auto-telemetry with Pixie, you start with our guided installation. The guided installation deploys Pixie with New Relic's Kubernetes integration on your cluster. You don't need to do any further configuration or installation to start using Pixie. If you want to install Auto-telemetry with Pixie on multiple clusters, re-run the guided install for each additional cluster. General prerequisites for using Pixie You must be a New Relic full platform user. Other user-related requirements: Users on our New Relic One user model must be assigned to a group that has a role with Pixie-related capabilities. Users on our original user model cannot be Restricted. Review this Pixie data security overview for actions to take to secure your data. Make sure you have sufficient memory: Pixie requires 2Gb of memory per node in your cluster. Review the other Pixie technical requirements. Setup steps depend on your account status Use the following table to find out where to start installing Auto-telemetry with Pixie. Where you start the installation depends on whether you already have a New Relic or Pixie account, or both. New Relic Pixie Next steps Start the guided install at the beginning of the process. If you already have both types of accounts, and used the same email address for each of them, click the New Relic icon in the Pixie UI. This brings you to the Configure the HELM command/manifest (yaml) file section of the guided installation. Then, follow the steps. If you're using different email addresses in Pixie and New Relic, create a new account for either Pixie or New Relic to match email addresses across both products. You can also contact New Relic support to manually link your existing New Relic account with your Pixie account. If you follow a link to New Relic from the Pixie UI and do not have a New Relic account, you must first create one. Click the New Relic icon in the Pixie UI, and follow the steps to create a New Relic account. When you do so, your Pixie account is linked to it. Then, continue the guided install process with these steps. Sign up for a free New Relic account. Then, start the guided install at the beginning of the process. Install from the beginning of the guided install process Open our New Relic One guided install. Select the account you want to use for the guided install, and click Continue. Note: if you have a single account, you won't see this option. Select Kubernetes and then continue with step one in the next section. Install from the Configure the HELM command/manifest (yaml) file If you arrived in the guided installation process by following a link from Pixie or from within New Relic, your steps begin here. Select the account and cluster for the install. If needed, select a namespace. Important Currently, Pixie performs best on clusters with up to 100 nodes (exceeding 100 nodes can lead to excessive memory usage and scripts failing to run). Friendly reminder: autoscaling can quickly drive up your node numbers. Click Continue. Select the data you want to gather, observe, and debug, and click Continue. On the Choose install method page, select either Helm or manifest. Helm method Run the provided Helm command on your command line. If you're concerned about the amount of Pixie data you'll ingest, check out strategies for reducing ingest. Helm installs a bundle containing the New Relic infrastructure agent, an integration to gather Prometheus metrics and Kubernetes events, and the Pixie integration. The deployment takes a few minutes to complete. To see the status of the install to the cluster, run kubectl get pods -n newrelic. For general information about installing a Kubernetes integration, see this Helm install info. manifest method Run the provided command in your console, and insert the path to your downloaded manifest. If you're running your Kubernetes cluster in the cloud, see the additional steps in the Kubernetes docs. Click Continue to open the Listening for data page. When you get the message, See your data, click Kubernetes Cluster Explorer to see your cluster. Auto-telemetry with Pixie might restart after installation. This is caused by the auto update feature. If you link the wrong Pixie and New Relic account Contact support to unlink a Pixie account from your New Relic account. Be aware that if you unlink a Pixie account that was created automatically through the guided install, you'll lose access to that Pixie account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.27832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "sections": "Install <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": " the additional steps in the <em>Kubernetes</em> docs. Click Continue to open the Listening for <em>data</em> page. When you get the message, See your <em>data</em>, click <em>Kubernetes</em> Cluster Explorer to see your cluster. <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> might restart after installation. This is caused by the <em>auto</em> update feature"
      },
      "id": "6174ca14e7b9d26ba513cd12"
    },
    {
      "sections": [
        "Manage your Auto-telemetry with Pixie data ingest",
        "Exclude namespaces and pods",
        "Use Kubernetes features to collect selected data"
      ],
      "title": "Manage your Auto-telemetry with Pixie data ingest",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Kubernetes pods",
        "Kubernetes",
        "manage Pixie data"
      ],
      "external_id": "2d4fe0c707ac63c7625317cb20a544bc5f0e03d8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/auto-telemetry-pixie/manage-pixie-data/",
      "published_at": "2021-10-24T23:32:39Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You have options for the type and the amount of data you ingest when you install Auto-telemetry with Pixie. During install, use Helm to reduce or exclude data, either by excluding specific namespaces or pods, or by collecting data for only the nodes you want. Exclude namespaces and pods If you want to reduce the amount of Pixie data that New Relic ingests, you can exclude namespaces or pods by adding the following parameters to your Helm chart during installation. Note that the data still exists in Pixie: excludeNamespacesRegex - use to identify the namespaces that you want to exclude from sending observability data to New Relic. If empty, data for all namespaces is sent to New Relic. For example: --set newrelic-pixie.excludeNamespacesRegex=\"examplenamespace-1|examplenamespace-2\" Copy excludePodsRegex - use to identify pods across all namespaces that you want to exclude from sending observability data to New Relic. If empty, data for all pods (except those in excluded namespaces) is sent to New Relic. For example: --set newrelic-pixie.excludePodsRegex=\"examplepod-1|examplepod-2\" Copy These two configuration options provide additional control over the Metric and Span data sent to New Relic from Pixie. For example, if you wanted to configure the newrelic-pixie integration to exclude all namespaces except for px-sock-shop and kafka-demo, append the following config parameter to your Helm install or Helm upgrade command. --set newrelic-pixie.excludeNamespacesRegex=\"default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator\" Copy Or, if you wanted to exclude pods running in a non-excluded namespace, you could add another configuration parameter to your Helm install or Helm upgrade. Instead of matching exact names, you can use a simple regex to match pod names related to load testing, just as an example. --set newrelic-pixie.excludePodsRegex=\"load-test.*|loadgen.*\" Copy If you're performing a brand new install, you'll need to append excludeNamespacesRegex and excludePodsRegex to the helm upgrade --install command provided by New Relic's guided install: kubectl apply -f https://raw.githubusercontent.com/pixie-labs/pixie/main/k8s/operator/crd/base/px.dev_viziers.yaml && \\ kubectl apply -f https://raw.githubusercontent.com/pixie-labs/pixie/main/k8s/operator/helm/crds/olm_crd.yaml && \\ helm repo add newrelic https://helm-charts.newrelic.com && helm repo update && \\ kubectl create namespace newrelic ; helm upgrade --install newrelic-bundle newrelic/nri-bundle \\ --set global.licenseKey=<NR LICENSE KEY> \\ --set global.cluster=pixie-auto-telemetry \\ --namespace=newrelic \\ --set newrelic-infrastructure.privileged=true \\ --set ksm.enabled=true \\ --set prometheus.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true \\ --set newrelic-pixie.enabled=true \\ --set newrelic-pixie.apiKey=<PIXIE API KEY> \\ --set pixie-chart.enabled=true \\ --set pixie-chart.deployKey=<PIXIE DEPLOY KEY> \\ --set pixie-chart.clusterName=pixie-auto-telemetry \\ --set newrelic-pixie.excludeNamespacesRegex=\"default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator\" \\ --set newrelic-pixie.excludePodsRegex=\"load-test.*|loadgen.*\" Copy If you're just upgrading an existing install, then this is a much simpler approach: helm upgrade newrelic-bundle newrelic/nri-bundle --reuse-values -n newrelic --set newrelic-pixie.excludeNamespacesRegex=\"default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator Copy Learn more about the available parameters for the newrelic-pixie Helm chart here. Use Kubernetes features to collect selected data When you deploy Auto-telemetry with Pixie, you're actually enabling the Auto-telemetry with Pixie Helm chart, as well as other New Relic components included in the New Relic infrastructure bundle. The Pixie Edge Module (PEM) pods are deployed to the cluster as a Kubernetes DaemonSet. This means that by default, a pod is scheduled to every cluster node and is responsible for collecting all of the observability metrics for that node. In Kubernetes, you can assign pods to a specific subset of cluster nodes using nodeSelectors, taints/tolerations, and node affinity/anti-affinity. That way, you'll only collect metrics for the nodes you choose, instead of every node. This is helpful if you only want to deploy Auto-telemetry with Pixie to five of your ten cluster nodes, for example. Maybe the designated five nodes are responsible for high-priority workloads, or perhaps you're running both Linux and Windows nodes in your cluster and only want to deploy on the Linux nodes, since Windows nodes are not currently supported. You can now assign pods to a subset of nodes by providing an additional option to the guided installation command. This option passes an escaped JSON string to the Auto-telemetry with Pixie chart, which enables a nodeSelector that only schedules the PEM DaemonSet on nodes with the label pixie=allowed. --set pixie-chart.patches.vizier-pem='\\{\\\"spec\\\"\\: \\{\\\"template\\\"\\: \\{\\\"spec\\\"\\: \\{ \\\"nodeSelector\\\"\\: \\{\\\"pixie\\\"\\: \\\"allowed\\\" \\}\\}\\}\\}\\}' Copy If you're using a values file, common with Helm, then this is what that would look like in the nri-bundle values.yaml: pixie-chart: enabled: true patches: vizier-pem: '{\"spec\": {\"template\": {\"spec\": { \"nodeSelector\": {\"pixie\": \"allowed\" }}}}}' Copy This approach gives you a multitude of configuration options; you just need to stick with the standard Kubernetes spec.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.15744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> <em>data</em> ingest",
        "sections": "Manage your <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> <em>data</em> ingest",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": " for the newrelic-<em>pixie</em> Helm chart here. Use <em>Kubernetes</em> features to collect selected <em>data</em> When you deploy <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>, you&#x27;re actually enabling the <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> Helm chart, as well as other New Relic components included in the New Relic infrastructure bundle. The <em>Pixie</em> Edge Module (PEM"
      },
      "id": "6174cb5b64441f9af45fe035"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration": [
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-24T16:09:52Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.0998,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Kubernetes</em> <em>integration</em>: compatibility and requirements",
        "sections": "<em>Kubernetes</em> <em>integration</em>: compatibility and requirements",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our <em>integration</em>. Compatibility EOL NOTICE We&#x27;re discontinuing support for several capabilities in December"
      },
      "id": "603e92dc64441f3a974e8891"
    },
    {
      "sections": [
        "Get started with New Relic observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2021-10-24T11:46:39Z",
      "updated_at": "2021-10-23T16:46:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our more curated observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.41599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " you to <em>start</em> your observability journey from any element of your stack. For example, you can <em>get</em> to crucial infrastructure logs from traces of an application running on a problematic <em>Kubernetes</em> pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Get started"
      ],
      "external_id": "9a44613b8a5ec0a9c9570b22c7d2f3ea726f2671",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/introduction-new-relic-integrations/",
      "published_at": "2021-10-24T11:54:18Z",
      "updated_at": "2021-10-24T00:59:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.75056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>integrations</em>",
        "sections": "Introduction to New Relic <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " <em>integrations</em>, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to <em>get</em> you <em>started</em>. Choose what&#x27;s right for you We offer a wide range of solutions so you can easily collect"
      },
      "id": "603e817f28ccbc4857eba798"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.2901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "<em>Get</em> <em>started</em>: Install the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " from the <em>start</em>. Clicking each node reveals its status and how each app is performing. <em>Get</em> <em>started</em>: Install the <em>Kubernetes</em> <em>integration</em> We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Get started with New Relic observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2021-10-24T11:46:39Z",
      "updated_at": "2021-10-23T16:46:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our more curated observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.41599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " you to <em>start</em> your observability journey from any element of your stack. For example, you can <em>get</em> to crucial infrastructure logs from traces of an application running on a problematic <em>Kubernetes</em> pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Get started"
      ],
      "external_id": "9a44613b8a5ec0a9c9570b22c7d2f3ea726f2671",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/introduction-new-relic-integrations/",
      "published_at": "2021-10-24T11:54:18Z",
      "updated_at": "2021-10-24T00:59:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.75056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>integrations</em>",
        "sections": "Introduction to New Relic <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " <em>integrations</em>, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to <em>get</em> you <em>started</em>. Choose what&#x27;s right for you We offer a wide range of solutions so you can easily collect"
      },
      "id": "603e817f28ccbc4857eba798"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/installation/configure-control-plane-monitoring": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.73477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Get started: <em>Install</em> the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " for the <em>installation</em>. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the <em>Kubernetes</em> <em>integration</em>. Allows users to seamlessly install our other products related to <em>Kubernetes</em> such as: <em>Kubernetes</em> events monitoring In-cluster prometheus services monitoring"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.26068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates <em>installation</em>, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.29326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Installation</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/installation/configure-kubernetes-proxy": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.73477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Get started: <em>Install</em> the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " for the <em>installation</em>. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the <em>Kubernetes</em> <em>integration</em>. Allows users to seamlessly install our other products related to <em>Kubernetes</em> such as: <em>Kubernetes</em> events monitoring In-cluster prometheus services monitoring"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.26068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates <em>installation</em>, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.29326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Installation</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/installation/install-fargate-integration": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/06/monitoring-amazon-eks-on-aws-fargate/",
      "sections": [
        "Monitor Amazon EKS on AWS Fargate integration with our public beta"
      ],
      "published_at": "2021-10-24T22:28:15Z",
      "title": "Monitor Amazon EKS on AWS Fargate integration with our public beta",
      "updated_at": "2021-07-07T14:12:51Z",
      "type": "docs",
      "external_id": "a7899b6302aa05b943053c2230e2787799a0fef4",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We are introducing New Relic's integration for Amazon EKS on AWS Fargate public beta. If you are interested in checking out the beta, please follow the steps found in the documentation. Our EKS Fargate integration supports any Fargate setup, whether the cluster is only composed of Fargate nodes or if it also coexists with EC2 nodes. The integration is also compatible with the New Relic One Kubernetes cluster explorer, providing a holistic view of a Kubernetes cluster and rapid troubleshooting. We've also improved the Kubernetes dashboard to list Fargate nodes and distinguish between standard and Fargate serverless nodes. Check it out today.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 713.20905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor Amazon <em>EKS</em> on AWS <em>Fargate</em> integration with our public beta",
        "sections": "Monitor Amazon <em>EKS</em> on AWS <em>Fargate</em> integration with our public beta",
        "body": "We are introducing New Relic&#x27;s integration for Amazon <em>EKS</em> on AWS <em>Fargate</em> public beta. If you are interested in checking out the beta, please follow the steps found in the documentation. Our <em>EKS</em> <em>Fargate</em> integration supports any <em>Fargate</em> setup, whether the cluster is only composed of <em>Fargate</em> nodes"
      },
      "id": "60e5b66364441f2e58c42399"
    },
    {
      "sections": [
        "Kubernetes integration: install and configure",
        "Use automated installer",
        "Installs for managed services and platforms",
        "Amazon EKS",
        "Amazon EKS Fargate",
        "Google Kubernetes Engine (GKE)",
        "OpenShift container platform",
        "Azure Kubernetes Service (AKS)",
        "Pivotal Container Service (PKS / VMware Tanzu)",
        "Upgrading our Kubernetes integration",
        "Upgrading using the automated installer and Helm",
        "Upgrading using the automated installer and plain manifests",
        "Tip",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data"
      ],
      "title": "Kubernetes integration: install and configure",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "ff06c8b1d8b2940d0b23034f3057377ce571e4ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/kubernetes-integration-install-configure/",
      "published_at": "2021-10-24T15:59:00Z",
      "updated_at": "2021-09-27T14:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The easiest way to install the Kubernetes integration is to use our automated installer to generate a manifest. It bundles not just the integration DaemonSets, but also other New Relic Kubernetes configurations, like Kubernetes events, Prometheus OpenMetrics, and New Relic log monitoring. Looking to install our New Relic One integration with Pixie for fine-grained telemetry data? See our Auto-telemetry with Pixie install instructions to get deeper insight into your Kubernetes clusters and workloads with just one install command. No language agents required. Want to try out our Kubernetes integration? Create a New Relic account for free! No credit card required. Use automated installer We encourage you to use our automated installer for servers, VMs, and unprivileged environments. The automated installer can provide you either a Helm command with the required values filled, or a plain manifest if you do not wish to use Helm. It also features great customizability and full control over which features and dependencies are enabled. If you are installing our integration on a managed cloud, please take a look at these preliminary notes before proceeding. Alternatively, we also offer fully manual instructions for deploying our integration using Helm. Start the installer If your New Relic account is in the EU region, access the installer from one.eu.newrelic.com. Installs for managed services and platforms Before starting our automated installer, check out these notes for your managed services or platforms: Amazon EKS The Kubernetes integration monitors worker nodes. In Amazon EKS, master nodes are managed by Amazon and abstracted from the Kubernetes platforms. Before starting our automated installer to deploy the Kubernetes integration in Amazon EKS, make sure you are using the version of kubectl provided by AWS. Amazon EKS Fargate Installation on EKS Fargate clusters requires dedicated steps, which are detailed in our fargate installation docs. Google Kubernetes Engine (GKE) The Kubernetes integration monitors worker nodes. In GKE, master nodes are managed by Google and abstracted from the Kubernetes platforms. Before starting our automated installer to deploy the Kubernetes integration on GKE, ensure you have sufficient permissions: Go to console.cloud.google.com/iam-admin/iam and find your username. Click edit. Ensure you have permissions to create Roles and ClusterRoles: If you are not sure, add the Kubernetes Engine Cluster Admin role. If you cannot edit your user role, ask the owner of the GCP project to give you the necessary permissions. OpenShift container platform To deploy the Kubernetes integration with OpenShift: Add the <>{'<release_name>'}</>-newrelic-infrastructure service account to your privileged Security Context Constraints: oc adm policy add-scc-to-user privileged \\ system:serviceaccount:<namespace>:<release_name>-newrelic-infrastructure Copy The default <>{'<release_name>'}</> provided by the installer is nri-bundle. Complete the steps in our automated installer. If you're using signed certificates, make sure they are properly configured by using the following variables in the DaemonSet portion of your manifest to set the .pem file: Copy name: NRIA_CA_BUNDLE_DIR value: YOUR_CA_BUNDLE_DIR name: NRIA_CA_BUNDLE_FILE value: YOUR_CA_BUNDLE_NAME YAML key path: `spec.template.spec.containers.name.env` Copy Save your changes. Azure Kubernetes Service (AKS) The Kubernetes integration monitors worker nodes. In Azure Kubernetes Service, master nodes are managed by Azure and abstracted from the Kubernetes platforms. To deploy in Azure Kubernetes Service (AKS), complete the steps in our automated installer. Pivotal Container Service (PKS / VMware Tanzu) To deploy in PKS, we recommend that you use the automated installer, or you can follow the manual instructions provided in Install the Kubernetes integration using Helm. Upgrading our Kubernetes integration Our Kubernetes integration is under active development and we regularly release updates which include bug fixes, new features, and support for newer Kubernetes versions and cloud providers. We strongly recommend all our customers to regularly update the Kubernetes integration to get the best experience. Upgrading using the automated installer and Helm In order to update an installation that was deployed using Helm command provided by the automated installer, just go through the process and run the Helm command again. This will pull the new version of the chart and its dependencies and upgrade it to the latest version. Upgrading using the automated installer and plain manifests Tip We encourage you to deploy our integration using Helm, as it provides a cleaner upgrade path comapred to using manifests directly. If custom manifests have been used instead of Helm, we encourage you to first remove the old installation using kubectl delete -f <mark>previous-manifest-file.yml</mark>, and then proceed through the guided installer again. This will generate an updated set of manifests that can be deployed using kubectl apply -f <mark>manifest-file.yml</mark>. We do not recommend applying a new version of the manifest file without removing the previous one first, since it might leave some leftover components in your cluster. Monitor services running on Kubernetes Tip We encourage you to deploy our integration using Helm, as it allows easier configuration on how to monitor services by just adding snippets to your values.yml file. After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 566.23114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Amazon <em>EKS</em> <em>Fargate</em>",
        "body": " the version of kubectl provided by AWS. Amazon <em>EKS</em> <em>Fargate</em> Installation on <em>EKS</em> <em>Fargate</em> clusters requires dedicated steps, which are detailed in our <em>fargate</em> installation docs. Google Kubernetes Engine (GKE) The Kubernetes integration monitors worker nodes. In GKE, master nodes are managed by Google"
      },
      "id": "60450ae964441f0603378f15"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-24T16:09:52Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 421.3204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster <em>EKS</em> (EC2 nodes or <em>Fargate</em>) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.73462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Get started: <em>Install</em> the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " for the <em>installation</em>. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the <em>Kubernetes</em> <em>integration</em>. Allows users to seamlessly install our other products related to <em>Kubernetes</em> such as: <em>Kubernetes</em> events monitoring In-cluster prometheus services monitoring"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.29312,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Installation</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-24T16:09:52Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.6283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Kubernetes</em> <em>integration</em>: compatibility and requirements",
        "sections": "<em>Kubernetes</em> <em>integration</em>: compatibility and requirements",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " 2021, including <em>Kubernetes</em> instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our <em>Kubernetes</em> <em>integration</em> is compatible with the following versions, depending on the <em>installation</em> mode: Install"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-windows": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.73447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Get started: <em>Install</em> the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " for the <em>installation</em>. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the <em>Kubernetes</em> <em>integration</em>. Allows users to seamlessly install our other products related to <em>Kubernetes</em> such as: <em>Kubernetes</em> events monitoring In-cluster prometheus services monitoring"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.26054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates <em>installation</em>, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.29297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Installation</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/installation/kubernetes-integration-install-configure": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.73447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Get started: <em>Install</em> the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " for the <em>installation</em>. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the <em>Kubernetes</em> <em>integration</em>. Allows users to seamlessly install our other products related to <em>Kubernetes</em> such as: <em>Kubernetes</em> events monitoring In-cluster prometheus services monitoring"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.26054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates <em>installation</em>, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.29297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Installation</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/installation/kubernetes-integration-recommended-alert-policy": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.73431,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Get started: <em>Install</em> the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " for the <em>installation</em>. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the <em>Kubernetes</em> <em>integration</em>. Allows users to seamlessly install our other products related to <em>Kubernetes</em> such as: <em>Kubernetes</em> events monitoring In-cluster prometheus services monitoring"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.26047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates <em>installation</em>, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.29282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Installation</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/kubernetes-events/install-kubernetes-events-integration": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.91785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the <em>Kubernetes</em> <em>integration</em>. Allows users to seamlessly install our other products related to <em>Kubernetes</em> such as: <em>Kubernetes</em> <em>events</em> monitoring In-cluster prometheus services monitoring"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.9111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.76355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/kubernetes-events/kubernetes-integration-predefined-alert-policy": [
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.73418,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Get started: <em>Install</em> the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " for the <em>installation</em>. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the <em>Kubernetes</em> <em>integration</em>. Allows users to seamlessly install our other products related to <em>Kubernetes</em> such as: <em>Kubernetes</em> events monitoring In-cluster prometheus services monitoring"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.2604,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "<em>Install</em> the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates <em>installation</em>, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.29268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Installation</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/link-apps-services/monitor-services-running-kubernetes": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 447.22403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and <em>services</em> in your <em>Kubernetes</em> cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Link your applications to Kubernetes",
        "Tip",
        "Compatibility and requirements",
        "Kubernetes requirements",
        "Network requirements",
        "APM agent compatibility",
        "Openshift requirements",
        "Important",
        "Configure the injection of metadata",
        "Default configuration",
        "Custom configuration",
        "Manage custom certificates",
        "Validate the injection of metadata",
        "Disable the injection of metadata",
        "Troubleshooting"
      ],
      "title": "Link your applications to Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "2ae58989813695b48f4924529d6fd6ea17e5f6c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-your-applications/link-your-applications-kubernetes/",
      "published_at": "2021-10-24T17:51:14Z",
      "updated_at": "2021-05-28T06:30:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can surface Kubernetes metadata and link it to your APM agents as distributed traces to explore performance issues and troubleshoot transaction errors. For more information, see this New Relic blog post. You can quickly start monitoring Kubernetes clusters using Auto-telemetry with Pixie, which is currently a beta release. This Pixie integration into New Relic does not require a language agent. Learn more about Auto-telemetry with Pixie here. Tip Our Kubernetes metadata injection project is open source. Here's the code to link APM and infrastructure data and the code to automatically manage certificates. Compatibility and requirements Before linking Kubernetes metadata to your APM agents, make sure you meet the following requirements: Kubernetes requirements Network requirements APM agent compatibility OpenShift requirements Kubernetes requirements To link your applications and Kubernetes, your cluster must have the MutatingAdmissionWebhook controller enabled, which requires Kubernetes 1.9 or higher. To verify that your cluster is compatible, run the following command: kubectl api-versions | grep admissionregistration.k8s.io/v1beta1 admissionregistration.k8s.io/v1beta1 Copy If you see a different result, follow the Kubernetes documentation to enable admission control in your cluster. Network requirements For Kubernetes to speak to our MutatingAdmissionWebhook, the master node (or the API server container, depending on how the cluster is set up) should be allowed egress for HTTPS traffic on port 443 to pods in all of the other nodes in the cluster. This might require specific configuration depending on how the infrastructure is set up (on-premises, AWS, Google Cloud, etc). Tip Until Kubernetes v1.14, users were only allowed to register admission webhooks on port 443. Since v1.15 it's possible to register them on different ports. To ensure backward compatibility, the webhook is registered by default on port 443 in the YAML config file we distribute. APM agent compatibility The following New Relic agents collect Kubernetes metadata: Go 2.3.0 or higher Java 4.10.0 or higher Node.js 5.3.0 or higher Python 4.14.0 or higher Ruby 6.1.0 or higher .NET 8.17.438 or higher Openshift requirements To link Openshift and Kubernetes you must enable mutating admission webhooks, which requires Openshift 3.9 or higher. During the process, install a resource that requires admin permissions to the cluster. Run this to log in as admin: oc login -u system:admin Copy Check that webhooks are correctly configured. If they are not, update the master-config.yaml file. admissionConfig: pluginConfig: MutatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission ValidatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission location: \"\" Copy Important Add kubeConfigFile: /dev/null to address some issues in Openshift. Enable certificate signing by editing the YAML file and updating your configuration: kubernetesMasterConfig: controllerArguments: cluster-signing-cert-file: - \"/etc/origin/master/ca.crt\" cluster-signing-key-file: - \"/etc/origin/master/ca.key\" Copy Restart the Openshift services in the master node. Configure the injection of metadata By default, all the pods you create that include APM agents have the correct environment variables set and the metadata injection applies to the entire cluster. To check that the environment variables have been set, any container that is running must be stopped, and a new instance started (see Validate the injection of metadata). This default configuration also uses the Kubernetes certificates API to automatically manage the certificates required for the injection. If needed, you can limit the injection of metadata to specific namespaces in your cluster or self-manage your certificates. Default configuration To proceed with the default injection of metadata, follow these steps: Download the YAML file: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-latest.yaml Copy Custom configuration You can limit the injection of metadata only to specific namespaces by using labels. To enable this feature, edit your YAML file by finding and uncommenting the following lines: # namespaceSelector: # matchLabels: # newrelic-metadata-injection: enabled Copy With this option, injection is only applied to those namespaces that have the newrelic-metadata-injection label set to enabled: kubectl label namespace YOUR_NAMESPACE newrelic-metadata-injection=enabled Copy Manage custom certificates To use custom certificates you need a specific YAML file: Download the YAML file without automatic certificate management: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-custom-certs-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-custom-certs-latest.yaml Copy Once you have the correct YAML file, you can proceed with the custom certificate management option. You need your certificate, server key, and Certification Authority (CA) bundle encoded in PEM format. If you have them in the standard certificate format (X.509), install openssl, and run the following: openssl x509 -in CERTIFICATE_FILENAME -outform PEM -out CERTIFICATE_FILENAME.pem openssl x509 -in SERVER_KEY_FILENAME -outform PEM -out SERVER_KEY_FILENAME.pem openssl x509 -in CA_BUNDLE_FILENAME -outform PEM -out BUNDLE_FILENAME.pem Copy If your certificate/key pair are in another format, see the Digicert knowledgebase for more help. Create the TLS secret with the signed certificate/key pair, and patch the mutating webhook configuration with the CA using the following commands: kubectl create secret tls newrelic-metadata-injection-secret \\ --key=PEM_ENCODED_SERVER_KEY \\ --cert=PEM_ENCODED_CERTIFICATE \\ --dry-run -o yaml | kubectl -n default apply -f - caBundle=$(cat PEM_ENCODED_CA_BUNDLE | base64 | td -d '\\n') kubectl patch mutatingwebhookconfiguration newrelic-metadata-injection-cfg --type='json' -p \"[{'op': 'replace', 'path': '/webhooks/0/clientConfig/caBundle', 'value':'${caBundle}'}]\" Copy Important Certificates signed by Kubernetes have an expiration of one year. For more information, see the Kubernetes source code in GitHub. Validate the injection of metadata In order to validate that the webhook (responsible for injecting the metadata) was installed correctly, deploy a new pod and check for the New Relic environment variables. Create a dummy pod containing Busybox by running: kubectl create -f https://git.io/vPieo Copy Check if New Relic environment variables were injected: kubectl exec busybox0 -- env | grep NEW_RELIC_METADATA_KUBERNETES NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME=fsi NEW_RELIC_METADATA_KUBERNETES_NODE_NAME=nodea NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME=default NEW_RELIC_METADATA_KUBERNETES_POD_NAME=busybox0 NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME=busybox Copy Disable the injection of metadata To disable/uninstall the injection of metadata, use the following commands: Delete the Kubernetes objects using the yaml file: kubectl delete -f k8s-metadata-injection-latest.yaml Copy Delete the TLS secret containing the certificate/key pair: kubectl delete secret/newrelic-metadata-injection-secret Copy Troubleshooting Follow these troubleshooting tips as needed. No Kubernetes metadata in APM or distributed tracing transactions Problem The creation of the secret by the k8s-webhook-cert-manager job used to fail due to the kubectl version used by the image when running in Kubernetes version 1.19.x, The new version 1.3.2 fixes this issue, therefore it is enough to run again the job using an update version of the image to fix the issue. Solution Update the image k8s-webhook-cert-manager (to a version >= 1.3.2) and re-run the job. The secret will be correctly created and the k8s-metadata-injection pod will be able to start. Note that the new version of the manifest and of the nri-bundle are already updated with the correct version of the image. Problem In OpenShift version 4.x, the CA that is used in order to patch the mutatingwebhookconfiguration resource is not the one used when signing the certificates. This is a known issue currently tracked here. In the logs of the Pod nri-metadata-injection, you'll see the following error message: TLS handshake error from 10.131.0.29:37428: remote error: tls: unknown certificate authority TLS handshake error from 10.129.0.1:49314: remote error: tls: bad certificate Copy Workaround Manually update the certificate stored in the mutatingwebhookconfiguration object. The correct CA locations might change according to the cluster configuration. However, you can usually find the CA in the secret csr-signer in the namespace openshift-kube-controller-manager. Problem There is no Kubernetes metadata included in the transactions' attributes of your APM agent or in distributed tracing. Solution Verify that the environment variables are being correctly injected by following the instructions described in the Validate your installation step. If they are not present, get the name of the metadata injection pod by running: kubectl get pods | grep newrelic-metadata-injection-deployment kubectl logs -f pod/podname Copy In another terminal, create a new pod (for example, see Validate your installation), and inspect the logs of the metadata injection deployment for errors. For every created pod there should be a set of 4 new entries in the logs like: {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.107Z\",\"caller\":\"server/main.go:139\",\"msg\":\"POST https://newrelic-metadata-injection-svc.default.svc:443/mutate?timeout=30s HTTP/2.0\\\" from 10.11.49.2:32836\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.110Z\",\"caller\":\"server/webhook.go:168\",\"msg\":\"received admission review\",\"kind\":\"/v1, Kind=Pod\",\"namespace\":\"default\",\"name\":\"\",\"pod\":\"busybox1\",\"UID\":\"6577519b-7a61-11ea-965e-0e46d1c9335c\",\"operation\":\"CREATE\",\"userinfo\":{\"username\":\"admin\",\"uid\":\"admin\",\"groups\":[\"system:masters\",\"system:authenticated\"]}} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:182\",\"msg\":\"admission response created\",\"response\":\"[{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env\\\",\\\"value\\\":[{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME\\\",\\\"value\\\":\\\"adn_kops\\\"}]},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NODE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"spec.nodeName\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.namespace\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_POD_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.name\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME\\\",\\\"value\\\":\\\"busybox\\\"}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_IMAGE_NAME\\\",\\\"value\\\":\\\"busybox\\\"}}]\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:257\",\"msg\":\"writing response\"} Copy If there are no new entries on the logs, it means that the apiserver is not being able to communicate with the webhook service, this could be due to networking rules or security groups rejecting the communication. To check if the apiserver is not being able to communicate with the webhook you should inspect the apiserver logs for errors like: failed calling webhook \"metadata-injection.newrelic.com\": ERROR_REASON Copy To get the apiserver logs: Start a proxy to the Kubernetes API server by the executing the following command in a terminal window and keep it running. kubectl proxy --port=8001 Copy Create a new pod in your cluster, this will make the apiserver try to communicate with the webhook. The following command will create a busybox. kubectl create -f https://git.io/vPieo Copy Retrieve the apiserver logs. curl localhost:8001/logs/kube-apiserver.log > apiserver.log Copy Delete the busybox container. kubectl delete -f https://git.io/vPieo Copy Inspect the logs for errors. grep -E 'failed calling webhook' apiserver.log Copy Remember that one of the requirements for the metadata injection is that the apiserver must be allowed egress to the pods running on the cluster. If you encounter errors regarding connection timeouts or failed connections, make sure to check the security groups and firewall rules of the cluster. If there are no log entries in either the apiserver logs or the metadata injection deployment, it means that the webhook was not properly registered. Ensure the metadata injection setup job ran successfully by inspecting the output of: kubectl get job newrelic-metadata-setup Copy If the job is not completed, investigate the logs of the setup job: kubectl logs job/newrelic-metadata-setup Copy Ensure the CertificateSigningRequest is approved and issued by running: kubectl get csr newrelic-metadata-injection-svc.default Copy Ensure the TLS secret is present by running: kubectl get secret newrelic-metadata-injection-secret Copy Ensure the CA bundle is present in the mutating webhook configuration: kubectl get mutatingwebhookconfiguration newrelic-metadata-injection-cfg -o json Copy Ensure the TargetPort of the Service resource matches the Port of the Deployment's container: kubectl describe service/newrelic-metadata-injection-svc kubectl describe deployment/newrelic-metadata-injection-deployment Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.99525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Link</em> your <em>applications</em> to <em>Kubernetes</em>",
        "sections": "<em>Link</em> your <em>applications</em> to <em>Kubernetes</em>",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": " is currently a beta release. This Pixie <em>integration</em> into New Relic does not require a language agent. Learn more about Auto-telemetry with Pixie here. Tip Our <em>Kubernetes</em> metadata injection project is open source. Here&#x27;s the code to <em>link</em> APM and infrastructure data and the code to automatically"
      },
      "id": "603ebb94196a674fd1a83df3"
    },
    {
      "sections": [
        "Tutorial: Monitor Redis running on Kubernetes",
        "What you need",
        "Step 1: Set up an example Redis application",
        "Step 2: Enable monitoring of Redis instances"
      ],
      "title": "Tutorial: Monitor Redis running on Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "30d0c7b52a792c21a50f98931d05a0665ff19fa1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/tutorial-monitor-redis-running-kubernetes/",
      "published_at": "2021-10-24T17:29:20Z",
      "updated_at": "2021-03-16T04:18:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a service running on Kubernetes, and it's a service we support, you can enable monitoring of that service by adding a configuration section for that integration to the Kubernetes integration's config. This tutorial shows how to enable monitoring for a Redis service running on the Kubernetes PHP Guestbook. For the general procedure, see Monitor a Kubernetes-running service. What you need See the general requirements for this feature, including supported services. The kubectl command-line tool must be configured to communicate with your cluster. If you don't have a cluster, you can create one using Minikube. Step 1: Set up an example Redis application This tutorial builds on the Kubernetes tutorial Deploying a PHP Guestbook application with Redis. Skip the Kubernetes tutorial and run the following command to set up the application needed for our tutorial: kubectl create -f https://raw.githubusercontent.com/kubernetes/examples/master/guestbook/all-in-one/guestbook-all-in-one.yaml Copy If you'd like to first complete the Kubernetes tutorial, follow their tutorial instructions but do not follow the instructions in the Cleaning up section. Step 2: Enable monitoring of Redis instances The PHP Guestbook application has three Redis instances: one master and two slave instances. Each instance is tagged with a label where app=redis. For this example, we're using our Redis monitoring integration. It can monitor both master and slave instances of Redis, so we don’t have to distinguish between them. In the Kubernetes integration's YAML config file (newrelic-infrastructure-k8s-latest.yaml), you need to update the nri-integration-cfg section. From the list of integration configs, get the Redis integration YAML and add it to the Kubernetes config. The Redis YAML is highlighted below. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: redis-config.yml: | --- # Run auto discovery to find pods with label \"app=redis\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: redis integrations: - name: nri-redis env: # using the discovered IP as the hostname address HOSTNAME: ${discovery.ip} PORT: 6379 KEYS: '{\"0\":[\"<KEY_1>\"],\"1\":[\"<KEY_2>\"]}' REMOTE_MONITORING: true labels: env: production Copy Deploy the updated service: kubectl create -f newrelic-infrastructure-k8s-latest.yaml Copy You should be able to see the following in the logs for the pod newrelic-infra: time=\"2019-12-23T17:37:07Z\" level=info msg=\"Integration health check starting\" instance=redis-metrics integration=com.newrelic.redis prefix=integration/com.newrelic.redis working-dir=/var/db/newrelic-infra/newrelic-integrations time=\"2019-12-23T17:37:07Z\" level=info msg=\"Integration health check finished with success\" instance=redis-metrics integration=com.newrelic.redis prefix=integration/com.newrelic.redis working-dir=/var/db/newrelic-infra/newrelic-integrations Copy If there are no errors, you should see Redis data in the Infrastructure UI. To find the Redis dashboards, go to one.newrelic.com > Infrastructure > Third party services, and select the Redis dashboard. For the general procedure of how to monitor services running on Kubernetes, including more detail about how configuration works, see Monitor a Kubernetes-running service.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.55238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tutorial: Monitor Redis running on <em>Kubernetes</em>",
        "sections": "Tutorial: Monitor Redis running on <em>Kubernetes</em>",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": " is highlighted below. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-<em>integration</em>-cfg namespace: default data: redis-config.yml: | --- # Run auto discovery to find pods with label &quot;<em>app</em>=redis&quot; # https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>integrations</em>&#x2F;host-<em>integrations</em>&#x2F;installation&#x2F;container-auto-discovery discovery"
      },
      "id": "603e7e8264441f332a4e8879"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/link-apps-services/tutorial-monitor-redis-running-kubernetes": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 447.22366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and <em>services</em> in your <em>Kubernetes</em> cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Monitor services running on Kubernetes",
        "Get started",
        "What you need",
        "Enable monitoring of services",
        "Get the config YAML for the integration",
        "Example configuration",
        "Configuration options for each integration",
        "Monitor services in our Kubernetes integration installed with Helm",
        "Learn more",
        "Manually configure service monitoring",
        "How the service-specific YAML config works",
        "Add a service YAML to the Kubernetes integration config",
        "Add multiple services to the same config"
      ],
      "title": "Monitor services running on Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "4c67f6272bda36eda4ad7883e89697a203aa2153",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/monitor-services-running-kubernetes/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-07T10:06:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's Kubernetes integration you can monitor both Kubernetes and the services running on it, such as Cassandra, Redis, MySQL, and other supported services. Get started Our Kubernetes integration comes bundled with some of our on-host integrations (like Cassandra, MySQL, and Apache). This lets you get data for those supported services by adding a section to the Kubernetes integration's configuration, which lives as a ConfigMap inside a manifest. What you need Enable this feature for a service Details about how configuration works For an example of how to monitor Redis running on a Kubernetes PHP Guestbook, see this tutorial. What you need To monitor services running on Kubernetes, you only need a Kubernetes cluster running the Kubernetes integration, version 1.16.0 or higher (install | check version | update). We support the following services running on Kubernetes: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP Enable monitoring of services To enable our Kubernetes integration to monitor one or more services: Expand this dropdown and get the YAML snippets for the service(s) you want to monitor: Get the config YAML for the integration For the services you want to monitor, follow the links to GitHub to get the YAML snippets you'll need for the next step: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Add the snippet to the Kubernetes integration's ConfigMap, after the data: section: Example configuration This example shows the YAML config for the Apache integration ( highlighted ) added to the Kubernetes integration's config. Respect the indentation levels. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: apache-config.yaml: | --- # Run auto discovery to find pods with label \"app=apache\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the optional arguments: # --namespaces: Comma separated namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: apache integrations: - name: nri-apache env: # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/server-status?auto METRICS: 1 Copy You can add snippets for multiple services to the same config file. See an example. Depending on your environment, you may need or want to set additional config options. Expand the dropdown below for links to configuration options. Configuration options for each integration Select a service to see available config options: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Verify monitoring is enabled: Go to one.newrelic.com > Infrastructure, select Third party services, and then select the service's dashboard. You should see data being reported. Additional notes about enabling services: Enabling multiple services may use more resources than what is set in the resource limits of the Kubernetes integration config file. If this becomes an issue, raise the limit in the resources section. The Kubernetes integration does not automatically update. For best results, regularly update. Monitor services in our Kubernetes integration installed with Helm If you installed our Kubernetes integration using Helm, to monitor services you need to update the existing installation with the new configuration, which contains the services to monitor: helm upgrade --reuse-values -f values.yaml [RELEASE] [CHART] Copy If you use nri-bundle charts, you need to update the children's chart values. Find some examples here. Learn more More resources for learning about configuration: Learn technical details about how configuration works. Learn how to configure monitoring of multiple services with the same config file. See a step-by-step tutorial showing how to monitor a Redis service on Kubernetes. Manually configure service monitoring The enable procedure should be all you need to get monitoring working, but if you run into problems, understanding some technical details about configuration can be helpful. This section goes into more detail about how configuration works. For each service you wish to monitor, you must add a configuration file for that integration to our Kubernetes integration's configuration. This document will cover these subjects: How the service-specific configuration YAML snippet works Adding the service-specific YAML in the Kubernetes integration's config file Adding multiple services to the Kubernetes integration's config file How the service-specific YAML config works Our Kubernetes integration's configuration follows the ConfigMap format. Using a ConfigMap allows us to decouple the configuration for the integrations from the Kubernetes image. The other benefit is that a ConfigMap can be updated automatically without reloading the running container. Because the infrastructure agent uses YAML to configure its associated integrations, ConfigMaps are a good choice for storing YAML. (For more information on config file format, see the Integration config file format.) The Kubernetes integration image comes with an auto-discovery feature that simplifies the configuration of multiple instances of services using a single configuration file. For example, if you have several NGINX instances running, creating an NGINX integration configuration file for every instance would be hard to implement and hard to update. With our auto-discovery option, you can discover and monitor all your NGINX instances with a single configuration file. Each integration has its own specific configuration YAML. Our NGINX integration default config file looks like this: nginx-config.yml: | --- discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --port: Port used to connect to the kubelet. Default is 10255 # --tls: Use secure (TLS) connection # Custom Example: # exec: /var/db/newrelic-infra/nri-discovery-kubernetes --namespaces namespace1,namespace2 --port 10250 --tls # Default exec: /var/db/newrelic-infra/nri-discovery-kubernetes match: label.app: nginx integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}/status STATUS_MODULE: discover METRICS: 1 Copy The above config enables the following: Runs nri-discovery-kubernetes to query the data for the node we are currently on. Parses the data that comes back and looks for any Kubernetes pod that has a Kubernetes container with an app= label with value nginx. For any matches, it attempts to run the NGINX integration. The status URL is built from: The pod's IP address The status page is pulled from the label on K8s pod called status_url This automatic discovery works the same as the container auto-discovery used by the infrastructure agent. For more advanced options, see Container auto-discovery. Add a service YAML to the Kubernetes integration config It's best practice to configure enabled integrations alongside the Kubernetes integration configuration. This is easier than maintaining configuration files for every single service/integration instance. Below is an example of a Kubernetes integration's ConfigMap. The highlighted section shows where an integration configuration YAML (in this case, NGINX) is placed. For more information on discovery:, see Container auto-discovery for on-host integrations. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 Copy This configuration map can then be referenced in the DaemonSet, the same as the one that was generated via the command line. Make sure the namespace used is the same one used by the Kubernetes integration manifest. If you haven't changed it in the downloaded manifest file, the value is default. Add multiple services to the same config You can monitor several services using the same Kubernetes integration config file. To do this, add another integration configuration YAML to the same Kubernetes integration config file. Below is the Kubernetes config created in the last section, with a new section for the Cassandra integration's config (highlighted). --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 cassandra-configuration.yml: | --- # Run auto discovery to find pods with label \"app=cassandra\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: cassandra integrations: - name: nri-cassandra env: # Use the discovered IP as the host address HOSTNAME: ${discovery.ip} PORT: 7199 USERNAME: cassandra PASSWORD: cassandra METRICS: 1/mark Copy The Kubernetes integration config is now set up to monitor these two services. Additionally, depending on your environment, there may be some additional service-specific configuration you must do. When you've completed configuration, our infrastructure agent looks for any pod with a label cassandra and runs the integration against it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.75507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>services</em> running on <em>Kubernetes</em>",
        "sections": "Monitor <em>services</em> in our <em>Kubernetes</em> <em>integration</em> installed with Helm",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": "With New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> you can monitor both <em>Kubernetes</em> and the <em>services</em> running on it, such as Cassandra, Redis, MySQL, and other supported <em>services</em>. Get started Our <em>Kubernetes</em> <em>integration</em> comes bundled with some of our on-host <em>integrations</em> (like Cassandra, MySQL, and Apache"
      },
      "id": "6044e50c196a676012960f35"
    },
    {
      "sections": [
        "Link your applications to Kubernetes",
        "Tip",
        "Compatibility and requirements",
        "Kubernetes requirements",
        "Network requirements",
        "APM agent compatibility",
        "Openshift requirements",
        "Important",
        "Configure the injection of metadata",
        "Default configuration",
        "Custom configuration",
        "Manage custom certificates",
        "Validate the injection of metadata",
        "Disable the injection of metadata",
        "Troubleshooting"
      ],
      "title": "Link your applications to Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "2ae58989813695b48f4924529d6fd6ea17e5f6c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-your-applications/link-your-applications-kubernetes/",
      "published_at": "2021-10-24T17:51:14Z",
      "updated_at": "2021-05-28T06:30:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can surface Kubernetes metadata and link it to your APM agents as distributed traces to explore performance issues and troubleshoot transaction errors. For more information, see this New Relic blog post. You can quickly start monitoring Kubernetes clusters using Auto-telemetry with Pixie, which is currently a beta release. This Pixie integration into New Relic does not require a language agent. Learn more about Auto-telemetry with Pixie here. Tip Our Kubernetes metadata injection project is open source. Here's the code to link APM and infrastructure data and the code to automatically manage certificates. Compatibility and requirements Before linking Kubernetes metadata to your APM agents, make sure you meet the following requirements: Kubernetes requirements Network requirements APM agent compatibility OpenShift requirements Kubernetes requirements To link your applications and Kubernetes, your cluster must have the MutatingAdmissionWebhook controller enabled, which requires Kubernetes 1.9 or higher. To verify that your cluster is compatible, run the following command: kubectl api-versions | grep admissionregistration.k8s.io/v1beta1 admissionregistration.k8s.io/v1beta1 Copy If you see a different result, follow the Kubernetes documentation to enable admission control in your cluster. Network requirements For Kubernetes to speak to our MutatingAdmissionWebhook, the master node (or the API server container, depending on how the cluster is set up) should be allowed egress for HTTPS traffic on port 443 to pods in all of the other nodes in the cluster. This might require specific configuration depending on how the infrastructure is set up (on-premises, AWS, Google Cloud, etc). Tip Until Kubernetes v1.14, users were only allowed to register admission webhooks on port 443. Since v1.15 it's possible to register them on different ports. To ensure backward compatibility, the webhook is registered by default on port 443 in the YAML config file we distribute. APM agent compatibility The following New Relic agents collect Kubernetes metadata: Go 2.3.0 or higher Java 4.10.0 or higher Node.js 5.3.0 or higher Python 4.14.0 or higher Ruby 6.1.0 or higher .NET 8.17.438 or higher Openshift requirements To link Openshift and Kubernetes you must enable mutating admission webhooks, which requires Openshift 3.9 or higher. During the process, install a resource that requires admin permissions to the cluster. Run this to log in as admin: oc login -u system:admin Copy Check that webhooks are correctly configured. If they are not, update the master-config.yaml file. admissionConfig: pluginConfig: MutatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission ValidatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission location: \"\" Copy Important Add kubeConfigFile: /dev/null to address some issues in Openshift. Enable certificate signing by editing the YAML file and updating your configuration: kubernetesMasterConfig: controllerArguments: cluster-signing-cert-file: - \"/etc/origin/master/ca.crt\" cluster-signing-key-file: - \"/etc/origin/master/ca.key\" Copy Restart the Openshift services in the master node. Configure the injection of metadata By default, all the pods you create that include APM agents have the correct environment variables set and the metadata injection applies to the entire cluster. To check that the environment variables have been set, any container that is running must be stopped, and a new instance started (see Validate the injection of metadata). This default configuration also uses the Kubernetes certificates API to automatically manage the certificates required for the injection. If needed, you can limit the injection of metadata to specific namespaces in your cluster or self-manage your certificates. Default configuration To proceed with the default injection of metadata, follow these steps: Download the YAML file: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-latest.yaml Copy Custom configuration You can limit the injection of metadata only to specific namespaces by using labels. To enable this feature, edit your YAML file by finding and uncommenting the following lines: # namespaceSelector: # matchLabels: # newrelic-metadata-injection: enabled Copy With this option, injection is only applied to those namespaces that have the newrelic-metadata-injection label set to enabled: kubectl label namespace YOUR_NAMESPACE newrelic-metadata-injection=enabled Copy Manage custom certificates To use custom certificates you need a specific YAML file: Download the YAML file without automatic certificate management: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-custom-certs-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-custom-certs-latest.yaml Copy Once you have the correct YAML file, you can proceed with the custom certificate management option. You need your certificate, server key, and Certification Authority (CA) bundle encoded in PEM format. If you have them in the standard certificate format (X.509), install openssl, and run the following: openssl x509 -in CERTIFICATE_FILENAME -outform PEM -out CERTIFICATE_FILENAME.pem openssl x509 -in SERVER_KEY_FILENAME -outform PEM -out SERVER_KEY_FILENAME.pem openssl x509 -in CA_BUNDLE_FILENAME -outform PEM -out BUNDLE_FILENAME.pem Copy If your certificate/key pair are in another format, see the Digicert knowledgebase for more help. Create the TLS secret with the signed certificate/key pair, and patch the mutating webhook configuration with the CA using the following commands: kubectl create secret tls newrelic-metadata-injection-secret \\ --key=PEM_ENCODED_SERVER_KEY \\ --cert=PEM_ENCODED_CERTIFICATE \\ --dry-run -o yaml | kubectl -n default apply -f - caBundle=$(cat PEM_ENCODED_CA_BUNDLE | base64 | td -d '\\n') kubectl patch mutatingwebhookconfiguration newrelic-metadata-injection-cfg --type='json' -p \"[{'op': 'replace', 'path': '/webhooks/0/clientConfig/caBundle', 'value':'${caBundle}'}]\" Copy Important Certificates signed by Kubernetes have an expiration of one year. For more information, see the Kubernetes source code in GitHub. Validate the injection of metadata In order to validate that the webhook (responsible for injecting the metadata) was installed correctly, deploy a new pod and check for the New Relic environment variables. Create a dummy pod containing Busybox by running: kubectl create -f https://git.io/vPieo Copy Check if New Relic environment variables were injected: kubectl exec busybox0 -- env | grep NEW_RELIC_METADATA_KUBERNETES NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME=fsi NEW_RELIC_METADATA_KUBERNETES_NODE_NAME=nodea NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME=default NEW_RELIC_METADATA_KUBERNETES_POD_NAME=busybox0 NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME=busybox Copy Disable the injection of metadata To disable/uninstall the injection of metadata, use the following commands: Delete the Kubernetes objects using the yaml file: kubectl delete -f k8s-metadata-injection-latest.yaml Copy Delete the TLS secret containing the certificate/key pair: kubectl delete secret/newrelic-metadata-injection-secret Copy Troubleshooting Follow these troubleshooting tips as needed. No Kubernetes metadata in APM or distributed tracing transactions Problem The creation of the secret by the k8s-webhook-cert-manager job used to fail due to the kubectl version used by the image when running in Kubernetes version 1.19.x, The new version 1.3.2 fixes this issue, therefore it is enough to run again the job using an update version of the image to fix the issue. Solution Update the image k8s-webhook-cert-manager (to a version >= 1.3.2) and re-run the job. The secret will be correctly created and the k8s-metadata-injection pod will be able to start. Note that the new version of the manifest and of the nri-bundle are already updated with the correct version of the image. Problem In OpenShift version 4.x, the CA that is used in order to patch the mutatingwebhookconfiguration resource is not the one used when signing the certificates. This is a known issue currently tracked here. In the logs of the Pod nri-metadata-injection, you'll see the following error message: TLS handshake error from 10.131.0.29:37428: remote error: tls: unknown certificate authority TLS handshake error from 10.129.0.1:49314: remote error: tls: bad certificate Copy Workaround Manually update the certificate stored in the mutatingwebhookconfiguration object. The correct CA locations might change according to the cluster configuration. However, you can usually find the CA in the secret csr-signer in the namespace openshift-kube-controller-manager. Problem There is no Kubernetes metadata included in the transactions' attributes of your APM agent or in distributed tracing. Solution Verify that the environment variables are being correctly injected by following the instructions described in the Validate your installation step. If they are not present, get the name of the metadata injection pod by running: kubectl get pods | grep newrelic-metadata-injection-deployment kubectl logs -f pod/podname Copy In another terminal, create a new pod (for example, see Validate your installation), and inspect the logs of the metadata injection deployment for errors. For every created pod there should be a set of 4 new entries in the logs like: {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.107Z\",\"caller\":\"server/main.go:139\",\"msg\":\"POST https://newrelic-metadata-injection-svc.default.svc:443/mutate?timeout=30s HTTP/2.0\\\" from 10.11.49.2:32836\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.110Z\",\"caller\":\"server/webhook.go:168\",\"msg\":\"received admission review\",\"kind\":\"/v1, Kind=Pod\",\"namespace\":\"default\",\"name\":\"\",\"pod\":\"busybox1\",\"UID\":\"6577519b-7a61-11ea-965e-0e46d1c9335c\",\"operation\":\"CREATE\",\"userinfo\":{\"username\":\"admin\",\"uid\":\"admin\",\"groups\":[\"system:masters\",\"system:authenticated\"]}} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:182\",\"msg\":\"admission response created\",\"response\":\"[{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env\\\",\\\"value\\\":[{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME\\\",\\\"value\\\":\\\"adn_kops\\\"}]},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NODE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"spec.nodeName\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.namespace\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_POD_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.name\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME\\\",\\\"value\\\":\\\"busybox\\\"}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_IMAGE_NAME\\\",\\\"value\\\":\\\"busybox\\\"}}]\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:257\",\"msg\":\"writing response\"} Copy If there are no new entries on the logs, it means that the apiserver is not being able to communicate with the webhook service, this could be due to networking rules or security groups rejecting the communication. To check if the apiserver is not being able to communicate with the webhook you should inspect the apiserver logs for errors like: failed calling webhook \"metadata-injection.newrelic.com\": ERROR_REASON Copy To get the apiserver logs: Start a proxy to the Kubernetes API server by the executing the following command in a terminal window and keep it running. kubectl proxy --port=8001 Copy Create a new pod in your cluster, this will make the apiserver try to communicate with the webhook. The following command will create a busybox. kubectl create -f https://git.io/vPieo Copy Retrieve the apiserver logs. curl localhost:8001/logs/kube-apiserver.log > apiserver.log Copy Delete the busybox container. kubectl delete -f https://git.io/vPieo Copy Inspect the logs for errors. grep -E 'failed calling webhook' apiserver.log Copy Remember that one of the requirements for the metadata injection is that the apiserver must be allowed egress to the pods running on the cluster. If you encounter errors regarding connection timeouts or failed connections, make sure to check the security groups and firewall rules of the cluster. If there are no log entries in either the apiserver logs or the metadata injection deployment, it means that the webhook was not properly registered. Ensure the metadata injection setup job ran successfully by inspecting the output of: kubectl get job newrelic-metadata-setup Copy If the job is not completed, investigate the logs of the setup job: kubectl logs job/newrelic-metadata-setup Copy Ensure the CertificateSigningRequest is approved and issued by running: kubectl get csr newrelic-metadata-injection-svc.default Copy Ensure the TLS secret is present by running: kubectl get secret newrelic-metadata-injection-secret Copy Ensure the CA bundle is present in the mutating webhook configuration: kubectl get mutatingwebhookconfiguration newrelic-metadata-injection-cfg -o json Copy Ensure the TargetPort of the Service resource matches the Port of the Deployment's container: kubectl describe service/newrelic-metadata-injection-svc kubectl describe deployment/newrelic-metadata-injection-deployment Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.99524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Link</em> your <em>applications</em> to <em>Kubernetes</em>",
        "sections": "<em>Link</em> your <em>applications</em> to <em>Kubernetes</em>",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": " is currently a beta release. This Pixie <em>integration</em> into New Relic does not require a language agent. Learn more about Auto-telemetry with Pixie here. Tip Our <em>Kubernetes</em> metadata injection project is open source. Here&#x27;s the code to <em>link</em> APM and infrastructure data and the code to automatically"
      },
      "id": "603ebb94196a674fd1a83df3"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/link-your-applications/link-your-applications-kubernetes": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 447.22366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and <em>services</em> in your <em>Kubernetes</em> cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Monitor services running on Kubernetes",
        "Get started",
        "What you need",
        "Enable monitoring of services",
        "Get the config YAML for the integration",
        "Example configuration",
        "Configuration options for each integration",
        "Monitor services in our Kubernetes integration installed with Helm",
        "Learn more",
        "Manually configure service monitoring",
        "How the service-specific YAML config works",
        "Add a service YAML to the Kubernetes integration config",
        "Add multiple services to the same config"
      ],
      "title": "Monitor services running on Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "4c67f6272bda36eda4ad7883e89697a203aa2153",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/monitor-services-running-kubernetes/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-07T10:06:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's Kubernetes integration you can monitor both Kubernetes and the services running on it, such as Cassandra, Redis, MySQL, and other supported services. Get started Our Kubernetes integration comes bundled with some of our on-host integrations (like Cassandra, MySQL, and Apache). This lets you get data for those supported services by adding a section to the Kubernetes integration's configuration, which lives as a ConfigMap inside a manifest. What you need Enable this feature for a service Details about how configuration works For an example of how to monitor Redis running on a Kubernetes PHP Guestbook, see this tutorial. What you need To monitor services running on Kubernetes, you only need a Kubernetes cluster running the Kubernetes integration, version 1.16.0 or higher (install | check version | update). We support the following services running on Kubernetes: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP Enable monitoring of services To enable our Kubernetes integration to monitor one or more services: Expand this dropdown and get the YAML snippets for the service(s) you want to monitor: Get the config YAML for the integration For the services you want to monitor, follow the links to GitHub to get the YAML snippets you'll need for the next step: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Add the snippet to the Kubernetes integration's ConfigMap, after the data: section: Example configuration This example shows the YAML config for the Apache integration ( highlighted ) added to the Kubernetes integration's config. Respect the indentation levels. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: apache-config.yaml: | --- # Run auto discovery to find pods with label \"app=apache\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the optional arguments: # --namespaces: Comma separated namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: apache integrations: - name: nri-apache env: # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/server-status?auto METRICS: 1 Copy You can add snippets for multiple services to the same config file. See an example. Depending on your environment, you may need or want to set additional config options. Expand the dropdown below for links to configuration options. Configuration options for each integration Select a service to see available config options: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Verify monitoring is enabled: Go to one.newrelic.com > Infrastructure, select Third party services, and then select the service's dashboard. You should see data being reported. Additional notes about enabling services: Enabling multiple services may use more resources than what is set in the resource limits of the Kubernetes integration config file. If this becomes an issue, raise the limit in the resources section. The Kubernetes integration does not automatically update. For best results, regularly update. Monitor services in our Kubernetes integration installed with Helm If you installed our Kubernetes integration using Helm, to monitor services you need to update the existing installation with the new configuration, which contains the services to monitor: helm upgrade --reuse-values -f values.yaml [RELEASE] [CHART] Copy If you use nri-bundle charts, you need to update the children's chart values. Find some examples here. Learn more More resources for learning about configuration: Learn technical details about how configuration works. Learn how to configure monitoring of multiple services with the same config file. See a step-by-step tutorial showing how to monitor a Redis service on Kubernetes. Manually configure service monitoring The enable procedure should be all you need to get monitoring working, but if you run into problems, understanding some technical details about configuration can be helpful. This section goes into more detail about how configuration works. For each service you wish to monitor, you must add a configuration file for that integration to our Kubernetes integration's configuration. This document will cover these subjects: How the service-specific configuration YAML snippet works Adding the service-specific YAML in the Kubernetes integration's config file Adding multiple services to the Kubernetes integration's config file How the service-specific YAML config works Our Kubernetes integration's configuration follows the ConfigMap format. Using a ConfigMap allows us to decouple the configuration for the integrations from the Kubernetes image. The other benefit is that a ConfigMap can be updated automatically without reloading the running container. Because the infrastructure agent uses YAML to configure its associated integrations, ConfigMaps are a good choice for storing YAML. (For more information on config file format, see the Integration config file format.) The Kubernetes integration image comes with an auto-discovery feature that simplifies the configuration of multiple instances of services using a single configuration file. For example, if you have several NGINX instances running, creating an NGINX integration configuration file for every instance would be hard to implement and hard to update. With our auto-discovery option, you can discover and monitor all your NGINX instances with a single configuration file. Each integration has its own specific configuration YAML. Our NGINX integration default config file looks like this: nginx-config.yml: | --- discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --port: Port used to connect to the kubelet. Default is 10255 # --tls: Use secure (TLS) connection # Custom Example: # exec: /var/db/newrelic-infra/nri-discovery-kubernetes --namespaces namespace1,namespace2 --port 10250 --tls # Default exec: /var/db/newrelic-infra/nri-discovery-kubernetes match: label.app: nginx integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}/status STATUS_MODULE: discover METRICS: 1 Copy The above config enables the following: Runs nri-discovery-kubernetes to query the data for the node we are currently on. Parses the data that comes back and looks for any Kubernetes pod that has a Kubernetes container with an app= label with value nginx. For any matches, it attempts to run the NGINX integration. The status URL is built from: The pod's IP address The status page is pulled from the label on K8s pod called status_url This automatic discovery works the same as the container auto-discovery used by the infrastructure agent. For more advanced options, see Container auto-discovery. Add a service YAML to the Kubernetes integration config It's best practice to configure enabled integrations alongside the Kubernetes integration configuration. This is easier than maintaining configuration files for every single service/integration instance. Below is an example of a Kubernetes integration's ConfigMap. The highlighted section shows where an integration configuration YAML (in this case, NGINX) is placed. For more information on discovery:, see Container auto-discovery for on-host integrations. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 Copy This configuration map can then be referenced in the DaemonSet, the same as the one that was generated via the command line. Make sure the namespace used is the same one used by the Kubernetes integration manifest. If you haven't changed it in the downloaded manifest file, the value is default. Add multiple services to the same config You can monitor several services using the same Kubernetes integration config file. To do this, add another integration configuration YAML to the same Kubernetes integration config file. Below is the Kubernetes config created in the last section, with a new section for the Cassandra integration's config (highlighted). --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 cassandra-configuration.yml: | --- # Run auto discovery to find pods with label \"app=cassandra\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: cassandra integrations: - name: nri-cassandra env: # Use the discovered IP as the host address HOSTNAME: ${discovery.ip} PORT: 7199 USERNAME: cassandra PASSWORD: cassandra METRICS: 1/mark Copy The Kubernetes integration config is now set up to monitor these two services. Additionally, depending on your environment, there may be some additional service-specific configuration you must do. When you've completed configuration, our infrastructure agent looks for any pod with a label cassandra and runs the integration against it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.7543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>services</em> running on <em>Kubernetes</em>",
        "sections": "Monitor <em>services</em> in our <em>Kubernetes</em> <em>integration</em> installed with Helm",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": "With New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> you can monitor both <em>Kubernetes</em> and the <em>services</em> running on it, such as Cassandra, Redis, MySQL, and other supported <em>services</em>. Get started Our <em>Kubernetes</em> <em>integration</em> comes bundled with some of our on-host <em>integrations</em> (like Cassandra, MySQL, and Apache"
      },
      "id": "6044e50c196a676012960f35"
    },
    {
      "sections": [
        "Tutorial: Monitor Redis running on Kubernetes",
        "What you need",
        "Step 1: Set up an example Redis application",
        "Step 2: Enable monitoring of Redis instances"
      ],
      "title": "Tutorial: Monitor Redis running on Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "30d0c7b52a792c21a50f98931d05a0665ff19fa1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/tutorial-monitor-redis-running-kubernetes/",
      "published_at": "2021-10-24T17:29:20Z",
      "updated_at": "2021-03-16T04:18:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a service running on Kubernetes, and it's a service we support, you can enable monitoring of that service by adding a configuration section for that integration to the Kubernetes integration's config. This tutorial shows how to enable monitoring for a Redis service running on the Kubernetes PHP Guestbook. For the general procedure, see Monitor a Kubernetes-running service. What you need See the general requirements for this feature, including supported services. The kubectl command-line tool must be configured to communicate with your cluster. If you don't have a cluster, you can create one using Minikube. Step 1: Set up an example Redis application This tutorial builds on the Kubernetes tutorial Deploying a PHP Guestbook application with Redis. Skip the Kubernetes tutorial and run the following command to set up the application needed for our tutorial: kubectl create -f https://raw.githubusercontent.com/kubernetes/examples/master/guestbook/all-in-one/guestbook-all-in-one.yaml Copy If you'd like to first complete the Kubernetes tutorial, follow their tutorial instructions but do not follow the instructions in the Cleaning up section. Step 2: Enable monitoring of Redis instances The PHP Guestbook application has three Redis instances: one master and two slave instances. Each instance is tagged with a label where app=redis. For this example, we're using our Redis monitoring integration. It can monitor both master and slave instances of Redis, so we don’t have to distinguish between them. In the Kubernetes integration's YAML config file (newrelic-infrastructure-k8s-latest.yaml), you need to update the nri-integration-cfg section. From the list of integration configs, get the Redis integration YAML and add it to the Kubernetes config. The Redis YAML is highlighted below. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: redis-config.yml: | --- # Run auto discovery to find pods with label \"app=redis\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: redis integrations: - name: nri-redis env: # using the discovered IP as the hostname address HOSTNAME: ${discovery.ip} PORT: 6379 KEYS: '{\"0\":[\"<KEY_1>\"],\"1\":[\"<KEY_2>\"]}' REMOTE_MONITORING: true labels: env: production Copy Deploy the updated service: kubectl create -f newrelic-infrastructure-k8s-latest.yaml Copy You should be able to see the following in the logs for the pod newrelic-infra: time=\"2019-12-23T17:37:07Z\" level=info msg=\"Integration health check starting\" instance=redis-metrics integration=com.newrelic.redis prefix=integration/com.newrelic.redis working-dir=/var/db/newrelic-infra/newrelic-integrations time=\"2019-12-23T17:37:07Z\" level=info msg=\"Integration health check finished with success\" instance=redis-metrics integration=com.newrelic.redis prefix=integration/com.newrelic.redis working-dir=/var/db/newrelic-infra/newrelic-integrations Copy If there are no errors, you should see Redis data in the Infrastructure UI. To find the Redis dashboards, go to one.newrelic.com > Infrastructure > Third party services, and select the Redis dashboard. For the general procedure of how to monitor services running on Kubernetes, including more detail about how configuration works, see Monitor a Kubernetes-running service.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.55186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tutorial: Monitor Redis running on <em>Kubernetes</em>",
        "sections": "Tutorial: Monitor Redis running on <em>Kubernetes</em>",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": " is highlighted below. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-<em>integration</em>-cfg namespace: default data: redis-config.yml: | --- # Run auto discovery to find pods with label &quot;<em>app</em>=redis&quot; # https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>integrations</em>&#x2F;host-<em>integrations</em>&#x2F;installation&#x2F;container-auto-discovery discovery"
      },
      "id": "603e7e8264441f332a4e8879"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter": [
    {
      "sections": [
        "Monitor services running on Kubernetes",
        "Get started",
        "What you need",
        "Enable monitoring of services",
        "Get the config YAML for the integration",
        "Example configuration",
        "Configuration options for each integration",
        "Monitor services in our Kubernetes integration installed with Helm",
        "Learn more",
        "Manually configure service monitoring",
        "How the service-specific YAML config works",
        "Add a service YAML to the Kubernetes integration config",
        "Add multiple services to the same config"
      ],
      "title": "Monitor services running on Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "4c67f6272bda36eda4ad7883e89697a203aa2153",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/monitor-services-running-kubernetes/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-07T10:06:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's Kubernetes integration you can monitor both Kubernetes and the services running on it, such as Cassandra, Redis, MySQL, and other supported services. Get started Our Kubernetes integration comes bundled with some of our on-host integrations (like Cassandra, MySQL, and Apache). This lets you get data for those supported services by adding a section to the Kubernetes integration's configuration, which lives as a ConfigMap inside a manifest. What you need Enable this feature for a service Details about how configuration works For an example of how to monitor Redis running on a Kubernetes PHP Guestbook, see this tutorial. What you need To monitor services running on Kubernetes, you only need a Kubernetes cluster running the Kubernetes integration, version 1.16.0 or higher (install | check version | update). We support the following services running on Kubernetes: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP Enable monitoring of services To enable our Kubernetes integration to monitor one or more services: Expand this dropdown and get the YAML snippets for the service(s) you want to monitor: Get the config YAML for the integration For the services you want to monitor, follow the links to GitHub to get the YAML snippets you'll need for the next step: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Add the snippet to the Kubernetes integration's ConfigMap, after the data: section: Example configuration This example shows the YAML config for the Apache integration ( highlighted ) added to the Kubernetes integration's config. Respect the indentation levels. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: apache-config.yaml: | --- # Run auto discovery to find pods with label \"app=apache\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the optional arguments: # --namespaces: Comma separated namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: apache integrations: - name: nri-apache env: # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/server-status?auto METRICS: 1 Copy You can add snippets for multiple services to the same config file. See an example. Depending on your environment, you may need or want to set additional config options. Expand the dropdown below for links to configuration options. Configuration options for each integration Select a service to see available config options: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Verify monitoring is enabled: Go to one.newrelic.com > Infrastructure, select Third party services, and then select the service's dashboard. You should see data being reported. Additional notes about enabling services: Enabling multiple services may use more resources than what is set in the resource limits of the Kubernetes integration config file. If this becomes an issue, raise the limit in the resources section. The Kubernetes integration does not automatically update. For best results, regularly update. Monitor services in our Kubernetes integration installed with Helm If you installed our Kubernetes integration using Helm, to monitor services you need to update the existing installation with the new configuration, which contains the services to monitor: helm upgrade --reuse-values -f values.yaml [RELEASE] [CHART] Copy If you use nri-bundle charts, you need to update the children's chart values. Find some examples here. Learn more More resources for learning about configuration: Learn technical details about how configuration works. Learn how to configure monitoring of multiple services with the same config file. See a step-by-step tutorial showing how to monitor a Redis service on Kubernetes. Manually configure service monitoring The enable procedure should be all you need to get monitoring working, but if you run into problems, understanding some technical details about configuration can be helpful. This section goes into more detail about how configuration works. For each service you wish to monitor, you must add a configuration file for that integration to our Kubernetes integration's configuration. This document will cover these subjects: How the service-specific configuration YAML snippet works Adding the service-specific YAML in the Kubernetes integration's config file Adding multiple services to the Kubernetes integration's config file How the service-specific YAML config works Our Kubernetes integration's configuration follows the ConfigMap format. Using a ConfigMap allows us to decouple the configuration for the integrations from the Kubernetes image. The other benefit is that a ConfigMap can be updated automatically without reloading the running container. Because the infrastructure agent uses YAML to configure its associated integrations, ConfigMaps are a good choice for storing YAML. (For more information on config file format, see the Integration config file format.) The Kubernetes integration image comes with an auto-discovery feature that simplifies the configuration of multiple instances of services using a single configuration file. For example, if you have several NGINX instances running, creating an NGINX integration configuration file for every instance would be hard to implement and hard to update. With our auto-discovery option, you can discover and monitor all your NGINX instances with a single configuration file. Each integration has its own specific configuration YAML. Our NGINX integration default config file looks like this: nginx-config.yml: | --- discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --port: Port used to connect to the kubelet. Default is 10255 # --tls: Use secure (TLS) connection # Custom Example: # exec: /var/db/newrelic-infra/nri-discovery-kubernetes --namespaces namespace1,namespace2 --port 10250 --tls # Default exec: /var/db/newrelic-infra/nri-discovery-kubernetes match: label.app: nginx integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}/status STATUS_MODULE: discover METRICS: 1 Copy The above config enables the following: Runs nri-discovery-kubernetes to query the data for the node we are currently on. Parses the data that comes back and looks for any Kubernetes pod that has a Kubernetes container with an app= label with value nginx. For any matches, it attempts to run the NGINX integration. The status URL is built from: The pod's IP address The status page is pulled from the label on K8s pod called status_url This automatic discovery works the same as the container auto-discovery used by the infrastructure agent. For more advanced options, see Container auto-discovery. Add a service YAML to the Kubernetes integration config It's best practice to configure enabled integrations alongside the Kubernetes integration configuration. This is easier than maintaining configuration files for every single service/integration instance. Below is an example of a Kubernetes integration's ConfigMap. The highlighted section shows where an integration configuration YAML (in this case, NGINX) is placed. For more information on discovery:, see Container auto-discovery for on-host integrations. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 Copy This configuration map can then be referenced in the DaemonSet, the same as the one that was generated via the command line. Make sure the namespace used is the same one used by the Kubernetes integration manifest. If you haven't changed it in the downloaded manifest file, the value is default. Add multiple services to the same config You can monitor several services using the same Kubernetes integration config file. To do this, add another integration configuration YAML to the same Kubernetes integration config file. Below is the Kubernetes config created in the last section, with a new section for the Cassandra integration's config (highlighted). --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 cassandra-configuration.yml: | --- # Run auto discovery to find pods with label \"app=cassandra\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: cassandra integrations: - name: nri-cassandra env: # Use the discovered IP as the host address HOSTNAME: ${discovery.ip} PORT: 7199 USERNAME: cassandra PASSWORD: cassandra METRICS: 1/mark Copy The Kubernetes integration config is now set up to monitor these two services. Additionally, depending on your environment, there may be some additional service-specific configuration you must do. When you've completed configuration, our infrastructure agent looks for any pod with a label cassandra and runs the integration against it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.7543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>services</em> running on <em>Kubernetes</em>",
        "sections": "Monitor <em>services</em> in our <em>Kubernetes</em> <em>integration</em> installed with Helm",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": "With New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> you can monitor both <em>Kubernetes</em> and the <em>services</em> running on it, such as Cassandra, Redis, MySQL, and other supported <em>services</em>. Get started Our <em>Kubernetes</em> <em>integration</em> comes bundled with some of our on-host <em>integrations</em> (like Cassandra, MySQL, and Apache"
      },
      "id": "6044e50c196a676012960f35"
    },
    {
      "sections": [
        "Link your applications to Kubernetes",
        "Tip",
        "Compatibility and requirements",
        "Kubernetes requirements",
        "Network requirements",
        "APM agent compatibility",
        "Openshift requirements",
        "Important",
        "Configure the injection of metadata",
        "Default configuration",
        "Custom configuration",
        "Manage custom certificates",
        "Validate the injection of metadata",
        "Disable the injection of metadata",
        "Troubleshooting"
      ],
      "title": "Link your applications to Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "2ae58989813695b48f4924529d6fd6ea17e5f6c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-your-applications/link-your-applications-kubernetes/",
      "published_at": "2021-10-24T17:51:14Z",
      "updated_at": "2021-05-28T06:30:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can surface Kubernetes metadata and link it to your APM agents as distributed traces to explore performance issues and troubleshoot transaction errors. For more information, see this New Relic blog post. You can quickly start monitoring Kubernetes clusters using Auto-telemetry with Pixie, which is currently a beta release. This Pixie integration into New Relic does not require a language agent. Learn more about Auto-telemetry with Pixie here. Tip Our Kubernetes metadata injection project is open source. Here's the code to link APM and infrastructure data and the code to automatically manage certificates. Compatibility and requirements Before linking Kubernetes metadata to your APM agents, make sure you meet the following requirements: Kubernetes requirements Network requirements APM agent compatibility OpenShift requirements Kubernetes requirements To link your applications and Kubernetes, your cluster must have the MutatingAdmissionWebhook controller enabled, which requires Kubernetes 1.9 or higher. To verify that your cluster is compatible, run the following command: kubectl api-versions | grep admissionregistration.k8s.io/v1beta1 admissionregistration.k8s.io/v1beta1 Copy If you see a different result, follow the Kubernetes documentation to enable admission control in your cluster. Network requirements For Kubernetes to speak to our MutatingAdmissionWebhook, the master node (or the API server container, depending on how the cluster is set up) should be allowed egress for HTTPS traffic on port 443 to pods in all of the other nodes in the cluster. This might require specific configuration depending on how the infrastructure is set up (on-premises, AWS, Google Cloud, etc). Tip Until Kubernetes v1.14, users were only allowed to register admission webhooks on port 443. Since v1.15 it's possible to register them on different ports. To ensure backward compatibility, the webhook is registered by default on port 443 in the YAML config file we distribute. APM agent compatibility The following New Relic agents collect Kubernetes metadata: Go 2.3.0 or higher Java 4.10.0 or higher Node.js 5.3.0 or higher Python 4.14.0 or higher Ruby 6.1.0 or higher .NET 8.17.438 or higher Openshift requirements To link Openshift and Kubernetes you must enable mutating admission webhooks, which requires Openshift 3.9 or higher. During the process, install a resource that requires admin permissions to the cluster. Run this to log in as admin: oc login -u system:admin Copy Check that webhooks are correctly configured. If they are not, update the master-config.yaml file. admissionConfig: pluginConfig: MutatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission ValidatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission location: \"\" Copy Important Add kubeConfigFile: /dev/null to address some issues in Openshift. Enable certificate signing by editing the YAML file and updating your configuration: kubernetesMasterConfig: controllerArguments: cluster-signing-cert-file: - \"/etc/origin/master/ca.crt\" cluster-signing-key-file: - \"/etc/origin/master/ca.key\" Copy Restart the Openshift services in the master node. Configure the injection of metadata By default, all the pods you create that include APM agents have the correct environment variables set and the metadata injection applies to the entire cluster. To check that the environment variables have been set, any container that is running must be stopped, and a new instance started (see Validate the injection of metadata). This default configuration also uses the Kubernetes certificates API to automatically manage the certificates required for the injection. If needed, you can limit the injection of metadata to specific namespaces in your cluster or self-manage your certificates. Default configuration To proceed with the default injection of metadata, follow these steps: Download the YAML file: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-latest.yaml Copy Custom configuration You can limit the injection of metadata only to specific namespaces by using labels. To enable this feature, edit your YAML file by finding and uncommenting the following lines: # namespaceSelector: # matchLabels: # newrelic-metadata-injection: enabled Copy With this option, injection is only applied to those namespaces that have the newrelic-metadata-injection label set to enabled: kubectl label namespace YOUR_NAMESPACE newrelic-metadata-injection=enabled Copy Manage custom certificates To use custom certificates you need a specific YAML file: Download the YAML file without automatic certificate management: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-custom-certs-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-custom-certs-latest.yaml Copy Once you have the correct YAML file, you can proceed with the custom certificate management option. You need your certificate, server key, and Certification Authority (CA) bundle encoded in PEM format. If you have them in the standard certificate format (X.509), install openssl, and run the following: openssl x509 -in CERTIFICATE_FILENAME -outform PEM -out CERTIFICATE_FILENAME.pem openssl x509 -in SERVER_KEY_FILENAME -outform PEM -out SERVER_KEY_FILENAME.pem openssl x509 -in CA_BUNDLE_FILENAME -outform PEM -out BUNDLE_FILENAME.pem Copy If your certificate/key pair are in another format, see the Digicert knowledgebase for more help. Create the TLS secret with the signed certificate/key pair, and patch the mutating webhook configuration with the CA using the following commands: kubectl create secret tls newrelic-metadata-injection-secret \\ --key=PEM_ENCODED_SERVER_KEY \\ --cert=PEM_ENCODED_CERTIFICATE \\ --dry-run -o yaml | kubectl -n default apply -f - caBundle=$(cat PEM_ENCODED_CA_BUNDLE | base64 | td -d '\\n') kubectl patch mutatingwebhookconfiguration newrelic-metadata-injection-cfg --type='json' -p \"[{'op': 'replace', 'path': '/webhooks/0/clientConfig/caBundle', 'value':'${caBundle}'}]\" Copy Important Certificates signed by Kubernetes have an expiration of one year. For more information, see the Kubernetes source code in GitHub. Validate the injection of metadata In order to validate that the webhook (responsible for injecting the metadata) was installed correctly, deploy a new pod and check for the New Relic environment variables. Create a dummy pod containing Busybox by running: kubectl create -f https://git.io/vPieo Copy Check if New Relic environment variables were injected: kubectl exec busybox0 -- env | grep NEW_RELIC_METADATA_KUBERNETES NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME=fsi NEW_RELIC_METADATA_KUBERNETES_NODE_NAME=nodea NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME=default NEW_RELIC_METADATA_KUBERNETES_POD_NAME=busybox0 NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME=busybox Copy Disable the injection of metadata To disable/uninstall the injection of metadata, use the following commands: Delete the Kubernetes objects using the yaml file: kubectl delete -f k8s-metadata-injection-latest.yaml Copy Delete the TLS secret containing the certificate/key pair: kubectl delete secret/newrelic-metadata-injection-secret Copy Troubleshooting Follow these troubleshooting tips as needed. No Kubernetes metadata in APM or distributed tracing transactions Problem The creation of the secret by the k8s-webhook-cert-manager job used to fail due to the kubectl version used by the image when running in Kubernetes version 1.19.x, The new version 1.3.2 fixes this issue, therefore it is enough to run again the job using an update version of the image to fix the issue. Solution Update the image k8s-webhook-cert-manager (to a version >= 1.3.2) and re-run the job. The secret will be correctly created and the k8s-metadata-injection pod will be able to start. Note that the new version of the manifest and of the nri-bundle are already updated with the correct version of the image. Problem In OpenShift version 4.x, the CA that is used in order to patch the mutatingwebhookconfiguration resource is not the one used when signing the certificates. This is a known issue currently tracked here. In the logs of the Pod nri-metadata-injection, you'll see the following error message: TLS handshake error from 10.131.0.29:37428: remote error: tls: unknown certificate authority TLS handshake error from 10.129.0.1:49314: remote error: tls: bad certificate Copy Workaround Manually update the certificate stored in the mutatingwebhookconfiguration object. The correct CA locations might change according to the cluster configuration. However, you can usually find the CA in the secret csr-signer in the namespace openshift-kube-controller-manager. Problem There is no Kubernetes metadata included in the transactions' attributes of your APM agent or in distributed tracing. Solution Verify that the environment variables are being correctly injected by following the instructions described in the Validate your installation step. If they are not present, get the name of the metadata injection pod by running: kubectl get pods | grep newrelic-metadata-injection-deployment kubectl logs -f pod/podname Copy In another terminal, create a new pod (for example, see Validate your installation), and inspect the logs of the metadata injection deployment for errors. For every created pod there should be a set of 4 new entries in the logs like: {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.107Z\",\"caller\":\"server/main.go:139\",\"msg\":\"POST https://newrelic-metadata-injection-svc.default.svc:443/mutate?timeout=30s HTTP/2.0\\\" from 10.11.49.2:32836\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.110Z\",\"caller\":\"server/webhook.go:168\",\"msg\":\"received admission review\",\"kind\":\"/v1, Kind=Pod\",\"namespace\":\"default\",\"name\":\"\",\"pod\":\"busybox1\",\"UID\":\"6577519b-7a61-11ea-965e-0e46d1c9335c\",\"operation\":\"CREATE\",\"userinfo\":{\"username\":\"admin\",\"uid\":\"admin\",\"groups\":[\"system:masters\",\"system:authenticated\"]}} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:182\",\"msg\":\"admission response created\",\"response\":\"[{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env\\\",\\\"value\\\":[{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME\\\",\\\"value\\\":\\\"adn_kops\\\"}]},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NODE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"spec.nodeName\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.namespace\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_POD_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.name\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME\\\",\\\"value\\\":\\\"busybox\\\"}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_IMAGE_NAME\\\",\\\"value\\\":\\\"busybox\\\"}}]\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:257\",\"msg\":\"writing response\"} Copy If there are no new entries on the logs, it means that the apiserver is not being able to communicate with the webhook service, this could be due to networking rules or security groups rejecting the communication. To check if the apiserver is not being able to communicate with the webhook you should inspect the apiserver logs for errors like: failed calling webhook \"metadata-injection.newrelic.com\": ERROR_REASON Copy To get the apiserver logs: Start a proxy to the Kubernetes API server by the executing the following command in a terminal window and keep it running. kubectl proxy --port=8001 Copy Create a new pod in your cluster, this will make the apiserver try to communicate with the webhook. The following command will create a busybox. kubectl create -f https://git.io/vPieo Copy Retrieve the apiserver logs. curl localhost:8001/logs/kube-apiserver.log > apiserver.log Copy Delete the busybox container. kubectl delete -f https://git.io/vPieo Copy Inspect the logs for errors. grep -E 'failed calling webhook' apiserver.log Copy Remember that one of the requirements for the metadata injection is that the apiserver must be allowed egress to the pods running on the cluster. If you encounter errors regarding connection timeouts or failed connections, make sure to check the security groups and firewall rules of the cluster. If there are no log entries in either the apiserver logs or the metadata injection deployment, it means that the webhook was not properly registered. Ensure the metadata injection setup job ran successfully by inspecting the output of: kubectl get job newrelic-metadata-setup Copy If the job is not completed, investigate the logs of the setup job: kubectl logs job/newrelic-metadata-setup Copy Ensure the CertificateSigningRequest is approved and issued by running: kubectl get csr newrelic-metadata-injection-svc.default Copy Ensure the TLS secret is present by running: kubectl get secret newrelic-metadata-injection-secret Copy Ensure the CA bundle is present in the mutating webhook configuration: kubectl get mutatingwebhookconfiguration newrelic-metadata-injection-cfg -o json Copy Ensure the TargetPort of the Service resource matches the Port of the Deployment's container: kubectl describe service/newrelic-metadata-injection-svc kubectl describe deployment/newrelic-metadata-injection-deployment Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.99524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Link</em> your <em>applications</em> to <em>Kubernetes</em>",
        "sections": "<em>Link</em> your <em>applications</em> to <em>Kubernetes</em>",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": " is currently a beta release. This Pixie <em>integration</em> into New Relic does not require a language agent. Learn more about Auto-telemetry with Pixie here. Tip Our <em>Kubernetes</em> metadata injection project is open source. Here&#x27;s the code to <em>link</em> APM and infrastructure data and the code to automatically"
      },
      "id": "603ebb94196a674fd1a83df3"
    },
    {
      "sections": [
        "Tutorial: Monitor Redis running on Kubernetes",
        "What you need",
        "Step 1: Set up an example Redis application",
        "Step 2: Enable monitoring of Redis instances"
      ],
      "title": "Tutorial: Monitor Redis running on Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "30d0c7b52a792c21a50f98931d05a0665ff19fa1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/tutorial-monitor-redis-running-kubernetes/",
      "published_at": "2021-10-24T17:29:20Z",
      "updated_at": "2021-03-16T04:18:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a service running on Kubernetes, and it's a service we support, you can enable monitoring of that service by adding a configuration section for that integration to the Kubernetes integration's config. This tutorial shows how to enable monitoring for a Redis service running on the Kubernetes PHP Guestbook. For the general procedure, see Monitor a Kubernetes-running service. What you need See the general requirements for this feature, including supported services. The kubectl command-line tool must be configured to communicate with your cluster. If you don't have a cluster, you can create one using Minikube. Step 1: Set up an example Redis application This tutorial builds on the Kubernetes tutorial Deploying a PHP Guestbook application with Redis. Skip the Kubernetes tutorial and run the following command to set up the application needed for our tutorial: kubectl create -f https://raw.githubusercontent.com/kubernetes/examples/master/guestbook/all-in-one/guestbook-all-in-one.yaml Copy If you'd like to first complete the Kubernetes tutorial, follow their tutorial instructions but do not follow the instructions in the Cleaning up section. Step 2: Enable monitoring of Redis instances The PHP Guestbook application has three Redis instances: one master and two slave instances. Each instance is tagged with a label where app=redis. For this example, we're using our Redis monitoring integration. It can monitor both master and slave instances of Redis, so we don’t have to distinguish between them. In the Kubernetes integration's YAML config file (newrelic-infrastructure-k8s-latest.yaml), you need to update the nri-integration-cfg section. From the list of integration configs, get the Redis integration YAML and add it to the Kubernetes config. The Redis YAML is highlighted below. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: redis-config.yml: | --- # Run auto discovery to find pods with label \"app=redis\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: redis integrations: - name: nri-redis env: # using the discovered IP as the hostname address HOSTNAME: ${discovery.ip} PORT: 6379 KEYS: '{\"0\":[\"<KEY_1>\"],\"1\":[\"<KEY_2>\"]}' REMOTE_MONITORING: true labels: env: production Copy Deploy the updated service: kubectl create -f newrelic-infrastructure-k8s-latest.yaml Copy You should be able to see the following in the logs for the pod newrelic-infra: time=\"2019-12-23T17:37:07Z\" level=info msg=\"Integration health check starting\" instance=redis-metrics integration=com.newrelic.redis prefix=integration/com.newrelic.redis working-dir=/var/db/newrelic-infra/newrelic-integrations time=\"2019-12-23T17:37:07Z\" level=info msg=\"Integration health check finished with success\" instance=redis-metrics integration=com.newrelic.redis prefix=integration/com.newrelic.redis working-dir=/var/db/newrelic-infra/newrelic-integrations Copy If there are no errors, you should see Redis data in the Infrastructure UI. To find the Redis dashboards, go to one.newrelic.com > Infrastructure > Third party services, and select the Redis dashboard. For the general procedure of how to monitor services running on Kubernetes, including more detail about how configuration works, see Monitor a Kubernetes-running service.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.55186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tutorial: Monitor Redis running on <em>Kubernetes</em>",
        "sections": "Tutorial: Monitor Redis running on <em>Kubernetes</em>",
        "tags": "<em>Link</em> <em>apps</em> <em>and</em> <em>services</em>",
        "body": " is highlighted below. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-<em>integration</em>-cfg namespace: default data: redis-config.yml: | --- # Run auto discovery to find pods with label &quot;<em>app</em>=redis&quot; # https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>integrations</em>&#x2F;host-<em>integrations</em>&#x2F;installation&#x2F;container-auto-discovery discovery"
      },
      "id": "603e7e8264441f332a4e8879"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/troubleshooting/certificate-signed-unknown-authority": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.42923,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.63647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> gives you full observability into the health and performance of your environment, no matter whether you run <em>Kubernetes</em> on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.7634,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/troubleshooting/get-logs-version": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.42694,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.63647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> gives you full observability into the health and performance of your environment, no matter whether you run <em>Kubernetes</em> on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.7634,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/troubleshooting/kubernetes-integration-troubleshooting-error-messages": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.42679,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.63635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> gives you full observability into the health and performance of your environment, no matter whether you run <em>Kubernetes</em> on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.76335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/troubleshooting/kubernetes-integration-troubleshooting-missing-nodes": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.42679,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.63635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> gives you full observability into the health and performance of your environment, no matter whether you run <em>Kubernetes</em> on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.76335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/troubleshooting/kubernetes-integration-troubleshooting-not-seeing-data": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.42664,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.63623,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> gives you full observability into the health and performance of your environment, no matter whether you run <em>Kubernetes</em> on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.76329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/troubleshooting/not-seeing-control-plane-data": [
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.42664,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements <em>Kubernetes</em> 1.16 or higher. The New Relic <em>Kubernetes</em> <em>integration</em>. New Relic&#x27;s user API key. No other External Metrics Adapter installed"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.63623,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "New Relic&#x27;s <em>Kubernetes</em> <em>integration</em> gives you full observability into the health and performance of your environment, no matter whether you run <em>Kubernetes</em> on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "Install the Kubernetes integration manually using Helm",
        "Compatibility and requirements",
        "Install Kubernetes integration with Helm",
        "Install with Helm 3 and nri-bundle (recommended)",
        "Installing and configuring nri-bundle with Helm",
        "Install with Helm 2 and nri-bundle (legacy)",
        "Installation instructions for Helm 2",
        "Important",
        "Tip",
        "Helm configuration options",
        "Upgrade using Helm",
        "Monitor services running on Kubernetes",
        "Use your Kubernetes data",
        "Reduce data ingest",
        "Prometheus OpenMetrics Integration",
        "New Relic Logging",
        "New Relic Pixie Integration"
      ],
      "title": "Install the Kubernetes integration manually using Helm",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a3e4c960777df00f17ce0e4b0d1083612bdca527",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm/",
      "published_at": "2021-10-24T15:58:04Z",
      "updated_at": "2021-10-19T03:53:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Helm is a package manager on top of Kubernetes. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in Kubernetes. To install the integration using Helm, we recommend our Kubernetes automated installer, which will prompt for almost all configuration options and autopopulate secrets and values for you. Additionally, our automated installer also allows to install our integration as plain manifests rather than a Helm release. See Kubernetes integration: install and configure for more details about how to use our automated installer. Start the installer This page describes in more depth how to install and configure the New Relic integration without using the automated installer. Compatibility and requirements Make sure Helm is installed on your machine. We strongly recommend using Helm 3 to manage the Kubernetes integration. Our charts are also compatible with Helm 2, but support for it might be removed in the future. To install the Kubernetes integration using Helm, you will need your New Relic account license key and your Kubernetes cluster's name: Find and copy your New Relic license key. Find the name of your cluster with this command: kubectl config current-context Copy Note this values somewhere safe as you will need them later during the installation process. Install Kubernetes integration with Helm Install with Helm 3 and nri-bundle (recommended) New Relic has several charts for the different components which offer different features for the platform: newrelic-infrastructure: Contains the main Kubernetes integration and the infrastructure agent. This is the core component for the New Relic Kubernetes experience, responsible of reporting most of the data that is surfaced in dashboard and the Kubernetes Cluster Explorer. newrelic-logging: Provides a DaemonSet with New Relic's Fluent Bit output plugin to easily forward your logs to New Relic. nri-kube-events: Collects and reports cluster events (such as kubectl get events) to New Relic. nri-prometheus: New Relic's Prometheus OpenMetrics Integration, automatically scrapes Prometheus endpoints present in the cluser and reports metrics to New Relic. nri-metadata-injection: Sets up a minimal MutatingAdmissionWebhook that injects a couple of environment to containers. These contain metadata about the cluster and New Relic installation and will be later picked up by applications instrumented using APM, allowing to correlate APM and infrastructure data. nri-statsd: New Relic StatsD integration. Additionally, New Relic provides nri-bundle, a chart which pulls a selectable set of the charts mentioned above. nri-bundle can also install Kube State Metrics and Pixie for you if needed. While it is possible to install those charts separately, we strongly recommend using the nri-bundle chart for Kubernetes deployments, as it ensures that values across all the charts are consistent and provides full control over which components are installed, as well as the possibility to configure all of them as Helm dependencies. This is the same chart that is used and referenced by our automated installer. Installing and configuring nri-bundle with Helm Ensure you are using the appropriate context in the machine where you will run Helm and kubectl: You can check the available contexts with: kubectl config get-contexts Copy And switch to the desired context using: kubectl config use-context CONTEXT_NAME Copy Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. Notice that we are specifying --dry-run and --debug, so nothing will be installed in this step: helm upgrade --install newrelic newrelic/nri-bundle \\ --dry-run \\ --debug \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Please notice and adjust the following flags: global.licenseKey=<var>YOUR_NEW_RELIC_LICENSE_KEY</var>: Must be set to a valid License Key for your account. global.cluster=<var>K8S_CLUSTER_NAME</var>: Is used to identify the cluster in the New Relic UI, so should be a descriptive value not used by any other Kubernetes cluster configured in your New Relic account. ksm.enabled=<mark>true</mark>: Setting this to true will automatically install Kube State Metrics (KSM) for you, which is required for our integration to run. You can set this to false if KSM is already present in your cluster, even if it is on a different namespace. newrelic-infrastructure.privileged=<mark>true</mark>: Can be set to false to install a trimmed down version of our integration that does not require extra privileges, such as hostPath mounts or running containers as root. Please note that this will disable detailed process collection from the host. For performance reasons, our logging solution still requires hostPath mounts, regardless of the value of this flag. If this is not allowedin your cluster, you will need to disable the logging solution by specifying logging.enabled=false. prometheus.enabled=true: Will deploy our Prometheus OpenMetrics integration, which automatically collects data from prometheus endpoints present in the cluster. webhook.enabled=true: Will install our minimal webhook, which adds environment variables that, in turn, allows linking applications instrumented with APM with infrastructure data. Our chart has a comprehensive set of flags and tunables that can be edited to configure our solution to your particular needs. For a full list of all the flags that can be configured, please check the chart's README and the default values.yaml file. Install the Kubernetes integration by running the customized command without --debug and --dry-run: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set ksm.enabled= true \\ --set newrelic-infrastructure.privileged= true \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set kubeEvents.enabled=true \\ --set logging.enabled=true Copy Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl -n newrelic get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node for newrelic-infrastructure, as well as one Deployment and one pod for any other component that you have enabled. Install with Helm 2 and nri-bundle (legacy) Installation instructions for Helm 2 Important Helm 2 has been deprecated and New Relic does not recommend using it for deployments. Instructions in this section are provided for legacy systems only. To install using Helm 2: Ensure that Helm 2, including their cluster-side components (i.e. Tiller) are properly installed and configured. Please check the official documentation for more details. Set the cluster where you want to install the agent: kubectl config set-cluster DESIRED_CLUSTER Copy To see the available clusters, run kubectl config get-clusters Make sure that kube-state-metrics is installed on your machine: kubectl get deployment --all-namespaces | grep kube-state-metrics Copy If it's not installed, follow the instructions in the kube-state-metrics GitHub repo to install it. Add the New Relic Helm charts repo: helm repo add newrelic https://helm-charts.newrelic.com Copy Make sure everything is configured properly in the chart by running the following command. This step uses the --dry-run and --debug switches and therefore the agent is not installed. helm install newrelic/newrelic-infrastructure \\ --dry-run \\ --debug \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Install the New Relic Kubernetes integration: helm install newrelic/newrelic-infrastructure \\ --set licenseKey=your_new_relic_license_key \\ --set cluster=K8S_CLUSTER_NAME \\ --set config.custom_attributes.cluster=K8S_CLUSTER_NAME Copy Tip Note that the --dry-run and --debug switches have been removed. Wait a few seconds, then check that the DaemonSet and pods have been created: kubectl get daemonsets,pods Copy Make sure you see a DaemonSet, and one pod per node. Helm configuration options When you install or upgrade the Kubernetes integration with Helm using the command line, you can pass your configuration variables with the --set flag. helm install newrelic/newrelic-infrastructure \\ --set licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set cluster=YOUR_CLUSTER_NAME Copy A full list of the configuration parameters can be found in the newrelic-infrastructure chart README Upgrade using Helm To update your Kubernetes integration installed via Helm: Update the local chart repository: helm repo update Copy Update the release by running again the appropriate helm upgrade --install ... command in the section above. Monitor services running on Kubernetes After having installed our Kubernetes integration, you can start instrumenting the services than run in your cluster. To learn more about how to do this, please check our Monitor services running on Kubernetes page. Use your Kubernetes data To learn more about how to use your Kubernetes data, please head to our detailed Find and use your Kubernetes data pages. Reduce data ingest Our charts support setting an option to reduce the amount of data ingest at the cost of dropping detailed information. To enable it, set global.lowDataMode=true in the nri-bundle chart. lowDataMode affects three specific components of the nri-bundle chart outlined below. Prometheus OpenMetrics Integration If lowDataMode is enabled, the following metrics are excluded by default as they are already collected and used by the New Relic Kubernetes Integration. - kube_ - container_ - machine_ - cadvisor_ Copy New Relic Logging If lowDataMode is enabled, Labels and Annotations are set to Off in the Filter section of the fluent-bit.conf file. This means that this detail will be dropped from the container log files which reduces the overall data ingest into New Relic. The following fields are retained: Allowlist_key container_name Allowlist_key namespace_name Allowlist_key pod_name Allowlist_key stream Allowlist_key log Copy Low Data Mode Log Example Complete Log Record [ { \"cluster_name\": \"api-test\", \"kubernetes\": { \"annotations\": { \"kubernetes.io/psp\": \"eks.privileged\" }, \"container_hash\": \"fryckbos/test@sha256:5b098eaf3c7d5b3585eb10cebee63665b6208bea31ef31a3f0856c5ffdda644b\", \"container_image\": \"fryckbos/test:latest\", \"container_name\": \"newrelic-logging\", \"docker_id\": \"134e1daf63761baa15e035b08b7aea04518a0f0e50af4215131a50c6a379a072\", \"host\": \"ip-192-168-17-123.ec2.internal\", \"labels\": { \"app\": \"newrelic-logging\", \"app.kubernetes.io/name\": \"newrelic-logging\", \"controller-revision-hash\": \"84db95db86\", \"pod-template-generation\": \"1\", \"release\": \"nri-bundle\" }, \"namespace_name\": \"nrlogs\", \"pod_id\": \"54556e3e-719c-46b5-af69-020b75d69bf1\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\" }, \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"plugin\": { \"source\": \"kubernetes\", \"type\": \"fluent-bit\", \"version\": \"1.8.1\" }, \"stream\": \"stderr\", \"time\": \"2021-09-14T12:30:49.138824971Z\", \"timestamp\": 1631622649138 } ] Copy Log Record after enabling lowDataMode. [ { \"cluster_name\": \"api-test\", \"container_name\": \"newrelic-logging\", \"namespace_name\": \"nrlogs\", \"pod_name\": \"nri-bundle-newrelic-logging-jxnbj\", \"message\": \"[2021/09/14 12:30:49] [ info] [engine] started (pid=1)\\n\", \"stream\": \"stderr\", \"timestamp\": 1631622649138 } ] Copy New Relic Pixie Integration If lowDataMode is enabled, the newrelic-pixie integration performs heavier sampling on Pixie spans and reduces the collection interval from 10 seconds to 15 seconds. lowDataMode settings: HTTP_SPAN_LIMIT: 750 DB_SPAN_LIMIT: 250 COLLECT_INTERVAL_SEC: 15 Copy The default settings for these parameters and others can be found in the newrelic-pixie-integration Github repo.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.76329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "sections": "Install the <em>Kubernetes</em> <em>integration</em> manually using Helm",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "Helm is a package manager on top of <em>Kubernetes</em>. It facilitates installation, upgrades, or revision tracking, and it manages dependencies for the services that you install in <em>Kubernetes</em>. To install the <em>integration</em> using Helm, we recommend our <em>Kubernetes</em> automated installer, which will prompt"
      },
      "id": "603eb326e7b9d2d5f82a080a"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data": [
    {
      "sections": [
        "Navigate the Kubernetes cluster explorer",
        "Meet the cluster explorer",
        "Cluster dashboard",
        "Cluster explorer node table",
        "Search and filter your cluster data",
        "Browse your Kubernetes events"
      ],
      "title": "Navigate the Kubernetes cluster explorer",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Understand and use data"
      ],
      "external_id": "a3ef4aa459ed4503201c686000dff3a75331c2f7",
      "image": "https://docs.newrelic.com/static/34f90215b59ab8d7b4ec986bbb110805/9b7bd/nr1-cluster-explorer-node-tooltip.png",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/understand-use-data/kubernetes-cluster-explorer/",
      "published_at": "2021-10-24T17:52:52Z",
      "updated_at": "2021-03-16T06:10:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes cluster explorer uses the data collected by the Kubernetes integration to show the status of your cluster, from the control plane to nodes and pods. You can find out about the health of each entity, explore logs, and see how your apps are performing. With the Events integration, everything that happens in your cluster becomes visible, and logs brought in using the logs plugin are also available. Meet the cluster explorer The cluster explorer represents your most relevant cluster data on a chart with the shape of a ship's wheel — which is also Kubernetes' logo. Outer ring: Contains up to 24 nodes of your cluster, the most relevant based on the amount of alerts. Hover over each node to check resource consumption and the percentage of allocable pods used. Inner rings: Contain the pods ( ) of each node. Pods with active alerts are shown in the third innermost ring, and pods that are pending or unable to run are in the center. Hover the mouse over each node or pod to get a quick overview of its resource usage. You can click each node and pod to view its resource usage over time or to get more information about its health and active alerts. Colors are based on predefined alert conditions: Yellow pods have active warning alerts, while red pods have active critical alerts. one.newrelic.com > Kubernetes cluster explorer: Click any pod to get more information about its status and health, and to dig deeper into application data and traces, logs, and events. Click a node to see the following data: Pod statistics CPU, memory, and storage consumption against allocatable amounts Amount of pods used by the node against the allocatable amount of pods For each pod, depending on the integrations and features you've enabled, you can see: Pod status and metadata, including namespace and deployment Container status and statistics Active alerts (both warning and critical) Kubernetes events that happened in that pod APM data and traces (if you've linked your APM data) A link to the pods' and containers' logs, collected using the Kubernetes plugin for New Relic Logs Cluster and control plane statistics are always visible on the left side. Cluster dashboard The cluster dashboard can be accessed at any time from the cluster explorer by clicking Kubernetes dashboard. It provides a curated dashboard experience for your Kubernetes cluster. one.newrelic.com > Kubernetes cluster explorer > Kubernetes dashboard: The Kubernetes dashboard can be accessed from the Kubernetes cluster explorer. It shows useful Kubernetes metric data. Cluster explorer node table Below the cluster explorer is the node table, which shows all the nodes of the cluster, namespace, or deployment. Like all other usage indicators, the table shows consumption against allocatable resources. Search and filter your cluster data The main way to modify the data view in the cluster explorer is by using the top bar to search for specific attributes or values. All the attributes and values collected by the Kubernetes integration can be combined to narrow down the cluster view. one.newrelic.com > Kubernetes cluster explorer: All your Kubernetes cluster's attributes and data points can be used to filter the cluster explorer view. You can also change the time frame using the time picker in the upper right corner. The Auto-refresh box turns the cluster explorer into a real-time dashboard that refreshes every 60 seconds. one.newrelic.com > Kubernetes cluster explorer: The time picker lets you select several predefined time spans. To reload the data every minute, check the auto-refresh box. Browse your Kubernetes events If you’ve enabled the Kubernetes events integration, you can click the Events tab to browse everything that happened in your cluster, from warnings to normal events. To set it up, select the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into logs and infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.31107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Navigate the <em>Kubernetes</em> cluster explorer",
        "sections": "Navigate the <em>Kubernetes</em> cluster explorer",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "New Relic&#x27;s <em>Kubernetes</em> cluster explorer uses the <em>data</em> collected by the <em>Kubernetes</em> <em>integration</em> to show the status of your cluster, from the control plane to nodes and pods. You can find out about the health of each entity, explore logs, and see how your apps are performing. With the Events"
      },
      "id": "603eb9a364441f82484e8879"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.63611,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " <em>Kubernetes</em> abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your <em>Kubernetes</em> <em>data</em>, which our <em>integration</em> collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.9104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can <em>use</em> metrics from your New Relic account to autoscale applications and services in your <em>Kubernetes</em> cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/kubernetes-pixie/kubernetes-integration/understand-use-data/kubernetes-cluster-explorer": [
    {
      "sections": [
        "Find and use your Kubernetes data",
        "Query Kubernetes data",
        "Event types",
        "Manage alerts",
        "Create an alert condition",
        "Use the predefined alert types and thresholds",
        "Select alert notifications",
        "Pod alert notification example",
        "Container resource notification example",
        "Create alert conditions using NRQL",
        "Kubernetes attributes and metrics",
        "Node data",
        "Namespace data",
        "Deployment data",
        "ReplicaSet data",
        "DaemonSet data",
        "StatefulSet data",
        "Pod data",
        "Cluster data",
        "Container data",
        "Volume data",
        "API server data",
        "Controller manager data",
        "Scheduler data",
        "ETCD data",
        "Endpoint data",
        "Service data",
        "Horizontal Pod Autoscaler data",
        "Kubernetes metadata in APM-monitored applications",
        "For more help"
      ],
      "title": "Find and use your Kubernetes data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Understand and use data"
      ],
      "external_id": "d36002ee54b0e3573ec4efef9f9c5ee940f49f96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-08-08T13:47:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own charts and query all your Kubernetes integration data using the query builder and the NerdGraph API. Our integration collects Kubernetes data by instrumenting the container orchestration layer. For a simpler and more visual experience, use the cluster explorer. one.newrelic.com > Dashboards: Using the query builder you can query your Kubernetes data and create clear visualizations. Query Kubernetes data The simplest way to query your Kubernetes data is using the query builder, which accepts NRQL queries. Alternatively, you can use the NerdGraph API to retrieve Kubernetes data. Event types Kubernetes data is attached to the following event types: Event name Type of Kubernetes data Available since K8sNodeSample Node data v1.0.0 K8sNamespaceSample Namespace data v1.0.0 K8sDeploymentSample Deployment data v1.0.0 K8sReplicasetSample ReplicaSet data v1.0.0 K8sDaemonsetSample DaemonSet data v1.13.0 K8sStatefulsetSample StatefulSet data v1.13.0 K8sPodSample Pod data v1.0.0 K8sClusterSample Cluster data v1.0.0 K8sContainerSample Container data v1.0.0 K8sVolumeSample Volume data v1.0.0 K8sApiServerSample API server data v1.11.0 K8sControllerManagerSample Controller manager data v1.11.0 K8sSchedulerSample Scheduler data v1.11.0 K8sEtcdSample ETCD data v1.11.0 K8sEndpointSample Endpoint data v1.13.0 K8sServiceSample Service data v1.13.0 K8sHpaSample Horizontal Pod Autoscaler data v2.3.0 Manage alerts You can be notified about alert violations for your Kubernetes data: Create an alert condition To create an alert condition for the Kubernetes integration: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Kubernetes, then select Create alert condition. To filter the alert to Kubernetes entities that only have the chosen attributes, select Filter. Select the threshold settings. For more on the Trigger an alert when... options, see Alert types. Select an existing alert policy, or create a new one. Select Create. When an alert condition's threshold is triggered, New Relic sends a notification to the policy's notification channels. Use the predefined alert types and thresholds The Kubernetes integration comes with its own alert policy and alert conditions. To see what the predefined alert conditions are, see Kubernetes integration: Predefined alert policy. In addition, you can create an alert condition for any metric collected by any New Relic integration you use, including the Kubernetes integration: Select the alert type Integrations. From the Select a data source dropdown, select a Kubernetes (K8s) data source. Select alert notifications When an alert condition's threshold is triggered, New Relic sends a message to the notification channel(s) chosen in the alert policy. Depending on the type of notification, you may have the following options: View the incident. Acknowledge the incident. Go to a chart of the incident data by selecting the identifier name. The entity identifier that triggered the alert appears near the top of the notification message. The format of the identifier depends on the alert type: Available pods are less than desired pods alerts: K8s:CLUSTER_NAME:PARENT_NAMESPACE:replicaset:REPLICASET_NAME Copy CPU or memory usage alerts: K8s:CLUSTER_NAME:PARENT_NAMESPACE:POD_NAME:container:CONTAINER_NAME Copy Here are some examples. Pod alert notification example For Available pods are less than desired pods alerts, the ID of the ReplicaSet triggering the issue might look like this: k8s:beam-production:default:replicaset:nginx-deployment-1623441481 Copy This identifier contains the following information: Cluster name: beam-production Parent namespace: default ReplicaSet name: nginx-deployment-1623441481 Container resource notification example For container CPU or memory usage alerts, the entity might look like this: k8s:beam-production:kube-system:kube-state-metrics-797bb87c75-zncwn:container:kube-state-metrics Copy This identifier contains the following information: Cluster name: beam-production Parent namespace: kube-system Pod namespace: kube-state-metrics-797bb87c75-zncwn Container name: kube-state-metrics Create alert conditions using NRQL Follow standard procedures to create alert conditions for NRQL queries. Kubernetes attributes and metrics The Kubernetes integration collects the following metrics and other attributes. Node data Query the K8sNodeSample event for node data: Node attribute Description allocatableCpuCores Node allocatable CPU cores allocatableMemoryBytes Node allocatable memory bytes allocatablePods Node allocatable pods allocatableEphemeralStorageBytes Node allocatable ephemeral-storage bytes capacityCpuCores Node CPU capacity capacityMemoryBytes Node memory capacity (in bytes) capacityPods Pod capacity of the node capacityEphemeralStorageBytes Node ephemeral-storage capacity clusterName Name that you assigned to the cluster when you installed the Kubernetes integration condition.{conditionName}={conditionValue} Status of the current observed node condition. The reported conditions can vary depending on your Kubernetes flavor and installed operators. Examples of common conditions are: Ready, DiskPressure, MemoryPressure, PIDPressure and NetworkUnavailable. Condition values can be 1 (true), 0 (false), or -1 (unknown). cpuUsedCoreMilliseconds Node CPU usage measured in core milliseconds cpuUsedCores Node CPU usage measured in cores cpuRequestedCores Total amount of CPU cores requested allocatableCpuCoresUtilization Percentage of CPU cores actually used with respect to the CPU cores allocatable fsAvailableBytes Bytes available in the node filesystem fsCapacityBytes Total capacity of the node filesystem in bytes fsInodes Total number of inodes in the node filesystem fsInodesFree Free inodes in the node filesystem fsInodesUsed Used inodes in the node filesystem fsUsedBytes Used bytes in the node filesystem fsCapacityUtilization Percentage of used bytes in the node filesystem with respect to the capacity memoryAvailableBytes Bytes of memory available in the node memoryMajorPageFaultsPerSecond Number of major page faults per second in the node memoryPageFaults Number of page faults in the node memoryRssBytes Bytes of rss memory memoryUsedBytes Bytes of memory used memoryWorkingSetBytes Bytes of memory in the working set memoryRequestedBytes Total amount of requested memory allocatableMemoryUtilization Percentage of bytes of memory in the working set with respect to the node allocatable memory net.errorCountPerSecond Number of errors per second while receiving/transmitting over the network nodeName Host name that the pod is running on runtimeAvailableBytes Bytes available to the container runtime filesystem runtimeCapacityBytes Total capacity assigned to the container runtime filesystem in bytes runtimeInodes Total number of inodes in the container runtime filesystem runtimeInodesFree Free inodes in the container runtime filesystem runtimeInodesUsed Used inodes in the container runtime filesystem runtimeUsedBytes Used bytes in the container runtime filesystem unschedulable Status of node schedulability of new pods. Its value can be 0 (false) or 1 (true) label.LABEL_NAME Labels associated with your node, so you can filter and query for specific nodes Namespace data Query the K8sNamespaceSample event for namespace data: Namespace attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of the namespace when it was created namespace Name of the namespace to be used as an identifier label.LABEL_NAME Labels associated with your namespace, so you can filter and query for specific namespaces status Current status of the namespace. The value can be Active or Terminated Deployment data Query the K8sDeploymentSample event for deployment data: Deployment attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the deployment was created deploymentName Name of the deployment to be used as an identifier namespace Name of the namespace that the deployment belongs to label.LABEL_NAME Labels associated with your deployment, so you can filter and query for specific deployments podsAvailable Number of replicas that are currently available podsDesired Number of replicas that you defined in the deployment podsTotal Total number of replicas that are currently running podsUnavailable Number of replicas that are currently unavailable podsUpdated Number of replicas that have been updated to achieve the desired state of the deployment podsMissing Total number of replicas that are missing (number of desired replicas, podsDesired, minus the total number of replicas, podsTotal) ReplicaSet data Query the K8sReplicasetSample event for ReplicaSet data: Replica attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the ReplicaSet was created deploymentName Name of the deployment to be used as an identifier namespace Name of the namespace that the ReplicaSet belongs to observedGeneration Integer representing generation observed by the ReplicaSet podsDesired Number of replicas that you defined in the deployment podsFullyLabeled Number of pods that have labels that match the ReplicaSet pod template labels podsReady Number of replicas that are ready for this ReplicaSet podsTotal Total number of replicas that are currently running podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) replicasetName Name of the ReplicaSet to be used as an identifier DaemonSet data Query the K8sDaemonsetSample event for DaemonSet data: DaemonSet attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the DaemonSet was created namespaceName Name of the namespace that the DaemonSet belongs to label.LABEL_NAME Labels associated with your DaemonSet, so you can filter and query for specific DaemonSet daemonsetName Name associated with the DaemonSet podsDesired The number of nodes that should be running the daemon pod podsScheduled The number of nodes running at least one daemon pod and are supposed to podsAvailable The number of nodes that should be running the daemon pod and have one or more of the daemon pod running and available podsReady The number of nodes that should be running the daemon pod and have one or more of the daemon pod running and ready podsUnavailable The number of nodes that should be running the daemon pod and have none of the daemon pod running and available podsMisscheduled The number of nodes running a daemon pod but are not supposed to podsUpdatedScheduled The total number of nodes that are running updated daemon pod podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) metadataGeneration Sequence number representing a specific generation of the desired state StatefulSet data Query the K8sStatefulsetSample event for StatefulSet data: StatefulSet attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the StatefulSet was created namespaceName Name of the namespace that the StatefulSet belongs to label.LABEL_NAME Labels associated with your StatefulSet, so you can filter and query for specific StatefulSet statefulsetName Name associated with the StatefulSet podsDesired Number of desired pods for a StatefulSet podsReady The number of ready replicas per StatefulSet podsCurrent The number of current replicas per StatefulSet podsTotal The number of replicas per StatefulSet podsUpdated The number of updated replicas per StatefulSet podsMissing Total number of replicas that are currently missing (number of desired replicas, podsDesired, minus the number of ready replicas, podsReady) observedGeneration The generation observed by the StatefulSet controller metadataGeneration Sequence number representing a specific generation of the desired state for the StatefulSet currentRevision Indicates the version of the StatefulSet used to generate pods in the sequence. Value range: between 0 and podsCurrent updateRevision Indicates the version of the StatefulSet used to generate pods in the sequence. Value range: between podsDesired-podsUpdated and podsDesired Pod data Query the K8sPodSample event for pod data: Pod attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the pod was created in epoch seconds createdBy Name of the Kubernetes object that created the pod. For example, newrelic-infra createdKind Kind of Kubernetes object that created the pod. For example, DaemonSet. deploymentName Name of the deployment to be used as an identifier isReady Boolean representing whether or not the pod is ready to serve requests isScheduled Boolean representing whether or not the pod has been scheduled to run on a node label.LABEL_NAME Labels associated with your pod, so you can filter and query for specific pods message Details related to the last pod status change namespace Name of the namespace that the pod belongs to net.errorCountPerSecond Number of errors per second while receiving/transmitting over the network net.errorsPerSecond Number of errors per second net.rxBytesPerSecond Number of bytes per second received over the network net.txBytesPerSecond Number of bytes per second transmitted over the network nodeIP Host IP address that the pod is running on nodeName Host name that the pod is running on podIP IP address of the pod. If it doesn't have an IP, it'll be empty podName Name of the pod to be used as an identifier reason Reason why the pod is in the current status startTime Timestamp of when the pod started running in epoch seconds status Current status of the pod. Value can be Pending, Running, Succeeded, Failed, Unknown Cluster data Query the K8sClusterSample event to see cluster data: Cluster attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration clusterK8sVersion Kubernetes version that the cluster is running Container data Query the K8sContainerSample event for container data: Container attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration containerID Unique ID associated with the container. If you are running Docker, this is the Docker container id containerImage Name of the image that the container is running containerImageID Unique ID associated with the image that the container is running containerName Name associated with the container cpuLimitCores Integer representing limit CPU cores defined for the container in the pod specification cpuRequestedCores Requested CPU cores defined for the container in the pod specification cpuUsedCores CPU cores actually used by the container cpuCoresUtilization Percentage of CPU cores actually used by the container with respect to the CPU limit specified. This percentage is based on this calculation: (cpuUsedCores / cpuLimitCores) * 100 requestedCpuCoresUtilization Percentage of CPU cores actually used by the container with respect to the CPU request specified deploymentName Name of the deployment to be used as an identifier isReady Boolean. Whether or not the container's readiness check succeeded label.LABEL_NAME Labels associated with your container, so you can filter and query for specific containers memoryLimitBytes Integer representing limit bytes of memory defined for the container in the pod specification memoryRequestedBytes Integer. Requested bytes of memory defined for the container in the pod specification memoryUsedBytes Integer. Bytes of memory actually used by the container memoryUtilization Percentage of memory actually used by the container with respect to the memory limit specified requestedMemoryUtilization Percentage of memory actually used by the container with respect to the memory request specified memoryWorkingSetBytes Integer. Bytes of memory in the working set memoryWorkingSetUtilization Percentage of working set memory actually used by the container with respect to the memory limit specified requestedMemoryWorkingSetUtilization Percentage of working set memory actually used by the container with respect to the memory request specified namespace Name of the namespace that the container belongs to nodeIP Host IP address the container is running on nodeName Host name that the container is running on podName Name of the pod that the container is in, to be used as an identifier reason Provides a reason why the container is in the current status restartCount Number of times the container has been restarted status Current status of the container. Value can be Running, Terminated, or Unknown containerCpuCfsPeriodsDelta Delta change of elapsed enforcement period intervals containerCpuCfsThrottledPeriodsDelta Delta change of throttled period intervals containerCpuCfsThrottledSecondsDelta Delta change of duration the container has been throttled, in seconds containerCpuCfsPeriodsTotal Total number of elapsed enforcement period intervals containerCpuCfsThrottledPeriodsTotal Total number of throttled period intervals containerCpuCfsThrottledSecondsTotal Total time duration the container has been throttled, in seconds containerMemoryMappedFileBytes Total size of memory mapped files used by this container, in bytes Volume data Query the K8sVolumeSample event for volume data: Volume attribute Description volumeName Name that you assigned to the volume at creation clusterName Cluster where the volume is configured namespace Namespace where the volume is configured podName The pod that the volume is attached to. The Kubernetes monitoring integration lists Volumes that are attached to a pod persistent If this is a persistent volume, this value is set to true pvcNamespace Namespace where the Persistent Volume Claim is configured pvcName Name that you assigned to the Persistent Volume Claim at creation fsCapacityBytes Capacity of the volume, in bytes fsUsedBytes Usage of the volume, in bytes fsAvailableBytes Capacity available of the volume, in bytes fsUsedPercent Usage of the volume in percentage fsInodes Total inodes of the volume fsInodesUsed inodes used in the volume fsInodesFree inodes available in the volume Volume data is available for volume plugins that implement the MetricsProvider interface: AWSElasticBlockStore AzureDisk AzureFile Cinder Flexvolume Flocker GCEPersistentDisk GlusterFS iSCSI StorageOS VsphereVolume API server data Query the K8sApiServerSample event to see API Server data. For more information, see Configure control plane monitoring: API server attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent, in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist apiserverRequestDelta_verb_VERB_code_CODE Difference of the number of apiserver requests, broken out for each verb and HTTP response code apiserverRequestRate_verb_VERB_code_CODE Rate of apiserver requests, broken out for each verb and HTTP response code restClientRequestsDelta_code_CODE_method_METHOD Difference of the number of HTTP requests, partitioned by method and code restClientRequestsRate_code_CODE_method_METHOD Rate of the number of HTTP requests, partitioned by method and code etcdObjectCounts_resource_RESOURCE-KIND Number of stored objects at the time of last check, split by kind Controller manager data Query the K8sControllerManagerSample event to see Controller manager data. For more information, see Configure control plane monitoring: Controller manager attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist workqueueAddsDelta_name_WORK-QUEUE-NAME Difference of the total number of adds handled by workqueue workqueueDepth_name_WORK-QUEUE-NAME Current depth of workqueue workqueueRetriesDelta_name_WORK-QUEUE-NAME Difference of the total number of retries handled by workqueue leaderElectionMasterStatus Gauge of if the reporting system is master of the relevant lease, 0 indicates backup, 1 indicates master Scheduler data Query the K8sSchedulerSample event in New Relic Insights to see Scheduler data. For more information, see Configure control plane monitoring: Scheduler attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist leaderElectionMasterStatus Gauge of if the reporting system is master of the relevant lease, 0 indicates backup, 1 indicates master httpRequestDurationMicroseconds_handler_HANDLER_quantile_QUANTILE The HTTP request latencies in microseconds, per quantile httpRequestDurationMicroseconds_handler_HANDLER_sum The sum of the HTTP request latencies, in microseconds httpRequestDurationMicroseconds_handler_HANDLER_count The number of observed HTTP requests events restClientRequestsDelta_code_CODE_host_HOST_method_METHOD Difference of the number of HTTP requests, partitioned by status code, method, and host restClientRequestsRate_code_CODE_host_HOST_method_METHOD Rate of the number of HTTP requests, partitioned by status code, method, and host schedulerScheduleAttemptsDelta_result_RESULT Difference of the number of attempts to schedule pods, by the result. unschedulable means a pod could not be scheduled, while error means an internal scheduler problem schedulerScheduleAttemptsRate_result_RESULT Rate of the number of attempts to schedule pods, by the result. unschedulable means a pod could not be scheduled, while error means an internal scheduler problem schedulerSchedulingDurationSeconds_operation_OPERATION_quantile_QUANTILE Scheduling latency in seconds split by sub-parts of the scheduling operation schedulerSchedulingDurationSeconds_operation_OPERATION_sum The sum of scheduling latency in seconds split by sub-parts of the scheduling operation schedulerSchedulingDurationSeconds_operation_OPERATION_count The number of observed events of schedulings split by sub-parts of the scheduling operation. schedulerPreemptionAttemptsDelta Difference of the total preemption attempts in the cluster till now schedulerPodPreemptionVictims Number of selected preemption victims ETCD data Query the K8sEtcdSample event to see ETCD data. For more information, see Configure control plane monitoring: ETCD attribute Description processResidentMemoryBytes Resident memory size, in bytes processCpuSecondsDelta Difference of the user and system CPU time spent in seconds goThreads Number of OS threads created goGoroutines Number of goroutines that currently exist etcdServerHasLeader Whether or not a leader exists. 1 is existence, 0 is not etcdServerLeaderChangesSeenDelta Difference of the number of leader changes seen etcdMvccDbTotalSizeInBytes Total size of the underlying database physically allocated, in bytes etcdServerProposalsCommittedDelta Difference of the total number of consensus proposals committed etcdServerProposalsCommittedRate Rate of the total number of consensus proposals committed etcdServerProposalsAppliedDelta Difference of the total number of consensus proposals applied etcdServerProposalsAppliedRate Rate of the total number of consensus proposals applied etcdServerProposalsPending The current number of pending proposals to commit etcdServerProposalsFailedDelta Difference of the total number of failed proposals seen etcdServerProposalsFailedRate Rate of the total number of failed proposals seen processOpenFds Number of open file descriptors processMaxFds Maximum number of open file descriptors processFdsUtilization Percentage open file descriptors with respect to the maximum number that can be opened etcdNetworkClientGrpcReceivedBytesRate Rate of the total number of bytes received from gRPC clients etcdNetworkClientGrpcSentBytesRate Rate of the total number of bytes sent to gRPC clients Endpoint data Query the K8sEndpointSample event in New Relic Insights for endpoint data: Endpoint attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the endpoint was created namespaceName Name of the namespace that the endpoint belongs to endpointName Name associated with the endpoint label.LABEL_NAME Labels associated with your endpoint, so you can filter and query for specific endpoints addressAvailable Number of addresses available in endpoint addressNotReady Number of addresses not ready in endpoint Service data Query the K8sServiceSample event for service data: Service attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration createdAt Timestamp of when the service was created namespaceName Name of the namespace that the service belongs to label.LABEL_NAME Labels associated with your service, so you can filter and query for specific service serviceName Name associated with the service loadBalancerIP The IP of the external load balancer, if Spectype is LoadBalancer. externalName The external name value, if Spectype is ExternalName clusterIP The internal cluster IP, if Spectype is ClusterIP specType Type of the service selector.LABEL_NAME The label selector that this service targets Horizontal Pod Autoscaler data Query the K8sHpaSample event in New Relic Insights for Horizontal Pod Autoscaler data: HPA attribute Description clusterName Name that you assigned to the cluster when you installed the Kubernetes integration label.LABEL_NAME Labels associated with your HPA, so you can filter and query for specific autoscaler currentReplicas Current number of replicas of pods managed by this autoscaler desiredReplicas Desired number of replicas of pods managed by this autoscaler minReplicas Lower limit for the number of pods that can be set by the autoscaler, 1 by default maxReplicas Upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than minReplicas targetMetric The metric specifications used by this autoscaler when calculating the desired replica count isAble Boolean representing whether or not the autoscaler is able to fetch and update scales, as well as whether or not any backoff-related conditions would prevent scaling isActive Boolean representing whether or not the autoscaler is enabled (if it's able to calculate the desired scales) isLimited Boolean representing whether or not the autoscaler is capped, either up or down, by the maximum or minimum replicas configured labels Number of Kubernetes labels converted to Prometheus labels metadataGeneration The generation observed by the HorizontalPodAutoscaler controller Kubernetes metadata in APM-monitored applications By linking your applications with Kubernetes, the following attributes are added to application trace and distributed trace: nodeName containerName podName clusterName deploymentName namespaceName For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.02724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>and</em> <em>use</em> your <em>Kubernetes</em> <em>data</em>",
        "sections": "Find <em>and</em> <em>use</em> your <em>Kubernetes</em> <em>data</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " Relic <em>integration</em> you <em>use</em>, including the <em>Kubernetes</em> <em>integration</em>: Select the alert type <em>Integrations</em>. From the Select a <em>data</em> source dropdown, select a <em>Kubernetes</em> (K8s) <em>data</em> source. Select alert notifications When an alert condition&#x27;s threshold is triggered, New Relic sends a message to the notification"
      },
      "id": "603eb9a4196a678bfca83dbb"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "81c1ba10f4c79655db595bd6423a7b03720af947",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-10-24T16:15:04Z",
      "updated_at": "2021-10-24T02:56:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Our automated installer will generate either a helm command or a set of plain manifests for you to install. Our automated installer: Allows users to select the cluster name and namespace for the installation. Allows users to selectively enable or disable bundling of Kube-state-metrics, a dependency of the Kubernetes integration. Allows users to seamlessly install our other products related to Kubernetes such as: Kubernetes events monitoring In-cluster prometheus services monitoring Service instrumentation without code changes using Pixie Automatically fills the required properties with the license keys the integration needs to work. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.63611,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "sections": "Introduction to the <em>Kubernetes</em> <em>integration</em>",
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": " <em>Kubernetes</em> abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your <em>Kubernetes</em> <em>data</em>, which our <em>integration</em> collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments"
      },
      "id": "6174cb5c28ccbcde75c6c73f"
    },
    {
      "sections": [
        "New Relic Metrics Adapter",
        "BETA FEATURE",
        "Requirements",
        "Installation",
        "Tip",
        "Configuration",
        "How it works",
        "Caution",
        "Troubleshooting",
        "Get verbose logs",
        "Get raw metrics",
        "Metrics not working"
      ],
      "title": "New Relic Metrics Adapter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "e2a825763b10ccf4bd1bd8423e2209f66dfb61bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/newrelic-hpa-metrics-adapter/newrelic-metrics-adapter/",
      "published_at": "2021-10-24T16:35:54Z",
      "updated_at": "2021-10-24T09:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can use metrics from your New Relic account to autoscale applications and services in your Kubernetes cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic and makes them available for the Horizontal Pod Autoscalers. The newrelic-k8s-metrics-adapter implements the external.metrics.k8s.io API to support the use of external metrics based New Relic NRQL queries results. Once deployed, the value for each configured metric is fetched using the NerdGraph API based on the configured NRQL query. The metrics adapter exposes the metrics over a secured endpoint with TLS. New Relic metrics adapter in a cluster. Requirements Kubernetes 1.16 or higher. The New Relic Kubernetes integration. New Relic's user API key. No other External Metrics Adapter installed in the cluster. Installation To install the New Relic Metrics Adapter, we provide the newrelic-k8s-metrics-adapter Helm chart, which is also included in the nri-bundle chart used to deploy all New Relic Kubernetes components. Install the New Relic Metrics Adapter by running the following command: helm upgrade --install newrelic newrelic/nri-bundle \\ --namespace newrelic --create-namespace \\ --set global.licenseKey=YOUR_NEW_RELIC_LICENSE_KEY \\ --set global.cluster=K8S_CLUSTER_NAME \\ --set infrastructure.enabled=true \\ --set prometheus.enabled=true \\ --set webhook.enabled=true \\ --set ksm.enabled=true \\ --set kubeEvents.enabled=true \\ --set metrics-adapter.enabled=true \\ --set newrelic-k8s-metrics-adapter.personalAPIKey=YOUR_NEW_RELIC_PERSONAL_API_KEY \\ --set newrelic-k8s-metrics-adapter.config.accountID=YOUR_NEW_RELIC_ACCOUNT_ID \\ --set newrelic-k8s-metrics-adapter.config.externalMetrics.external_metric_name.query=NRQL query Copy Please notice and adjust the following flags: metrics-adapter.enabled: Must be set to true so the metrics adapter chart is installed. newrelic-k8s-metrics-adapter.personalAPIKey: Must be set to valid New Relic Personal API key. newrelic-k8s-metrics-adapter.accountID: Must be set to valid New Relic account where metrics are going to be fetched from. newrelic-k8s-metrics-adapter.config.externalMetrics.<var>external_metric_name</var>.<var>query</var>: Adds a new external metric where: <var>external_metric_name</var>: The metric name. <var>query</var>: The base NRQL query that is used to get the value for the metric. Tip Alternatively, you can use a values.yaml file that can be passed to the helm command with the --values flag. Values files can contain all parameters needed to configure the metrics explained in the configuration section. Configuration You can configure multiple metrics in the metrics adapter and change some parameters to modify the behaviour of the metrics cache and filtering. To see the full list and descriptions of all parameters that can be modified, refer to the chart README.md and values.yaml files. How it works The following values enable the metrics adapter on the nri-bundle chart installation: metrics-adapter: enabled: true newrelic-k8s-metrics-adapter: personalAPIKey: <Personal API Key> config: accountID: <Account ID> externalMetrics: nginx_average_requests: query: \"FROM Metric SELECT average(nginx.server.net.requestsPerSecond) SINCE 2 MINUTES AGO\" Copy Caution The default time span for metrics is 1h. Therefore, you should define queries with the SINCE clause to adjust the time span according to your environment and needs. There is an HPA consuming the external metric as follows: kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta2 metadata: name: nginx-scaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx minReplicas: 1 maxReplicas: 10 metrics: - type: External external: metric: name: nginx_average_requests selector: matchLabels: k8s.namespaceName: nginx target: type: Value value: 10000 Copy Based on the HPA definition, the controller manager fetches the metrics from the external metrics API which are served by the New Relic metrics adapter. The New Relic metrics adapter receives the query including the nginx_average_requests metric name and all the selectors, and searches for a matching metric name in the internal memory based on the configured metrics. Then, it adds the selectors to the query to form a final query that is executed using NerdGraph to fetch the value from New Relic. The above example will generate a query like the following: FROM Metric SELECT average(nginx.server.net.requestsPerSecond) WHERE clusterName=<clusterName> AND `k8s.namespaceName`='nginx' SINCE 2 MINUTES AGO Copy Notice that a clusterName filter has been automatically added to the query to exclude metrics from other clusters in the same account. You can remove it by using the removeClusterFilter configuration parameter. Also the value is cached for a period of time defined by the cacheTTLSeconds configuration parameter, whose deafult is 30 seconds. Troubleshooting Get verbose logs Most common errors are displayed in the standard (non-verbose) logs. If you're doing a more in-depth investigation on your own or with New Relic Support, you can enable verbose mode. To get verbose logging details for an integration using Helm: Enable verbose logging: bash Copy $ helm upgrade -n <namespace> --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=true newrelic/nri-bundle Leave on verbose mode for a few minutes, or until enough activity has occurred. When you have the information you need, disable verbose logging: bash Copy $ helm upgrade --reuse-values newrelic-bundle --set newrelic-k8s-metrics-adapter.verboseLog=false newrelic/nri-bundle Caution Verbose mode increases significantly the amount of information sent to log files. Enable this mode temporarily, only for troubleshooting purposes, and reset the log level when finished. Get raw metrics Sometimes it's useful to get the list of available metrics and also to get the current value of an specific metric. To get the list of metrics available, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/\" To get the value for a specific metric with a selector, run: bash Copy $ kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/*/<metric_name>?labelSelector=<selector_key>=<selector_value>\" Tip You must replace <metric_name>, <selector_key> and <selector_value> with your values. Metrics not working There are some usual errors that could cause a metric fail to retrieve the value. These errors are showed in the status of the metrics when you describe the HPA or are printed when you get the raw metrics directly. executing query: NRQL Syntax Error: Error at line...: The query that is being run has syntax errors. The same error message gives you the executed query and position of the error. You can try this query inside the New Relic query builder and correct the configuration from the adapter. extracting return value: expected first value to be of type \"float64\", got %!q(<nil>): The query doesn't return any value. The same error message gives you the executed query so you can try this query inside the New Relic query builder and correct the configuration from the adapter or the match selectors in the HPA.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.9104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Kubernetes</em> <em>integration</em>",
        "body": "BETA FEATURE This feature is still in development, but we encourage you to try it out! You can <em>use</em> metrics from your New Relic account to autoscale applications and services in your <em>Kubernetes</em> cluster by deploying the New Relic Metrics Adapter. This adapter fetches the metric values from New Relic"
      },
      "id": "6175209d28ccbcf310c6bb2f"
    }
  ],
  "/docs/licenses/index": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.3318,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Licenses</em>"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.17078,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Important",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-24T17:40:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Important NOTE: If you are a New Relic HIPAA customer, please be advised that you must follow the requirements specified in the Global Technical Support Section of HIPAA enablement - what you need to know and do when requesting support and engaging with the New Relic Global Technical Support team for assistance. Support plan for New Relic One pricing and packaging model The New Relic One Support Plan below applies only to a customer’s paid subscription on the New Relic One pricing plan. Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance for: the New Relic One platform and its features and capabilities, New Relic's monitoring and observability solutions, and our alerting and Applied Intelligence features. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Important As of March 10, 2021, you're no longer able to create a New Relic support ticket by emailing support@newrelic.com. If you have ticketed support as part of your subscription, when logged into your New Relic account, go to one.newrelic.com to create a support ticket. Once you're there, follow these steps: Click the ? icon in the upper right hand corner. Click I need more help. Select Create a Support Ticket. By creating a support ticket directly within your account, it will speed up the support process and improve our team’s ability to troubleshoot your issue more effectively. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.07624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Licenses</em>"
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.8944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89417,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89417,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions": [
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Important",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-24T17:40:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Important NOTE: If you are a New Relic HIPAA customer, please be advised that you must follow the requirements specified in the Global Technical Support Section of HIPAA enablement - what you need to know and do when requesting support and engaging with the New Relic Global Technical Support team for assistance. Support plan for New Relic One pricing and packaging model The New Relic One Support Plan below applies only to a customer’s paid subscription on the New Relic One pricing plan. Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance for: the New Relic One platform and its features and capabilities, New Relic's monitoring and observability solutions, and our alerting and Applied Intelligence features. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Important As of March 10, 2021, you're no longer able to create a New Relic support ticket by emailing support@newrelic.com. If you have ticketed support as part of your subscription, when logged into your New Relic account, go to one.newrelic.com to create a support ticket. Once you're there, follow these steps: Click the ? icon in the upper right hand corner. Click I need more help. Select Create a Support Ticket. By creating a support ticket directly within your account, it will speed up the support process and improve our team’s ability to troubleshoot your issue more effectively. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.53842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan <em>information</em>, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement"
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Important",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-24T17:40:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Important NOTE: If you are a New Relic HIPAA customer, please be advised that you must follow the requirements specified in the Global Technical Support Section of HIPAA enablement - what you need to know and do when requesting support and engaging with the New Relic Global Technical Support team for assistance. Support plan for New Relic One pricing and packaging model The New Relic One Support Plan below applies only to a customer’s paid subscription on the New Relic One pricing plan. Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance for: the New Relic One platform and its features and capabilities, New Relic's monitoring and observability solutions, and our alerting and Applied Intelligence features. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Important As of March 10, 2021, you're no longer able to create a New Relic support ticket by emailing support@newrelic.com. If you have ticketed support as part of your subscription, when logged into your New Relic account, go to one.newrelic.com to create a support ticket. Once you're there, follow these steps: Click the ? icon in the upper right hand corner. Click I need more help. Select Create a Support Ticket. By creating a support ticket directly within your account, it will speed up the support process and improve our team’s ability to troubleshoot your issue more effectively. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.41522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "View limits and manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-19T04:02:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its child accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data For information about system and account limits, and for links to data ingest API limits, go to View limits. To manage your data ingest, storage, and limits for organization or billing purposes, go to Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.2901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other customers&#x27; accounts, we have various data volume and rate limits in place. We reserve the right to enforce"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    },
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings": [
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relic’s Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-10-24T17:39:16Z",
      "updated_at": "2021-10-24T17:39:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (“AUP”). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the “New Relic Properties”) and is part of the technical guides documentation that New Relic makes available at dedicated 'Documentation' pages on New Relic websites, including, but not limited to, https://docs.newrelic.com, https://docs.pixielabs.ai/, and https://docs.codestream.com/userguide/ (the “Documentation”). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relic’s Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relic’s or a third party’s intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using “botnets”, “robots,” “spiders” and “offline readers”); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other “hidden text”; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including “scraping” or using any data mining methods); Sharing your New Relic Properties account or login credentials, including API keys, with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other user’s account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Using the New Relic Properties in violation of your company's policy(ies) and procedures, or attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by “spoofing” or “phishing”); Collecting or harvesting any personally identifiable information, including account names, from any other user’s account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other people’s private and confidential information without their express permission; Using anyone’s name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Querying or otherwise configuring, processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (“HIPAA”); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any “personal information” as such term is defined under the Children’s Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, driver’s license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; (vii) precise geo-location data; or (viii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R. §§ 120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. “Third-Party Services” means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if you’re a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers’ compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term “content” means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, “you” may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and “we” means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.3924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " identification numbers, including Social Security numbers, driver’s <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "View limits and manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-19T04:02:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its child accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data For information about system and account limits, and for links to data ingest API limits, go to View limits. To manage your data ingest, storage, and limits for organization or billing purposes, go to Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.2901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other customers&#x27; accounts, we have various data volume and rate limits in place. We reserve the right to enforce"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    },
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/government-addendum": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Important",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-24T17:40:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Important NOTE: If you are a New Relic HIPAA customer, please be advised that you must follow the requirements specified in the Global Technical Support Section of HIPAA enablement - what you need to know and do when requesting support and engaging with the New Relic Global Technical Support team for assistance. Support plan for New Relic One pricing and packaging model The New Relic One Support Plan below applies only to a customer’s paid subscription on the New Relic One pricing plan. Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance for: the New Relic One platform and its features and capabilities, New Relic's monitoring and observability solutions, and our alerting and Applied Intelligence features. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Important As of March 10, 2021, you're no longer able to create a New Relic support ticket by emailing support@newrelic.com. If you have ticketed support as part of your subscription, when logged into your New Relic account, go to one.newrelic.com to create a support ticket. Once you're there, follow these steps: Click the ? icon in the upper right hand corner. Click I need more help. Select Create a Support Ticket. By creating a support ticket directly within your account, it will speed up the support process and improve our team’s ability to troubleshoot your issue more effectively. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.4148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relic’s Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-10-24T17:39:16Z",
      "updated_at": "2021-10-24T17:39:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (“AUP”). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the “New Relic Properties”) and is part of the technical guides documentation that New Relic makes available at dedicated 'Documentation' pages on New Relic websites, including, but not limited to, https://docs.newrelic.com, https://docs.pixielabs.ai/, and https://docs.codestream.com/userguide/ (the “Documentation”). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relic’s Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relic’s or a third party’s intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using “botnets”, “robots,” “spiders” and “offline readers”); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other “hidden text”; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including “scraping” or using any data mining methods); Sharing your New Relic Properties account or login credentials, including API keys, with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other user’s account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Using the New Relic Properties in violation of your company's policy(ies) and procedures, or attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by “spoofing” or “phishing”); Collecting or harvesting any personally identifiable information, including account names, from any other user’s account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other people’s private and confidential information without their express permission; Using anyone’s name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Querying or otherwise configuring, processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (“HIPAA”); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any “personal information” as such term is defined under the Children’s Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, driver’s license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; (vii) precise geo-location data; or (viii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R. §§ 120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. “Third-Party Services” means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if you’re a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers’ compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term “content” means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, “you” may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and “we” means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " identification numbers, including Social Security numbers, driver’s <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "View limits and manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-19T04:02:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its child accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data For information about system and account limits, and for links to data ingest API limits, go to View limits. To manage your data ingest, storage, and limits for organization or billing purposes, go to Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.28995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other customers&#x27; accounts, we have various data volume and rate limits in place. We reserve the right to enforce"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Important",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-24T17:40:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Important NOTE: If you are a New Relic HIPAA customer, please be advised that you must follow the requirements specified in the Global Technical Support Section of HIPAA enablement - what you need to know and do when requesting support and engaging with the New Relic Global Technical Support team for assistance. Support plan for New Relic One pricing and packaging model The New Relic One Support Plan below applies only to a customer’s paid subscription on the New Relic One pricing plan. Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance for: the New Relic One platform and its features and capabilities, New Relic's monitoring and observability solutions, and our alerting and Applied Intelligence features. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Important As of March 10, 2021, you're no longer able to create a New Relic support ticket by emailing support@newrelic.com. If you have ticketed support as part of your subscription, when logged into your New Relic account, go to one.newrelic.com to create a support ticket. Once you're there, follow these steps: Click the ? icon in the upper right hand corner. Click I need more help. Select Create a Support Ticket. By creating a support ticket directly within your account, it will speed up the support process and improve our team’s ability to troubleshoot your issue more effectively. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.4148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relic’s Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-10-24T17:39:16Z",
      "updated_at": "2021-10-24T17:39:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (“AUP”). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the “New Relic Properties”) and is part of the technical guides documentation that New Relic makes available at dedicated 'Documentation' pages on New Relic websites, including, but not limited to, https://docs.newrelic.com, https://docs.pixielabs.ai/, and https://docs.codestream.com/userguide/ (the “Documentation”). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relic’s Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relic’s or a third party’s intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using “botnets”, “robots,” “spiders” and “offline readers”); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other “hidden text”; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including “scraping” or using any data mining methods); Sharing your New Relic Properties account or login credentials, including API keys, with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other user’s account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Using the New Relic Properties in violation of your company's policy(ies) and procedures, or attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by “spoofing” or “phishing”); Collecting or harvesting any personally identifiable information, including account names, from any other user’s account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other people’s private and confidential information without their express permission; Using anyone’s name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Querying or otherwise configuring, processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (“HIPAA”); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any “personal information” as such term is defined under the Children’s Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, driver’s license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; (vii) precise geo-location data; or (viii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R. §§ 120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. “Third-Party Services” means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if you’re a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers’ compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term “content” means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, “you” may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and “we” means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " identification numbers, including Social Security numbers, driver’s <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    },
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/new-relics-provision-services": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Important",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-24T17:40:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Important NOTE: If you are a New Relic HIPAA customer, please be advised that you must follow the requirements specified in the Global Technical Support Section of HIPAA enablement - what you need to know and do when requesting support and engaging with the New Relic Global Technical Support team for assistance. Support plan for New Relic One pricing and packaging model The New Relic One Support Plan below applies only to a customer’s paid subscription on the New Relic One pricing plan. Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance for: the New Relic One platform and its features and capabilities, New Relic's monitoring and observability solutions, and our alerting and Applied Intelligence features. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Important As of March 10, 2021, you're no longer able to create a New Relic support ticket by emailing support@newrelic.com. If you have ticketed support as part of your subscription, when logged into your New Relic account, go to one.newrelic.com to create a support ticket. Once you're there, follow these steps: Click the ? icon in the upper right hand corner. Click I need more help. Select Create a Support Ticket. By creating a support ticket directly within your account, it will speed up the support process and improve our team’s ability to troubleshoot your issue more effectively. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.41437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relic’s Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-10-24T17:39:16Z",
      "updated_at": "2021-10-24T17:39:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (“AUP”). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the “New Relic Properties”) and is part of the technical guides documentation that New Relic makes available at dedicated 'Documentation' pages on New Relic websites, including, but not limited to, https://docs.newrelic.com, https://docs.pixielabs.ai/, and https://docs.codestream.com/userguide/ (the “Documentation”). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relic’s Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relic’s or a third party’s intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using “botnets”, “robots,” “spiders” and “offline readers”); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other “hidden text”; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including “scraping” or using any data mining methods); Sharing your New Relic Properties account or login credentials, including API keys, with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other user’s account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Using the New Relic Properties in violation of your company's policy(ies) and procedures, or attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by “spoofing” or “phishing”); Collecting or harvesting any personally identifiable information, including account names, from any other user’s account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other people’s private and confidential information without their express permission; Using anyone’s name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Querying or otherwise configuring, processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (“HIPAA”); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any “personal information” as such term is defined under the Children’s Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, driver’s license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; (vii) precise geo-location data; or (viii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R. §§ 120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. “Third-Party Services” means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if you’re a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers’ compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term “content” means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, “you” may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and “we” means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.39157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " identification numbers, including Social Security numbers, driver’s <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "View limits and manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-19T04:02:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its child accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data For information about system and account limits, and for links to data ingest API limits, go to View limits. To manage your data ingest, storage, and limits for organization or billing purposes, go to Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.2898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other customers&#x27; accounts, we have various data volume and rate limits in place. We reserve the right to enforce"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/peoples-republic-china": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Important",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-24T17:40:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Important NOTE: If you are a New Relic HIPAA customer, please be advised that you must follow the requirements specified in the Global Technical Support Section of HIPAA enablement - what you need to know and do when requesting support and engaging with the New Relic Global Technical Support team for assistance. Support plan for New Relic One pricing and packaging model The New Relic One Support Plan below applies only to a customer’s paid subscription on the New Relic One pricing plan. Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance for: the New Relic One platform and its features and capabilities, New Relic's monitoring and observability solutions, and our alerting and Applied Intelligence features. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Important As of March 10, 2021, you're no longer able to create a New Relic support ticket by emailing support@newrelic.com. If you have ticketed support as part of your subscription, when logged into your New Relic account, go to one.newrelic.com to create a support ticket. Once you're there, follow these steps: Click the ? icon in the upper right hand corner. Click I need more help. Select Create a Support Ticket. By creating a support ticket directly within your account, it will speed up the support process and improve our team’s ability to troubleshoot your issue more effectively. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.41437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relic’s Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-10-24T17:39:16Z",
      "updated_at": "2021-10-24T17:39:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (“AUP”). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the “New Relic Properties”) and is part of the technical guides documentation that New Relic makes available at dedicated 'Documentation' pages on New Relic websites, including, but not limited to, https://docs.newrelic.com, https://docs.pixielabs.ai/, and https://docs.codestream.com/userguide/ (the “Documentation”). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relic’s Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relic’s or a third party’s intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using “botnets”, “robots,” “spiders” and “offline readers”); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other “hidden text”; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including “scraping” or using any data mining methods); Sharing your New Relic Properties account or login credentials, including API keys, with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other user’s account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Using the New Relic Properties in violation of your company's policy(ies) and procedures, or attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by “spoofing” or “phishing”); Collecting or harvesting any personally identifiable information, including account names, from any other user’s account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other people’s private and confidential information without their express permission; Using anyone’s name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Querying or otherwise configuring, processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (“HIPAA”); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any “personal information” as such term is defined under the Children’s Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, driver’s license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; (vii) precise geo-location data; or (viii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R. §§ 120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. “Third-Party Services” means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if you’re a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers’ compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term “content” means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, “you” may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and “we” means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 460.39157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " identification numbers, including Social Security numbers, driver’s <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "View limits and manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-19T04:02:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its child accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data For information about system and account limits, and for links to data ingest API limits, go to View limits. To manage your data ingest, storage, and limits for organization or billing purposes, go to Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.2898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other customers&#x27; accounts, we have various data volume and rate limits in place. We reserve the right to enforce"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    }
  ],
  "/docs/licenses/license-information/other-licenses/services-licenses": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.8932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/product-definitions/legacy-product-definitions": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.8932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related <em>products</em>?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make &quot;New Relic One - Standard Users&quot; available in line with industry standards. If you subscribe to any other New Relic Products on a <em>product</em>-based"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " forth in the New Relic One pricing <em>definitions</em> page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly <em>Product</em> Usage will be invoiced"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related <em>products</em>?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make &quot;New Relic One - Standard Users&quot; available in line with industry standards. If you subscribe to any other New Relic Products on a <em>product</em>-based"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.2222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " forth in the New Relic One pricing <em>definitions</em> page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly <em>Product</em> Usage will be invoiced"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy": [
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 480.57016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.30347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Security policy",
        "New Relic Security Policy",
        "1. Purpose",
        "2. Security Overview",
        "3.Security Certifications",
        "4. Data Control and Encryption",
        "5. Facilities",
        "6. Employee Access, Screening and Controls.",
        "7. Security Incident and Data Breach Response",
        "8. Network and Systems Security",
        "9. Authentication and Access Management",
        "10. Vulnerability Management",
        "11. System Access and Logging",
        "12. Disaster Recovery and Data Backup",
        "13. Copies and Removal",
        "14. Third Party Vendor Management",
        "15. Disclosure by Law",
        "16. Updates"
      ],
      "title": "Security policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "291509f6b521ca34ac9d49039518e7da8b883518",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/",
      "published_at": "2021-10-24T16:05:02Z",
      "updated_at": "2021-09-27T15:05:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Updated 23 September 2021. The below Security Policy applies only to customers with an existing New Relic agreement in place that explicitly references this Security Policy applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic Security Policy 1. Purpose This Policy describes New Relic's security program and the technical and organizational security controls to protect New Relic’s systems as shown in New Relic’s third-party audits and certifications. New Relic may update this Policy from time to time, and such updates will not materially reduce the overall protections set forth in this Policy. The then-current terms of this Policy are available at https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/. 2. Security Overview 2.1. New Relic maintains a comprehensive Information Protection Program to manage information security within New Relic that includes administrative, technical, and physical safeguards designed to protect the confidentiality, integrity, and availability of Customer Data and that is appropriate to the nature, size, and complexity of New Relic's business operations. New Relic’s Information Protection Program includes: 2.1.1. executive review, support and accountability for all security related policies and practices; 2.1.2. formal written policies and procedures that are designed to protect against the loss, theft, or other unauthorized access or alteration of Customer Data, meet or exceed applicable industry standards, outlines a definition of information security and its overall objectives, include defined information security roles and responsibilities, a framework for setting control objectives and controls, a formal and effective risk mitigation program and a service provider security management program; 2.1.3. periodic risk assessments, including internal audits and/or independent 3rd party audits, to measure the effectiveness and appropriateness of controls for all systems processing Customer Data; 2.1.4. in-depth review of security incidents, including effective determination of root cause and corrective action; formal, industry-recognized controls frameworks based on an external audit standard; 2.1.5. employee screening and access management; and 2.1.6. comprehensive security testing, vulnerability identification, and mitigation methodology that consists of a variety of independent approaches that, when combined, are designed to maximize coverage for a diverse set of attack vectors. 2.2. New Relic's Chief Information Security Officer (CISO) leads New Relic's Information Security Program and develops, reviews, and approves, with appropriate stakeholders, New Relic's security policies and procedures. New Relic has appointed data protection officer(s) as described in New Relic’s Privacy Notices who are consulted as necessary under applicable laws. 2.3. Information security objectives, approach, scope, importance, goals, and principles for the organization’s security program are formally identified, communicated throughout the organization to users in a form that is relevant, accessible, and understandable to the intended reader; and supported by a controls framework that considers legislative, regulatory, contractual requirements, and other policy-related requirements. 2.4. New Relic will maintain written policies and procedures to review, test, and approve (as appropriate) changes affecting New Relic infrastructure and systems that process Customer Data including, but not limited to, peer reviews prior to introducing new code into production. New Relic will establish acceptance criteria for new information systems, upgrades, and new versions and will carry out suitable tests of the system(s) during development and prior to acceptance. Any changes or updates will not materially decrease the security of the systems. 3.Security Certifications 3.1. New Relic regularly tests, assesses, and evaluates its security measures for protecting Customer Data using industry-recognized standards and uses independent third-party auditors to verify such controls. 3.2. New Relic agrees to provide Customer, upon request, with applicable certifications or reports about New Relic systems. All information exchanged in connection with the audit activities described in this section is deemed to be the Confidential Information of New Relic. 3.3. Additional information about New Relic’s security certifications are available on New Relic’s Security Guide. 4. Data Control and Encryption 4.1. The Service and related features are designed to provide Customer with control over Customer’s data sources and Customer’s environments that are monitored and sending data to New Relic. 4.2. New Relic will have established methods to: (i) enable Customer to use encryption on Customer Data in transit, and (ii) securely hash passwords in storage following industry standard practices (e.g. scrypt) as described in the Documentation. Server certificate-based authentication is used as part of the TLS encryption with a trusted certificate authority. 4.3. New Relic receives and processes data in accordance with the Agreement and the Services as described in the Documentation. New Relic permits customers to delete personal data in accordance with applicable privacy laws as further described in the Documentation. In the event of error in personal data sent in Customer Data Customers may request personal data deletion and re-send data that is accurate. 4.4. Additional information for Customer data control and encryption, including encryption of data at rest, is available on New Relic’s Security Guide. 5. Facilities 5.1. All physical locations that process Customer Data are co-locations and third party data centers. All physical locations have security measures in place that are designed to prevent unauthorized physical access to data processing facilities and unlawful access, modification, or destruction of Customer Data. 5.2. New Relic will seek assurances (e.g., in the form of an independent 3rd party audit report such as the SOC 2 Type 2, ISO 27001, and vendor security evaluations) from its data processing facilities vendors that store or process Customer Data: 5.2.1. secure its data process facilities in an access-controlled location and have protections in place to prevent unauthorized access, damage, and interference; 5.2.2 employ physical security appropriate to the classification of the assets and information being managed which may include card key access, security cameras, and solid wall construction for all exterior walls; 5.2.3 limit and screen all entrants, which may include measures such as on-site security guard, badge reader, electronic lock, or a monitored closed caption television (CCTV); and 5.2.4 maintain relevant access logs. 5.3. Additional information about New Relic’s third party data centers are available on New Relic’s Security Guide. 6. Employee Access, Screening and Controls. New Relic will have and maintain policies and practices that include, at a minimum, the following controls and safeguards applied to New Relic employees and contractors who may access Customer Data: 6.1. For U.S. New Relic employees and subject to applicable law, a criminal background screening of each of its new employees to whom it gives access to Customer Data at the federal, state, and county levels. For non-U.S. New Relic employees, New Relic will use commercially reasonable efforts to meet the same criteria as established for U.S.-based New Relic employees, subject to general business practices in the respective country and in compliance with applicable local law requirements; 6.2. All New Relic employees with access to Customer Data will undergo adequate training, such as annual security awareness training, in the care, protection and handling of Customer Data, and will align with the privacy and security measures set out in this Addendum by following the guidance provided in their welcome package, which includes New Relic’s security policies and a security acknowledgement; 6.3. A disciplinary policy and process, to be used when New Relic employees violate New Relic security or privacy policies or access Customer Data without prior authorization; 6.4. Administrative or remote access to New Relic systems that process Customer Data will align with industry standard practices, including multi-factor authentication; 6.5. Restricted access to New Relic proprietary source code to prevent unauthorized access; 6.6. Controls designed to ensure that only those New Relic employees with an actual need-to-know will have access to New Relic systems including, but not limited to, the use of a formal access management process for the request, review, approval, and provisioning; 6.7. Controls designed to ensure that New Relic employees are granted access to New Relic systems based on least-privilege principles; and 6.8. Revoke access to New Relic employees no longer requiring access. 7. Security Incident and Data Breach Response 7.1. New Relic will take appropriate physical, technical, and administrative security measures that are commercially reasonable and consistent with industry standards to prevent a Data Breach, and as required by any applicable law or regulation. “Data Breach” means the theft, loss, or unauthorized access of Customer Data. Without limiting the foregoing, New Relic will implement security measures at least as stringent as those set out in this Addendum. New Relic will designate a senior representative to provide incident briefings, as needed in case of a Data Breach, and to respond to reasonable requests by Customer pertaining to privacy and data security issues within a commercially reasonable time frame. 7.2. New Relic will: 7.2.1. Notify Customer without undue delay if New Relic becomes aware of a Data Breach; 7.2.2. Maintain a security incident response plan, including procedures and means to respond in a manner consistent with industry standards; 7.2.3. Reasonably cooperate with Customer to investigate and remediate a Data Breach and mitigate any further risk to the Customer Data, or risk to data subjects and/or Customer’s reputation or brand; 7.2.4. Provide reasonable assistance to Customer at New Relic’s sole cost and expense; and 7.2.5. Make commercially reasonable efforts to preserve evidence and reasonably cooperate with Customer and legal authorities (as applicable and legally permissible) during an investigation of a Data Breach. 8. Network and Systems Security 8.1. All extranet connectivity by New Relic personnel to systems processing Customer Data will be through secure remote connections. 8.2. Network segments connected to the Internet will be protected by secure access control mechanisms, such as a firewall configured to secure all devices behind it and properly addresses security concerns according to industry standard practices. 8.3. New Relic will have industry standard measures in place to actively monitor its systems and help detect a potential hostile attack, such as Network Intrusion Detection (NID) or Host Intrusion Detection (HID)/Prevention. 8.4. Applications, ports, services, and similar access points installed on a computer or network facility, which are not specifically required for business functionality, will be disabled or removed. 8.5. New Relic maintains configuration standards for authorized operating systems and software for systems that support processing of Customer Data. New Relic will establish and follow server configuration guidelines and processes for preventing unauthorized access to Customer Data. New Relic maintains secure images or templates for systems based on the organization’s approved configuration standards. 8.6. Development, test, and operational environments will be logically separated to reduce the risks of unauthorized access or changes to the operational system. 8.7. New Relic network architecture will be designed to limit site access and restrict the availability of information systems that are considered to be vulnerable to attack. 8.8. New Relic provides appropriate TLS certificates when users access and view Customer Data in the Service. New Relic’s software for sending Customer Data to New Relic will encrypt Customer Data in transit by default. 9. Authentication and Access Management If you subscribe to the requisite New Relic One Service, New Relic will provide industry standard authentication and access controls to protect Customer Data, including industry standard authentication methods utilized to help prevent unauthorized access to the Service. New Relic’s access control methods will clearly state the rules and rights for each user or group of users including applications and information sharing and will include a process for granting and removing access to all information systems processing Customer Data. A record of all privileges allocated will be maintained pursuant to the requirements herein. 9.1. In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic shall (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed. 10. Vulnerability Management New Relic will have and maintain the following vulnerability management processes for all devices used to connect to the New Relic network and Services. 10.1. New Relic will align to industry standard practices for build out, minimization of services and secure configuration, in accordance with, industry-recognized minimum security baselines for the New Relic platform and subcontractor systems connected to the New Relic platform in relation to the provision of the Services. 10.2. New Relic will employ industry-recognized standards and tools to conduct frequent infrastructure vulnerability scanning to test New Relic’s network and infrastructure and application penetration testing to test the New Relic Services. New Relic applies “Medium”, “High” and “Critical” security patches for all components in production and development environments as soon as commercially possible in accordance with its vulnerability management protocol, and consistent with industry standard practices and standards; 10.3. New Relic will have processes in place designed to ensure adherence to industry standard security development practices for development and testing for all code, APIs, and applications deployed and implemented in support of the Service; 10.4. New Relic will have and maintain solutions to identify and prevent malicious attackers or code from accessing or compromising Customer Data or systems that process Customer Data. These include, but are not limited to, software that identifies and removes malware and detects attempted intrusions. New Relic will have a security event and incident monitoring system and supporting processes to notify appropriate personnel in response to threats. 11. System Access and Logging 11.1. Access to New Relic’s systems will not be granted to employees of New Relic unless they have been uniquely identified and have sufficient credentials. 11.2. Access to New Relic’s systems will be logged and retained for no less than 6 months to assist in investigations and access control monitoring, including, but not limited to, end user access and activities, and information security events. 11.3. New Relic agrees to provide Customer the capability to access log records relating to Customer Accounts and the New Relic systems that process Customer Data in the event of a Data Breach or if required in connection with a law enforcement request. 12. Disaster Recovery and Data Backup 12.1. New Relic will have plans designed to respond to loss of services, which are tested and reviewed at least annually. This plan will include documented policies and procedures to restore service in the event of a service failure. 12.2. New Relic will establish and follow backup and restore procedures for Customer Data. 12.3. New Relic business continuity plan identifies critical systems. Annual disaster recovery tests are performed to check and restore customer data in the event of an incident. 12.4. New Relic will provide Customer with redacted copies of its plan(s) and evidence of tests/reviews upon request, but not more frequently than once annually, and subject to confidentiality requirements. 12.5. Additional information for Customer Data control and encryption are available on New Relic’s Security Guide. 13. Copies and Removal 13.1. In addition to any obligations of New Relic in the Agreement, upon expiration or termination of the Agreement for any reason: (a) New Relic will, and will cause its personnel, to cease all access and use of any Customer Data, and (b) New Relic will delete all copies of Customer Data within ninety (90) days. 13.2. New Relic will maintain a process of ensuring secure destruction and deletion of all Customer Data, when reasonably requested by Customer or as otherwise provided in the Agreement. The process will include industry standard processes so that: (i) Customer Data cannot be practicably read or reconstructed, and (ii) the systems that store Customer Data are securely erased and/or decommissioned disks are destroyed. 14. Third Party Vendor Management New Relic may use third party vendors to provide the Services. New Relic performs a security risk-based assessment of prospective vendors before working with them to validate they meet New Relic’s security and business continuity standards, including the type of access and classification of data being accessed (if any), controls necessary to protect data, and legal/regulatory requirements. New Relic enters into written agreements with its vendors that process Customer Data which include confidentiality, privacy, and security obligations that provide an appropriate level of protection for Customer Data that these vendors may process for New Relic to maintain the security posture in this Policy, including following industry security standards. 15. Disclosure by Law In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic will (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed. New Relic publishes its law enforcement requests report on New Relic’s Security Guide. 16. Updates As New Relic releases new products, services, functionality, and features, New Relic may update this Policy to account for such products, services, functionality, and features. For additional information, see our Security Guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.6299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security <em>policy</em>",
        "sections": "Security <em>policy</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " time to time, and such updates will not materially reduce the overall protections set forth in this Policy. The then-current terms of this Policy are available at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;<em>referenced</em>-<em>policies</em>&#x2F;security-policy&#x2F;. 2. Security Overview 2.1. New Relic"
      },
      "id": "603ea3dbe7b9d22b802a0802"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/security-guide": [
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 480.56973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.30322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Security policy",
        "New Relic Security Policy",
        "1. Purpose",
        "2. Security Overview",
        "3.Security Certifications",
        "4. Data Control and Encryption",
        "5. Facilities",
        "6. Employee Access, Screening and Controls.",
        "7. Security Incident and Data Breach Response",
        "8. Network and Systems Security",
        "9. Authentication and Access Management",
        "10. Vulnerability Management",
        "11. System Access and Logging",
        "12. Disaster Recovery and Data Backup",
        "13. Copies and Removal",
        "14. Third Party Vendor Management",
        "15. Disclosure by Law",
        "16. Updates"
      ],
      "title": "Security policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "291509f6b521ca34ac9d49039518e7da8b883518",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/",
      "published_at": "2021-10-24T16:05:02Z",
      "updated_at": "2021-09-27T15:05:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Updated 23 September 2021. The below Security Policy applies only to customers with an existing New Relic agreement in place that explicitly references this Security Policy applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic Security Policy 1. Purpose This Policy describes New Relic's security program and the technical and organizational security controls to protect New Relic’s systems as shown in New Relic’s third-party audits and certifications. New Relic may update this Policy from time to time, and such updates will not materially reduce the overall protections set forth in this Policy. The then-current terms of this Policy are available at https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/. 2. Security Overview 2.1. New Relic maintains a comprehensive Information Protection Program to manage information security within New Relic that includes administrative, technical, and physical safeguards designed to protect the confidentiality, integrity, and availability of Customer Data and that is appropriate to the nature, size, and complexity of New Relic's business operations. New Relic’s Information Protection Program includes: 2.1.1. executive review, support and accountability for all security related policies and practices; 2.1.2. formal written policies and procedures that are designed to protect against the loss, theft, or other unauthorized access or alteration of Customer Data, meet or exceed applicable industry standards, outlines a definition of information security and its overall objectives, include defined information security roles and responsibilities, a framework for setting control objectives and controls, a formal and effective risk mitigation program and a service provider security management program; 2.1.3. periodic risk assessments, including internal audits and/or independent 3rd party audits, to measure the effectiveness and appropriateness of controls for all systems processing Customer Data; 2.1.4. in-depth review of security incidents, including effective determination of root cause and corrective action; formal, industry-recognized controls frameworks based on an external audit standard; 2.1.5. employee screening and access management; and 2.1.6. comprehensive security testing, vulnerability identification, and mitigation methodology that consists of a variety of independent approaches that, when combined, are designed to maximize coverage for a diverse set of attack vectors. 2.2. New Relic's Chief Information Security Officer (CISO) leads New Relic's Information Security Program and develops, reviews, and approves, with appropriate stakeholders, New Relic's security policies and procedures. New Relic has appointed data protection officer(s) as described in New Relic’s Privacy Notices who are consulted as necessary under applicable laws. 2.3. Information security objectives, approach, scope, importance, goals, and principles for the organization’s security program are formally identified, communicated throughout the organization to users in a form that is relevant, accessible, and understandable to the intended reader; and supported by a controls framework that considers legislative, regulatory, contractual requirements, and other policy-related requirements. 2.4. New Relic will maintain written policies and procedures to review, test, and approve (as appropriate) changes affecting New Relic infrastructure and systems that process Customer Data including, but not limited to, peer reviews prior to introducing new code into production. New Relic will establish acceptance criteria for new information systems, upgrades, and new versions and will carry out suitable tests of the system(s) during development and prior to acceptance. Any changes or updates will not materially decrease the security of the systems. 3.Security Certifications 3.1. New Relic regularly tests, assesses, and evaluates its security measures for protecting Customer Data using industry-recognized standards and uses independent third-party auditors to verify such controls. 3.2. New Relic agrees to provide Customer, upon request, with applicable certifications or reports about New Relic systems. All information exchanged in connection with the audit activities described in this section is deemed to be the Confidential Information of New Relic. 3.3. Additional information about New Relic’s security certifications are available on New Relic’s Security Guide. 4. Data Control and Encryption 4.1. The Service and related features are designed to provide Customer with control over Customer’s data sources and Customer’s environments that are monitored and sending data to New Relic. 4.2. New Relic will have established methods to: (i) enable Customer to use encryption on Customer Data in transit, and (ii) securely hash passwords in storage following industry standard practices (e.g. scrypt) as described in the Documentation. Server certificate-based authentication is used as part of the TLS encryption with a trusted certificate authority. 4.3. New Relic receives and processes data in accordance with the Agreement and the Services as described in the Documentation. New Relic permits customers to delete personal data in accordance with applicable privacy laws as further described in the Documentation. In the event of error in personal data sent in Customer Data Customers may request personal data deletion and re-send data that is accurate. 4.4. Additional information for Customer data control and encryption, including encryption of data at rest, is available on New Relic’s Security Guide. 5. Facilities 5.1. All physical locations that process Customer Data are co-locations and third party data centers. All physical locations have security measures in place that are designed to prevent unauthorized physical access to data processing facilities and unlawful access, modification, or destruction of Customer Data. 5.2. New Relic will seek assurances (e.g., in the form of an independent 3rd party audit report such as the SOC 2 Type 2, ISO 27001, and vendor security evaluations) from its data processing facilities vendors that store or process Customer Data: 5.2.1. secure its data process facilities in an access-controlled location and have protections in place to prevent unauthorized access, damage, and interference; 5.2.2 employ physical security appropriate to the classification of the assets and information being managed which may include card key access, security cameras, and solid wall construction for all exterior walls; 5.2.3 limit and screen all entrants, which may include measures such as on-site security guard, badge reader, electronic lock, or a monitored closed caption television (CCTV); and 5.2.4 maintain relevant access logs. 5.3. Additional information about New Relic’s third party data centers are available on New Relic’s Security Guide. 6. Employee Access, Screening and Controls. New Relic will have and maintain policies and practices that include, at a minimum, the following controls and safeguards applied to New Relic employees and contractors who may access Customer Data: 6.1. For U.S. New Relic employees and subject to applicable law, a criminal background screening of each of its new employees to whom it gives access to Customer Data at the federal, state, and county levels. For non-U.S. New Relic employees, New Relic will use commercially reasonable efforts to meet the same criteria as established for U.S.-based New Relic employees, subject to general business practices in the respective country and in compliance with applicable local law requirements; 6.2. All New Relic employees with access to Customer Data will undergo adequate training, such as annual security awareness training, in the care, protection and handling of Customer Data, and will align with the privacy and security measures set out in this Addendum by following the guidance provided in their welcome package, which includes New Relic’s security policies and a security acknowledgement; 6.3. A disciplinary policy and process, to be used when New Relic employees violate New Relic security or privacy policies or access Customer Data without prior authorization; 6.4. Administrative or remote access to New Relic systems that process Customer Data will align with industry standard practices, including multi-factor authentication; 6.5. Restricted access to New Relic proprietary source code to prevent unauthorized access; 6.6. Controls designed to ensure that only those New Relic employees with an actual need-to-know will have access to New Relic systems including, but not limited to, the use of a formal access management process for the request, review, approval, and provisioning; 6.7. Controls designed to ensure that New Relic employees are granted access to New Relic systems based on least-privilege principles; and 6.8. Revoke access to New Relic employees no longer requiring access. 7. Security Incident and Data Breach Response 7.1. New Relic will take appropriate physical, technical, and administrative security measures that are commercially reasonable and consistent with industry standards to prevent a Data Breach, and as required by any applicable law or regulation. “Data Breach” means the theft, loss, or unauthorized access of Customer Data. Without limiting the foregoing, New Relic will implement security measures at least as stringent as those set out in this Addendum. New Relic will designate a senior representative to provide incident briefings, as needed in case of a Data Breach, and to respond to reasonable requests by Customer pertaining to privacy and data security issues within a commercially reasonable time frame. 7.2. New Relic will: 7.2.1. Notify Customer without undue delay if New Relic becomes aware of a Data Breach; 7.2.2. Maintain a security incident response plan, including procedures and means to respond in a manner consistent with industry standards; 7.2.3. Reasonably cooperate with Customer to investigate and remediate a Data Breach and mitigate any further risk to the Customer Data, or risk to data subjects and/or Customer’s reputation or brand; 7.2.4. Provide reasonable assistance to Customer at New Relic’s sole cost and expense; and 7.2.5. Make commercially reasonable efforts to preserve evidence and reasonably cooperate with Customer and legal authorities (as applicable and legally permissible) during an investigation of a Data Breach. 8. Network and Systems Security 8.1. All extranet connectivity by New Relic personnel to systems processing Customer Data will be through secure remote connections. 8.2. Network segments connected to the Internet will be protected by secure access control mechanisms, such as a firewall configured to secure all devices behind it and properly addresses security concerns according to industry standard practices. 8.3. New Relic will have industry standard measures in place to actively monitor its systems and help detect a potential hostile attack, such as Network Intrusion Detection (NID) or Host Intrusion Detection (HID)/Prevention. 8.4. Applications, ports, services, and similar access points installed on a computer or network facility, which are not specifically required for business functionality, will be disabled or removed. 8.5. New Relic maintains configuration standards for authorized operating systems and software for systems that support processing of Customer Data. New Relic will establish and follow server configuration guidelines and processes for preventing unauthorized access to Customer Data. New Relic maintains secure images or templates for systems based on the organization’s approved configuration standards. 8.6. Development, test, and operational environments will be logically separated to reduce the risks of unauthorized access or changes to the operational system. 8.7. New Relic network architecture will be designed to limit site access and restrict the availability of information systems that are considered to be vulnerable to attack. 8.8. New Relic provides appropriate TLS certificates when users access and view Customer Data in the Service. New Relic’s software for sending Customer Data to New Relic will encrypt Customer Data in transit by default. 9. Authentication and Access Management If you subscribe to the requisite New Relic One Service, New Relic will provide industry standard authentication and access controls to protect Customer Data, including industry standard authentication methods utilized to help prevent unauthorized access to the Service. New Relic’s access control methods will clearly state the rules and rights for each user or group of users including applications and information sharing and will include a process for granting and removing access to all information systems processing Customer Data. A record of all privileges allocated will be maintained pursuant to the requirements herein. 9.1. In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic shall (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed. 10. Vulnerability Management New Relic will have and maintain the following vulnerability management processes for all devices used to connect to the New Relic network and Services. 10.1. New Relic will align to industry standard practices for build out, minimization of services and secure configuration, in accordance with, industry-recognized minimum security baselines for the New Relic platform and subcontractor systems connected to the New Relic platform in relation to the provision of the Services. 10.2. New Relic will employ industry-recognized standards and tools to conduct frequent infrastructure vulnerability scanning to test New Relic’s network and infrastructure and application penetration testing to test the New Relic Services. New Relic applies “Medium”, “High” and “Critical” security patches for all components in production and development environments as soon as commercially possible in accordance with its vulnerability management protocol, and consistent with industry standard practices and standards; 10.3. New Relic will have processes in place designed to ensure adherence to industry standard security development practices for development and testing for all code, APIs, and applications deployed and implemented in support of the Service; 10.4. New Relic will have and maintain solutions to identify and prevent malicious attackers or code from accessing or compromising Customer Data or systems that process Customer Data. These include, but are not limited to, software that identifies and removes malware and detects attempted intrusions. New Relic will have a security event and incident monitoring system and supporting processes to notify appropriate personnel in response to threats. 11. System Access and Logging 11.1. Access to New Relic’s systems will not be granted to employees of New Relic unless they have been uniquely identified and have sufficient credentials. 11.2. Access to New Relic’s systems will be logged and retained for no less than 6 months to assist in investigations and access control monitoring, including, but not limited to, end user access and activities, and information security events. 11.3. New Relic agrees to provide Customer the capability to access log records relating to Customer Accounts and the New Relic systems that process Customer Data in the event of a Data Breach or if required in connection with a law enforcement request. 12. Disaster Recovery and Data Backup 12.1. New Relic will have plans designed to respond to loss of services, which are tested and reviewed at least annually. This plan will include documented policies and procedures to restore service in the event of a service failure. 12.2. New Relic will establish and follow backup and restore procedures for Customer Data. 12.3. New Relic business continuity plan identifies critical systems. Annual disaster recovery tests are performed to check and restore customer data in the event of an incident. 12.4. New Relic will provide Customer with redacted copies of its plan(s) and evidence of tests/reviews upon request, but not more frequently than once annually, and subject to confidentiality requirements. 12.5. Additional information for Customer Data control and encryption are available on New Relic’s Security Guide. 13. Copies and Removal 13.1. In addition to any obligations of New Relic in the Agreement, upon expiration or termination of the Agreement for any reason: (a) New Relic will, and will cause its personnel, to cease all access and use of any Customer Data, and (b) New Relic will delete all copies of Customer Data within ninety (90) days. 13.2. New Relic will maintain a process of ensuring secure destruction and deletion of all Customer Data, when reasonably requested by Customer or as otherwise provided in the Agreement. The process will include industry standard processes so that: (i) Customer Data cannot be practicably read or reconstructed, and (ii) the systems that store Customer Data are securely erased and/or decommissioned disks are destroyed. 14. Third Party Vendor Management New Relic may use third party vendors to provide the Services. New Relic performs a security risk-based assessment of prospective vendors before working with them to validate they meet New Relic’s security and business continuity standards, including the type of access and classification of data being accessed (if any), controls necessary to protect data, and legal/regulatory requirements. New Relic enters into written agreements with its vendors that process Customer Data which include confidentiality, privacy, and security obligations that provide an appropriate level of protection for Customer Data that these vendors may process for New Relic to maintain the security posture in this Policy, including following industry security standards. 15. Disclosure by Law In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic will (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed. New Relic publishes its law enforcement requests report on New Relic’s Security Guide. 16. Updates As New Relic releases new products, services, functionality, and features, New Relic may update this Policy to account for such products, services, functionality, and features. For additional information, see our Security Guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.6299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security <em>policy</em>",
        "sections": "Security <em>policy</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " time to time, and such updates will not materially reduce the overall protections set forth in this Policy. The then-current terms of this Policy are available at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;<em>referenced</em>-<em>policies</em>&#x2F;security-policy&#x2F;. 2. Security Overview 2.1. New Relic"
      },
      "id": "603ea3dbe7b9d22b802a0802"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/security-policy": [
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 480.56973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.30322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.15901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/service-level-availability-commitment": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.30298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Security policy",
        "New Relic Security Policy",
        "1. Purpose",
        "2. Security Overview",
        "3.Security Certifications",
        "4. Data Control and Encryption",
        "5. Facilities",
        "6. Employee Access, Screening and Controls.",
        "7. Security Incident and Data Breach Response",
        "8. Network and Systems Security",
        "9. Authentication and Access Management",
        "10. Vulnerability Management",
        "11. System Access and Logging",
        "12. Disaster Recovery and Data Backup",
        "13. Copies and Removal",
        "14. Third Party Vendor Management",
        "15. Disclosure by Law",
        "16. Updates"
      ],
      "title": "Security policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "291509f6b521ca34ac9d49039518e7da8b883518",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/",
      "published_at": "2021-10-24T16:05:02Z",
      "updated_at": "2021-09-27T15:05:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Updated 23 September 2021. The below Security Policy applies only to customers with an existing New Relic agreement in place that explicitly references this Security Policy applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic Security Policy 1. Purpose This Policy describes New Relic's security program and the technical and organizational security controls to protect New Relic’s systems as shown in New Relic’s third-party audits and certifications. New Relic may update this Policy from time to time, and such updates will not materially reduce the overall protections set forth in this Policy. The then-current terms of this Policy are available at https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/. 2. Security Overview 2.1. New Relic maintains a comprehensive Information Protection Program to manage information security within New Relic that includes administrative, technical, and physical safeguards designed to protect the confidentiality, integrity, and availability of Customer Data and that is appropriate to the nature, size, and complexity of New Relic's business operations. New Relic’s Information Protection Program includes: 2.1.1. executive review, support and accountability for all security related policies and practices; 2.1.2. formal written policies and procedures that are designed to protect against the loss, theft, or other unauthorized access or alteration of Customer Data, meet or exceed applicable industry standards, outlines a definition of information security and its overall objectives, include defined information security roles and responsibilities, a framework for setting control objectives and controls, a formal and effective risk mitigation program and a service provider security management program; 2.1.3. periodic risk assessments, including internal audits and/or independent 3rd party audits, to measure the effectiveness and appropriateness of controls for all systems processing Customer Data; 2.1.4. in-depth review of security incidents, including effective determination of root cause and corrective action; formal, industry-recognized controls frameworks based on an external audit standard; 2.1.5. employee screening and access management; and 2.1.6. comprehensive security testing, vulnerability identification, and mitigation methodology that consists of a variety of independent approaches that, when combined, are designed to maximize coverage for a diverse set of attack vectors. 2.2. New Relic's Chief Information Security Officer (CISO) leads New Relic's Information Security Program and develops, reviews, and approves, with appropriate stakeholders, New Relic's security policies and procedures. New Relic has appointed data protection officer(s) as described in New Relic’s Privacy Notices who are consulted as necessary under applicable laws. 2.3. Information security objectives, approach, scope, importance, goals, and principles for the organization’s security program are formally identified, communicated throughout the organization to users in a form that is relevant, accessible, and understandable to the intended reader; and supported by a controls framework that considers legislative, regulatory, contractual requirements, and other policy-related requirements. 2.4. New Relic will maintain written policies and procedures to review, test, and approve (as appropriate) changes affecting New Relic infrastructure and systems that process Customer Data including, but not limited to, peer reviews prior to introducing new code into production. New Relic will establish acceptance criteria for new information systems, upgrades, and new versions and will carry out suitable tests of the system(s) during development and prior to acceptance. Any changes or updates will not materially decrease the security of the systems. 3.Security Certifications 3.1. New Relic regularly tests, assesses, and evaluates its security measures for protecting Customer Data using industry-recognized standards and uses independent third-party auditors to verify such controls. 3.2. New Relic agrees to provide Customer, upon request, with applicable certifications or reports about New Relic systems. All information exchanged in connection with the audit activities described in this section is deemed to be the Confidential Information of New Relic. 3.3. Additional information about New Relic’s security certifications are available on New Relic’s Security Guide. 4. Data Control and Encryption 4.1. The Service and related features are designed to provide Customer with control over Customer’s data sources and Customer’s environments that are monitored and sending data to New Relic. 4.2. New Relic will have established methods to: (i) enable Customer to use encryption on Customer Data in transit, and (ii) securely hash passwords in storage following industry standard practices (e.g. scrypt) as described in the Documentation. Server certificate-based authentication is used as part of the TLS encryption with a trusted certificate authority. 4.3. New Relic receives and processes data in accordance with the Agreement and the Services as described in the Documentation. New Relic permits customers to delete personal data in accordance with applicable privacy laws as further described in the Documentation. In the event of error in personal data sent in Customer Data Customers may request personal data deletion and re-send data that is accurate. 4.4. Additional information for Customer data control and encryption, including encryption of data at rest, is available on New Relic’s Security Guide. 5. Facilities 5.1. All physical locations that process Customer Data are co-locations and third party data centers. All physical locations have security measures in place that are designed to prevent unauthorized physical access to data processing facilities and unlawful access, modification, or destruction of Customer Data. 5.2. New Relic will seek assurances (e.g., in the form of an independent 3rd party audit report such as the SOC 2 Type 2, ISO 27001, and vendor security evaluations) from its data processing facilities vendors that store or process Customer Data: 5.2.1. secure its data process facilities in an access-controlled location and have protections in place to prevent unauthorized access, damage, and interference; 5.2.2 employ physical security appropriate to the classification of the assets and information being managed which may include card key access, security cameras, and solid wall construction for all exterior walls; 5.2.3 limit and screen all entrants, which may include measures such as on-site security guard, badge reader, electronic lock, or a monitored closed caption television (CCTV); and 5.2.4 maintain relevant access logs. 5.3. Additional information about New Relic’s third party data centers are available on New Relic’s Security Guide. 6. Employee Access, Screening and Controls. New Relic will have and maintain policies and practices that include, at a minimum, the following controls and safeguards applied to New Relic employees and contractors who may access Customer Data: 6.1. For U.S. New Relic employees and subject to applicable law, a criminal background screening of each of its new employees to whom it gives access to Customer Data at the federal, state, and county levels. For non-U.S. New Relic employees, New Relic will use commercially reasonable efforts to meet the same criteria as established for U.S.-based New Relic employees, subject to general business practices in the respective country and in compliance with applicable local law requirements; 6.2. All New Relic employees with access to Customer Data will undergo adequate training, such as annual security awareness training, in the care, protection and handling of Customer Data, and will align with the privacy and security measures set out in this Addendum by following the guidance provided in their welcome package, which includes New Relic’s security policies and a security acknowledgement; 6.3. A disciplinary policy and process, to be used when New Relic employees violate New Relic security or privacy policies or access Customer Data without prior authorization; 6.4. Administrative or remote access to New Relic systems that process Customer Data will align with industry standard practices, including multi-factor authentication; 6.5. Restricted access to New Relic proprietary source code to prevent unauthorized access; 6.6. Controls designed to ensure that only those New Relic employees with an actual need-to-know will have access to New Relic systems including, but not limited to, the use of a formal access management process for the request, review, approval, and provisioning; 6.7. Controls designed to ensure that New Relic employees are granted access to New Relic systems based on least-privilege principles; and 6.8. Revoke access to New Relic employees no longer requiring access. 7. Security Incident and Data Breach Response 7.1. New Relic will take appropriate physical, technical, and administrative security measures that are commercially reasonable and consistent with industry standards to prevent a Data Breach, and as required by any applicable law or regulation. “Data Breach” means the theft, loss, or unauthorized access of Customer Data. Without limiting the foregoing, New Relic will implement security measures at least as stringent as those set out in this Addendum. New Relic will designate a senior representative to provide incident briefings, as needed in case of a Data Breach, and to respond to reasonable requests by Customer pertaining to privacy and data security issues within a commercially reasonable time frame. 7.2. New Relic will: 7.2.1. Notify Customer without undue delay if New Relic becomes aware of a Data Breach; 7.2.2. Maintain a security incident response plan, including procedures and means to respond in a manner consistent with industry standards; 7.2.3. Reasonably cooperate with Customer to investigate and remediate a Data Breach and mitigate any further risk to the Customer Data, or risk to data subjects and/or Customer’s reputation or brand; 7.2.4. Provide reasonable assistance to Customer at New Relic’s sole cost and expense; and 7.2.5. Make commercially reasonable efforts to preserve evidence and reasonably cooperate with Customer and legal authorities (as applicable and legally permissible) during an investigation of a Data Breach. 8. Network and Systems Security 8.1. All extranet connectivity by New Relic personnel to systems processing Customer Data will be through secure remote connections. 8.2. Network segments connected to the Internet will be protected by secure access control mechanisms, such as a firewall configured to secure all devices behind it and properly addresses security concerns according to industry standard practices. 8.3. New Relic will have industry standard measures in place to actively monitor its systems and help detect a potential hostile attack, such as Network Intrusion Detection (NID) or Host Intrusion Detection (HID)/Prevention. 8.4. Applications, ports, services, and similar access points installed on a computer or network facility, which are not specifically required for business functionality, will be disabled or removed. 8.5. New Relic maintains configuration standards for authorized operating systems and software for systems that support processing of Customer Data. New Relic will establish and follow server configuration guidelines and processes for preventing unauthorized access to Customer Data. New Relic maintains secure images or templates for systems based on the organization’s approved configuration standards. 8.6. Development, test, and operational environments will be logically separated to reduce the risks of unauthorized access or changes to the operational system. 8.7. New Relic network architecture will be designed to limit site access and restrict the availability of information systems that are considered to be vulnerable to attack. 8.8. New Relic provides appropriate TLS certificates when users access and view Customer Data in the Service. New Relic’s software for sending Customer Data to New Relic will encrypt Customer Data in transit by default. 9. Authentication and Access Management If you subscribe to the requisite New Relic One Service, New Relic will provide industry standard authentication and access controls to protect Customer Data, including industry standard authentication methods utilized to help prevent unauthorized access to the Service. New Relic’s access control methods will clearly state the rules and rights for each user or group of users including applications and information sharing and will include a process for granting and removing access to all information systems processing Customer Data. A record of all privileges allocated will be maintained pursuant to the requirements herein. 9.1. In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic shall (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed. 10. Vulnerability Management New Relic will have and maintain the following vulnerability management processes for all devices used to connect to the New Relic network and Services. 10.1. New Relic will align to industry standard practices for build out, minimization of services and secure configuration, in accordance with, industry-recognized minimum security baselines for the New Relic platform and subcontractor systems connected to the New Relic platform in relation to the provision of the Services. 10.2. New Relic will employ industry-recognized standards and tools to conduct frequent infrastructure vulnerability scanning to test New Relic’s network and infrastructure and application penetration testing to test the New Relic Services. New Relic applies “Medium”, “High” and “Critical” security patches for all components in production and development environments as soon as commercially possible in accordance with its vulnerability management protocol, and consistent with industry standard practices and standards; 10.3. New Relic will have processes in place designed to ensure adherence to industry standard security development practices for development and testing for all code, APIs, and applications deployed and implemented in support of the Service; 10.4. New Relic will have and maintain solutions to identify and prevent malicious attackers or code from accessing or compromising Customer Data or systems that process Customer Data. These include, but are not limited to, software that identifies and removes malware and detects attempted intrusions. New Relic will have a security event and incident monitoring system and supporting processes to notify appropriate personnel in response to threats. 11. System Access and Logging 11.1. Access to New Relic’s systems will not be granted to employees of New Relic unless they have been uniquely identified and have sufficient credentials. 11.2. Access to New Relic’s systems will be logged and retained for no less than 6 months to assist in investigations and access control monitoring, including, but not limited to, end user access and activities, and information security events. 11.3. New Relic agrees to provide Customer the capability to access log records relating to Customer Accounts and the New Relic systems that process Customer Data in the event of a Data Breach or if required in connection with a law enforcement request. 12. Disaster Recovery and Data Backup 12.1. New Relic will have plans designed to respond to loss of services, which are tested and reviewed at least annually. This plan will include documented policies and procedures to restore service in the event of a service failure. 12.2. New Relic will establish and follow backup and restore procedures for Customer Data. 12.3. New Relic business continuity plan identifies critical systems. Annual disaster recovery tests are performed to check and restore customer data in the event of an incident. 12.4. New Relic will provide Customer with redacted copies of its plan(s) and evidence of tests/reviews upon request, but not more frequently than once annually, and subject to confidentiality requirements. 12.5. Additional information for Customer Data control and encryption are available on New Relic’s Security Guide. 13. Copies and Removal 13.1. In addition to any obligations of New Relic in the Agreement, upon expiration or termination of the Agreement for any reason: (a) New Relic will, and will cause its personnel, to cease all access and use of any Customer Data, and (b) New Relic will delete all copies of Customer Data within ninety (90) days. 13.2. New Relic will maintain a process of ensuring secure destruction and deletion of all Customer Data, when reasonably requested by Customer or as otherwise provided in the Agreement. The process will include industry standard processes so that: (i) Customer Data cannot be practicably read or reconstructed, and (ii) the systems that store Customer Data are securely erased and/or decommissioned disks are destroyed. 14. Third Party Vendor Management New Relic may use third party vendors to provide the Services. New Relic performs a security risk-based assessment of prospective vendors before working with them to validate they meet New Relic’s security and business continuity standards, including the type of access and classification of data being accessed (if any), controls necessary to protect data, and legal/regulatory requirements. New Relic enters into written agreements with its vendors that process Customer Data which include confidentiality, privacy, and security obligations that provide an appropriate level of protection for Customer Data that these vendors may process for New Relic to maintain the security posture in this Policy, including following industry security standards. 15. Disclosure by Law In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic will (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed. New Relic publishes its law enforcement requests report on New Relic’s Security Guide. 16. Updates As New Relic releases new products, services, functionality, and features, New Relic may update this Policy to account for such products, services, functionality, and features. For additional information, see our Security Guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.62988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security <em>policy</em>",
        "sections": "Security <em>policy</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " time to time, and such updates will not materially reduce the overall protections set forth in this Policy. The then-current terms of this Policy are available at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;<em>referenced</em>-<em>policies</em>&#x2F;security-policy&#x2F;. 2. Security Overview 2.1. New Relic"
      },
      "id": "603ea3dbe7b9d22b802a0802"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.15878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/data-collector-licenses": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Service</em> level availability commitment",
        "sections": "<em>Service</em> level availability commitment",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the <em>Services</em> you use. Capitalized terms not defined below shall"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic One Pro and Enterprise <em>Service</em> Level Availability Commitment",
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Service</em> level availability commitment",
        "sections": "<em>Service</em> level availability commitment",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the <em>Services</em> you use. Capitalized terms not defined below shall"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic One Pro and Enterprise <em>Service</em> Level Availability Commitment",
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-premium-support": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.8922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Service</em> level availability commitment",
        "sections": "<em>Service</em> level availability commitment",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the <em>Services</em> you use. Capitalized terms not defined below shall"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic One Pro and Enterprise <em>Service</em> Level Availability Commitment",
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-priority-support": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.8922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing docs. Q: Where can I find more <em>information</em> about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth <em>information</em>, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Service</em> level availability commitment",
        "sections": "<em>Service</em> level availability commitment",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the <em>Services</em> you use. Capitalized terms not defined below shall"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.22153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic One Pro and Enterprise <em>Service</em> Level Availability Commitment",
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions": [
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One pricing <em>plan</em>: Frequently asked questions",
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": "These are some frequently asked questions about the New Relic One pricing <em>plan</em> that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Important",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-10-24T17:40:11Z",
      "updated_at": "2021-10-24T17:40:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Important NOTE: If you are a New Relic HIPAA customer, please be advised that you must follow the requirements specified in the Global Technical Support Section of HIPAA enablement - what you need to know and do when requesting support and engaging with the New Relic Global Technical Support team for assistance. Support plan for New Relic One pricing and packaging model The New Relic One Support Plan below applies only to a customer’s paid subscription on the New Relic One pricing plan. Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance for: the New Relic One platform and its features and capabilities, New Relic's monitoring and observability solutions, and our alerting and Applied Intelligence features. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Important As of March 10, 2021, you're no longer able to create a New Relic support ticket by emailing support@newrelic.com. If you have ticketed support as part of your subscription, when logged into your New Relic account, go to one.newrelic.com to create a support ticket. Once you're there, follow these steps: Click the ? icon in the upper right hand corner. Click I need more help. Select Create a Support Ticket. By creating a support ticket directly within your account, it will speed up the support process and improve our team’s ability to troubleshoot your issue more effectively. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.53648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Support <em>plans</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": "The New Relic Support <em>Plan</em> offers a variety of resources based on your service subscription. Check out the Support <em>Plan</em> <em>information</em>, resources, channels, and scope of support below. Support <em>plans</em> These Support <em>Plans</em> apply only to your paid service subscription under an existing New Relic agreement"
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan": [
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 434.99326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One <em>usage</em> <em>plan</em> descriptions",
        "sections": "New Relic One <em>usage</em> <em>plan</em> descriptions",
        "tags": "<em>License</em> <em>information</em>",
        "body": "This document is about the New Relic One pricing <em>plan</em>. For an explanation of how that <em>plan</em> works, see New Relic One pricing. The document below goes into <em>license</em>-level details. The <em>Usage</em> <em>Plan</em> applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    },
    {
      "sections": [
        "New Relic One pricing plan: Frequently asked questions",
        "Frequently asked questions",
        "Q: Where can I find more information about New Relic One and related products?",
        "Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account?",
        "Q: What terms govern my use of the Products?",
        "Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month?",
        "Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account?",
        "Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account?",
        "Q: What is included in New Relic's Free Tier of Products?",
        "Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription?"
      ],
      "title": "New Relic One pricing plan: Frequently asked questions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "FAQ"
      ],
      "external_id": "cc702038ec7eb4983faa152108a4a233bd285264",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions/",
      "published_at": "2021-10-24T16:21:34Z",
      "updated_at": "2021-10-24T16:21:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These are some frequently asked questions about the New Relic One pricing plan that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One pricing docs. Q: Where can I find more information about New Relic One and related products? A: For a high level description of user entitlements for our features, see our pricing page. For more in-depth information, see New Relic One pricing. Q: Is there a limit on the number of concurrent sessions or IP addresses that may be used with a user account? A: Yes. See Manage users. Q: What terms govern my use of the Products? A: If a Customer has paid New Relic during a rolling 12-month period, then Customer’s usage of the Products is covered by the Paid Terms of Service. If a Customer has not paid New Relic during a 12-month period, then Customer’s usage of the Products is covered by the Unpaid Terms of Service. Q: How are the number of full users (also referred to as Monthly Provisioned Users) calculated for each month? A: Please see Calculation details. Q: Can I mix and match New Relic One Standard, Pro, and Enterprise users in a billing account? A: No. For the New Relic One pricing plan, you can only have one subscription per organization (group of accounts that share the same billing ID). Q: Can Event extended retention, additional Synthetics Checks, or additional New Relic Edge data be added to my account? A: For additional retention for Events or Logs beyond the Standard Data Retention, contact your New Relic account executive. Note: Minimum requirement for Extended Retention requires an Annual Pool of Funds subscription. Q: What is included in New Relic's Free Tier of Products? A: Please see this pricing doc for a description of what's included. Customer’s use of the Free Tier shall be governed by the terms and conditions described in the Unpaid Terms of Service. If Customer’s usage exceeds the Free Tier, Customer is fully responsible for fees incurred in excess of the Free Tier as described in the “Pay-as-you-go” program and as described in the Paid Terms of Service. Q: How does the ‘Free Tier’ impact my pay-as-you-go (PAYG) or Annual Pool of Funds (APOF) subscription? A: The Free Tier usage will be deducted automatically from the Monthly Product Usage for Pay-as-you-go or Annual pool of funds subscriptions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.89197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One pricing <em>plan</em>: Frequently asked questions",
        "sections": "Q: Where can I find more <em>information</em> about New Relic One and related products?",
        "tags": "<em>License</em> <em>information</em>",
        "body": "These are some frequently asked questions about the New Relic One pricing <em>plan</em> that arise for agreement-level language. This is meant to serve as a supplement to the main New Relic One pricing docs. Frequently asked questions These FAQs are meant to serve as a supplement to the main New Relic One"
      },
      "id": "6044e6e5196a67b568960f3e"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-10-24T17:41:15Z",
      "updated_at": "2021-10-24T17:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\", the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to \"New Relic One - Standard Users\", any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.00221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    }
  ],
  "/docs/licenses/product-or-service-licenses/codestream/codestream-licenses": [
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.86264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.70917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>"
      },
      "id": "603e891464441f2af14e883b"
    },
    {
      "sections": [
        "New Relic One usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions",
        "Separate Platforms"
      ],
      "title": "New Relic One usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is about the New Relic One pricing plan. For an explanation of how that plan works, see New Relic One pricing. The document below goes into license-level details. The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription (see a description of these two plans). New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as October 21, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users,\" you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the \"New Relic One - Pro Users\" or \"New Relic One - Enterprise Users\". If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make \"New Relic One - Standard Users\" available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users, New Relic provides an updated support plan commitment. By subscribing to New Relic One Users, you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the \"New Relic One - Standard Users Product,\" you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms. Separate Platforms Customer access to any separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or CodeStream, is subject to their respective terms of service. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your behalf. For clarity, such other platforms do not form part of the New Relic One offering and, unless otherwise expressly provided in the terms and then only to the extent provided, New Relic One warranties, indemnities, etc., do not apply to use of any other platforms for purposes of applicability of governing terms. Separate platforms are not intended to meet any legal obligations for Prohibited Data uses. Further, unless otherwise agreed to in writing by New Relic, (a) for users of separate platforms, New Relic is neither a Business Associate or a subcontractor (as defined under HIPAA), nor a payment card processor, and (b) separate platforms are neither HIPAA nor PCI DSS compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.60806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic One Pro and Enterprise <em>Service</em> Level Availability Commitment",
        "tags": "<em>Licenses</em>",
        "body": " separate platforms for purposes of applicability of governing terms, such as Community Cloud for Pixie or <em>CodeStream</em>, is subject to their respective terms of <em>service</em>. If you enable a separate platform with New Relic One, New Relic may access and exchange Customer Data with the separate platform on your"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    }
  ],
  "/docs/licenses/product-or-service-licenses/miscellaneous/help-center-documentation-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.5542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.86264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.70917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses": [
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 475.84396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses": [
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 475.84396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.3371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>"
      },
      "id": "603e891464441f2af14e883b"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.89476,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/apm-agent-sdk-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.89166,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.3371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/c-sdk-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37933,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/java-agent-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.3791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.3791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.3791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-resource-provider-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.89084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.3363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.89084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.3363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/nodejs-agent-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.89056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/php-agent-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.89056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/ruby-agent-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/browser-agent-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.55304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.86057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.70718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/new-relic-browser-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.55304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.86057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.70718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-edition": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.88977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-program-resources": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.88977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-infrastructure/new-relic-infrastructure-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.55258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.86002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.7067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.55258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.86002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.7067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.3775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.88922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.3775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.88922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/ios-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.88895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.88895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Introduction to New Relic One",
        "Tip",
        "Quickly understand context",
        "Query your data more easily",
        "Enhanced dashboards",
        "Build on New Relic One",
        "What’s next?"
      ],
      "title": "Introduction to New Relic One",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Get started"
      ],
      "external_id": "c9ba93c83a579625a4ba3364c6046f3c475cba3a",
      "image": "https://docs.newrelic.com/static/2bc08b6d64c16b39697bb43d8e66870e/c1b63/nrone20210722.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/get-started/introduction-new-relic-one/",
      "published_at": "2021-10-24T17:36:54Z",
      "updated_at": "2021-10-24T17:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One is the platform that gives you access to core platform capabilities like querying data and building charts, our more curated observability UI experiences features, and our alerting and Applied Intelligence tools. With New Relic One, you can see and act on all the data throughout your entire system. To access New Relic One: Go to one.newrelic.com. Or, if you report data to the EU data center go to one.eu.newrelic.com. Tip Learn more about New Relic One’s basic UI features. Quickly understand context We provide multiple ways to understand your system's dependencies, so you can easily see how everything fits together and troubleshoot problems. New Relic One gives you and your teams a connected view that cuts through complexity! If you want to... Use this Have an overall view of your system, and drill down to get performance details. Use the New Relic Explorer as the front door to New Relic One: observe, group, and filter the performance data from all the entities (that is, all applications, services, hosts, or containers) in your system. Gain extensive visibility into each entity in your solution, its alert status, and how the entities are connected. Use the New Relic Navigator to give you a high density overview of all your entities so you can detect any issues at a glance. And use the New Relic Lookout to spot entities recently experiencing behavior deviations. Provide context for your entities. Add tags to all your entities. Or create tags for teams and all the services they monitor. Use tags to illustrate relationships and contextual information for what you monitor. By thoughtfully tagging your entities, you can connect all the data your teams need to understand their increasingly complex and interdependent systems. See how each part of your system is connected. Service maps illustrate your upstream and downstream dependencies. Visualize the aggregated health and activity data from all you monitor. Group and monitor any entities together into functional team-focused, project-focused groupings, or any other attribute, with workloads. Fetch and analyze specific data. Get more context while you query with the query builder, which surfaces data definitions as you craft and edit queries. Create visuals that showcase your business needs at a glance. Tailor custom dashboards for your unique needs. Find a service or dashboard in a complex environment. Search by name across all accounts in the unified search, or filter the explorer by tags or text. View everything you’re monitoring in one place, like entities or dashboards across your organization. View a list of all the dependencies for a service. The dependencies view tab in an entity summary shows all the dependencies of the entity you’re viewing. Track activity as it moves across your distributed system. Distributed tracing helps you analyze your modern environment. Understand how everything is connected via API. The NerdGraph GraphiQL explorer manages all your entities, tags, and relationships. Query your data more easily On the Browse data menu on the top navigation menu you can easily access your basic telemetry data (metrics, events, logs, and traces). Wherever you go in the UI, Query your data is available. No matter your level of proficiency with our query language, you can create custom queries and charts: Browse your data in a query-less experience with our data explorer. Use your NRQL (our query language) expertise to build custom charts in the query builder. Run PromQL-style queries in the query builder. one.newrelic.com > Query your data: Build NRQL and PROMQL-like queries. Enhanced dashboards one.newrelic.com > Dashboards: Quickly create information dense custom views into the data that matters most to you with dashboards in New Relic One. New Relic One dashboards let you build better visualizations more easily, with more options to customize. Dashboard features include: Perform NRQL queries and create charts and dashboards everywhere in the platform using the query builder. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our agents, integrations, and APIs. Share dashboards or charts as a .pdf, or embed a chart in an external site. Tip If you previously used New Relic Insights to create dashboards, these are available as New Relic One dashboards. Build on New Relic One If custom charts and dashboards don't solve your current challenge, we give you a framework for building React JavaScript applications that: Live on New Relic One, alongside your other New Relic-monitored data. Feature highly tailored visualizations. Display data from any source you want, whether from a New Relic-monitored entity or data from any service or API. And you can use open source apps built by the community, and contribute your own open source apps. To learn more, see New Relic One applications. What’s next? To get started understanding how to get around in New Relic One: See what data you have available with the data explorer. Browse your monitored entities with the New Relic Explorer. Use our NerdGraph API to add tags to your data. Learn about dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.38577,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>One</em>",
        "sections": "Introduction to <em>New</em> <em>Relic</em> <em>One</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>One</em>",
        "body": ". Feature highly tailored visualizations. Display data from any source you want, whether from a <em>New</em> <em>Relic</em>-monitored entity or data from any <em>service</em> or API. And you can use open source apps built by the community, and contribute your own open source apps. To learn more, see <em>New</em> <em>Relic</em> <em>One</em> applications"
      },
      "id": "603ec19164441f9e704e8896"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-plugins/plugins-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-synthetics/new-relic-synthetics-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.37704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.8887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.33426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/logs/forward-logs/aws-firelens-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.03754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 424.9926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 383.68597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/aws-lambda-sending-cloudwatch-logs": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.03754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 424.9926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 383.68597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ]
}